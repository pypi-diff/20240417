# Comparing `tmp/nvidia_modulus-0.5.0-py3-none-any.whl.zip` & `tmp/nvidia_modulus-0.6.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,147 +1,147 @@
-Zip file size: 309290 bytes, number of entries: 145
--rw-r--r--  2.0 unx      805 b- defN 24-Jan-23 17:57 modulus/__init__.py
--rw-r--r--  2.0 unx     1307 b- defN 24-Jan-23 17:57 modulus/constants.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/datapipes/__init__.py
--rw-r--r--  2.0 unx     2030 b- defN 24-Jan-23 17:57 modulus/datapipes/datapipe.py
--rw-r--r--  2.0 unx      961 b- defN 24-Jan-23 17:57 modulus/datapipes/meta.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/__init__.py
--rw-r--r--  2.0 unx    11693 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/darcy.py
--rw-r--r--  2.0 unx    16670 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kelvin_helmholtz.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/__init__.py
--rw-r--r--  2.0 unx     4263 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/finite_difference.py
--rw-r--r--  2.0 unx    20510 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/finite_volume.py
--rw-r--r--  2.0 unx     3658 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/indexing.py
--rw-r--r--  2.0 unx     2054 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/initialization.py
--rw-r--r--  2.0 unx     4246 b- defN 24-Jan-23 17:57 modulus/datapipes/benchmarks/kernels/utils.py
--rw-r--r--  2.0 unx      663 b- defN 24-Jan-23 17:57 modulus/datapipes/climate/__init__.py
--rw-r--r--  2.0 unx    14950 b- defN 24-Jan-23 17:57 modulus/datapipes/climate/era5_hdf5.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/datapipes/climate/era5_netcdf.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/datapipes/gnn/__init__.py
--rw-r--r--  2.0 unx    22868 b- defN 24-Jan-23 17:57 modulus/datapipes/gnn/ahmed_body_dataset.py
--rw-r--r--  2.0 unx    11081 b- defN 24-Jan-23 17:57 modulus/datapipes/gnn/stokes_dataset.py
--rw-r--r--  2.0 unx     2566 b- defN 24-Jan-23 17:57 modulus/datapipes/gnn/utils.py
--rw-r--r--  2.0 unx    15454 b- defN 24-Jan-23 17:57 modulus/datapipes/gnn/vortex_shedding_dataset.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/deploy/__init__.py
--rw-r--r--  2.0 unx      684 b- defN 24-Jan-23 17:57 modulus/deploy/onnx/__init__.py
--rw-r--r--  2.0 unx     4675 b- defN 24-Jan-23 17:57 modulus/deploy/onnx/utils.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/deploy/triton/__init__.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/deploy/trt/__init__.py
--rw-r--r--  2.0 unx      878 b- defN 24-Jan-23 17:57 modulus/distributed/__init__.py
--rw-r--r--  2.0 unx    15242 b- defN 24-Jan-23 17:57 modulus/distributed/autograd.py
--rw-r--r--  2.0 unx     8069 b- defN 24-Jan-23 17:57 modulus/distributed/config.py
--rw-r--r--  2.0 unx     7077 b- defN 24-Jan-23 17:57 modulus/distributed/fft.py
--rw-r--r--  2.0 unx    18814 b- defN 24-Jan-23 17:57 modulus/distributed/manager.py
--rw-r--r--  2.0 unx     4489 b- defN 24-Jan-23 17:57 modulus/distributed/mappings.py
--rw-r--r--  2.0 unx    24623 b- defN 24-Jan-23 17:57 modulus/distributed/utils.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/experimental/__init__.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/experimental/datapipes/__init__.py
--rw-r--r--  2.0 unx      669 b- defN 24-Jan-23 17:57 modulus/experimental/datapipes/climate/__init__.py
--rw-r--r--  2.0 unx    23725 b- defN 24-Jan-23 17:57 modulus/experimental/datapipes/climate/climate_hdf5.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/experimental/datapipes/climate/utils/__init__.py
--rw-r--r--  2.0 unx     6993 b- defN 24-Jan-23 17:57 modulus/experimental/datapipes/climate/utils/zenith_angle.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/launch/__init__.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/launch/config/__init__.py
--rw-r--r--  2.0 unx      788 b- defN 24-Jan-23 17:57 modulus/launch/logging/__init__.py
--rw-r--r--  2.0 unx     2979 b- defN 24-Jan-23 17:57 modulus/launch/logging/console.py
--rw-r--r--  2.0 unx    14776 b- defN 24-Jan-23 17:57 modulus/launch/logging/launch.py
--rw-r--r--  2.0 unx     6791 b- defN 24-Jan-23 17:57 modulus/launch/logging/mlflow.py
--rw-r--r--  2.0 unx     1938 b- defN 24-Jan-23 17:57 modulus/launch/logging/utils.py
--rw-r--r--  2.0 unx     4066 b- defN 24-Jan-23 17:57 modulus/launch/logging/wandb.py
--rw-r--r--  2.0 unx      680 b- defN 24-Jan-23 17:57 modulus/launch/utils/__init__.py
--rw-r--r--  2.0 unx    13398 b- defN 24-Jan-23 17:57 modulus/launch/utils/checkpoint.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/metrics/__init__.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/metrics/climate/__init__.py
--rw-r--r--  2.0 unx     2736 b- defN 24-Jan-23 17:57 modulus/metrics/climate/acc.py
--rw-r--r--  2.0 unx     4507 b- defN 24-Jan-23 17:57 modulus/metrics/climate/efi.py
--rw-r--r--  2.0 unx     5505 b- defN 24-Jan-23 17:57 modulus/metrics/climate/reduction.py
--rw-r--r--  2.0 unx      742 b- defN 24-Jan-23 17:57 modulus/metrics/diffusion/__init__.py
--rw-r--r--  2.0 unx     1792 b- defN 24-Jan-23 17:57 modulus/metrics/diffusion/fid.py
--rw-r--r--  2.0 unx    17554 b- defN 24-Jan-23 17:57 modulus/metrics/diffusion/loss.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/metrics/general/__init__.py
--rw-r--r--  2.0 unx     4892 b- defN 24-Jan-23 17:57 modulus/metrics/general/calibration.py
--rw-r--r--  2.0 unx     9869 b- defN 24-Jan-23 17:57 modulus/metrics/general/crps.py
--rw-r--r--  2.0 unx    13443 b- defN 24-Jan-23 17:57 modulus/metrics/general/ensemble_metrics.py
--rw-r--r--  2.0 unx     4719 b- defN 24-Jan-23 17:57 modulus/metrics/general/entropy.py
--rw-r--r--  2.0 unx    27431 b- defN 24-Jan-23 17:57 modulus/metrics/general/histogram.py
--rw-r--r--  2.0 unx     1857 b- defN 24-Jan-23 17:57 modulus/metrics/general/mse.py
--rw-r--r--  2.0 unx     4307 b- defN 24-Jan-23 17:57 modulus/metrics/general/reduction.py
--rw-r--r--  2.0 unx     5625 b- defN 24-Jan-23 17:57 modulus/metrics/general/wasserstein.py
--rw-r--r--  2.0 unx      650 b- defN 24-Jan-23 17:57 modulus/models/__init__.py
--rw-r--r--  2.0 unx    11885 b- defN 24-Jan-23 17:57 modulus/models/fcn_mip_plugin.py
--rw-r--r--  2.0 unx     1613 b- defN 24-Jan-23 17:57 modulus/models/meta.py
--rw-r--r--  2.0 unx    14964 b- defN 24-Jan-23 17:57 modulus/models/module.py
--rw-r--r--  2.0 unx      687 b- defN 24-Jan-23 17:57 modulus/models/afno/__init__.py
--rw-r--r--  2.0 unx    18143 b- defN 24-Jan-23 17:57 modulus/models/afno/afno.py
--rw-r--r--  2.0 unx      657 b- defN 24-Jan-23 17:57 modulus/models/afno/distributed/__init__.py
--rw-r--r--  2.0 unx    11667 b- defN 24-Jan-23 17:57 modulus/models/afno/distributed/afno.py
--rw-r--r--  2.0 unx    15034 b- defN 24-Jan-23 17:57 modulus/models/afno/distributed/layers.py
--rw-r--r--  2.0 unx     1018 b- defN 24-Jan-23 17:57 modulus/models/diffusion/__init__.py
--rw-r--r--  2.0 unx     9193 b- defN 24-Jan-23 17:57 modulus/models/diffusion/dhariwal_unet.py
--rw-r--r--  2.0 unx    19431 b- defN 24-Jan-23 17:57 modulus/models/diffusion/layers.py
--rw-r--r--  2.0 unx    25221 b- defN 24-Jan-23 17:57 modulus/models/diffusion/preconditioning.py
--rw-r--r--  2.0 unx    14252 b- defN 24-Jan-23 17:57 modulus/models/diffusion/song_unet.py
--rw-r--r--  2.0 unx     5913 b- defN 24-Jan-23 17:57 modulus/models/diffusion/unet.py
--rw-r--r--  2.0 unx     2587 b- defN 24-Jan-23 17:57 modulus/models/diffusion/utils.py
--rw-r--r--  2.0 unx      646 b- defN 24-Jan-23 17:57 modulus/models/dlwp/__init__.py
--rw-r--r--  2.0 unx    13354 b- defN 24-Jan-23 17:57 modulus/models/dlwp/dlwp.py
--rw-r--r--  2.0 unx      710 b- defN 24-Jan-23 17:57 modulus/models/fno/__init__.py
--rw-r--r--  2.0 unx    31886 b- defN 24-Jan-23 17:57 modulus/models/fno/fno.py
--rw-r--r--  2.0 unx      837 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/__init__.py
--rw-r--r--  2.0 unx    34458 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/distributed_graph.py
--rw-r--r--  2.0 unx     6077 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/embedder.py
--rw-r--r--  2.0 unx    17029 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/graph.py
--rw-r--r--  2.0 unx     3098 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/mesh_edge_block.py
--rw-r--r--  2.0 unx     4496 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/mesh_graph_decoder.py
--rw-r--r--  2.0 unx     5265 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/mesh_graph_encoder.py
--rw-r--r--  2.0 unx    15234 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/mesh_graph_mlp.py
--rw-r--r--  2.0 unx     3155 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/mesh_node_block.py
--rw-r--r--  2.0 unx    13517 b- defN 24-Jan-23 17:57 modulus/models/gnn_layers/utils.py
--rw-r--r--  2.0 unx      664 b- defN 24-Jan-23 17:57 modulus/models/graphcast/__init__.py
--rw-r--r--  2.0 unx    27599 b- defN 24-Jan-23 17:57 modulus/models/graphcast/graph_cast_net.py
--rw-r--r--  2.0 unx     6019 b- defN 24-Jan-23 17:57 modulus/models/graphcast/graph_cast_processor.py
--rw-r--r--  2.0 unx     1196 b- defN 24-Jan-23 17:57 modulus/models/layers/__init__.py
--rw-r--r--  2.0 unx     4186 b- defN 24-Jan-23 17:57 modulus/models/layers/activations.py
--rw-r--r--  2.0 unx     3313 b- defN 24-Jan-23 17:57 modulus/models/layers/dgm_layers.py
--rw-r--r--  2.0 unx    18044 b- defN 24-Jan-23 17:57 modulus/models/layers/fft.py
--rw-r--r--  2.0 unx     5985 b- defN 24-Jan-23 17:57 modulus/models/layers/fourier_layers.py
--rw-r--r--  2.0 unx    10789 b- defN 24-Jan-23 17:57 modulus/models/layers/fully_connected_layers.py
--rw-r--r--  2.0 unx     8921 b- defN 24-Jan-23 17:57 modulus/models/layers/fused_silu.py
--rw-r--r--  2.0 unx    16507 b- defN 24-Jan-23 17:57 modulus/models/layers/interpolation.py
--rw-r--r--  2.0 unx     2464 b- defN 24-Jan-23 17:57 modulus/models/layers/siren_layers.py
--rw-r--r--  2.0 unx    24177 b- defN 24-Jan-23 17:57 modulus/models/layers/spectral_layers.py
--rw-r--r--  2.0 unx     3561 b- defN 24-Jan-23 17:57 modulus/models/layers/weight_fact.py
--rw-r--r--  2.0 unx     2485 b- defN 24-Jan-23 17:57 modulus/models/layers/weight_norm.py
--rw-r--r--  2.0 unx      662 b- defN 24-Jan-23 17:57 modulus/models/meshgraphnet/__init__.py
--rw-r--r--  2.0 unx    11990 b- defN 24-Jan-23 17:57 modulus/models/meshgraphnet/meshgraphnet.py
--rw-r--r--  2.0 unx      667 b- defN 24-Jan-23 17:57 modulus/models/mlp/__init__.py
--rw-r--r--  2.0 unx     4509 b- defN 24-Jan-23 17:57 modulus/models/mlp/fully_connected.py
--rw-r--r--  2.0 unx      652 b- defN 24-Jan-23 17:57 modulus/models/pix2pix/__init__.py
--rw-r--r--  2.0 unx    12183 b- defN 24-Jan-23 17:57 modulus/models/pix2pix/pix2pix.py
--rw-r--r--  2.0 unx      697 b- defN 24-Jan-23 17:57 modulus/models/rnn/__init__.py
--rw-r--r--  2.0 unx    16148 b- defN 24-Jan-23 17:57 modulus/models/rnn/layers.py
--rw-r--r--  2.0 unx     8260 b- defN 24-Jan-23 17:57 modulus/models/rnn/rnn_one2many.py
--rw-r--r--  2.0 unx     8575 b- defN 24-Jan-23 17:57 modulus/models/rnn/rnn_seq2seq.py
--rw-r--r--  2.0 unx      659 b- defN 24-Jan-23 17:57 modulus/models/srrn/__init__.py
--rw-r--r--  2.0 unx    12099 b- defN 24-Jan-23 17:57 modulus/models/srrn/super_res_net.py
--rw-r--r--  2.0 unx      665 b- defN 24-Jan-23 17:57 modulus/registry/__init__.py
--rw-r--r--  2.0 unx     4531 b- defN 24-Jan-23 17:57 modulus/registry/model_registry.py
--rw-r--r--  2.0 unx      708 b- defN 24-Jan-23 17:57 modulus/utils/__init__.py
--rw-r--r--  2.0 unx    17791 b- defN 24-Jan-23 17:57 modulus/utils/capture.py
--rw-r--r--  2.0 unx     7832 b- defN 24-Jan-23 17:57 modulus/utils/filesystem.py
--rw-r--r--  2.0 unx    17882 b- defN 24-Jan-23 17:57 modulus/utils/zenith_angle.py
--rw-r--r--  2.0 unx     1427 b- defN 24-Jan-23 17:57 modulus/utils/generative/__init__.py
--rw-r--r--  2.0 unx     7322 b- defN 24-Jan-23 17:57 modulus/utils/generative/sampler.py
--rw-r--r--  2.0 unx    26293 b- defN 24-Jan-23 17:57 modulus/utils/generative/utils.py
--rw-r--r--  2.0 unx      622 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/__init__.py
--rw-r--r--  2.0 unx     4016 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/data_utils.py
--rw-r--r--  2.0 unx     9596 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/graph.py
--rw-r--r--  2.0 unx    11206 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/graph_utils.py
--rw-r--r--  2.0 unx     2087 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/icospheres.py
--rw-r--r--  2.0 unx     3427 b- defN 24-Jan-23 17:57 modulus/utils/graphcast/loss.py
--rw-r--r--  2.0 unx    11314 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx     8033 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/WHEEL
--rw-r--r--  2.0 unx      396 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        8 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    13383 b- defN 24-Jan-23 19:32 nvidia_modulus-0.5.0.dist-info/RECORD
-145 files, 1076383 bytes uncompressed, 287900 bytes compressed:  73.3%
+Zip file size: 320947 bytes, number of entries: 145
+-rw-rw-r--  2.0 unx      899 b- defN 24-Apr-15 20:24 modulus/__init__.py
+-rw-rw-r--  2.0 unx     1401 b- defN 24-Apr-15 20:24 modulus/constants.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/__init__.py
+-rw-rw-r--  2.0 unx     2124 b- defN 24-Apr-15 20:24 modulus/datapipes/datapipe.py
+-rw-rw-r--  2.0 unx     1055 b- defN 24-Apr-15 20:24 modulus/datapipes/meta.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/__init__.py
+-rw-rw-r--  2.0 unx    11787 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/darcy.py
+-rw-rw-r--  2.0 unx    16764 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kelvin_helmholtz.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/__init__.py
+-rw-rw-r--  2.0 unx     4357 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/finite_difference.py
+-rw-rw-r--  2.0 unx    20604 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/finite_volume.py
+-rw-rw-r--  2.0 unx     3752 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/indexing.py
+-rw-rw-r--  2.0 unx     2148 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/initialization.py
+-rw-rw-r--  2.0 unx     4340 b- defN 24-Apr-15 20:24 modulus/datapipes/benchmarks/kernels/utils.py
+-rw-rw-r--  2.0 unx      817 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/__init__.py
+-rw-rw-r--  2.0 unx    32261 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/climate.py
+-rw-rw-r--  2.0 unx    15198 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/era5_hdf5.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/era5_netcdf.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/utils/__init__.py
+-rw-rw-r--  2.0 unx     4656 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/utils/invariant.py
+-rw-rw-r--  2.0 unx     6926 b- defN 24-Apr-15 20:24 modulus/datapipes/climate/utils/zenith_angle.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/datapipes/gnn/__init__.py
+-rw-rw-r--  2.0 unx    22445 b- defN 24-Apr-15 20:24 modulus/datapipes/gnn/ahmed_body_dataset.py
+-rw-rw-r--  2.0 unx    11175 b- defN 24-Apr-15 20:24 modulus/datapipes/gnn/stokes_dataset.py
+-rw-rw-r--  2.0 unx     2660 b- defN 24-Apr-15 20:24 modulus/datapipes/gnn/utils.py
+-rw-rw-r--  2.0 unx    15548 b- defN 24-Apr-15 20:24 modulus/datapipes/gnn/vortex_shedding_dataset.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/deploy/__init__.py
+-rw-rw-r--  2.0 unx      778 b- defN 24-Apr-15 20:24 modulus/deploy/onnx/__init__.py
+-rw-rw-r--  2.0 unx     4769 b- defN 24-Apr-15 20:24 modulus/deploy/onnx/utils.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/deploy/triton/__init__.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/deploy/trt/__init__.py
+-rw-rw-r--  2.0 unx      972 b- defN 24-Apr-15 20:24 modulus/distributed/__init__.py
+-rw-rw-r--  2.0 unx    15336 b- defN 24-Apr-15 20:24 modulus/distributed/autograd.py
+-rw-rw-r--  2.0 unx     8163 b- defN 24-Apr-15 20:24 modulus/distributed/config.py
+-rw-rw-r--  2.0 unx     7171 b- defN 24-Apr-15 20:24 modulus/distributed/fft.py
+-rw-rw-r--  2.0 unx    19737 b- defN 24-Apr-15 20:24 modulus/distributed/manager.py
+-rw-rw-r--  2.0 unx     4583 b- defN 24-Apr-15 20:24 modulus/distributed/mappings.py
+-rw-rw-r--  2.0 unx    24717 b- defN 24-Apr-15 20:24 modulus/distributed/utils.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/experimental/__init__.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/launch/__init__.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/launch/config/__init__.py
+-rw-rw-r--  2.0 unx      882 b- defN 24-Apr-15 20:24 modulus/launch/logging/__init__.py
+-rw-rw-r--  2.0 unx     3073 b- defN 24-Apr-15 20:24 modulus/launch/logging/console.py
+-rw-rw-r--  2.0 unx    14870 b- defN 24-Apr-15 20:24 modulus/launch/logging/launch.py
+-rw-rw-r--  2.0 unx     6886 b- defN 24-Apr-15 20:24 modulus/launch/logging/mlflow.py
+-rw-rw-r--  2.0 unx     2032 b- defN 24-Apr-15 20:24 modulus/launch/logging/utils.py
+-rw-rw-r--  2.0 unx     4160 b- defN 24-Apr-15 20:24 modulus/launch/logging/wandb.py
+-rw-rw-r--  2.0 unx      774 b- defN 24-Apr-15 20:24 modulus/launch/utils/__init__.py
+-rw-rw-r--  2.0 unx    13492 b- defN 24-Apr-15 20:24 modulus/launch/utils/checkpoint.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/metrics/__init__.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/metrics/climate/__init__.py
+-rw-rw-r--  2.0 unx     2830 b- defN 24-Apr-15 20:24 modulus/metrics/climate/acc.py
+-rw-rw-r--  2.0 unx     4601 b- defN 24-Apr-15 20:24 modulus/metrics/climate/efi.py
+-rw-rw-r--  2.0 unx     5599 b- defN 24-Apr-15 20:24 modulus/metrics/climate/reduction.py
+-rw-rw-r--  2.0 unx      836 b- defN 24-Apr-15 20:24 modulus/metrics/diffusion/__init__.py
+-rw-rw-r--  2.0 unx     1886 b- defN 24-Apr-15 20:24 modulus/metrics/diffusion/fid.py
+-rw-rw-r--  2.0 unx    20281 b- defN 24-Apr-15 20:24 modulus/metrics/diffusion/loss.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/metrics/general/__init__.py
+-rw-rw-r--  2.0 unx     4986 b- defN 24-Apr-15 20:24 modulus/metrics/general/calibration.py
+-rw-rw-r--  2.0 unx     9963 b- defN 24-Apr-15 20:24 modulus/metrics/general/crps.py
+-rw-rw-r--  2.0 unx    13531 b- defN 24-Apr-15 20:24 modulus/metrics/general/ensemble_metrics.py
+-rw-rw-r--  2.0 unx     4813 b- defN 24-Apr-15 20:24 modulus/metrics/general/entropy.py
+-rw-rw-r--  2.0 unx    27525 b- defN 24-Apr-15 20:24 modulus/metrics/general/histogram.py
+-rw-rw-r--  2.0 unx     1951 b- defN 24-Apr-15 20:24 modulus/metrics/general/mse.py
+-rw-rw-r--  2.0 unx     4401 b- defN 24-Apr-15 20:24 modulus/metrics/general/reduction.py
+-rw-rw-r--  2.0 unx     5719 b- defN 24-Apr-15 20:24 modulus/metrics/general/wasserstein.py
+-rw-rw-r--  2.0 unx      744 b- defN 24-Apr-15 20:24 modulus/models/__init__.py
+-rw-rw-r--  2.0 unx    11979 b- defN 24-Apr-15 20:24 modulus/models/fcn_mip_plugin.py
+-rw-rw-r--  2.0 unx     1707 b- defN 24-Apr-15 20:24 modulus/models/meta.py
+-rw-rw-r--  2.0 unx    15766 b- defN 24-Apr-15 20:24 modulus/models/module.py
+-rw-rw-r--  2.0 unx      781 b- defN 24-Apr-15 20:24 modulus/models/afno/__init__.py
+-rw-rw-r--  2.0 unx    18237 b- defN 24-Apr-15 20:24 modulus/models/afno/afno.py
+-rw-rw-r--  2.0 unx      751 b- defN 24-Apr-15 20:24 modulus/models/afno/distributed/__init__.py
+-rw-rw-r--  2.0 unx    11761 b- defN 24-Apr-15 20:24 modulus/models/afno/distributed/afno.py
+-rw-rw-r--  2.0 unx    15128 b- defN 24-Apr-15 20:24 modulus/models/afno/distributed/layers.py
+-rw-rw-r--  2.0 unx     1112 b- defN 24-Apr-15 20:24 modulus/models/diffusion/__init__.py
+-rw-rw-r--  2.0 unx     9287 b- defN 24-Apr-15 20:24 modulus/models/diffusion/dhariwal_unet.py
+-rw-rw-r--  2.0 unx    20429 b- defN 24-Apr-15 20:24 modulus/models/diffusion/layers.py
+-rw-rw-r--  2.0 unx    31133 b- defN 24-Apr-15 20:24 modulus/models/diffusion/preconditioning.py
+-rw-rw-r--  2.0 unx    14346 b- defN 24-Apr-15 20:24 modulus/models/diffusion/song_unet.py
+-rw-rw-r--  2.0 unx     6007 b- defN 24-Apr-15 20:24 modulus/models/diffusion/unet.py
+-rw-rw-r--  2.0 unx     2681 b- defN 24-Apr-15 20:24 modulus/models/diffusion/utils.py
+-rw-rw-r--  2.0 unx      740 b- defN 24-Apr-15 20:24 modulus/models/dlwp/__init__.py
+-rw-rw-r--  2.0 unx    13448 b- defN 24-Apr-15 20:24 modulus/models/dlwp/dlwp.py
+-rw-rw-r--  2.0 unx      804 b- defN 24-Apr-15 20:24 modulus/models/fno/__init__.py
+-rw-rw-r--  2.0 unx    31980 b- defN 24-Apr-15 20:24 modulus/models/fno/fno.py
+-rw-rw-r--  2.0 unx      931 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/__init__.py
+-rw-rw-r--  2.0 unx    34552 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/distributed_graph.py
+-rw-rw-r--  2.0 unx     6171 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/embedder.py
+-rw-rw-r--  2.0 unx    17123 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/graph.py
+-rw-rw-r--  2.0 unx     3192 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/mesh_edge_block.py
+-rw-rw-r--  2.0 unx     4590 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/mesh_graph_decoder.py
+-rw-rw-r--  2.0 unx     5359 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/mesh_graph_encoder.py
+-rw-rw-r--  2.0 unx    15328 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/mesh_graph_mlp.py
+-rw-rw-r--  2.0 unx     3249 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/mesh_node_block.py
+-rw-rw-r--  2.0 unx    13611 b- defN 24-Apr-15 20:24 modulus/models/gnn_layers/utils.py
+-rw-rw-r--  2.0 unx      758 b- defN 24-Apr-15 20:24 modulus/models/graphcast/__init__.py
+-rw-rw-r--  2.0 unx    27693 b- defN 24-Apr-15 20:24 modulus/models/graphcast/graph_cast_net.py
+-rw-rw-r--  2.0 unx     6113 b- defN 24-Apr-15 20:24 modulus/models/graphcast/graph_cast_processor.py
+-rw-rw-r--  2.0 unx     1290 b- defN 24-Apr-15 20:24 modulus/models/layers/__init__.py
+-rw-rw-r--  2.0 unx     4280 b- defN 24-Apr-15 20:24 modulus/models/layers/activations.py
+-rw-rw-r--  2.0 unx     3407 b- defN 24-Apr-15 20:24 modulus/models/layers/dgm_layers.py
+-rw-rw-r--  2.0 unx    18138 b- defN 24-Apr-15 20:24 modulus/models/layers/fft.py
+-rw-rw-r--  2.0 unx     6079 b- defN 24-Apr-15 20:24 modulus/models/layers/fourier_layers.py
+-rw-rw-r--  2.0 unx    10883 b- defN 24-Apr-15 20:24 modulus/models/layers/fully_connected_layers.py
+-rw-rw-r--  2.0 unx     9015 b- defN 24-Apr-15 20:24 modulus/models/layers/fused_silu.py
+-rw-rw-r--  2.0 unx    16601 b- defN 24-Apr-15 20:24 modulus/models/layers/interpolation.py
+-rw-rw-r--  2.0 unx     2558 b- defN 24-Apr-15 20:24 modulus/models/layers/siren_layers.py
+-rw-rw-r--  2.0 unx    24271 b- defN 24-Apr-15 20:24 modulus/models/layers/spectral_layers.py
+-rw-rw-r--  2.0 unx     3655 b- defN 24-Apr-15 20:24 modulus/models/layers/weight_fact.py
+-rw-rw-r--  2.0 unx     2579 b- defN 24-Apr-15 20:24 modulus/models/layers/weight_norm.py
+-rw-rw-r--  2.0 unx      756 b- defN 24-Apr-15 20:24 modulus/models/meshgraphnet/__init__.py
+-rw-rw-r--  2.0 unx    12173 b- defN 24-Apr-15 20:24 modulus/models/meshgraphnet/meshgraphnet.py
+-rw-rw-r--  2.0 unx      761 b- defN 24-Apr-15 20:24 modulus/models/mlp/__init__.py
+-rw-rw-r--  2.0 unx     4603 b- defN 24-Apr-15 20:24 modulus/models/mlp/fully_connected.py
+-rw-rw-r--  2.0 unx      746 b- defN 24-Apr-15 20:24 modulus/models/pix2pix/__init__.py
+-rw-rw-r--  2.0 unx    12183 b- defN 24-Apr-15 20:24 modulus/models/pix2pix/pix2pix.py
+-rw-rw-r--  2.0 unx      791 b- defN 24-Apr-15 20:24 modulus/models/rnn/__init__.py
+-rw-rw-r--  2.0 unx    16242 b- defN 24-Apr-15 20:24 modulus/models/rnn/layers.py
+-rw-rw-r--  2.0 unx     8354 b- defN 24-Apr-15 20:24 modulus/models/rnn/rnn_one2many.py
+-rw-rw-r--  2.0 unx     8669 b- defN 24-Apr-15 20:24 modulus/models/rnn/rnn_seq2seq.py
+-rw-rw-r--  2.0 unx      753 b- defN 24-Apr-15 20:24 modulus/models/srrn/__init__.py
+-rw-rw-r--  2.0 unx    12099 b- defN 24-Apr-15 20:24 modulus/models/srrn/super_res_net.py
+-rw-rw-r--  2.0 unx      759 b- defN 24-Apr-15 20:24 modulus/registry/__init__.py
+-rw-rw-r--  2.0 unx     4625 b- defN 24-Apr-15 20:24 modulus/registry/model_registry.py
+-rw-rw-r--  2.0 unx      802 b- defN 24-Apr-15 20:24 modulus/utils/__init__.py
+-rw-rw-r--  2.0 unx    17885 b- defN 24-Apr-15 20:24 modulus/utils/capture.py
+-rw-rw-r--  2.0 unx     8941 b- defN 24-Apr-15 20:24 modulus/utils/filesystem.py
+-rw-rw-r--  2.0 unx     5891 b- defN 24-Apr-15 20:24 modulus/utils/neighbor_list.py
+-rw-rw-r--  2.0 unx    17882 b- defN 24-Apr-15 20:24 modulus/utils/zenith_angle.py
+-rw-rw-r--  2.0 unx     1502 b- defN 24-Apr-15 20:24 modulus/utils/generative/__init__.py
+-rw-rw-r--  2.0 unx     7416 b- defN 24-Apr-15 20:24 modulus/utils/generative/sampler.py
+-rw-rw-r--  2.0 unx    26153 b- defN 24-Apr-15 20:24 modulus/utils/generative/utils.py
+-rw-rw-r--  2.0 unx      716 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/__init__.py
+-rw-rw-r--  2.0 unx     4110 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/data_utils.py
+-rw-rw-r--  2.0 unx     9690 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/graph.py
+-rw-rw-r--  2.0 unx    11300 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/graph_utils.py
+-rw-rw-r--  2.0 unx     2181 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/icospheres.py
+-rw-rw-r--  2.0 unx     3521 b- defN 24-Apr-15 20:24 modulus/utils/graphcast/loss.py
+-rw-rw-r--  2.0 unx    11314 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/LICENSE.txt
+-rw-rw-r--  2.0 unx     8529 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx      396 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx        8 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    13324 b- defN 24-Apr-15 20:25 nvidia_modulus-0.6.0.dist-info/RECORD
+145 files, 1118388 bytes uncompressed, 299681 bytes compressed:  73.2%
```

## zipnote {}

```diff
@@ -39,20 +39,32 @@
 
 Filename: modulus/datapipes/benchmarks/kernels/utils.py
 Comment: 
 
 Filename: modulus/datapipes/climate/__init__.py
 Comment: 
 
+Filename: modulus/datapipes/climate/climate.py
+Comment: 
+
 Filename: modulus/datapipes/climate/era5_hdf5.py
 Comment: 
 
 Filename: modulus/datapipes/climate/era5_netcdf.py
 Comment: 
 
+Filename: modulus/datapipes/climate/utils/__init__.py
+Comment: 
+
+Filename: modulus/datapipes/climate/utils/invariant.py
+Comment: 
+
+Filename: modulus/datapipes/climate/utils/zenith_angle.py
+Comment: 
+
 Filename: modulus/datapipes/gnn/__init__.py
 Comment: 
 
 Filename: modulus/datapipes/gnn/ahmed_body_dataset.py
 Comment: 
 
 Filename: modulus/datapipes/gnn/stokes_dataset.py
@@ -99,29 +111,14 @@
 
 Filename: modulus/distributed/utils.py
 Comment: 
 
 Filename: modulus/experimental/__init__.py
 Comment: 
 
-Filename: modulus/experimental/datapipes/__init__.py
-Comment: 
-
-Filename: modulus/experimental/datapipes/climate/__init__.py
-Comment: 
-
-Filename: modulus/experimental/datapipes/climate/climate_hdf5.py
-Comment: 
-
-Filename: modulus/experimental/datapipes/climate/utils/__init__.py
-Comment: 
-
-Filename: modulus/experimental/datapipes/climate/utils/zenith_angle.py
-Comment: 
-
 Filename: modulus/launch/__init__.py
 Comment: 
 
 Filename: modulus/launch/config/__init__.py
 Comment: 
 
 Filename: modulus/launch/logging/__init__.py
@@ -381,14 +378,17 @@
 
 Filename: modulus/utils/capture.py
 Comment: 
 
 Filename: modulus/utils/filesystem.py
 Comment: 
 
+Filename: modulus/utils/neighbor_list.py
+Comment: 
+
 Filename: modulus/utils/zenith_angle.py
 Comment: 
 
 Filename: modulus/utils/generative/__init__.py
 Comment: 
 
 Filename: modulus/utils/generative/sampler.py
@@ -411,26 +411,26 @@
 
 Filename: modulus/utils/graphcast/icospheres.py
 Comment: 
 
 Filename: modulus/utils/graphcast/loss.py
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/LICENSE.txt
+Filename: nvidia_modulus-0.6.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/METADATA
+Filename: nvidia_modulus-0.6.0.dist-info/METADATA
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/WHEEL
+Filename: nvidia_modulus-0.6.0.dist-info/WHEEL
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/entry_points.txt
+Filename: nvidia_modulus-0.6.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/top_level.txt
+Filename: nvidia_modulus-0.6.0.dist-info/top_level.txt
 Comment: 
 
-Filename: nvidia_modulus-0.5.0.dist-info/RECORD
+Filename: nvidia_modulus-0.6.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## modulus/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,8 +15,8 @@
 # limitations under the License.
 
 from .datapipes.datapipe import Datapipe
 from .datapipes.meta import DatapipeMetaData
 from .models.meta import ModelMetaData
 from .models.module import Module
 
-__version__ = "0.5.0"
+__version__ = "0.6.0"
```

## modulus/constants.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/datapipe.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/meta.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/darcy.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kelvin_helmholtz.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/finite_difference.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/finite_volume.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/indexing.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/initialization.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/benchmarks/kernels/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/climate/__init__.py

```diff
@@ -1,15 +1,18 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+from .climate import ClimateDatapipe, ClimateDataSourceSpec
 from .era5_hdf5 import ERA5HDF5Datapipe
```

## modulus/datapipes/climate/era5_hdf5.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -150,16 +152,19 @@
         self.n_years = len(self.data_paths)
         self.logger.info(f"Number of years: {self.n_years}")
 
         # get total number of examples and image shape from the first file,
         # assuming other files have exactly the same format.
         self.logger.info(f"Getting file stats from {self.data_paths[0]}")
         with h5py.File(self.data_paths[0], "r") as f:
-            # truncate the dataset to avoid out-of-range sampling
-            data_samples_per_year = f["fields"].shape[0] - self.num_steps * self.stride
+            # truncate the dataset to avoid out-of-range sampling and ensure each
+            # rank has same number of samples (to avoid deadlocks)
+            data_samples_per_year = (
+                (f["fields"].shape[0] - self.num_steps * self.stride) // self.world_size
+            ) * self.world_size
             self.img_shape = f["fields"].shape[2:]
 
             # If channels not provided, use all of them
             if self.channels is None:
                 self.channels = [i for i in range(f["fields"].shape[1])]
 
             # If num_samples_per_year use all
```

## modulus/datapipes/climate/era5_netcdf.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/gnn/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/gnn/ahmed_body_dataset.py

```diff
@@ -1,28 +1,32 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import concurrent.futures as cf
 import os
 import re
 from dataclasses import dataclass
-from typing import Any, Dict, List, Tuple, Union
+from typing import Any, Dict, Iterable, List, Optional, Tuple, Union
 
 import numpy as np
 import torch
+import yaml
 from torch import Tensor
 
 from modulus.datapipes.datapipe import Datapipe
 from modulus.datapipes.meta import DatapipeMetaData
 
 from .utils import load_json, read_vtp_file, save_json
 
@@ -42,14 +46,28 @@
     raise ImportError(
         "Ahmed Body Dataset requires the vtk and pyvista libraries. Install with "
         + "pip install vtk pyvista"
     )
 
 
 @dataclass
+class FileInfo:
+    """VTP file info storage."""
+
+    velocity: float
+    reynolds_number: float
+    length: float
+    width: float
+    height: float
+    ground_clearance: float
+    slant_angle: float
+    fillet_radius: float
+
+
+@dataclass
 class MetaData(DatapipeMetaData):
     name: str = "AhmedBody"
     # Optimization
     auto_device: bool = True
     cuda_graphs: bool = False
     # Parallel
     ddp_sharding: bool = True
@@ -63,66 +81,69 @@
     ----------
     data_dir: str
         The directory where the data is stored.
     split: str, optional
         The dataset split. Can be 'train', 'validation', or 'test', by default 'train'.
     num_samples: int, optional
         The number of samples to use, by default 10.
-    invar_keys: List[str], optional
+    invar_keys: Iterable[str], optional
         The input node features to consider. Default includes 'pos', 'velocity', 'reynolds_number', 'length', 'width', 'height', 'ground_clearance', 'slant_angle', and 'fillet_radius'.
-    outvar_keys: List[str], optional
+    outvar_keys: Iterable[str], optional
         The output features to consider. Default includes 'p' and 'wallShearStress'.
-    normalize_keys List[str], optional
+    normalize_keys Iterable[str], optional
         The features to normalize. Default includes 'p', 'wallShearStress', 'velocity', 'length', 'width', 'height', 'ground_clearance', 'slant_angle', and 'fillet_radius'.
     normalization_bound: Tuple[float, float], optional
         The lower and upper bounds for normalization. Default is (-1, 1).
     force_reload: bool, optional
         If True, forces a reload of the data, by default False.
     name: str, optional
         The name of the dataset, by default 'dataset'.
     verbose: bool, optional
         If True, enables verbose mode, by default False.
     compute_drag: bool, optional
         If True, also returns the coefficient and mesh area and normals that are required for computing the drag coefficient.
+    num_workers: int, optional
+        Number of dataset pre-loading workers. If None, will be chosen automatically.
     """
 
     def __init__(
         self,
         data_dir: str,
         split: str = "train",
         num_samples: int = 10,
-        invar_keys: List[str] = [
+        invar_keys: Iterable[str] = (
             "pos",
             "velocity",
             "reynolds_number",
             "length",
             "width",
             "height",
             "ground_clearance",
             "slant_angle",
             "fillet_radius",
-        ],
-        outvar_keys: List[str] = ["p", "wallShearStress"],
-        normalize_keys: List[str] = [
+        ),
+        outvar_keys: Iterable[str] = ("p", "wallShearStress"),
+        normalize_keys: Iterable[str] = (
             "p",
             "wallShearStress",
             "velocity",
             "reynolds_number",
             "length",
             "width",
             "height",
             "ground_clearance",
             "slant_angle",
             "fillet_radius",
-        ],
+        ),
         normalization_bound: Tuple[float, float] = (-1.0, 1.0),
         force_reload: bool = False,
         name: str = "dataset",
         verbose: bool = False,
         compute_drag: bool = False,
+        num_workers: Optional[int] = None,
     ):
         DGLDataset.__init__(
             self,
             name=name,
             force_reload=force_reload,
             verbose=verbose,
         )
@@ -130,16 +151,17 @@
             self,
             meta=MetaData(),
         )
         self.split = split
         self.num_samples = num_samples
         self.data_dir = os.path.join(data_dir, self.split)
         self.info_dir = os.path.join(data_dir, self.split + "_info")
-        self.input_keys = invar_keys
-        self.output_keys = outvar_keys
+        self.input_keys = list(invar_keys)
+        self.output_keys = list(outvar_keys)
+        self.normalize_keys = list(normalize_keys)
         self.normalization_bound = normalization_bound
         self.compute_drag = compute_drag
 
         # get the list of all files in the data_dir
         all_entries = os.listdir(self.data_dir)
         all_info = os.listdir(self.info_dir)
 
@@ -185,91 +207,56 @@
         if self.num_samples > self.length:
             raise ValueError(
                 f"Number of available {self.split} dataset entries "
                 f"({self.length}) is less than the number of samples "
                 f"({self.num_samples})"
             )
 
-        self.graphs = []
+        self.graphs = [None] * self.length
         if self.compute_drag:
-            self.normals = []
-            self.areas = []
-            self.coeff = []
-        for i in range(self.length):
-            file_path = data_list[i]
-            info_path = info_list[i]
-            polydata = read_vtp_file(file_path)
-            graph = self._create_dgl_graph(polydata, outvar_keys, dtype=torch.int32)
-            (
-                velocity,
-                reynolds_number,
-                length,
-                width,
-                height,
-                ground_clearance,
-                slant_angle,
-                fillet_radius,
-            ) = self._read_info_file(info_path)
-            if "velocity" in invar_keys:
-                graph.ndata["velocity"] = velocity * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "reynolds_number" in invar_keys:
-                graph.ndata["reynolds_number"] = reynolds_number * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "length" in invar_keys:
-                graph.ndata["length"] = length * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "width" in invar_keys:
-                graph.ndata["width"] = width * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "height" in invar_keys:
-                graph.ndata["height"] = height * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "ground_clearance" in invar_keys:
-                graph.ndata["ground_clearance"] = ground_clearance * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "slant_angle" in invar_keys:
-                graph.ndata["slant_angle"] = slant_angle * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-            if "fillet_radius" in invar_keys:
-                graph.ndata["fillet_radius"] = fillet_radius * torch.ones_like(
-                    graph.ndata["pos"][:, [0]]
-                )
-
-            if "normals" in invar_keys or self.compute_drag:
-                mesh = pv.read(file_path)
-                mesh.compute_normals(
-                    cell_normals=True, point_normals=False, inplace=True
-                )
-                if "normals" in invar_keys:
-                    graph.ndata["normals"] = torch.from_numpy(
-                        mesh.cell_data_to_point_data()["Normals"]
-                    )
+            self.normals = [None] * self.length
+            self.areas = [None] * self.length
+            self.coeff = [None] * self.length
+
+        # create graphs from VTP files using multiprocessing.
+        if num_workers is None or num_workers <= 0:
+
+            def get_num_workers():
+                # Make sure we don't oversubscribe CPUs on a node.
+                # TODO(akamenev): this should be in DistributedManager.
+                local_node_size = max(
+                    int(os.environ.get("OMPI_COMM_WORLD_LOCAL_SIZE", 1)), 1
+                )
+                num_workers = len(os.sched_getaffinity(0)) // local_node_size
+                return max(num_workers - 1, 1)
+
+            num_workers = get_num_workers()
+        with cf.ProcessPoolExecutor(
+            max_workers=num_workers,
+            mp_context=torch.multiprocessing.get_context("spawn"),
+        ) as executor:
+            for (i, graph, coeff, normal, area) in executor.map(
+                self.create_graph,
+                range(self.length),
+                data_list[: self.length],
+                info_list[: self.length],
+                chunksize=max(1, self.length // num_workers),
+            ):
+                self.graphs[i] = graph
                 if self.compute_drag:
-                    mesh = mesh.compute_cell_sizes()
-                    mesh = mesh.cell_data_to_point_data()
-                    frontal_area = width * height / 2 * (10 ** (-6))
-                    self.coeff.append(2.0 / ((velocity**2) * frontal_area))
-                    self.normals.append(torch.from_numpy(mesh["Normals"]))
-                    self.areas.append(torch.from_numpy(mesh["Area"]))
-            self.graphs.append(graph)
+                    self.coeff[i] = coeff
+                    self.normals[i] = normal
+                    self.areas[i] = area
 
         # add the edge features
         self.graphs = self.add_edge_features()
 
         # normalize the node and edge features
         if self.split == "train":
-            self.node_stats = self._get_node_stats(keys=normalize_keys)
+            self.node_stats = self._get_node_stats(keys=self.normalize_keys)
             self.edge_stats = self._get_edge_stats()
         else:
             if not os.path.exists("node_stats.json"):
                 raise FileNotFoundError(
                     "node_stats.json not found! Node stats must be computed on the training set."
                 )
             if not os.path.exists("edge_stats.json"):
@@ -278,14 +265,52 @@
                 )
             self.node_stats = load_json("node_stats.json")
             self.edge_stats = load_json("edge_stats.json")
 
         self.graphs = self.normalize_node()
         self.graphs = self.normalize_edge()
 
+    def create_graph(self, index: int, file_path: str, info_path: str) -> None:
+        """Creates a graph from VTP file.
+
+        This method is used in parallel loading of graphs.
+
+        Returns
+        -------
+            Tuple that contains graph index, graph, and optionally coeff, normal and area values.
+        """
+        polydata = read_vtp_file(file_path)
+        graph = self._create_dgl_graph(polydata, self.output_keys, dtype=torch.int32)
+        info = self._read_info_file(info_path)
+        for v in vars(info):
+            if v not in self.input_keys:
+                continue
+            graph.ndata[v] = getattr(info, v) * torch.ones_like(
+                graph.ndata["pos"][:, [0]]
+            )
+
+        coeff = None
+        normal = None
+        area = None
+        if "normals" in self.input_keys or self.compute_drag:
+            mesh = pv.read(file_path)
+            mesh.compute_normals(cell_normals=True, point_normals=False, inplace=True)
+            if "normals" in self.input_keys:
+                graph.ndata["normals"] = torch.from_numpy(
+                    mesh.cell_data_to_point_data()["Normals"]
+                )
+            if self.compute_drag:
+                mesh = mesh.compute_cell_sizes()
+                mesh = mesh.cell_data_to_point_data()
+                frontal_area = info.width * info.height / 2 * (10 ** (-6))
+                coeff = 2.0 / ((info.velocity**2) * frontal_area)
+                normal = torch.from_numpy(mesh["Normals"])
+                area = torch.from_numpy(mesh["Area"])
+        return index, graph, coeff, normal, area
+
     def __getitem__(self, idx):
         graph = self.graphs[idx]
         if self.compute_drag:
             sid = self.numbers[idx]
             return graph, sid, self.normals[idx], self.areas[idx], self.coeff[idx]
         return graph
 
@@ -495,66 +520,40 @@
             stats.pop(key + "_meansqr")
 
         # save to file
         save_json(stats, "node_stats.json")
         return stats
 
     @staticmethod
-    def _read_info_file(
-        file_path: str,
-    ) -> Tuple[float, float, float, float, float, float, float, float]:
+    def _read_info_file(file_path: str) -> FileInfo:
         """
         Parse the values of specific parameters from a given text file.
 
         Parameters
         ----------
         file_path : str
             Path to the text file.
 
         Returns
         -------
-        tuple
-            A tuple containing values of velocity, reynolds number, length, width, height, ground clearance, slant angle, and fillet radius.
+        FileInfo
+            A FileInfo object.
         """
-        # Initialize variables to default value 0.0
-        velocity = (
-            reynolds_number
-        ) = (
-            length
-        ) = width = height = ground_clearance = slant_angle = fillet_radius = 0.0
-
-        with open(file_path, "r") as file:
-            for line in file:
-                if "Velocity" in line:
-                    velocity = float(line.split(":")[1].strip())
-                elif "Re" in line:
-                    reynolds_number = float(line.split(":")[1].strip())
-                elif "Length" in line:
-                    length = float(line.split(":")[1].strip())
-                elif "Width" in line:
-                    width = float(line.split(":")[1].strip())
-                elif "Height" in line:
-                    height = float(line.split(":")[1].strip())
-                elif "GroundClearance" in line:
-                    ground_clearance = float(line.split(":")[1].strip())
-                elif "SlantAngle" in line:
-                    slant_angle = float(line.split(":")[1].strip())
-                elif "FilletRadius" in line:
-                    fillet_radius = float(line.split(":")[1].strip())
-
-        return (
-            velocity,
-            reynolds_number,
-            length,
-            width,
-            height,
-            ground_clearance,
-            slant_angle,
-            fillet_radius,
-        )
+        with open(file_path, mode="rt", encoding="utf-8") as file:
+            info = yaml.safe_load(file)
+            return FileInfo(
+                info["Velocity"],
+                info["Re (based on length)"],
+                info["Length"],
+                info["Width"],
+                info["Height"],
+                info["GroundClearance"],
+                info["SlantAngle"],
+                info["FilletRadius"],
+            )
 
     @staticmethod
     def _create_dgl_graph(
         polydata: Any,
         outvar_keys: List[str],
         to_bidirected: bool = True,
         add_self_loop: bool = False,
```

## modulus/datapipes/gnn/stokes_dataset.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/gnn/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/datapipes/gnn/vortex_shedding_dataset.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/deploy/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/deploy/onnx/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/deploy/onnx/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/deploy/triton/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/deploy/trt/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/autograd.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/config.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/fft.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/manager.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -326,26 +328,25 @@
     ):
         """Set up PyTorch distributed process group and update manager attributes"""
         os.environ["MASTER_ADDR"] = addr
         os.environ["MASTER_PORT"] = str(port)
 
         manager = DistributedManager()
 
-        manager._distributed = (world_size > 1) and torch.distributed.is_available()
+        manager._distributed = torch.distributed.is_available()
         if manager._distributed:
             # Update rank and world_size if using distributed
             manager._rank = rank
             manager._world_size = world_size
             if local_rank is None:
                 manager._local_rank = rank % torch.cuda.device_count()
             else:
                 manager._local_rank = local_rank
 
             # Setup distributed process group
-            # time.sleep(1)
             dist.init_process_group(
                 backend, rank=manager.rank, world_size=manager.world_size
             )
 
         manager._device = torch.device(
             f"cuda:{manager.local_rank}" if torch.cuda.is_available() else "cpu"
         )
@@ -366,31 +367,36 @@
         """
         Create a process subgroup of a parent process group. This must be a collective
         call by all processes participating in this application.
 
         Parameters
         ----------
         name : str
-        Name of the process subgroup to be created.
+            Name of the process subgroup to be created.
 
         size : int
-        Size of the process subgroup to be created. This must be an integer factor of
-        the parent group's size.
+            Size of the process subgroup to be created. This must be an integer factor of
+            the parent group's size.
 
         group_name : Optional[str]
-        Name of the parent process group, optional. If None, the default process group
-        will be used. Default None.
+            Name of the parent process group, optional. If None, the default process group
+            will be used. Default None.
 
         verbose : bool
-        Print out ranks of each created process group, default False.
+            Print out ranks of each created process group, default False.
 
         """
         manager = DistributedManager()
         if not manager.distributed:
-            return None
+            raise AssertionError(
+                "torch.distributed is unavailable. "
+                "Check pytorch build to ensure the distributed package is available. "
+                "If building PyTorch from source, set `USE_DISTRIBUTED=1` "
+                "to enable the distributed package"
+            )
 
         if name in manager._groups:
             raise AssertionError(f"Group with name {name} already exists")
 
         # Get parent group's params
         group = manager._groups[group_name] if group_name else None
         group_size = dist.get_world_size(group=group)
@@ -447,15 +453,20 @@
 
         verbose : bool
             Print out ranks of each created process group, default False.
 
         """
         manager = DistributedManager()
         if not manager.distributed:
-            return None
+            raise AssertionError(
+                "torch.distributed is unavailable. "
+                "Check pytorch build to ensure the distributed package is available. "
+                "If building PyTorch from source, set `USE_DISTRIBUTED=1` "
+                "to enable the distributed package"
+            )
 
         if group_name not in manager._groups:
             raise ValueError(f"Group with name {group_name} does not exist")
         if orthogonal_group_name in manager._groups:
             raise ValueError(f"Group with name {orthogonal_group_name} already exists")
 
         group_ranks = manager._group_ranks[group_name]
@@ -529,10 +540,16 @@
                 # Add child ids to the queue
                 q.put(child.identifier)
 
     @staticmethod
     def cleanup():
         """Clean up distributed group and singleton"""
         # Destroying group.WORLD is enough for all process groups to get destroyed
-        dist.barrier()  # just make sure that no process hangs
-        dist.destroy_process_group()
+        if DistributedManager().distributed:
+            if torch.cuda.is_available():
+                dist.barrier(
+                    device_ids=[DistributedManager().local_rank]
+                )  # just make sure that no process hangs
+            else:
+                dist.barrier()  # just make sure that no process hangs
+            dist.destroy_process_group()
         DistributedManager._shared_state = {}
```

## modulus/distributed/mappings.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/distributed/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/experimental/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/config/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/logging/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/logging/console.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/logging/launch.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/logging/mlflow.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -163,15 +165,15 @@
     """Checks to see if MLFlow URI is functioning
 
     This isn't the best solution right now and overrides http timeout. Can update if MLFlow
     use is increased.
     """
 
     logger.warning(
-        "Checking MLFlow logging location is working (if this hangs its not)"
+        "Checking MLFlow logging location is working (if this hangs it's not)"
     )
     t0 = os.environ.get("MLFLOW_HTTP_REQUEST_TIMEOUT", None)
     try:
         # Adjust http timeout to 5 seconds
         os.environ["MLFLOW_HTTP_REQUEST_TIMEOUT"] = str(max(int(t0), 5)) if t0 else "5"
         experiment = client.create_experiment("test")
         client.delete_experiment(experiment)
```

## modulus/launch/logging/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/logging/wandb.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/utils/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/launch/utils/checkpoint.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/climate/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/climate/acc.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/climate/efi.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/climate/reduction.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/diffusion/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/diffusion/fid.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/diffusion/loss.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,14 +14,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
 """Loss functions used in the paper
 "Elucidating the Design Space of Diffusion-Based Generative Models"."""
 
+import random
 from typing import Callable, Optional, Union
 
 import torch
 
 
 class VPLoss:
     """
@@ -430,22 +433,32 @@
     Generative Residual Diffusion Modeling for Km-scale Atmospheric Downscaling.
     arXiv preprint arXiv:2309.15214.
     """
 
     def __init__(
         self,
         regression_net,
+        img_shape_x,
+        img_shape_y,
+        patch_shape_x,
+        patch_shape_y,
+        patch_num,
         P_mean: float = 0.0,
         P_std: float = 1.2,
         sigma_data: float = 0.5,
     ):
         self.unet = regression_net
         self.P_mean = P_mean
         self.P_std = P_std
         self.sigma_data = sigma_data
+        self.img_shape_x = img_shape_x
+        self.img_shape_y = img_shape_y
+        self.patch_shape_x = patch_shape_x
+        self.patch_shape_y = patch_shape_y
+        self.patch_num = patch_num
 
     def __call__(self, net, img_clean, img_lr, labels=None, augment_pipe=None):
         """
         Calculate and return the loss for denoising score matching.
 
         Parameters:
         ----------
@@ -487,14 +500,79 @@
         y_mean = self.unet(
             torch.zeros_like(y, device=img_clean.device),
             y_lr,
             sigma,
             labels,
             augment_labels=augment_labels,
         )
+
         y = y - y_mean
 
+        # patchified training
+        if (
+            self.img_shape_x != self.patch_shape_x
+            or self.img_shape_y != self.patch_shape_y
+        ):
+
+            b = y.shape[0]
+            c_in = y_lr.shape[1]
+            c_out = y.shape[1]
+            rnd_normal = torch.randn(
+                [img_clean.shape[0] * self.patch_num, 1, 1, 1], device=img_clean.device
+            )
+            sigma = (rnd_normal * self.P_std + self.P_mean).exp()
+            weight = (sigma**2 + self.sigma_data**2) / (
+                sigma * self.sigma_data
+            ) ** 2
+
+            # global interpolation
+            input_interp = torch.nn.functional.interpolate(
+                img_lr[:, 0 : c_in - 4],
+                (self.patch_shape_x, self.patch_shape_y),
+                mode="bilinear",
+            )
+
+            # patch generation from a single sample (not from random samples due to memory consumption of regression)
+            y_new = torch.zeros(
+                b * self.patch_num,
+                c_out,
+                self.patch_shape_x,
+                self.patch_shape_y,
+                device=img_clean.device,
+            )
+            y_lr_new = torch.zeros(
+                b * self.patch_num,
+                c_in + input_interp.shape[1],
+                self.patch_shape_x,
+                self.patch_shape_y,
+                device=img_clean.device,
+            )
+            for i in range(self.patch_num):
+                rnd_x = random.randint(0, self.img_shape_x - self.patch_shape_x)
+                rnd_y = random.randint(0, self.img_shape_y - self.patch_shape_y)
+                y_new[b * i : b * (i + 1),] = y[
+                    :,
+                    :,
+                    rnd_x : rnd_x + self.patch_shape_x,
+                    rnd_y : rnd_y + self.patch_shape_y,
+                ]
+                y_lr_new[b * i : b * (i + 1),] = torch.cat(
+                    (
+                        y_lr[
+                            :,
+                            :,
+                            rnd_x : rnd_x + self.patch_shape_x,
+                            rnd_y : rnd_y + self.patch_shape_y,
+                        ],
+                        input_interp,
+                    ),
+                    1,
+                )
+
+            y = y_new
+            y_lr = y_lr_new
+
         latent = y + torch.randn_like(y) * sigma
         D_yn = net(latent, y_lr, sigma, labels, augment_labels=augment_labels)
         loss = weight * ((D_yn - y) ** 2)
 
         return loss
```

## modulus/metrics/general/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/calibration.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/crps.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/ensemble_metrics.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -189,15 +191,15 @@
             )
 
         # TODO(Dallas) Move distributed calls into finalize.
         if (
             DistributedManager.is_initialized() and dist.is_initialized()
         ):  # pragma: no cover
             # Collect local sums, n
-            sums = torch.sum(inputs, batch_dim=dim)
+            sums = torch.sum(inputs, dim=dim)
             n = torch.as_tensor([inputs.shape[dim]], device=self.device)
 
             # Reduce
             dist.all_reduce(sums, op=dist.ReduceOp.SUM)
             dist.all_reduce(n, op=dist.ReduceOp.SUM)
 
             # Update
```

## modulus/metrics/general/entropy.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/histogram.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/mse.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/reduction.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/metrics/general/wasserstein.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/fcn_mip_plugin.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/meta.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/module.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -51,25 +53,42 @@
     _file_extension = ".mdlus"  # Set file extension for saving and loading
     __model_checkpoint_version__ = (
         "0.1.0"  # Used for file versioning and is not the same as modulus version
     )
 
     def __new__(cls, *args, **kwargs):
         out = super().__new__(cls)
+
+        # Get signature of __init__ function
         sig = inspect.signature(cls.__init__)
+
+        # Bind args and kwargs to signature
         bound_args = sig.bind_partial(
             *([None] + list(args)), **kwargs
         )  # Add None to account for self
         bound_args.apply_defaults()
-        bound_args.arguments.pop("self", None)
 
+        # Get args and kwargs (excluding self and unroll kwargs)
+        instantiate_args = {}
+        for param, (k, v) in zip(sig.parameters.values(), bound_args.arguments.items()):
+            # Skip self
+            if k == "self":
+                continue
+
+            # Add args and kwargs to instantiate_args
+            if param.kind == param.VAR_KEYWORD:
+                instantiate_args.update(v)
+            else:
+                instantiate_args[k] = v
+
+        # Store args needed for instantiation
         out._args = {
             "__name__": cls.__name__,
             "__module__": cls.__module__,
-            "__args__": {k: v for k, v in bound_args.arguments.items()},
+            "__args__": instantiate_args,
         }
         return out
 
     def __init__(self, meta: Union[ModelMetaData, None] = None):
         super().__init__()
         self.meta = meta
         self.register_buffer("device_buffer", torch.empty(0))
@@ -248,24 +267,29 @@
                 != Module.__model_checkpoint_version__
             ):
                 raise IOError(
                     f"Model checkpoint version {metadata_info['mdlus_file_version']} is not compatible with current version {Module.__version__}"
                 )
 
     def load(
-        self, file_name: str, map_location: Union[None, str, torch.device] = None
+        self,
+        file_name: str,
+        map_location: Union[None, str, torch.device] = None,
+        strict: bool = True,
     ) -> None:
         """Simple utility for loading the model weights from checkpoint
 
         Parameters
         ----------
         file_name : str
             Checkpoint file name
         map_location : Union[None, str, torch.device], optional
             Map location for loading the model weights, by default None will use model's device
+        strict: bool, optional
+            whether to strictly enforce that the keys in state_dict match, by default True
 
         Raises
         ------
         IOError
             If file_name provided does not exist or is not a valid checkpoint
         """
 
@@ -286,15 +310,15 @@
             Module._check_checkpoint(local_path)
 
             # Load the model weights
             device = map_location if map_location is not None else self.device
             model_dict = torch.load(
                 local_path.joinpath("model.pt"), map_location=device
             )
-            self.load_state_dict(model_dict)
+            self.load_state_dict(model_dict, strict=strict)
 
     @classmethod
     def from_checkpoint(cls, file_name: str) -> "Module":
         """Simple utility for constructing a model from a checkpoint
 
         Parameters
         ----------
```

## modulus/models/afno/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/afno/afno.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/afno/distributed/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/afno/distributed/afno.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/afno/distributed/layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/diffusion/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/diffusion/dhariwal_unet.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/diffusion/layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,14 +19,15 @@
 Diffusion-Based Generative Models".
 """
 
 from typing import Any, Dict, List
 
 import numpy as np
 import torch
+from einops import rearrange
 from torch.nn.functional import silu
 
 from modulus.models.diffusion import weight_init
 
 
 class Linear(torch.nn.Module):
     """
@@ -263,21 +266,42 @@
         super().__init__()
         self.num_groups = min(num_groups, num_channels // min_channels_per_group)
         self.eps = eps
         self.weight = torch.nn.Parameter(torch.ones(num_channels))
         self.bias = torch.nn.Parameter(torch.zeros(num_channels))
 
     def forward(self, x):
-        x = torch.nn.functional.group_norm(
-            x,
-            num_groups=self.num_groups,
-            weight=self.weight.to(x.dtype),
-            bias=self.bias.to(x.dtype),
-            eps=self.eps,
-        )
+        if self.training:
+            # Use default torch implementation of GroupNorm for training
+            # This does not support channels last memory format
+            x = torch.nn.functional.group_norm(
+                x,
+                num_groups=self.num_groups,
+                weight=self.weight.to(x.dtype),
+                bias=self.bias.to(x.dtype),
+                eps=self.eps,
+            )
+        else:
+            # Use custom GroupNorm implementation that supports channels last
+            # memory layout for inference
+            dtype = x.dtype
+            x = x.float()
+            x = rearrange(x, "b (g c) h w -> b g c h w", g=self.num_groups)
+
+            mean = x.mean(dim=[2, 3, 4], keepdim=True)
+            var = x.var(dim=[2, 3, 4], keepdim=True)
+
+            x = (x - mean) * (var + self.eps).rsqrt()
+            x = rearrange(x, "b g c h w -> b (g c) h w")
+
+            weight = rearrange(self.weight, "c -> 1 c 1 1")
+            bias = rearrange(self.bias, "c -> 1 c 1 1")
+            x = x * weight + bias
+
+            x = x.type(dtype)
         return x
 
 
 class AttentionOp(torch.autograd.Function):
     """
     Attention weight computation, i.e., softmax(Q^T * K).
     Performs all computation using FP32, but uses the original datatype for
@@ -286,15 +310,15 @@
 
     @staticmethod
     def forward(ctx, q, k):
         w = (
             torch.einsum(
                 "ncq,nck->nqk",
                 q.to(torch.float32),
-                (k / np.sqrt(k.shape[1])).to(torch.float32),
+                (k / torch.sqrt(torch.tensor(k.shape[1]))).to(torch.float32),
             )
             .softmax(dim=2)
             .to(q.dtype)
         )
         ctx.save_for_backward(q, k, w)
         return w
```

## modulus/models/diffusion/preconditioning.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,14 +16,15 @@
 
 """
 Preconditioning schemes used in the paper"Elucidating the Design Space of 
 Diffusion-Based Generative Models".
 """
 
 import importlib
+import warnings
 from dataclasses import dataclass
 from typing import List, Union
 
 import numpy as np
 import nvtx
 import torch
 
@@ -727,14 +730,21 @@
         use_fp16=False,
         sigma_min=0.0,
         sigma_max=float("inf"),
         sigma_data=0.5,
         model_type="DhariwalUNet",
         **model_kwargs,
     ):
+        warnings.warn(
+            "EDMPrecondSR has a bug in how the conditional input is scaled "
+            "(see https://github.com/NVIDIA/modulus/issues/229). "
+            "This preconditioner is now deprecated. "
+            "Please use EDMPrecondSRV2 instead.",
+            DeprecationWarning,
+        )
         super().__init__(meta=EDMPrecondSRMetaData)
         self.img_resolution = img_resolution
         self.img_channels = img_channels
         self.img_in_channels = img_in_channels
         self.img_out_channels = img_out_channels
         self.label_dim = label_dim
         self.use_fp16 = use_fp16
@@ -798,7 +808,170 @@
     @staticmethod
     def round_sigma(sigma: Union[float, List, torch.Tensor]):
         """
         Convert a given sigma value(s) to a tensor representation.
         See EDMPrecond.round_sigma
         """
         return EDMPrecond.round_sigma(sigma)
+
+
+class _ConditionalPrecond(torch.nn.Module):
+    """EDM Preconditioner with appropriate handling of conditional inputs via concatenation
+
+    This class is more modular since ``model`` is not constructed here.
+
+    """
+
+    def __init__(
+        self,
+        *,
+        model: torch.nn.Module,
+        img_resolution: int,
+        img_channels: int,
+        label_dim=0,
+        use_fp16=False,
+        sigma_min=0,
+        sigma_max=float("inf"),
+        sigma_data=0.5,
+    ):
+        super().__init__()
+
+        # metadata. Not clear which is of these is used externally. I believe
+        # img_resolution and img_channels are.
+        self.label_dim = label_dim
+        self.use_fp16 = use_fp16
+        self.sigma_min = sigma_min
+        self.sigma_max = sigma_max
+        self.sigma_data = sigma_data
+        self.img_resolution = img_resolution
+        self.img_channels = img_channels
+        self.model = model
+
+    @nvtx.annotate(message="_ConditionalPrecond", color="orange")
+    def forward(
+        self,
+        x,
+        sigma,
+        class_labels=None,
+        condition=None,
+        force_fp32=False,
+        **model_kwargs,
+    ):
+        x = x.to(torch.float32)
+        sigma = sigma.to(torch.float32).reshape(-1, 1, 1, 1)
+        class_labels = (
+            None
+            if self.label_dim == 0
+            else (
+                torch.zeros([1, self.label_dim], device=x.device)
+                if class_labels is None
+                else class_labels.to(torch.float32).reshape(-1, self.label_dim)
+            )
+        )
+        dtype = (
+            torch.float16
+            if (self.use_fp16 and not force_fp32 and x.device.type == "cuda")
+            else torch.float32
+        )
+
+        c_skip = self.sigma_data**2 / (sigma**2 + self.sigma_data**2)
+        c_out = sigma * self.sigma_data / (sigma**2 + self.sigma_data**2).sqrt()
+        c_in = 1 / (self.sigma_data**2 + sigma**2).sqrt()
+        c_noise = sigma.log() / 4
+
+        if condition is None:
+            arg = c_in * x
+        else:
+            condition = condition.to(torch.float32)
+            arg = torch.cat([c_in * x, condition], dim=1)
+
+        F_x = self.model(
+            arg.to(dtype), c_noise.flatten(), class_labels=class_labels, **model_kwargs
+        )
+        D_x = c_skip * x + c_out * F_x.to(torch.float32)
+        return D_x
+
+    def round_sigma(self, sigma):
+        return torch.as_tensor(sigma)
+
+
+class EDMPrecondSRV2(_ConditionalPrecond, Module):
+    # note this order of inheritance is necessesary  since Module.__init__ calls
+    # super().__init__
+    """EDM Preconditioner with appropriate handling of conditional inputs via concatenation
+
+    This helper is provided to have a similar interface to EDMPrecondSR,
+    which includes the model construction.
+
+    Parameters
+    ----------
+    img_resolution : int
+        Image resolution.
+    img_in_channels : int
+        Number of input color channels.
+    img_out_channels : int
+        Number of output color channels.
+    label_dim : int
+        Number of class labels, 0 = unconditional, by default 0.
+    use_fp16 : bool
+        Execute the underlying model at FP16 precision?, by default False.
+    sigma_min : float
+        Minimum supported noise level, by default 0.0.
+    sigma_max : float
+        Maximum supported noise level, by default inf.
+    sigma_data : float
+        Expected standard deviation of the training data, by default 0.5.
+    model_type :str
+        Class name of the underlying model, by default "DhariwalUNet".
+    **model_kwargs : dict
+        Keyword arguments for the underlying model.
+
+    Note
+    ----
+    References:
+    - Karras, T., Aittala, M., Aila, T. and Laine, S., 2022. Elucidating the
+    design space of diffusion-based generative models. Advances in Neural Information
+    Processing Systems, 35, pp.26565-26577.
+    - Mardani, M., Brenowitz, N., Cohen, Y., Pathak, J., Chen, C.Y.,
+    Liu, C.C.,Vahdat, A., Kashinath, K., Kautz, J. and Pritchard, M., 2023.
+    Generative Residual Diffusion Modeling for Km-scale Atmospheric Downscaling.
+    arXiv preprint arXiv:2309.15214.
+    """
+
+    def __init__(
+        self,
+        img_resolution,
+        img_in_channels,
+        img_out_channels,
+        label_dim=0,
+        use_fp16=False,
+        sigma_min=0.0,
+        sigma_max=float("inf"),
+        sigma_data=0.5,
+        model_type="DhariwalUNet",
+        **model_kwargs,
+    ) -> None:
+        # The use of multiple inheritance here is a workaround to make the
+        # preconditioner serializeable. The arguments of a Modulus model must be
+        # serializeable, but _ConditionalPrecond uses a compositional design for
+        # easier testing and modularity. Would be easier if modulus didn't rely
+        # on object inheritance for saving/loading.
+        Module.__init__(self, meta=EDMPrecondSRMetaData)
+        model_class = getattr(network_module, model_type)
+        model = model_class(
+            img_resolution=img_resolution,
+            in_channels=img_in_channels + img_out_channels,
+            out_channels=img_out_channels,
+            label_dim=label_dim,
+            **model_kwargs,
+        )
+        _ConditionalPrecond.__init__(
+            self,
+            model=model,
+            img_resolution=img_resolution,
+            img_channels=img_out_channels,
+            label_dim=label_dim,
+            use_fp16=use_fp16,
+            sigma_min=sigma_min,
+            sigma_max=sigma_max,
+            sigma_data=sigma_data,
+        )
```

## modulus/models/diffusion/song_unet.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/diffusion/unet.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/diffusion/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/dlwp/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/dlwp/dlwp.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/fno/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/fno/fno.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/distributed_graph.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/embedder.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/graph.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/mesh_edge_block.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/mesh_graph_decoder.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/mesh_graph_encoder.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/mesh_graph_mlp.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/mesh_node_block.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/gnn_layers/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/graphcast/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/graphcast/graph_cast_net.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/graphcast/graph_cast_processor.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/activations.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/dgm_layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/fft.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/fourier_layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/fully_connected_layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/fused_silu.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/interpolation.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/siren_layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/spectral_layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/weight_fact.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/layers/weight_norm.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/meshgraphnet/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/meshgraphnet/meshgraphnet.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -132,47 +134,48 @@
         hidden_dim_edge_encoder: int = 128,
         num_layers_edge_encoder: Union[int, None] = 2,
         hidden_dim_node_decoder: int = 128,
         num_layers_node_decoder: Union[int, None] = 2,
         aggregation: str = "sum",
         do_concat_trick: bool = False,
         num_processor_checkpoint_segments: int = 0,
+        recompute_activation: bool = False,
     ):
         super().__init__(meta=MetaData())
 
         activation_fn = get_activation(mlp_activation_fn)
 
         self.edge_encoder = MeshGraphMLP(
             input_dim_edges,
             output_dim=hidden_dim_processor,
             hidden_dim=hidden_dim_edge_encoder,
             hidden_layers=num_layers_edge_encoder,
             activation_fn=activation_fn,
             norm_type="LayerNorm",
-            recompute_activation=False,
+            recompute_activation=recompute_activation,
         )
 
         self.node_encoder = MeshGraphMLP(
             input_dim_nodes,
             output_dim=hidden_dim_processor,
             hidden_dim=hidden_dim_node_encoder,
             hidden_layers=num_layers_node_encoder,
             activation_fn=activation_fn,
             norm_type="LayerNorm",
-            recompute_activation=False,
+            recompute_activation=recompute_activation,
         )
 
         self.node_decoder = MeshGraphMLP(
             hidden_dim_processor,
             output_dim=output_dim,
             hidden_dim=hidden_dim_node_decoder,
             hidden_layers=num_layers_node_decoder,
             activation_fn=activation_fn,
             norm_type=None,
-            recompute_activation=False,
+            recompute_activation=recompute_activation,
         )
         self.processor = MeshGraphNetProcessor(
             processor_size=processor_size,
             input_dim_node=hidden_dim_processor,
             input_dim_edge=hidden_dim_processor,
             num_layers_node=num_layers_node_processor,
             num_layers_edge=num_layers_edge_processor,
```

## modulus/models/mlp/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/mlp/fully_connected.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/pix2pix/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/rnn/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/rnn/layers.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/rnn/rnn_one2many.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/rnn/rnn_seq2seq.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/models/srrn/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/registry/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/registry/model_registry.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/capture.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/filesystem.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -51,80 +53,101 @@
     """Pulls files from model registry on NGC. Supports private registries when NGC
     API key is set the the `NGC_API_KEY` environment variable. If download file is a zip
     folder it will get unzipped.
 
     Args:
         path (str): NGC model file path of form:
             `ngc://models/<org_id/team_id/model_id>@<version>/<path/in/repo>`
+            or if no team
+            `ngc://models/<org_id/model_id>@<version>/<path/in/repo>`
         out_path (str): Output path to save file / folder as
         timeout (int): Time out of requests, default 5 minutes
 
     Raises:
         ValueError: Invlaid url
 
     Returns:
         str: output file / folder path
     """
     # Strip ngc model url prefix
     suffix = "ngc://models/"
     # The regex check
-    pattern = re.compile(f"{suffix}[\w-]+/[\w-]+/[\w-]+@[A-Za-z0-9.]+/[\w/]+")
+    pattern = re.compile(f"{suffix}[\w-]+(/[\w-]+)?/[\w-]+@[A-Za-z0-9.]+/[\w/](.*)")
     if not pattern.match(path):
         raise ValueError(
             "Invalid URL, should be of form ngc://models/<org_id/team_id/model_id>@<version>/<path/in/repo>"
         )
 
     path = path.replace(suffix, "")
-    (org, team, model_version, filename) = path.split("/", 4)
-    (model, version) = model_version.split("@", 1)
+    if len(path.split("@")[0].split("/")) == 3:
+        (org, team, model_version, filename) = path.split("/", 3)
+        (model, version) = model_version.split("@", 1)
+    else:
+        (org, model_version, filename) = path.split("/", 2)
+        (model, version) = model_version.split("@", 1)
+        team = None
+
     token = ""
     # If API key environment variable
     if "NGC_API_KEY" in os.environ:
         try:
-            session = requests.Session()
-            session.auth = ("$oauthtoken", os.environ["NGC_API_KEY"])
-            headers = {"Accept": "application/json"}
-            authn_url = f"https://authn.nvidia.com/token?service=ngc&scope=group/ngc:{org}&group/ngc:{org}/{team}"
-            r = session.get(authn_url, headers=headers, timeout=5)
-            r.raise_for_status()
-            token = json.loads(r.content)["token"]
+            # SSA tokens
+            if os.environ["NGC_API_KEY"].startswith("nvapi-"):
+                raise NotImplementedError("New personal keys not supported yet")
+            # Legacy tokens
+            # https://docs.nvidia.com/ngc/gpu-cloud/ngc-catalog-user-guide/index.html#download-models-via-wget-authenticated-access
+            else:
+                session = requests.Session()
+                session.auth = ("$oauthtoken", os.environ["NGC_API_KEY"])
+                headers = {"Accept": "application/json"}
+                authn_url = f"https://authn.nvidia.com/token?service=ngc&scope=group/ngc:{org}&group/ngc:{org}/{team}"
+                r = session.get(authn_url, headers=headers, timeout=5)
+                r.raise_for_status()
+                token = json.loads(r.content)["token"]
         except requests.exceptions.RequestException:
             logger.warning(
                 "Failed to get JWT using the API set in NGC_API_KEY environment variable"
             )
             raise  # Re-raise the exception
 
     # Download file, apparently the URL for private registries is different than the public?
     if len(token) > 0:
-        file_url = f"https://api.ngc.nvidia.com/v2/org/{org}/team/{team}/models/{model}/versions/{version}/files/{filename}"
+        # Sloppy but works
+        if team:
+            file_url = f"https://api.ngc.nvidia.com/v2/org/{org}/team/{team}/models/{model}/versions/{version}/files/{filename}"
+        else:
+            file_url = f"https://api.ngc.nvidia.com/v2/org/{org}/models/{model}/versions/{version}/files/{filename}"
     else:
-        file_url = f"https://api.ngc.nvidia.com/v2/models/{org}/{team}/{model}/versions/{version}/files/{filename}"
-    local_url = f"{LOCAL_CACHE}/{filename}"
+        if team:
+            file_url = f"https://api.ngc.nvidia.com/v2/models/{org}/{team}/{model}/versions/{version}/files/{filename}"
+        else:
+            file_url = f"https://api.ngc.nvidia.com/v2/models/{org}/{model}/versions/{version}/files/{filename}"
+
     headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
     # Streaming here for larger files
     with requests.get(file_url, headers=headers, stream=True, timeout=timeout) as r:
         r.raise_for_status()
         total_size_in_bytes = int(r.headers.get("content-length", 0))
         chunk_size = 1024  # 1 kb
         progress_bar = tqdm(total=total_size_in_bytes, unit="iB", unit_scale=True)
         progress_bar.set_description(f"Fetching {filename}")
-        with open(local_url, "wb") as f:
+        with open(out_path, "wb") as f:
             for chunk in r.iter_content(chunk_size=chunk_size):
                 progress_bar.update(len(chunk))
                 f.write(chunk)
         progress_bar.close()
 
     # Unzip contents if zip file (most model files are)
-    if zipfile.is_zipfile(local_url):
-        with zipfile.ZipFile(local_url, "r") as zip_ref:
+    if zipfile.is_zipfile(out_path) and path.endswith(".zip"):
+        temp_path = out_path + ".zip"
+        os.rename(out_path, temp_path)
+        with zipfile.ZipFile(temp_path, "r") as zip_ref:
             zip_ref.extractall(out_path)
         # Clean up zip
-        os.remove(local_url)
-    else:
-        os.rename(local_url, out_path)
+        os.remove(temp_path)
 
     return out_path
 
 
 def _download_cached(
     path: str, recursive: bool = False, local_cache_path: str = LOCAL_CACHE
 ) -> str:
```

## modulus/utils/generative/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -30,15 +32,14 @@
     format_time_brief,
     get_dtype_and_ctype,
     get_module_dir_by_obj_name,
     get_module_from_obj_name,
     get_obj_by_name,
     get_obj_from_module,
     get_top_level_function_name,
-    is_pickleable,
     is_top_level_function,
     list_dir_recursively_with_ignore,
     named_params_and_buffers,
     params_and_buffers,
     parse_int_list,
     print_module_summary,
     profiled_function,
```

## modulus/utils/generative/sampler.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/generative/utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,17 +19,15 @@
 
 import contextlib
 import ctypes
 import datetime
 import fnmatch
 import importlib
 import inspect
-import io
 import os
-import pickle
 import re
 import shutil
 import sys
 import types
 import warnings
 from typing import Any, List, Tuple, Union
 
@@ -203,23 +203,14 @@
         raise ValueError(
             "Numpy and ctypes types for '{}' have different sizes!".format(type_str)
         )
 
     return my_dtype, my_ctype
 
 
-def is_pickleable(obj: Any) -> bool:  # TODO remove  # pragma: no cover
-    try:
-        with io.BytesIO() as stream:
-            pickle.dump(obj, stream)
-        return True
-    except:
-        return False
-
-
 # Functionality to import modules/objects by name, and call functions by name
 # -------------------------------------------------------------------------------------
 
 
 def get_module_from_obj_name(
     obj_name: str,
 ) -> Tuple[types.ModuleType, str]:  # pragma: no cover
```

## modulus/utils/graphcast/__init__.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/graphcast/data_utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/graphcast/graph.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/graphcast/graph_utils.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/graphcast/icospheres.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## modulus/utils/graphcast/loss.py

```diff
@@ -1,8 +1,10 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

## Comparing `modulus/experimental/datapipes/climate/climate_hdf5.py` & `modulus/datapipes/climate/climate.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,475 +1,602 @@
-# Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
+# SPDX-FileCopyrightText: All rights reserved.
+# SPDX-License-Identifier: Apache-2.0
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
+import json
+from abc import ABC, abstractmethod
 from datetime import datetime, timedelta
+from itertools import chain
 
 import h5py
 import netCDF4 as nc
 import numpy as np
+import scipy
 import torch
 
 try:
     import nvidia.dali as dali
     import nvidia.dali.plugin.pytorch as dali_pth
 except ImportError:
     raise ImportError(
         "DALI dataset requires NVIDIA DALI package to be installed. "
         + "The package can be installed at:\n"
         + "https://docs.nvidia.com/deeplearning/dali/user-guide/docs/installation.html"
     )
 
 from dataclasses import dataclass
 from pathlib import Path
-from typing import Iterable, List, Tuple, Union
+from typing import Callable, Iterable, List, Mapping, Tuple, Union
 
+from modulus.datapipes.climate.utils.invariant import latlon_grid
+from modulus.datapipes.climate.utils.zenith_angle import cos_zenith_angle
 from modulus.datapipes.datapipe import Datapipe
 from modulus.datapipes.meta import DatapipeMetaData
-from modulus.experimental.datapipes.climate.utils.zenith_angle import cos_zenith_angle
+from modulus.launch.logging import PythonLogger
 
 Tensor = torch.Tensor
 
 
 @dataclass
 class MetaData(DatapipeMetaData):
-    name: str = "ClimateHDF5"
+    name: str = "Climate"
     # Optimization
     auto_device: bool = True
     cuda_graphs: bool = True
     # Parallel
     ddp_sharding: bool = True
 
 
-class ClimateHDF5Datapipe(Datapipe):
+class ClimateDataSourceSpec:
     """
-    A Climate DALI data pipeline for HDF5 files. This pipeline loads data from
-    HDF5 files, which can include latitude, longitude, cosine of the solar zenith
-    angle, geopotential, and land sea mask if specified. Additionally, it normalizes
-    the data if a statistics file is provided. The pipeline returns a dictionary
-    with the following structure:
+    A data source specification for ClimateDatapipe.
 
-    - `state_seq`: Tensor of shape (batch_size, num_steps, num_channels, height,
-      width). This sequence is drawn from the HDF5 file and normalized if a
-      statistics file is provided.
-    - `timestamps`: Tensor of shape (batch_size, num_steps), containing
-      timestamps for each timestep in the sequence.
-    - `land_sea_mask`: Tensor of shape (batch_size, 1, height, width),
-      containing the land sea mask if a path to a land sea mask file is
-      provided.
-    - `geopotential`: Tensor of shape (batch_size, 1, height, width), containing
-      geopotential if a path to a geopotential file is provided.
-    - `latlon`: Tensor of shape (batch_size, 2, height, width), containing
-      latitude and longitude meshgrid if specified.
-    - `cos_latlon`: Tensor of shape (batch_size, 3, height, width), containing
-      `[cos(lat), sin(lon), cos(lon)]` if specified. This is required by many
-      neural climate models.
-    - `cos_zenith`: Tensor of shape (batch_size, num_steps, 1, height, width),
-      containing the cosine of the solar zenith angle if specified.
-
-    To use this data pipeline, your data directory must be structured as
-    follows:
-    ```
-     data_dir
-        1980.h5
-        1981.h5
-        1982.h5
-        ...
-        2020.h5
-     stats_dir
-    
-     global_means.npy
-    
-     global_stds.npy
-    ```
-    The HDF5 files should contain the following variable
-    with the corresponding name:
+    HDF5 files should contain the following variable with the corresponding
+    name:
     - `fields`: Tensor of shape (num_timesteps, num_channels, height, width),
       containing climate data. The order of the channels should match the order
       of the channels in the statistics files. The statistics files should be
       `.npy` files with the shape (1, num_channels, 1, 1).
+    The names of the variables are found in the metadata file found in
+    `metadata_path`.
 
-    This pipeline assumes the HDF5 files have no metadata, such as timestamps.
-    Because of this, it's important to specify the `dt` parameter and the
-    `start_year` parameter so that the pipeline can compute the correct
-    timestamps for each timestep. These timestamps are then used to compute the
-    cosine of the solar zenith angle, if specified.
+    NetCDF4 files should contain a variable of shape
+    (num_timesteps, height, width) for each variable they provide. Only the
+    variables listed in `variables` will be loaded.
 
     Parameters
     ----------
     data_dir : str
         Directory where climate data is stored
-    stats_dir : Union[str, None], optional
-        Directory to data statistic numpy files for normalization, if None, no normalization
-        will be used, by default None
+    name: Union[str, None], optional
+        The name that is used to label datapipe outputs from this source.
+        If None, the datapipe uses the number of the source in sequential order.
+    file_type: str
+        Type of files to read, supported values are "hdf5" (default) and "netcdf4"
+    stats_files: Union[Mapping[str, str], None], optional
+        Numpy files to data statistics for normalization. Supports either a channels
+        format, in which case the dict should contain the keys "mean" and "std", or a
+        named-variable format, in which case the dict should contain the key "norm" .
+        If None, no normalization will be used, by default None
+    metadata_path: Union[Mapping[str, str], None], optional for NetCDF, required for HDF5
+        Path to the metadata JSON file for the dataset (usually called data.json).
     channels : Union[List[int], None], optional
         Defines which climate variables to load, if None will use all in HDF5 file, by default None
-    batch_size : int, optional
-        Batch size, by default 1
+    variables: Union[List[str], None], optional for HDF5 files, mandatory for NetCDF4 files
+        List of named variables to load. Variables will be read in the order specified
+        by this parameter. Must be used for NetCDF4 files. Supported for HDF5 files
+        in which case it will override `channels`.
+    use_cos_zenith: bool, optional
+        If True, the cosine zenith angles corresponding to the coordinates of this
+        data source will be produced, default False
+    aux_variables : Union[Mapping[str, Callable], None], optional
+        A dictionary mapping strings to callables that accept arguments
+        (timestamps: numpy.ndarray, latlon: numpy.ndarray). These define any auxiliary
+        variables returned from this source.
+    num_steps : int, optional
+        Number of timesteps to return, by default 1
     stride : int, optional
         Number of steps between input and output variables. For example, if the dataset
         contains data at every 6 hours, a stride 1 = 6 hour delta t and
         stride 2 = 12 hours delta t, by default 1
-    dt : float, optional
-        Time in hours between each timestep in the dataset, by default 6 hr
-    start_year : int, optional
-        Start year of dataset, by default 1980
-    num_steps : int, optional
-        Number of timesteps to return, by default 2 (1 for input, 1 for output)
-    lsm_filename : str, optional
-        Path to land sea mask file, by default None
-    geopotential_filename : str, optional
-        Path to geopotential file, by default None
-    use_latlon : bool, optional
-        Include latitude and longitude meshgrid, by default False
-    use_cos_zenith : bool, optional
-        Include cosine of the solar zenith angle, by default False. If True then latitude and longitude
-        will also be computed.
-    latlon_lower_bound : Tuple[float, float], optional
-        Lower bound of latitude and longitude, by default (-90, -180)
-    patch_size : Union[Tuple[int, int], int, None], optional
-        If specified, crops input and output variables so image dimensions are
-        divisible by patch_size, by default None
-    num_samples_per_year : int, optional
-        Number of samples randomly taken from each year. If None, all will be use, by default None
-    shuffle : bool, optional
-        Shuffle dataset, by default True
-    num_workers : int, optional
-        Number of workers, by default 1
-    device: Union[str, torch.device], optional
-        Device for DALI pipeline to run on, by default cuda
-    process_rank : int, optional
-        Rank ID of local process, by default 0
-    world_size : int, optional
-        Number of training processes, by default 1
     """
 
     def __init__(
         self,
         data_dir: str,
-        stats_dir: Union[str, None] = None,
+        name: Union[str, None] = None,
+        file_type: str = "hdf5",
+        stats_files: Union[Mapping[str, str], None] = None,
+        metadata_path: Union[str, None] = None,
         channels: Union[List[int], None] = None,
-        batch_size: int = 1,
-        stride: int = 1,
-        dt: float = 6.0,
-        start_year: int = 1980,
-        num_steps: int = 2,
-        lsm_filename: str = None,
-        geopotential_filename: str = None,
-        use_latlon: bool = False,
+        variables: Union[List[str], None] = None,
         use_cos_zenith: bool = False,
-        latlon_lower_bound: Tuple[float, float] = (-90, -180),
-        patch_size: Union[Tuple[int, int], int, None] = None,
-        num_samples_per_year: Union[int, None] = None,
-        shuffle: bool = True,
-        num_workers: int = 1,
-        device: Union[str, torch.device] = "cuda",
-        process_rank: int = 0,
-        world_size: int = 1,
+        aux_variables: Union[Mapping[str, Callable], None] = None,
+        num_steps: int = 1,
+        stride: int = 1,
     ):
-        super().__init__(meta=MetaData())
-        self.batch_size = batch_size
-        self.num_workers = num_workers
-        self.shuffle = shuffle
         self.data_dir = Path(data_dir)
-        self.stats_dir = Path(stats_dir) if stats_dir is not None else None
+        self.name = name
+        self.file_type = file_type
+        self.stats_files = (
+            {k: Path(fn) for (k, fn) in stats_files.items()}
+            if stats_files is not None
+            else None
+        )
+        self.metadata_path = Path(metadata_path) if metadata_path is not None else None
         self.channels = channels
-        self.stride = stride
-        self.dt = dt
-        self.start_year = start_year
-        self.num_steps = num_steps
-        self.lsm_filename = lsm_filename
-        self.geopotential_filename = geopotential_filename
-        if use_cos_zenith:
-            use_latlon = True
-        self.use_latlon = use_latlon
+        self.variables = variables
         self.use_cos_zenith = use_cos_zenith
-        self.latlon_lower_bound = latlon_lower_bound
-        self.process_rank = process_rank
-        self.world_size = world_size
-        if isinstance(patch_size, int):
-            patch_size = (patch_size, patch_size)
-        self.patch_size = patch_size
-        self.num_samples_per_year = num_samples_per_year
-
-        # Determine outputs of pipeline
-        self.pipe_outputs = ["state_seq", "timestamps"]
-        if self.lsm_filename is not None:
-            self.pipe_outputs.append("land_sea_mask")
-        if self.geopotential_filename is not None:
-            self.pipe_outputs.append("geopotential")
-        if self.use_latlon:
-            self.pipe_outputs.append("latlon")
-            self.pipe_outputs.append("cos_latlon")
-        if self.use_cos_zenith:
-            self.pipe_outputs.append("cos_zenith")
-
-        # Set up device, needed for pipeline
-        if isinstance(device, str):
-            device = torch.device(device)
+        self.aux_variables = aux_variables if aux_variables is not None else {}
+        self.num_steps = num_steps
+        self.stride = stride
+        self.logger = PythonLogger()
 
-        # Need a index id if cuda
-        if device.type == "cuda" and device.index is None:
-            device = torch.device("cuda:0")
-        self.device = device
+        if file_type == "netcdf4" and not variables:
+            raise ValueError("Variables must be specified for a NetCDF4 source.")
 
         # check root directory exists
         if not self.data_dir.is_dir():
             raise IOError(f"Error, data directory {self.data_dir} does not exist")
-        if self.stats_dir is not None and not self.stats_dir.is_dir():
-            raise IOError(f"Error, stats directory {self.stats_dir} does not exist")
-        if self.stats_dir is None:
+        if self.stats_files is None:
             self.logger.warning(
-                "Warning, no stats directory specified, this will result in no normalisation"
+                "Warning, no stats files specified, this will result in no normalisation"
             )
 
-        # Load all data files and statistics
-        self._parse_dataset_files()
-        self._load_statistics()
-        if self.lsm_filename is not None:
-            self._load_land_sea_mask()
-        if self.geopotential_filename is not None:
-            self._load_geopotential()
-        if self.use_latlon:
-            self._load_latlon()
-
-        # Create pipeline
-        self.pipe = self._create_pipeline()
+    def dimensions_compatible(self, other) -> bool:
+        """
+        Basic sanity check to test if two `ClimateDataSourceSpec` are
+        compatible.
+        """
+        return (
+            self.data_shape == other.data_shape
+            and self.cropped_data_shape == other.cropped_data_shape
+            and self.num_samples_per_year == other.num_samples_per_year
+            and self.total_length == other.total_length
+            and self.n_years == other.n_years
+        )
 
-    def _parse_dataset_files(self) -> None:
-        """Parses the data directory for valid HDF5 files and determines training samples
+    def parse_dataset_files(
+        self,
+        num_samples_per_year: Union[int, None] = None,
+        patch_size: Union[int, None] = None,
+    ) -> None:
+        """Parses the data directory for valid files and determines training samples
+
+        Parameters
+        ----------
+        num_samples_per_year : int, optional
+            Number of samples taken from each year. If None, all will be used, by default None
+        patch_size : Union[Tuple[int, int], int, None], optional
+            If specified, crops input and output variables so image dimensions are
+            divisible by patch_size, by default None
 
         Raises
         ------
         ValueError
             In channels specified or number of samples per year is not valid
         """
         # get all input data files
-        self.data_paths = sorted(self.data_dir.glob("*.h5"))
+        suffix = {"hdf5": "h5", "netcdf4": "nc"}[self.file_type]
+        self.data_paths = sorted(self.data_dir.glob(f"*.{suffix}"))
         for data_path in self.data_paths:
-            self.logger.info(f"Climate file found: {data_path}")
+            self.logger.info(f"Climate data file found: {data_path}")
         self.n_years = len(self.data_paths)
         self.logger.info(f"Number of years: {self.n_years}")
 
         # get total number of examples and image shape from the first file,
         # assuming other files have exactly the same format.
         self.logger.info(f"Getting file stats from {self.data_paths[0]}")
-        with h5py.File(self.data_paths[0], "r") as f:
-            # truncate the dataset to avoid out-of-range sampling
-            data_samples_per_year = (
-                f["fields"].shape[0] - (self.num_steps - 1) * self.stride
-            )
-            self.data_shape = f["fields"].shape[2:]
-
-            # If channels not provided, use all of them
-            if self.channels is None:
-                self.channels = [i for i in range(f["fields"].shape[1])]
-
-            # If num_samples_per_year use all
-            if self.num_samples_per_year is None:
-                self.num_samples_per_year = data_samples_per_year
-
-            # Adjust image shape if patch_size defined
-            if self.patch_size is not None:
-                self.cropped_data_shape = [
-                    s - s % self.patch_size[i] for i, s in enumerate(self.data_shape)
-                ]
+        if self.file_type == "hdf5":
+            with h5py.File(self.data_paths[0], "r") as f:
+                dataset_shape = f["fields"].shape
+        else:
+            with nc.Dataset(self.data_paths[0], "r") as f:
+                var_shape = f[self.variables[0]].shape
+                dataset_shape = (var_shape[0], len(self.variables)) + var_shape[1:]
+
+        # truncate the dataset to avoid out-of-range sampling
+        data_samples_per_year = dataset_shape[0] - (self.num_steps - 1) * self.stride
+        self.data_shape = dataset_shape[2:]
+
+        # interpret list of variables into list of channels or vice versa
+        if self.file_type == "hdf5":
+            with open(self.metadata_path, "r") as f:
+                metadata = json.load(f)
+            data_vars = metadata["coords"]["channel"]
+            if self.variables is not None:
+                self.channels = [data_vars.index(v) for v in self.variables]
             else:
-                self.cropped_data_shape = self.data_shape
-            self.logger.info(f"Input data shape: {self.cropped_data_shape}")
+                if self.channels is None:
+                    self.variables = data_vars
+                else:
+                    self.variables = [data_vars[i] for i in self.channels]
+
+        # If channels not provided, use all of them
+        if self.channels is None:
+            self.channels = list(range(dataset_shape[1]))
+
+        # If num_samples_per_year use all
+        if num_samples_per_year is None:
+            num_samples_per_year = data_samples_per_year
+        self.num_samples_per_year = num_samples_per_year
 
-            # Get total length
-            self.total_length = self.n_years * self.num_samples_per_year
+        # Adjust image shape if patch_size defined
+        if patch_size is not None:
+            self.cropped_data_shape = tuple(
+                s - s % patch_size[i] for i, s in enumerate(self.data_shape)
+            )
+        else:
+            self.cropped_data_shape = self.data_shape
+        self.logger.info(f"Input data shape: {self.cropped_data_shape}")
+
+        # Get total length
+        self.total_length = self.n_years * self.num_samples_per_year
+
+        # Sanity checks
+        print(self.channels, dataset_shape)
+        if max(self.channels) >= dataset_shape[1]:
+            raise ValueError(
+                f"Provided channel has indexes greater than the number \
+            of fields {dataset_shape[1]}"
+            )
 
-            # Sanity checks
-            if max(self.channels) >= f["fields"].shape[1]:
-                raise ValueError(
-                    f"Provided channel has indexes greater than the number \
-                of fields {f['fields'].shape[1]}"
-                )
+        if self.num_samples_per_year > data_samples_per_year:
+            raise ValueError(
+                f"num_samples_per_year ({self.num_samples_per_year}) > number of \
+                samples available ({data_samples_per_year})!"
+            )
 
-            if self.num_samples_per_year > data_samples_per_year:
-                raise ValueError(
-                    f"num_samples_per_year ({self.num_samples_per_year}) > number of \
-                    samples available ({data_samples_per_year})!"
-                )
+        self._load_statistics()
 
-            self.logger.info(f"Number of samples/year: {self.num_samples_per_year}")
-            self.logger.info(f"Number of channels available: {f['fields'].shape[1]}")
+        self.logger.info(f"Number of samples/year: {self.num_samples_per_year}")
+        self.logger.info(f"Number of channels available: {dataset_shape[1]}")
 
     def _load_statistics(self) -> None:
         """Loads climate statistics from pre-computed numpy files
 
         The statistic files should be of name global_means.npy and global_std.npy with
         a shape of [1, C, 1, 1] located in the stat_dir.
 
         Raises
         ------
         IOError
-            If mean or std numpy files are not found
+            If statistics files are not found
         AssertionError
             If loaded numpy arrays are not of correct size
         """
-        # If no stats dir we just skip loading the stats
-        if self.stats_dir is None:
+        # If no stats files we just skip loading the stats
+        if self.stats_files is None:
             self.mu = None
             self.std = None
             return
         # load normalisation values
-        mean_stat_file = self.stats_dir / Path("global_means.npy")
-        std_stat_file = self.stats_dir / Path("global_stds.npy")
-
-        if not mean_stat_file.exists():
-            raise IOError(f"Mean statistics file {mean_stat_file} not found")
-        if not std_stat_file.exists():
-            raise IOError(f"Std statistics file {std_stat_file} not found")
-
-        # has shape [1, C, 1, 1]
-        self.mu = np.load(str(mean_stat_file))[:, self.channels]
-        # has shape [1, C, 1, 1]
-        self.sd = np.load(str(std_stat_file))[:, self.channels]
+        if set(self.stats_files) == {"mean", "std"}:  # use mean and std files
+            mean_stat_file = self.stats_files["mean"]
+            std_stat_file = self.stats_files["std"]
+
+            if not mean_stat_file.exists():
+                raise IOError(f"Mean statistics file {mean_stat_file} not found")
+            if not std_stat_file.exists():
+                raise IOError(f"Std statistics file {std_stat_file} not found")
+
+            # has shape [1, C, 1, 1]
+            self.mu = np.load(str(mean_stat_file))[:, self.channels]
+            # has shape [1, C, 1, 1]
+            self.sd = np.load(str(std_stat_file))[:, self.channels]
+        elif set(self.stats_files) == {
+            "norm",
+        }:  # use dict formatted file with named variables
+            norm_stat_file = self.stats_files["norm"]
+            if not norm_stat_file.exists():
+                raise IOError(f"Statistics file {norm_stat_file} not found")
+
+            norm = np.load(str(norm_stat_file), allow_pickle=True).item()
+            mu = np.array([norm[var]["mean"] for var in self.variables])
+            self.mu = mu.reshape((1, len(mu), 1, 1))
+            sd = np.array([norm[var]["std"] for var in self.variables])
+            self.sd = sd.reshape((1, len(sd), 1, 1))
+        else:
+            raise ValueError(("Invalid statistics file specification"))
 
         if not self.mu.shape == self.sd.shape == (1, len(self.channels), 1, 1):
-            raise AssertionError("Error, normalisation arrays have wrong shape")
+            raise ValueError("Error, normalisation arrays have wrong shape")
+
+
+class ClimateDatapipe(Datapipe):
+    """
+    A Climate DALI data pipeline. This pipeline loads data from
+    HDF5/NetCDF4 files. It can also return additional data such as the
+    solar zenith angle for each time step. Additionally, it normalizes
+    the data if a statistics file is provided. The pipeline returns a dictionary
+    with the following structure, where {name} indicates the name of the data
+    source provided:
 
-    def _load_land_sea_mask(self) -> None:
-        """Load land-sea mask from netCDF file."""
-        ds = nc.Dataset(self.lsm_filename)
-        lsm = np.array(ds["lsm"]).astype(np.float32)
-        lsm = np.flip(
-            lsm, axis=1
-        )  # flip latitude axis, TODO hacky fix and we should get this from the file
-        if lsm.shape[1:] != self.data_shape:
-            raise AssertionError(
-                "Land-sea mask shape {lsm.shape} does not match data shape {self.data_shape}"
+    - `state_seq-{name}`: Tensors of shape
+      (batch_size, num_steps, num_channels, height, width).
+      This sequence is drawn from the data file and normalized if a
+      statistics file is provided.
+    - `timestamps-{name}`: Tensors of shape (batch_size, num_steps), containing
+      timestamps for each timestep in the sequence.
+    - `{aux_variable}-{name}`: Tensors of shape
+      (batch_size, num_steps, aux_channels, height, width),
+      containing the auxiliary variables returned by each data source
+    - `cos_zenith-{name}`: Tensors of shape (batch_size, num_steps, 1, height, width),
+      containing the cosine of the solar zenith angle if specified.
+    - `{invariant_name}: Tensors of shape (batch_size, invariant_channels, height, width),
+      containing the time-invariant data (depending only on spatial coordinates)
+      returned by the datapipe. These can include e.g.
+      land-sea mask and geopotential/surface elevation.
+
+    To use this data pipeline, your data directory must be structured as
+    follows:
+    ```
+    data_dir
+     1980.h5
+     1981.h5
+     1982.h5
+     ...
+     2020.h5
+    ```
+
+    The files are assumed have no metadata, such as timestamps.
+    Because of this, it's important to specify the `dt` parameter and the
+    `start_year` parameter so that the pipeline can compute the correct
+    timestamps for each timestep. These timestamps are then used to compute the
+    cosine of the solar zenith angle, if specified.
+
+    Parameters
+    ----------
+    sources: Iterable[ClimateDataSpec]
+        A list of data specifications defining the sources for the climate variables
+    batch_size : int, optional
+        Batch size, by default 1
+    dt : float, optional
+        Time in hours between each timestep in the dataset, by default 6 hr
+    start_year : int, optional
+        Start year of dataset, by default 1980
+    latlon_bounds : Tuple[Tuple[float, float], Tuple[float, float]], optional
+        Bounds of latitude and longitude in the data, in the format
+        ((lat_start, lat_end,), (lon_start, lon_end)).
+        By default ((90, -90), (0, 360)).
+    crop_window: Union[Tuple[Tuple[float, float], Tuple[float, float]], None], optional
+        The window to crop the data to, in the format ((i0,i1), (j0,j1)) where the
+        first spatial dimension will be cropped to i0:i1 and the second to j0:j1.
+        If not given, all data will be used.
+    invariants : Mapping[str,Callable], optional
+        Specifies the time-invariant data (for example latitude and longitude)
+        included in the data samples. Should be a dict where the keys are the
+        names of the invariants and the values are the corresponding
+        functions. The functions need to accept an argument of the shape
+        (2, data_shape[0], data_shape[1]) where the first dimension contains
+        latitude and longitude in degrees and the other dimensions corresponding
+        to the shape of data in the data files. For example,
+        invariants={"trig_latlon": invariants.LatLon()}
+        will include the sin/cos of lat/lon in the output.
+    num_samples_per_year : int, optional
+        Number of samples taken from each year. If None, all will be used, by default None
+    shuffle : bool, optional
+        Shuffle dataset, by default True
+    num_workers : int, optional
+        Number of workers, by default 1
+    device: Union[str, torch.device], optional
+        Device for DALI pipeline to run on, by default cuda
+    process_rank : int, optional
+        Rank ID of local process, by default 0
+    world_size : int, optional
+        Number of training processes, by default 1
+    """
+
+    def __init__(
+        self,
+        sources: Iterable[ClimateDataSourceSpec],
+        batch_size: int = 1,
+        dt: float = 6.0,
+        start_year: int = 1980,
+        latlon_bounds: Tuple[Tuple[float, float], Tuple[float, float]] = (
+            (90, -90),
+            (0, 360),
+        ),
+        crop_window: Union[
+            Tuple[Tuple[float, float], Tuple[float, float]], None
+        ] = None,
+        invariants: Union[Mapping[str, Callable], None] = None,
+        num_samples_per_year: Union[int, None] = None,
+        shuffle: bool = True,
+        num_workers: int = 1,  # TODO: is there a faster good default?
+        device: Union[str, torch.device] = "cuda",
+        process_rank: int = 0,
+        world_size: int = 1,
+    ):
+        super().__init__(meta=MetaData())
+        self.sources = list(sources)
+        self.batch_size = batch_size
+        self.num_workers = num_workers
+        self.shuffle = shuffle
+        self.dt = dt
+        self.start_year = start_year
+        self.data_latlon_bounds = latlon_bounds
+        self.process_rank = process_rank
+        self.world_size = world_size
+        self.num_samples_per_year = num_samples_per_year
+        self.logger = PythonLogger()
+
+        if invariants is None:
+            invariants = {}
+
+        # Determine outputs of pipeline
+        self.pipe_outputs = []
+        for (i, spec) in enumerate(self.sources):
+            name = spec.name if spec.name is not None else i
+            self.pipe_outputs += [f"state_seq-{name}", f"timestamps-{name}"]
+            self.pipe_outputs.extend(
+                f"{aux_var}-{name}" for aux_var in spec.aux_variables
             )
-        lsm = lsm[:, : self.cropped_data_shape[0], : self.cropped_data_shape[1]]
-        self.lsm = dali.types.Constant(lsm)
+            if spec.use_cos_zenith:
+                self.pipe_outputs.append(f"cos_zenith-{name}")
+        self.pipe_outputs.extend(invariants.keys())
+
+        # Set up device, needed for pipeline
+        if isinstance(device, str):
+            device = torch.device(device)
+
+        # Need a index id if cuda
+        if device.type == "cuda" and device.index is None:
+            device = torch.device("cuda:0")
+        self.device = device
 
-    def _load_geopotential(self, normalize: bool = True) -> None:
-        """Get geopotential from netCDF file."""
-        ds = nc.Dataset(self.geopotential_filename)
-        geop = np.array(ds["z"]).astype(np.float32)
-        geop = np.flip(
-            geop, axis=1
-        )  # flip latitude axis, TODO hacky fix and we should get this from the file
-        if geop.shape[1:] != self.data_shape:
-            raise AssertionError(
-                f"Geopotential shape {geop.shape} does not match data shape {self.data_shape}"
+        # Load all data files and statistics
+        for spec in sources:
+            spec.parse_dataset_files(num_samples_per_year=num_samples_per_year)
+        for (i, spec_i) in enumerate(sources):
+            for spec_j in sources[i + 1 :]:
+                if not spec_i.dimensions_compatible(spec_j):
+                    raise ValueError("Incompatible data sources")
+
+        self.data_latlon = np.stack(
+            latlon_grid(bounds=self.data_latlon_bounds, shape=sources[0].data_shape),
+            axis=0,
+        )
+        if crop_window is None:
+            crop_window = (
+                (0, sources[0].cropped_data_shape[0]),
+                (0, sources[0].cropped_data_shape[1]),
             )
-        geop = geop[:, : self.cropped_data_shape[0], : self.cropped_data_shape[1]]
-        if normalize:
-            geop = (geop - geop.mean()) / geop.std()
-        self.geopotential = dali.types.Constant(geop)
-
-    def _load_latlon(self) -> None:
-        """Load latitude and longitude coordinates from data shape and compute cos/sin versions."""
-
-        # get latitudes and longitudes from data shape
-        lat = np.linspace(
-            self.latlon_lower_bound[0],
-            self.latlon_lower_bound[0] + 180,
-            self.cropped_data_shape[0],
-        ).astype(np.float32)
-        lon = np.linspace(
-            self.latlon_lower_bound[1],
-            self.latlon_lower_bound[1] + 360,
-            self.cropped_data_shape[1] + 1,
-        ).astype(np.float32)[1:]
-        lat, lon = np.meshgrid(lat, lon, indexing="ij")
-        self.latlon = dali.types.Constant(np.stack((lat, lon), axis=0))
-
-        # cos/sin latitudes and longitudes
-        cos_lat = np.cos(np.deg2rad(lat))
-        sin_lon = np.sin(np.deg2rad(lon))
-        cos_lon = np.cos(np.deg2rad(lon))
-        self.cos_latlon = dali.types.Constant(
-            np.stack((cos_lat, sin_lon, cos_lon), axis=0)
+        self.crop_window = crop_window
+        self.window_latlon = self._crop_to_window(self.data_latlon)
+        self.window_latlon_dali = dali.types.Constant(self.window_latlon)
+
+        # load invariants
+        self.invariants = {
+            var: callback(self.window_latlon) for (var, callback) in invariants.items()
+        }
+
+        # Create pipeline
+        self.pipe = self._create_pipeline()
+
+    def _source_cls_from_type(self, source_type: str) -> type:
+        """Get the external source class based on a string descriptor."""
+        return {
+            "hdf5": ClimateHDF5DaliExternalSource,
+            "netcdf4": ClimateNetCDF4DaliExternalSource,
+        }[source_type]
+
+    def _crop_to_window(self, x):
+        cw = self.crop_window
+        if isinstance(x, dali.pipeline.DataNode):
+            # DALI doesn't support ellipsis notation
+            return x[:, :, cw[0][0] : cw[0][1], cw[1][0] : cw[1][1]]
+        else:
+            return x[..., cw[0][0] : cw[0][1], cw[1][0] : cw[1][1]]
+
+    def _source_outputs(self, spec: ClimateDataSourceSpec) -> List:
+        """Create DALI outputs for a given data source specification.
+
+        Parameters
+        ----------
+        spec: ClimateDataSourceSpec
+            The data source specification.
+        """
+        # HDF5/NetCDF source
+        source_cls = self._source_cls_from_type(spec.file_type)
+        source = source_cls(
+            data_paths=spec.data_paths,
+            num_samples=spec.total_length,
+            channels=spec.channels,
+            latlon=self.data_latlon,
+            variables=spec.variables,
+            aux_variables=spec.aux_variables,
+            stride=spec.stride,
+            dt=self.dt,
+            start_year=self.start_year,
+            num_steps=spec.num_steps,
+            num_samples_per_year=spec.num_samples_per_year,
+            batch_size=self.batch_size,
+            shuffle=self.shuffle,
+            process_rank=self.process_rank,
+            world_size=self.world_size,
+        )
+
+        # Update length of dataset
+        self.total_length = len(source) // self.batch_size
+
+        # Read current batch
+        (state_seq, timestamps, *aux) = dali.fn.external_source(
+            source,
+            num_outputs=source.num_outputs(),
+            parallel=True,
+            batch=False,
         )
 
+        # Crop
+        state_seq = self._crop_to_window(state_seq)
+        aux = (self._crop_to_window(x) for x in aux)
+
+        # Normalize
+        if spec.stats_files is not None:
+            state_seq = dali.fn.normalize(state_seq, mean=spec.mu, stddev=spec.sd)
+
+        # Make output list
+        outputs = [state_seq, timestamps, *aux]
+
+        # Get cosine zenith angle
+        if spec.use_cos_zenith:
+            cos_zenith = dali.fn.cast(
+                cos_zenith_angle(timestamps, latlon=self.window_latlon_dali),
+                dtype=dali.types.FLOAT,
+            )
+            outputs.append(cos_zenith)
+
+        return outputs
+
+    def _invariant_outputs(self):
+        for inv in self.invariants.values():
+            if self.crop_window is not None:
+                inv = self._crop_to_window(inv)
+            yield dali.types.Constant(inv)
+
     def _create_pipeline(self) -> dali.Pipeline:
         """Create DALI pipeline
 
         Returns
         -------
         dali.Pipeline
-            HDF5 DALI pipeline
+            Climate DALI pipeline
         """
         pipe = dali.Pipeline(
             batch_size=self.batch_size,
             num_threads=2,
             prefetch_queue_depth=2,
             py_num_workers=self.num_workers,
             device_id=self.device.index,
             py_start_method="spawn",
         )
 
         with pipe:
-            # HDF5 source
-            source = ClimateDaliExternalSource(
-                data_paths=self.data_paths,
-                num_samples=self.total_length,
-                channels=self.channels,
-                stride=self.stride,
-                dt=self.dt,
-                start_year=self.start_year,
-                num_steps=self.num_steps,
-                num_samples_per_year=self.num_samples_per_year,
-                batch_size=self.batch_size,
-                shuffle=self.shuffle,
-                process_rank=self.process_rank,
-                world_size=self.world_size,
-            )
-
-            # Update length of dataset
-            self.total_length = len(source) // self.batch_size
-
-            # Read current batch
-            state_seq, timestamps = dali.fn.external_source(
-                source,
-                num_outputs=2,
-                parallel=True,
-                batch=False,
+            # Concatenate outputs from all sources as well as invariants
+            outputs = list(
+                chain(
+                    *(self._source_outputs(spec) for spec in self.sources),
+                    self._invariant_outputs(),
+                )
             )
 
-            # Crop
-            h, w = self.cropped_data_shape
-            state_seq = state_seq[:, :, :h, :w]
-
-            # Normalize
-            if self.stats_dir is not None:
-                state_seq = dali.fn.normalize(state_seq, mean=self.mu, stddev=self.sd)
-
-            # Make output list
-            outputs = [state_seq, timestamps]
-
-            # Get static inputs
-            if self.lsm_filename is not None:
-                outputs.append(self.lsm)
-            if self.geopotential_filename is not None:
-                outputs.append(self.geopotential)
-            if self.use_latlon:
-                outputs.append(self.latlon)
-                outputs.append(self.cos_latlon)
-
-            # Get cosine zenith angle
-            if self.use_cos_zenith:
-                cos_zenith = cos_zenith_angle(timestamps, latlon=self.latlon)
-                outputs.append(cos_zenith)
-
             if self.device.type == "cuda":
                 # Move tensors to GPU as external_source won't do that
                 outputs = [o.gpu() for o in outputs]
 
             # Set outputs
             pipe.set_outputs(*outputs)
 
@@ -481,31 +608,42 @@
         # Create DALI PyTorch iterator.
         return dali_pth.DALIGenericIterator([self.pipe], self.pipe_outputs)
 
     def __len__(self):
         return self.total_length
 
 
-class ClimateDaliExternalSource:
-    """DALI Source for lazy-loading the HDF5 climate files
+class ClimateDaliExternalSource(ABC):
+    """DALI Source for lazy-loading the HDF5/NetCDF4 climate files
 
     Parameters
     ----------
     data_paths : Iterable[str]
         Directory where climate data is stored
     num_samples : int
         Total number of training samples
     channels : Iterable[int]
         List representing which climate variables to load
-    stride : int
-        Number of steps between input and output variables
     num_steps : int
         Number of timesteps to load
+    stride : int
+        Number of steps between input and output variables
+    dt : float, optional
+        Time in hours between each timestep in the dataset, by default 6 hr
+    start_year : int, optional
+        Start year of dataset, by default 1980
     num_samples_per_year : int
         Number of samples randomly taken from each year
+    variables: Union[List[str], None], optional for HDF5 files, mandatory for NetCDF4 files
+        List of named variables to load. Variables will be read in the order specified
+        by this parameter.
+    aux_variables : Union[Mapping[str, Callable], None], optional
+        A dictionary mapping strings to callables that accept arguments
+        (timestamps: numpy.ndarray, latlon: numpy.ndarray). These define any auxiliary
+        variables returned from this source.
     batch_size : int, optional
         Batch size, by default 1
     shuffle : bool, optional
         Shuffle dataset, by default True
     process_rank : int, optional
         Rank ID of local process, by default 0
     world_size : int, optional
@@ -523,24 +661,30 @@
         num_samples: int,
         channels: Iterable[int],
         num_steps: int,
         stride: int,
         dt: float,
         start_year: int,
         num_samples_per_year: int,
+        latlon: np.ndarray,
+        variables: Union[List[str], None] = None,
+        aux_variables: List[Union[str, Callable]] = (),
         batch_size: int = 1,
         shuffle: bool = True,
         process_rank: int = 0,
         world_size: int = 1,
     ):
         self.data_paths = list(data_paths)
         # Will be populated later once each worker starts running in its own process.
-        self.data_files = None
+        self.data_files = [None] * len(self.data_paths)
         self.num_samples = num_samples
         self.chans = list(channels)
+        self.latlon = latlon
+        self.variables = variables
+        self.aux_variables = aux_variables
         self.num_steps = num_steps
         self.stride = stride
         self.dt = dt
         self.start_year = start_year
         self.num_samples_per_year = num_samples_per_year
         self.batch_size = batch_size
         self.shuffle = shuffle
@@ -551,60 +695,103 @@
         # Shard from indices if running in parallel
         self.indices = np.array_split(self.indices, world_size)[process_rank]
 
         # Get number of full batches, ignore possible last incomplete batch for now.
         # Also, DALI external source does not support incomplete batches in parallel mode.
         self.num_batches = len(self.indices) // self.batch_size
 
-    def __call__(
-        self, sample_info: dali.types.SampleInfo
-    ) -> Tuple[Tensor, Tensor, np.ndarray, np.ndarray, np.ndarray]:
+    @abstractmethod
+    def _load_sequence(self, year_idx: int, idx: int) -> np.array:
+        """Write data from year index `year_idx` and sample index `idx` to output"""
+        pass
+
+    def __call__(self, sample_info: dali.types.SampleInfo) -> Tuple[Tensor, np.ndarray]:
         if sample_info.iteration >= self.num_batches:
             raise StopIteration()
 
-        if self.data_files is None:
-            # This will be called once per worker. Workers are persistent,
-            # so there is no need to explicitly close the files - this will be done
-            # when corresponding pipeline/dataset is destroyed
-            self.data_files = [h5py.File(path, "r") for path in self.data_paths]
-
         # Shuffle before the next epoch starts
         if self.shuffle and sample_info.epoch_idx != self.last_epoch:
             # All workers use the same rng seed so the resulting
             # indices are the same across workers
             np.random.default_rng(seed=sample_info.epoch_idx).shuffle(self.indices)
             self.last_epoch = sample_info.epoch_idx
 
         # Get local indices from global index
         # TODO: This is very hacky, but it works for now
         idx = self.indices[sample_info.idx_in_epoch]
         year_idx = idx // self.num_samples_per_year
         in_idx = idx % self.num_samples_per_year
 
-        # Get data for the current year
-        data = self.data_files[year_idx]["fields"]
-
-        # Load sequence of input variables
-        state_seq = np.empty(
-            (self.num_steps, len(self.chans)) + data.shape[2:], dtype=data.dtype
-        )
-        for i in range(self.num_steps):
-            ind = in_idx + i * self.stride
-            state_seq[i] = data[ind, self.chans]
+        state_seq = self._load_sequence(year_idx, in_idx)
 
         # Load sequence of timestamps
         year = self.start_year + year_idx
+        start_time = datetime(year, 1, 1) + timedelta(hours=int(in_idx) * self.dt)
         timestamps = np.array(
             [
-                (
-                    datetime(year, 1, 1)
-                    + timedelta(hours=int(in_idx) * self.dt)
-                    + timedelta(hours=i * self.stride * self.dt)
-                ).timestamp()
+                (start_time + timedelta(hours=i * self.stride * self.dt)).timestamp()
                 for i in range(self.num_steps)
             ]
-        ).astype(np.float32)
+        )
+
+        # outputs from auxiliary sources
+        aux_outputs = (
+            callback(timestamps, self.latlon)
+            for callback in self.aux_variables.values()
+        )
 
-        return state_seq, timestamps
+        return (state_seq, timestamps, *aux_outputs)
+
+    def num_outputs(self):
+        return 2 + len(self.aux_variables)
 
     def __len__(self):
         return len(self.indices)
+
+
+class ClimateHDF5DaliExternalSource(ClimateDaliExternalSource):
+    """DALI source for reading HDF5 formatted climate data files."""
+
+    def _get_data_file(self, year_idx: int) -> h5py.File:
+        """Return the opened file for year `year_idx`."""
+        if self.data_files[year_idx] is None:
+            # This will be called once per worker. Workers are persistent,
+            # so there is no need to explicitly close the files - this will be done
+            # when corresponding pipeline/dataset is destroyed.
+            # Lazy opening avoids unnecessary file open ops when sharding.
+            self.data_files[year_idx] = h5py.File(self.data_paths[year_idx], "r")
+        return self.data_files[year_idx]
+
+    def _load_sequence(self, year_idx: int, idx: int) -> np.array:
+        # TODO: the data is returned in a weird (time, channels, width, height) shape
+        data = self._get_data_file(year_idx)["fields"]
+        return data[idx : idx + self.num_steps * self.stride : self.stride, self.chans]
+
+
+class ClimateNetCDF4DaliExternalSource(ClimateDaliExternalSource):
+    """DALI source for reading NetCDF4 formatted climate data files."""
+
+    def _get_data_file(self, year_idx: int) -> scipy.io.netcdf_file:
+        """Return the opened file for year `year_idx`."""
+        if self.data_files[year_idx] is None:
+            # This will be called once per worker. Workers are persistent,
+            # so there is no need to explicitly close the files - this will be done
+            # when corresponding pipeline/dataset is destroyed
+            # Lazy opening avoids unnecessary file open ops when sharding.
+            # NOTE: The SciPy NetCDF reader is used because the netCDF4 library
+            # was prone to crashing after many reads.
+            self.data_files[year_idx] = scipy.io.netcdf_file(self.data_paths[year_idx])
+        return self.data_files[year_idx]
+
+    def _load_sequence(self, year_idx: int, idx: int) -> np.array:
+        data_file = self._get_data_file(year_idx)
+        shape = data_file.variables[self.variables[0]].shape
+        shape = (self.num_steps, len(self.variables)) + shape[1:]
+        # TODO: this can be optimized to do the NetCDF scale/offset on GPU
+        output = np.empty(shape, dtype=np.float32)
+        for (i, var) in enumerate(self.variables):
+            output[:, i] = data_file.variables[var][
+                idx : idx + self.num_steps * self.stride : self.stride
+            ].copy()  # .copy() avoids hanging references
+            output[:, i] *= data_file.variables[var].scale_factor
+            output[:, i] += data_file.variables[var].add_offset
+        return output
```

## Comparing `modulus/experimental/datapipes/climate/utils/zenith_angle.py` & `modulus/datapipes/climate/utils/zenith_angle.py`

 * *Files 2% similar despite different names*

```diff
@@ -71,16 +71,15 @@
     lon = latlon[dali.newaxis, 1:2, :, :] * RAD_PER_DEG
     time = time[:, dali.newaxis, dali.newaxis, dali.newaxis]
     return _star_cos_zenith(time, lat, lon)
 
 
 def _days_from_2000(model_time):  # pragma: no cover
     """Get the days since year 2000."""
-    # return (model_time - DATETIME_2000) / (24.0 * 3600.0)
-    return (3600 + model_time - DATETIME_2000) / (24.0 * 3600.0)
+    return (model_time - DATETIME_2000) / (24.0 * 3600.0)
 
 
 def _greenwich_mean_sidereal_time(model_time):
     """
     Greenwich mean sidereal time, in radians.
     Reference:
         The AIAA 2006 implementation:
```

## Comparing `nvidia_modulus-0.5.0.dist-info/LICENSE.txt` & `nvidia_modulus-0.6.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `nvidia_modulus-0.5.0.dist-info/METADATA` & `nvidia_modulus-0.6.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,17 @@
 Metadata-Version: 2.1
 Name: nvidia-modulus
-Version: 0.5.0
+Version: 0.6.0
 Summary: A deep learning framework for AI-driven multi-physics systems
 Author: NVIDIA Modulus Team
 License: Apache 2.0
+Project-URL: Homepage, https://github.com/NVIDIA/modulus
+Project-URL: Documentation, https://docs.nvidia.com/modulus/#core
+Project-URL: Issues, https://github.com/NVIDIA/modulus/issues
+Project-URL: Changelog, https://github.com/NVIDIA/modulus/blob/main/CHANGELOG.md
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown
 License-File: LICENSE.txt
 Requires-Dist: torch >=2.0.0
@@ -19,28 +23,29 @@
 Requires-Dist: nvidia-dali-cuda110 >=1.16.0
 Requires-Dist: setuptools >=67.6.0
 Requires-Dist: certifi >=2023.7.22
 Requires-Dist: pytz >=2023.3
 Requires-Dist: treelib >=1.2.5
 Requires-Dist: tqdm >=4.60.0
 Requires-Dist: nvtx >=0.2.8
+Requires-Dist: onnx >=1.14.0
 Provides-Extra: all
 Requires-Dist: h5py >=3.7.0 ; extra == 'all'
 Requires-Dist: netcdf4 >=1.6.3 ; extra == 'all'
 Requires-Dist: ruamel.yaml >=0.17.22 ; extra == 'all'
 Requires-Dist: scikit-learn >=1.0.2 ; extra == 'all'
 Requires-Dist: warp-lang >=0.6.0 ; extra == 'all'
 Requires-Dist: vtk >=9.2.6 ; extra == 'all'
 Requires-Dist: pyvista >=0.40.1 ; extra == 'all'
-Requires-Dist: onnx >=1.14.0 ; extra == 'all'
 Requires-Dist: cftime >=1.6.2 ; extra == 'all'
 Requires-Dist: einops >=0.7.0 ; extra == 'all'
 Requires-Dist: pyspng >=0.1.0 ; extra == 'all'
 Requires-Dist: nvidia-modulus[launch] ; extra == 'all'
 Requires-Dist: nvidia-modulus[dev] ; extra == 'all'
+Requires-Dist: nvidia-modulus[makani] ; extra == 'all'
 Provides-Extra: dev
 Requires-Dist: pytest >=6.0.0 ; extra == 'dev'
 Requires-Dist: pyyaml >=6.0 ; extra == 'dev'
 Requires-Dist: black ==22.10.0 ; extra == 'dev'
 Requires-Dist: interrogate ==1.5.0 ; extra == 'dev'
 Requires-Dist: coverage ==6.5.0 ; extra == 'dev'
 Requires-Dist: ruff ==0.0.290 ; extra == 'dev'
@@ -48,14 +53,18 @@
 Requires-Dist: hydra-core >=1.2.0 ; extra == 'launch'
 Requires-Dist: termcolor >=2.1.1 ; extra == 'launch'
 Requires-Dist: wandb >=0.13.7 ; extra == 'launch'
 Requires-Dist: mlflow >=2.1.1 ; extra == 'launch'
 Requires-Dist: pydantic >=2.4.2 ; extra == 'launch'
 Requires-Dist: imageio >=2.28.1 ; extra == 'launch'
 Requires-Dist: moviepy >=1.0.3 ; extra == 'launch'
+Provides-Extra: makani
+Requires-Dist: torch-harmonics >=0.6.5 ; extra == 'makani'
+Requires-Dist: tensorly >=0.8.1 ; extra == 'makani'
+Requires-Dist: tensorly-torch >=0.4.0 ; extra == 'makani'
 
 # Modulus (Beta)
 
 <!-- markdownlint-disable -->
 [![Project Status: Active - The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
 [![GitHub](https://img.shields.io/github/license/NVIDIA/modulus)](https://github.com/NVIDIA/modulus/blob/master/LICENSE.txt)
 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
```

## Comparing `nvidia_modulus-0.5.0.dist-info/RECORD` & `nvidia_modulus-0.6.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,145 +1,145 @@
-modulus/__init__.py,sha256=FmVKsH0XOEWnh0fivnRN-uIKGJvzXpj5hLuQhZp9rJU,805
-modulus/constants.py,sha256=TpT7Nfu4nQMsrERUl-EJUcYnD9LlpUNO7t9Lpb9y444,1307
-modulus/datapipes/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/datapipes/datapipe.py,sha256=yC-9178qFEeO64-jKufaIjt38RsxDEtMJvfSxMbvQ_0,2030
-modulus/datapipes/meta.py,sha256=XTCcUdREdbSwufMlwdDmHR2gVIUzkjRNL4V6HWXh4UU,961
-modulus/datapipes/benchmarks/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/datapipes/benchmarks/darcy.py,sha256=PgKo0H6UUYLHzPUhAtqxsiLgr4V3L3kMI3YxgrFsUqQ,11693
-modulus/datapipes/benchmarks/kelvin_helmholtz.py,sha256=1LFe6ASZlF76YLisIhtUWLZQMwSrkIrlB2_MHCaZK1g,16670
-modulus/datapipes/benchmarks/kernels/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/datapipes/benchmarks/kernels/finite_difference.py,sha256=e72OdMjGlhHSbo8nFcY8rdIZSdRnbIkfycFRA1Eweh8,4263
-modulus/datapipes/benchmarks/kernels/finite_volume.py,sha256=6eK73_-cg8KSqkI4uGAI6H-AkICoreSPBcRPQtF015s,20510
-modulus/datapipes/benchmarks/kernels/indexing.py,sha256=WAx0_t28ZvDpCHzJ88t2siUz_msEYdiEvG-rq9hyxVM,3658
-modulus/datapipes/benchmarks/kernels/initialization.py,sha256=P5UYpLxb3t1YGgUcKKvudzUF6FcddtIiSAonrJDTW4A,2054
-modulus/datapipes/benchmarks/kernels/utils.py,sha256=pU-ko4qUigTqnSxYBVVpNaqxsg4ILedMu2cr_uZRo1A,4246
-modulus/datapipes/climate/__init__.py,sha256=3Fz9a137SP6vgywlMNjxZ0l6y1p-ZHtxN_0upGg6X6A,663
-modulus/datapipes/climate/era5_hdf5.py,sha256=0PZPrSqNLBdvZPwBMxKNkOmRSOHtLnmsQkIaNWmK7xM,14950
-modulus/datapipes/climate/era5_netcdf.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/datapipes/gnn/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/datapipes/gnn/ahmed_body_dataset.py,sha256=faEvg-8-ka-KVbZ7btz42yLegkuUfIG1NC3EsDyP2Io,22868
-modulus/datapipes/gnn/stokes_dataset.py,sha256=0ui9qzF6dJ15M4l8Qx-7EBpZ96KBBCqCvCy1NEfh-Ms,11081
-modulus/datapipes/gnn/utils.py,sha256=hER_AbD8cts1E2w8jN36rITmwAVZCWEdrU85N9benZk,2566
-modulus/datapipes/gnn/vortex_shedding_dataset.py,sha256=XQhn-nlUPTOVVtytNFQyRRHNRnLsGZb5YbkGbEQBogk,15454
-modulus/deploy/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/deploy/onnx/__init__.py,sha256=ipb0OCMkSZE9WYSc-ZVax0WIRw0oiv7MaUQn4IujbGU,684
-modulus/deploy/onnx/utils.py,sha256=rT_Oyd7_tDfPLvE4xYyHxPIKAerT587vWYiI2KQ-mxE,4675
-modulus/deploy/triton/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/deploy/trt/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/distributed/__init__.py,sha256=xL8XphhChsjtBFrLtk73uxkqqUQZ7DBKTgeE48QgmB4,878
-modulus/distributed/autograd.py,sha256=Dyp9iEIeuBBGP6eyOwqBd_vvX7qYyGXI5yxhGF8DaVs,15242
-modulus/distributed/config.py,sha256=XJUtzI-EfcwAuo5nq1HfDdovVgAkwqKv3bmGOsbihKI,8069
-modulus/distributed/fft.py,sha256=URcAezY13nH7jRUfvGRoiYtV2WVTNN296nx-eewmcSI,7077
-modulus/distributed/manager.py,sha256=HJ0CuQ38wxc0cNvjG4bmh2J7ybCJDlsRDusK6Mwt6XY,18814
-modulus/distributed/mappings.py,sha256=S04F1oRI7E3cESJqeT1X2BoTg_qQLcZHEZkmSTGMFqA,4489
-modulus/distributed/utils.py,sha256=LOkOcDvi20WLOyiqXQoM9llzlgHygMSOMkagF7I-_KE,24623
-modulus/experimental/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/experimental/datapipes/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/experimental/datapipes/climate/__init__.py,sha256=0oflz5hobeZYeP18rZt_Spmc_30aHIVeuaVJ8egMU3g,669
-modulus/experimental/datapipes/climate/climate_hdf5.py,sha256=4ViY-Smcib9U3DVMCK1vJzKh-HX5wha0-prD90oLlqM,23725
-modulus/experimental/datapipes/climate/utils/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/experimental/datapipes/climate/utils/zenith_angle.py,sha256=YD62nLejemq0vTynmsOJ9opjvskDMs7VISburIAXJ7g,6993
-modulus/launch/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/launch/config/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/launch/logging/__init__.py,sha256=HjXtmgnXtO4PJSaDSAmipM3dcc9o7e25FPGkBFjzw-s,788
-modulus/launch/logging/console.py,sha256=-zOaf06oaJriNnJ0sLOTs3fySr_0FcTMOHOxPqiyDCY,2979
-modulus/launch/logging/launch.py,sha256=yckWj4q-Flb1nSFzgkF2o8LA4E4V4jfYmQqZk294pgU,14776
-modulus/launch/logging/mlflow.py,sha256=5np6ey_o9ndqtZ07cDVB5e3kFPDSYhLKUkaBsBKaEgg,6791
-modulus/launch/logging/utils.py,sha256=uGwNYqMlXwmOzxZIDTLVpEahoB9zkbTAg8JiUtBjCYk,1938
-modulus/launch/logging/wandb.py,sha256=T8CfqnZBSGKv0FyfVhUmkKdtu3abfltrfqyUDQPFufk,4066
-modulus/launch/utils/__init__.py,sha256=rRWXt3aioznDrpi55GV_8-ha6q8pp29TPjNY54UoHVc,680
-modulus/launch/utils/checkpoint.py,sha256=EawrG3n70CKvF54r00v0TxFcr7lVyPwJfCw68JcwUDI,13398
-modulus/metrics/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/metrics/climate/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/metrics/climate/acc.py,sha256=2SmCIwmIPiwiSqhl7VNRQmsmj2WTjZWgXwi7wqEljpQ,2736
-modulus/metrics/climate/efi.py,sha256=XEY7OX933iNud9uppDrVDMPKgX35yxFHlZLPHjD7aaE,4507
-modulus/metrics/climate/reduction.py,sha256=LQVlhvNswwBeQ8bew2Pqt5-kv89ayQQcJNP4a1vuXMk,5505
-modulus/metrics/diffusion/__init__.py,sha256=CztHpxqORlYdAn489WbUkHUzbDTMI5MK5AnfBGTUa0o,742
-modulus/metrics/diffusion/fid.py,sha256=82KCFFX4shhyupEIef0mEXZJjF_RW4DmFNjLPWc5ogw,1792
-modulus/metrics/diffusion/loss.py,sha256=STUXh71G_H-vuAQU-fvTwzLLAmB12KwWGonEEV9m7QA,17554
-modulus/metrics/general/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/metrics/general/calibration.py,sha256=jzJhyYQ8Eh15WnnQfB9yHVtdUfa_hQhRJsTVPKrfSxg,4892
-modulus/metrics/general/crps.py,sha256=l38AFxFTDFBcjy58VDlIrfH2Lpc4i1WEa8McwNS_nk8,9869
-modulus/metrics/general/ensemble_metrics.py,sha256=qTfgnVMl77L2pOCdG7fv-nqAzmHOANoTIt8ezgnpDgY,13443
-modulus/metrics/general/entropy.py,sha256=k2RoW_35uKSmcf7GMG8I1YtxWBzuEyNepaXaVRumazI,4719
-modulus/metrics/general/histogram.py,sha256=zNAeeL5yEigwTly4S3To2vbWDZGdPY7c4oeqD2dw6JE,27431
-modulus/metrics/general/mse.py,sha256=ByIDAJrRmkLM4gXGRjYdwdKTvo4XN6MjdRRSyVddS50,1857
-modulus/metrics/general/reduction.py,sha256=YCVj0f6e5sJkvvmizlmn2a38wbDxhPG5cyiDipy6qxQ,4307
-modulus/metrics/general/wasserstein.py,sha256=aAnUjNRLYzM8Ol4RfyZVo9dZKImF63Y_hbIsAB8cnoY,5625
-modulus/models/__init__.py,sha256=uEwhaeBBs7NFiOOdtxjPp_bW1LU3T7hHQlUsmVQGT8w,650
-modulus/models/fcn_mip_plugin.py,sha256=NmFNyK21L4_Jq03L53ewj27U36JzmxwKKvvNoDc0YEU,11885
-modulus/models/meta.py,sha256=salZInKA7CPDtGuK0WcoKXfGklOIY7vdN6XKJJlTj3o,1613
-modulus/models/module.py,sha256=x7iAo-MXpSQwcVsq5tA0TrGnJI75oJ1w8hRUZR2tM4U,14964
-modulus/models/afno/__init__.py,sha256=6dHWMlvmW3uTqBBi2qvw2ntnAIeDB9gUVJr3jdbx_OM,687
-modulus/models/afno/afno.py,sha256=Yr80CMuYAnCPBEAW1zxbPPUMN2BTMK3ugEaU4lQfz7w,18143
-modulus/models/afno/distributed/__init__.py,sha256=1aTLxoQkvKQMz4mflS-DmJZJIFxWIfv5wDI3vc399kU,657
-modulus/models/afno/distributed/afno.py,sha256=qIO8KACbQ3Fuxva_aGVlwE35bqv9Iye-xUQHzwFGwYo,11667
-modulus/models/afno/distributed/layers.py,sha256=d6toy_U2KKxIHVG81E2L3SIs1CZ5j9QpDYhvgFB-HGk,15034
-modulus/models/diffusion/__init__.py,sha256=weP0HhhurjCsyxmD_iN5YZdG8kbBzo3CEAx-kwXfn-0,1018
-modulus/models/diffusion/dhariwal_unet.py,sha256=UYPY2HXV5WSGDNaSksJofqkj0d15B_rS_V5f5u7cGRg,9193
-modulus/models/diffusion/layers.py,sha256=t8kDLpyk9oWlvPDVAWxXBzmubMOf4ADPcXRYtskxiu8,19431
-modulus/models/diffusion/preconditioning.py,sha256=O1Gdk7tgk1M1PweVS3xCQo5mr223VqZOa6GhhEP8LBI,25221
-modulus/models/diffusion/song_unet.py,sha256=kjPy9wIpQBEM-3Hg0l8EUTyGxCdO62PZ-8FoOgL1Nng,14252
-modulus/models/diffusion/unet.py,sha256=KKg7HeaU2H1wgZTlPr2hBFEXeMxRfsaeSVzarm9f17A,5913
-modulus/models/diffusion/utils.py,sha256=MHac-LiCU_tq7lxWI_WwE9Fkuhw6IjfCLliIf7pMXOs,2587
-modulus/models/dlwp/__init__.py,sha256=6WAk9ERsrskKNvVY5lJxDDVPbTiRScQz7vzhVcWIgP8,646
-modulus/models/dlwp/dlwp.py,sha256=W_oyxVkdL7iU-3DKgtn32lZnZp29o25LdGKM1em4R7k,13354
-modulus/models/fno/__init__.py,sha256=X4ywjd4veWASHQy0ZjZ8pl9Yvg7mDr_6uJjIGD7n_Hc,710
-modulus/models/fno/fno.py,sha256=Bs8xOJ4IN9aTx1Vpi0yqkKx1RH_-uIXuN7p6_vR5jYU,31886
-modulus/models/gnn_layers/__init__.py,sha256=1_x1HfUr06PdmVMnxO3Cn0nP-rP_eDCzZ9XF2FMHv9I,837
-modulus/models/gnn_layers/distributed_graph.py,sha256=nm4uVAmlfpIHJALlGWP2743pAoEEQSw3iP6J7y30XSc,34458
-modulus/models/gnn_layers/embedder.py,sha256=xgCxX-af7B3OtQ0ykXGWiHn4GYtm_6YZww_xr40OdvI,6077
-modulus/models/gnn_layers/graph.py,sha256=lgFnaujDHncx2FThaW8Bze8QlmUBD9a2KgSYQdf0F2o,17029
-modulus/models/gnn_layers/mesh_edge_block.py,sha256=WwPM8Q_wFvXfZ9NmLsWiiKC0L8AzFcpA-mG3DY2ezgI,3098
-modulus/models/gnn_layers/mesh_graph_decoder.py,sha256=aDpfKQuT3EnZHTtq_Er-pFyTONRExYAL-xgII-Pej0U,4496
-modulus/models/gnn_layers/mesh_graph_encoder.py,sha256=bwFXY1ejor9zEy2eBVC_pA-laE7UMSueqwspsnxBxI4,5265
-modulus/models/gnn_layers/mesh_graph_mlp.py,sha256=fTwgboigtidzJpU_pjNJ1A2GHwbbtT96H5IWu81EGGc,15234
-modulus/models/gnn_layers/mesh_node_block.py,sha256=FHk6TCzhC7bGCuf0wYmrWSe7auwh9bBu_oQ9pg0qclU,3155
-modulus/models/gnn_layers/utils.py,sha256=bOe_klwc5U5T1LhVO7466diRcMqkuzcUEdl7nqp-72w,13517
-modulus/models/graphcast/__init__.py,sha256=N1uOLcBWFxGJiIVHqeDgn5WCRfFjtkYlThEiuVEeTmY,664
-modulus/models/graphcast/graph_cast_net.py,sha256=9fPROkpXQDsTX9NlMux5-qijJxInmDdsHOUBI-7y304,27599
-modulus/models/graphcast/graph_cast_processor.py,sha256=ThDdliHiZQ5nVn0mVWmFlNMBQ5Y0xpRYpRQyStiXTqU,6019
-modulus/models/layers/__init__.py,sha256=JXVXNGy1H7_wFaVCjp_KlRaZGRcs5Z7eTMIVVYhLsUo,1196
-modulus/models/layers/activations.py,sha256=X8VNIgFOR64ohZm07-RIGQscnHAZZebx87NJxqjCzOQ,4186
-modulus/models/layers/dgm_layers.py,sha256=PFdLXqRTYfBcan6Al0KUPr8zAGOdDax7OQQmhOqWK9Y,3313
-modulus/models/layers/fft.py,sha256=L95t3lU0EBA4Gc9H0_c476gEQ97mZ3e2LQjinITWhjQ,18044
-modulus/models/layers/fourier_layers.py,sha256=dWgzi-K_W-hEHnDKrHIWTNSMEzP35egOc1KjWPogjwg,5985
-modulus/models/layers/fully_connected_layers.py,sha256=EezkCsk2_i5ANfQu7HM0sRBYIA8Lqy9XqBiV2N9OpdA,10789
-modulus/models/layers/fused_silu.py,sha256=HnM4c0LIlFxQQwLkPLWfhZV1LZc9jmweeXrh9HjNr0A,8921
-modulus/models/layers/interpolation.py,sha256=HqDmUWUSJGbPl5w9WNDAoPg1MBRUjhbOWhdUyfVfnPk,16507
-modulus/models/layers/siren_layers.py,sha256=D_vSp58k0J6FSS8-L8pFB1gRKRCj1F2n6wGoEnDPngs,2464
-modulus/models/layers/spectral_layers.py,sha256=PG1XIaZqmcgQjVAFpQhAP1eyZONvSkTWTMEk24WkeL4,24177
-modulus/models/layers/weight_fact.py,sha256=BQHbZkZLghCeebf3HqWkscVVjjXPcuyNANvDxZQsduI,3561
-modulus/models/layers/weight_norm.py,sha256=Ef-AmOJaTPuS1PWCCAqPWtuA1jFupfntsmnLcU6DZrc,2485
-modulus/models/meshgraphnet/__init__.py,sha256=wL9bykLZg9yPW-d5Pnnak-s7GPvpMsPXduGillL86w0,662
-modulus/models/meshgraphnet/meshgraphnet.py,sha256=IoBo5WG7sWJdaqvk5aYeZ1nQ_ZPOlrTkQnWWLGCzQ_8,11990
-modulus/models/mlp/__init__.py,sha256=jiLib7FXV-jMkegjyU_j-PuExwJvWjBzsBGCloFv5jg,667
-modulus/models/mlp/fully_connected.py,sha256=peVWTMC6waQs2Hv07Qy-uwR8qpwUEZdyrSHpOemcQ-U,4509
-modulus/models/pix2pix/__init__.py,sha256=W_jfK5wJ2YkOPkbILdohTpxsn8My8I-5JGq6d3pRgNQ,652
+modulus/__init__.py,sha256=zMiyMfmxnLL6T1ScC0eeiQFuepjo-gk5arCSvtz9GbU,899
+modulus/constants.py,sha256=p8Z2v7St9FlDXMf-AOnYJmWMkoRonqh5An_Y3UOuOwk,1401
+modulus/datapipes/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/datapipe.py,sha256=eXEtpytLqexfKhA3iaiQ996H7qHd_oOUeKlpNuJabDA,2124
+modulus/datapipes/meta.py,sha256=-8SYSIWTDmLEVxmIJClLcNlGk0KyLaeRDAVHP4vKe4o,1055
+modulus/datapipes/benchmarks/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/benchmarks/darcy.py,sha256=tbn-5_JtqBuddOWaG7txV1EL0xTDHl37DO3np7y4YS8,11787
+modulus/datapipes/benchmarks/kelvin_helmholtz.py,sha256=8wJo3Gweq6lXlhCXZUW44Gh2HGiMasCpkAI5bL8ftC8,16764
+modulus/datapipes/benchmarks/kernels/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/benchmarks/kernels/finite_difference.py,sha256=LOaUW5Pl6IMuniJ4Jzq9yEVgRRuSMbFBY065a89QgHM,4357
+modulus/datapipes/benchmarks/kernels/finite_volume.py,sha256=pZGXwmzu1PzGruWi-sODEIN3lAIre4oLBZlZ8vKIKHI,20604
+modulus/datapipes/benchmarks/kernels/indexing.py,sha256=zrBN1WG-zkPtdu19Y8eo2h1TWxoZfpj4v-9-ahe1rtA,3752
+modulus/datapipes/benchmarks/kernels/initialization.py,sha256=0GLXg0LbGHttyz_rLU6jh98jRkANPDZqY81waxDc1eM,2148
+modulus/datapipes/benchmarks/kernels/utils.py,sha256=fiwUYImiDg8eQFa6XUrhBD25T5uR3HqTdx5OqZ41y2Y,4340
+modulus/datapipes/climate/__init__.py,sha256=mwJ7WYMWRBk-2KZSo7Phc3To1XpWGJbAXDAjepDIGqc,817
+modulus/datapipes/climate/climate.py,sha256=-h1AwXezNvVQ6Mkov76QbC9WrtcXVzYQGsc8H16YLBc,32261
+modulus/datapipes/climate/era5_hdf5.py,sha256=AKbuKTnRax4v2DToehaJfAT9N1lHx9w0EmMCPBPk2K4,15198
+modulus/datapipes/climate/era5_netcdf.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/climate/utils/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/climate/utils/invariant.py,sha256=wVIZhrRVW1xINISd9tfvoJSjbUc-CgUDTQkzm4Ub0MY,4656
+modulus/datapipes/climate/utils/zenith_angle.py,sha256=bqd_n0WQrLCBSbGWovZBleLZqR5ipYHGE2CAj54EC-8,6926
+modulus/datapipes/gnn/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/datapipes/gnn/ahmed_body_dataset.py,sha256=LOqOdLmuoOeKvuRplxPBFHd9R2s7J-4EXhU4yJhq9oI,22445
+modulus/datapipes/gnn/stokes_dataset.py,sha256=gWNGrkWPXYHD2PBV9i34ZdBARnPm6iYg1GH7qv44koo,11175
+modulus/datapipes/gnn/utils.py,sha256=mp4dRCBu1ZJHfpma5nBa1uYb3_778mkGoVW8PojJw4I,2660
+modulus/datapipes/gnn/vortex_shedding_dataset.py,sha256=MlVpXKm9SsJ2lTA8ReAk4UQOQY9q-1tdgjwGljsTf8I,15548
+modulus/deploy/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/deploy/onnx/__init__.py,sha256=K8k4JhR6o021VY4ugoqmlrD-xhReL1b4odC9SV1goK4,778
+modulus/deploy/onnx/utils.py,sha256=CfoQVWwU4dVGIaeTQSujv1eYW8qo43gZFIDVehHzgXU,4769
+modulus/deploy/triton/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/deploy/trt/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/distributed/__init__.py,sha256=Mvs010QXNqs5Zxq8s8_oFy8Xlak71jdgkNJv0u9OvWc,972
+modulus/distributed/autograd.py,sha256=Fq4nyHFzBDLLMYLp_4tvoWWv--vdAV4_YpUBjdgIMUo,15336
+modulus/distributed/config.py,sha256=IvFDzheedFu9vvz-w8rpb65p0-YsKtr-vPY1PPwwhAg,8163
+modulus/distributed/fft.py,sha256=A84kAh3nHKwtbe6v-iihJBudrWeELB1yEaaQiyVDUyQ,7171
+modulus/distributed/manager.py,sha256=x8Q9OCgH_1ly62HfQ8QtKhHqieL766KTcLglWyDfKHg,19737
+modulus/distributed/mappings.py,sha256=3SHrFROLjp8S4COJwVWDonhg1ZoTCeagtiXYKwuS92Q,4583
+modulus/distributed/utils.py,sha256=DUHxK_rPja85ymA-si8Q_fnhpCyoUwwEAl43eYs7G9A,24717
+modulus/experimental/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/launch/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/launch/config/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/launch/logging/__init__.py,sha256=wPaU4YekMfom3OtsxdrgMBEbQWXqr2Ht9pINV4UotgY,882
+modulus/launch/logging/console.py,sha256=Icj9kLp3CIAEuLSuwKw5cu7wrhbewhgGgbs7dTh7CLI,3073
+modulus/launch/logging/launch.py,sha256=i5LEZTTJPGaHJOPkMVtaUYwf0ggRhkVN-CWvkARhTGs,14870
+modulus/launch/logging/mlflow.py,sha256=mmw_8HnfzIZRkpjqZv26uXBGcW-Ig4CMykCpK3l-xIU,6886
+modulus/launch/logging/utils.py,sha256=nNlRM4ag-7AmuycM0oDFYk4O6DlqRVf_PSgz2Sx952c,2032
+modulus/launch/logging/wandb.py,sha256=bmb8_dy_6Dw3XrAJyWlpqLh422l_hdAqCvUCXPPl4Ic,4160
+modulus/launch/utils/__init__.py,sha256=PA_rLI0eJ79Gmm4WZnjouOA_r7eunztMYiaFDb4bdSU,774
+modulus/launch/utils/checkpoint.py,sha256=HEOKjO7vJJUBzIqPPpsU8IePsv-bjaMlkbc7fr0yMWU,13492
+modulus/metrics/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/metrics/climate/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/metrics/climate/acc.py,sha256=bTHUeo4DUmMehHsUQLNNmsPT4J_jxsJP08_zN2COkNQ,2830
+modulus/metrics/climate/efi.py,sha256=DpCgfC3qhpw7i824AL6poYetvZWfbS4NLGBdbGMEyzI,4601
+modulus/metrics/climate/reduction.py,sha256=hmQaYORhxR454GshbooCIv5uX_Zrm1Jdpg1V7Fok1II,5599
+modulus/metrics/diffusion/__init__.py,sha256=CjzHOcLYKiFqSX7FDF4dLtp76E3Sw5hmtHCfVMWegMo,836
+modulus/metrics/diffusion/fid.py,sha256=jl3OT2U4eJDBfuVE_KNK1jW9tgQqszBp6Nozmg2tya4,1886
+modulus/metrics/diffusion/loss.py,sha256=6CtGor0qAa1UZ11JPwLsmurU4OiUIGl79Sr20n5EtyI,20281
+modulus/metrics/general/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/metrics/general/calibration.py,sha256=px7RUDwX6y_0ARD6aEv1dKJX_7qnKdVQz4EfrphBTME,4986
+modulus/metrics/general/crps.py,sha256=cpCteVZJT2e0VyJIahC_2fKuE7g6QDYRIfk0wIGZcxA,9963
+modulus/metrics/general/ensemble_metrics.py,sha256=wYJR47UK_piHnfPijvmJlKp_SvYXsUF8zK-SfwiZya0,13531
+modulus/metrics/general/entropy.py,sha256=wVFVIN74meTJwxgjsYuFFUHdSdI7UvdeOqjCprw0fDA,4813
+modulus/metrics/general/histogram.py,sha256=ZQwrgk5lNCqGaTSgvZ1bbxQMo9KhwimbR60OTJRTsLE,27525
+modulus/metrics/general/mse.py,sha256=s_OcQ4BAt-4ABlP0GNTrm_KrZYpLZGgkMIPhxitt9mM,1951
+modulus/metrics/general/reduction.py,sha256=jXUi0K86A_6uMFg9OyiqMPZqtz_-9XYtz2LkIUjGs0o,4401
+modulus/metrics/general/wasserstein.py,sha256=v-ddmoosTx7q70xlCU1JorhaCWdcno3EW8Qs4UY31Bc,5719
+modulus/models/__init__.py,sha256=S-ABX3XgPmfzkT7vB1nw9sVRbpPrgdx2hbDsROJpia4,744
+modulus/models/fcn_mip_plugin.py,sha256=unT5pi-FRAZorckl0crqxtOotEf6RgMtk5n5wJiC3YQ,11979
+modulus/models/meta.py,sha256=rCpHRa6Wq_CJpRlVVf9Nj6Vj7BgmIghvkQsjv8KwWXQ,1707
+modulus/models/module.py,sha256=vJnpYP8Utp0NAr93HuhQk9R7fCUFEPUBzQPPoKy6J2M,15766
+modulus/models/afno/__init__.py,sha256=GUsRtgMLkKrJmDAvDGvA775GDUL3YFWWegy2FS2sx0o,781
+modulus/models/afno/afno.py,sha256=XQ1dIoM3ZLu8ymi9A1NIOU7OIvkCtGUXevMDCGWBdxo,18237
+modulus/models/afno/distributed/__init__.py,sha256=1NIxpJHKEILoc3ZG94GrNn-iLlmaagnbiGSMsQwK1v8,751
+modulus/models/afno/distributed/afno.py,sha256=EyWq5pqtXoFTbpVHPQMPqkfAfbdX_DSrjilwaPpoR_w,11761
+modulus/models/afno/distributed/layers.py,sha256=JX3bxYl4bN3lc6VXQUrRih1zaAIhZNHfBolJWk6MBw4,15128
+modulus/models/diffusion/__init__.py,sha256=tFE4NF1zDRuu43oULVLZHfGTBAzjk_eAVnCPO6l9an0,1112
+modulus/models/diffusion/dhariwal_unet.py,sha256=NEjwboCGYbCeTqChtBXsHNic28JaFyKC1G2f-ESavhY,9287
+modulus/models/diffusion/layers.py,sha256=k3NT4uGA_2nmeHP2mwwJNQEnIhOrXnkYBBRVBmEmDrc,20429
+modulus/models/diffusion/preconditioning.py,sha256=Uj2oGp2iytTEiACDeWIN4tA3rGinQrFuSp3fNSReii8,31133
+modulus/models/diffusion/song_unet.py,sha256=UDRQlf1X5CRJ-RnZC1lwCs1wpmwBq0uZr7faFsCxzZw,14346
+modulus/models/diffusion/unet.py,sha256=4zJnpKSt44zqHkut6XM4YeveU6BB6mbD1xXU7dHXy2o,6007
+modulus/models/diffusion/utils.py,sha256=OMIKF8aBeZ7iNjRq8GQVWoBilDwVtc5F6Ybj50sKGT8,2681
+modulus/models/dlwp/__init__.py,sha256=mSMtF8WhiDiw6I8LYGMYhxZt-qulz778w1ShmXv1jo8,740
+modulus/models/dlwp/dlwp.py,sha256=91oPPsOmbYvXz8wsLVQBuf2NUhXAUerzj67CbSKezHQ,13448
+modulus/models/fno/__init__.py,sha256=mOVRtGk0yA-FVvVliiyjlIn8gZMLzT0SIYx80UyVJx4,804
+modulus/models/fno/fno.py,sha256=egTvJ7dl9ak8nh4RxEUc-S5rlo9hkuyPMGlHuNTJVZ0,31980
+modulus/models/gnn_layers/__init__.py,sha256=q-AH1ThloRYuEJuh58XMrUP6B1Giq_ZXcrd4ylc51hs,931
+modulus/models/gnn_layers/distributed_graph.py,sha256=JC5d5FXWIDgEJMDsIFa3_aw_7lUONwhedT5a-scrXqY,34552
+modulus/models/gnn_layers/embedder.py,sha256=ipaHnAWMyXJf5pVcQ73bkRGuNM2HGj-EFqqhtKqEbj4,6171
+modulus/models/gnn_layers/graph.py,sha256=2os85TfRF2kKtT3iyxm6S25qHS7tzMDIvgSDaMivo6M,17123
+modulus/models/gnn_layers/mesh_edge_block.py,sha256=NM6UkK7r3tkefCsk46VxhL4nP0_SkmWAGgOxoskbiLs,3192
+modulus/models/gnn_layers/mesh_graph_decoder.py,sha256=E3-JSwEeytlX7l623_ZJ3zeBEBq-BZY7d9YW5jzaSSY,4590
+modulus/models/gnn_layers/mesh_graph_encoder.py,sha256=otbIM4pWKcpdNIeBkiTwMLD3Z-k2E9v3Tlv99yr38V4,5359
+modulus/models/gnn_layers/mesh_graph_mlp.py,sha256=Bik_fFwdsJgtZSu5_QzcLHq75E6siuC00T71ydk59Xg,15328
+modulus/models/gnn_layers/mesh_node_block.py,sha256=GJCe488CFI6W7P_zHghoksMulMB3TjgfnFpm2EEpL2Q,3249
+modulus/models/gnn_layers/utils.py,sha256=WHNlmIp5UBCmQaYgKD4FNT5ff0DILfrGlHGfckpROsw,13611
+modulus/models/graphcast/__init__.py,sha256=Rtg4_DQCoz_7tpTsLOhCmcX2Cc9eXf2xhzfK4oj784s,758
+modulus/models/graphcast/graph_cast_net.py,sha256=lI9MXeY-0biy4vYcFx5rRhq_F1jmngu5dmAvP-s1yxA,27693
+modulus/models/graphcast/graph_cast_processor.py,sha256=4JTbCgtFfNWxTfJexJKGio1OG0R7AJr33BJkIv2yWZE,6113
+modulus/models/layers/__init__.py,sha256=QQ8qDEQHIPXeYwDeY5eOLRgJ3fQsAC-hI9fKJGsYzNA,1290
+modulus/models/layers/activations.py,sha256=mt_6CjahEwUDIg_gZH3F5ggf2QK_Czq0dYY7wnCpQqY,4280
+modulus/models/layers/dgm_layers.py,sha256=XotF27djih4sgJBwtA0_GSw_BoQ5PsyINz1FVHu-BQs,3407
+modulus/models/layers/fft.py,sha256=Fi9u6PvvbdjB-fCRpYrWod2HlixZxPblxSSkbGxqCeY,18138
+modulus/models/layers/fourier_layers.py,sha256=-N6VVK3C8bya9v4p-p7qDafI-_UlTl0LzQCA2rzTMj0,6079
+modulus/models/layers/fully_connected_layers.py,sha256=QDEmK-DMSfKzsNv4iAVfOHkETAYFS4QNabRQ4_-pN2o,10883
+modulus/models/layers/fused_silu.py,sha256=yyaFOTCRKMLDAloxfcyiWgpIUifV8BEPEn2CJ26iwG8,9015
+modulus/models/layers/interpolation.py,sha256=mYsGqdqrVBRxvxt70m8d_vUz0yUByo1QC1ZBJgXN0s4,16601
+modulus/models/layers/siren_layers.py,sha256=TI7g-A4dzA_JGPjAoJr-s9WQvyF2_HNH8TLeJfpmnpU,2558
+modulus/models/layers/spectral_layers.py,sha256=QwAJBap9za53qROFdGW5OGk_hWJ-LQhAOxt-67DbUD8,24271
+modulus/models/layers/weight_fact.py,sha256=agAFVC8qU0nG4xx356XYnvMy16kQ30e9ELGQ5Czk-yU,3655
+modulus/models/layers/weight_norm.py,sha256=LJi7sIn0rY4vu8-Tz8337y_IdxlyipXxUky04echKWQ,2579
+modulus/models/meshgraphnet/__init__.py,sha256=B87yYuEx_32mOioKVysXzHsQmMTy24qM83EJ_fyVgEY,756
+modulus/models/meshgraphnet/meshgraphnet.py,sha256=2rebOzU8WRomwOIfTw_ejMHh5WMRRuXQj7JHDIrdJ-M,12173
+modulus/models/mlp/__init__.py,sha256=OudIo06xFEWs-E6Wqd53fWrTAHWFm6Oai3dAp6FoYUc,761
+modulus/models/mlp/fully_connected.py,sha256=ZBhrryW76z2mR6Aw2ILIBBH-OTEPxCsagZ_8i7bku14,4603
+modulus/models/pix2pix/__init__.py,sha256=fJia9g9QLY9FYF71YSSx2ys2_KLTxxtse-liIM4iM1k,746
 modulus/models/pix2pix/pix2pix.py,sha256=OOmenMNMqZAWri5_VE3qsOElVhbbos7uvvgYQ_BFMHU,12183
-modulus/models/rnn/__init__.py,sha256=R0D4JI_IL6mXTQSZ6043DpIAfBz5msXIj_LSkME1y5k,697
-modulus/models/rnn/layers.py,sha256=6AnG593uz5E85-wNa--henrgdUCEFY16DqPSBxFWHqQ,16148
-modulus/models/rnn/rnn_one2many.py,sha256=c-wg0GHOWkbPKvp5vp35sVCdGCzVJMnjkW3N51UPCbo,8260
-modulus/models/rnn/rnn_seq2seq.py,sha256=GuYpsQN1aRUJIcNjSend_6buCY5xjagBSQARXKJWax8,8575
-modulus/models/srrn/__init__.py,sha256=vFBhlt_qaLNSvcTwiAx-XUG9h33c3HbFQM_kQjnvYpU,659
+modulus/models/rnn/__init__.py,sha256=PYfmrybD0WZLgklgxuskcPrTCGuNawsZm2C-MDntRNw,791
+modulus/models/rnn/layers.py,sha256=fIbMpkfv39kWokd7QixYT0toZSJ4OvuyBMimMzlZxlU,16242
+modulus/models/rnn/rnn_one2many.py,sha256=jRyQnmvE7svmtoDeUHEcO6ryxCgFPaQvGHkQlLDXypw,8354
+modulus/models/rnn/rnn_seq2seq.py,sha256=3M3njb70AM1ufwcAg1a45cQJl_e0FYerE5aZbw5ULZU,8669
+modulus/models/srrn/__init__.py,sha256=i08PYycRVB5pwxkDzAEccj-_PRoPEXdYnd9IBLsqlZY,753
 modulus/models/srrn/super_res_net.py,sha256=SnhulE8n4vo6zh5BKzQavoDqkeJo7kvOlSRIPqwopbM,12099
-modulus/registry/__init__.py,sha256=poiVXnlezjCca0KCbvVZBE8Www2CCTYSJx5PTNEkqmQ,665
-modulus/registry/model_registry.py,sha256=DzgpohShtgg7q34HB6i_KKN4Zba1PBVCtG6-ry4bBAM,4531
-modulus/utils/__init__.py,sha256=aWbokgLnSZ6owqZJJW9JBz5ku8WV7YUQmn1d2cmnPd4,708
-modulus/utils/capture.py,sha256=ApjjsJ3GkOGgS1fnCwX1H-GUg9BiMG001mLlJMgroHg,17791
-modulus/utils/filesystem.py,sha256=2eJ-8im5eNgo4E9jwepV7P-aiIm8ZO6365WKXH0wakU,7832
+modulus/registry/__init__.py,sha256=1-xYEpNqQGCP_xFgVr-u6c9U3BjE8_lxVAAR66DU71o,759
+modulus/registry/model_registry.py,sha256=--AhIT9uKmkRk6VQCEx07-3_tkEPDq7sDFxtLRq-6Wo,4625
+modulus/utils/__init__.py,sha256=ZdV6G6F3G3itF0NNGFX2Lcux7NZ7s1TDnrfwsn9encY,802
+modulus/utils/capture.py,sha256=rTNUp2bmZCci8Cdi46I9GBwqdhHdS-y3VyImJXEQMPc,17885
+modulus/utils/filesystem.py,sha256=JKwstdSQ1tcknetwU-DbSd5sLnthKPlu2HdVba6sxB0,8941
+modulus/utils/neighbor_list.py,sha256=ImhnAnsTrhEa7pziK9d3HmJQRy56HGf0pfoD6VknQoU,5891
 modulus/utils/zenith_angle.py,sha256=DgXJLV4OzfkV2TwAgWccrS8sHvlJBuIMT6sKfaBVGAQ,17882
-modulus/utils/generative/__init__.py,sha256=Bf9tFNhuF3702hLndGPKlgPi0PD5KrW89fE3FxCB174,1427
-modulus/utils/generative/sampler.py,sha256=xf-sN7vUEy989tm4Sn8GP4CBtM5HXI_OOJEOqN6V1qs,7322
-modulus/utils/generative/utils.py,sha256=pgiwqXMX8bDDT3oC2QP_tEk_6W9a9ExhJ9b_xCQT7LI,26293
-modulus/utils/graphcast/__init__.py,sha256=pZRn-lDBQJc_ZVivpk05ze9AHshNCy5nLphrQ_jzfOs,622
-modulus/utils/graphcast/data_utils.py,sha256=0QF8T5fH1LagQkknIYuOimQ6OWGEHyyLW9bQ4om2zTg,4016
-modulus/utils/graphcast/graph.py,sha256=krY42-E1QH3RLmXozr1vF-4yVPngXQx5QsMlzPCdAjk,9596
-modulus/utils/graphcast/graph_utils.py,sha256=8k7egMBxHdjPvv8Fk_Ro6pX22XCtGZIiPiMSH2glFDo,11206
-modulus/utils/graphcast/icospheres.py,sha256=e0Txi_dKULrIqclklKu3hUHvBp_bIM_nRWwZaQ2r7dc,2087
-modulus/utils/graphcast/loss.py,sha256=jVwwrMrkNSry3R5AsASjpTS7WNEpORcyWrV1RyILeus,3427
-nvidia_modulus-0.5.0.dist-info/LICENSE.txt,sha256=-ATP1Ss7rP0Wy56Awa9VzNl6DEEVn8BkUte4tEQyFJ8,11314
-nvidia_modulus-0.5.0.dist-info/METADATA,sha256=y-7jjL5Gon1VLyQ-nCkyX0iNuCqcunta39c3aw7jHz8,8033
-nvidia_modulus-0.5.0.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-nvidia_modulus-0.5.0.dist-info/entry_points.txt,sha256=-UytRud4hqnKF8PVsFxxivxYX0gVYmWi8Ag00OiR0y8,396
-nvidia_modulus-0.5.0.dist-info/top_level.txt,sha256=Z4xMRahCKo9D7ZQXDoTUqVdssItN7HaeXe18Jx7VLkA,8
-nvidia_modulus-0.5.0.dist-info/RECORD,,
+modulus/utils/generative/__init__.py,sha256=ivWSOCz2PXXI2S7JegB43TX_YY5jJVPfYMqzBTjNqHI,1502
+modulus/utils/generative/sampler.py,sha256=2fvZBfgJ12FJO7fidrF6vBIhtSUxNtt7Vvz_hVfG-Vc,7416
+modulus/utils/generative/utils.py,sha256=4uRKmGYaUW4DGnaZxP08hhkVyLc9611PyH46YIodC5I,26153
+modulus/utils/graphcast/__init__.py,sha256=6RCPqCXnxF7xs_LolQ94VlK79E5t3NNqmBsi_d7JwOU,716
+modulus/utils/graphcast/data_utils.py,sha256=3jCDYDkDnnp8Ax1jCXBj_eBlSHFvyQ5tnEvsKMnupe8,4110
+modulus/utils/graphcast/graph.py,sha256=Q0xAfW75RRQBvEYR64TKEyM9fANdwIDpBj_SgO8mb1g,9690
+modulus/utils/graphcast/graph_utils.py,sha256=2o5Q6wwUaNidc1m7gSi895fIIqRD-5FawObpDAadbD0,11300
+modulus/utils/graphcast/icospheres.py,sha256=UvTL7LbPzHp9VmOF99wY01ZkQxWwEoYLfZooQsUrfuM,2181
+modulus/utils/graphcast/loss.py,sha256=SO6TjIebWVg2MXk4gRbhezboy4-7SIPr2DmZ72ElGAk,3521
+nvidia_modulus-0.6.0.dist-info/LICENSE.txt,sha256=-ATP1Ss7rP0Wy56Awa9VzNl6DEEVn8BkUte4tEQyFJ8,11314
+nvidia_modulus-0.6.0.dist-info/METADATA,sha256=PIQBp3KvzZsOacvmLACTb2lVvj7LQ4RAquMRYzJxdqQ,8529
+nvidia_modulus-0.6.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+nvidia_modulus-0.6.0.dist-info/entry_points.txt,sha256=-UytRud4hqnKF8PVsFxxivxYX0gVYmWi8Ag00OiR0y8,396
+nvidia_modulus-0.6.0.dist-info/top_level.txt,sha256=Z4xMRahCKo9D7ZQXDoTUqVdssItN7HaeXe18Jx7VLkA,8
+nvidia_modulus-0.6.0.dist-info/RECORD,,
```


# Comparing `tmp/doxstractor-0.0.9-py3-none-any.whl.zip` & `tmp/doxstractor-0.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,21 @@
-Zip file size: 18032 bytes, number of entries: 19
+Zip file size: 19857 bytes, number of entries: 19
 -rw-r--r--  2.0 unx      295 b- defN 24-Apr-17 13:46 doxstractor/__init__.py
--rw-r--r--  2.0 unx     3064 b- defN 24-Apr-16 13:05 doxstractor/nodes.py
+-rw-r--r--  2.0 unx     3566 b- defN 24-Apr-17 14:45 doxstractor/nodes.py
 -rw-r--r--  2.0 unx     3960 b- defN 24-Apr-12 13:51 doxstractor/utils.py
 -rw-r--r--  2.0 unx      142 b- defN 24-Apr-16 10:20 doxstractor/extractors/__init__.py
--rw-r--r--  2.0 unx     1204 b- defN 24-Apr-16 12:59 doxstractor/extractors/base.py
--rw-r--r--  2.0 unx     2734 b- defN 24-Apr-17 13:39 doxstractor/extractors/category.py
--rw-r--r--  2.0 unx     2100 b- defN 24-Apr-17 13:33 doxstractor/extractors/numeric.py
--rw-r--r--  2.0 unx     1784 b- defN 24-Apr-17 13:45 doxstractor/extractors/text.py
+-rw-r--r--  2.0 unx     1587 b- defN 24-Apr-17 14:30 doxstractor/extractors/base.py
+-rw-r--r--  2.0 unx     3300 b- defN 24-Apr-17 14:30 doxstractor/extractors/category.py
+-rw-r--r--  2.0 unx     2225 b- defN 24-Apr-17 14:25 doxstractor/extractors/numeric.py
+-rw-r--r--  2.0 unx     1886 b- defN 24-Apr-17 14:24 doxstractor/extractors/text.py
 -rw-r--r--  2.0 unx      229 b- defN 24-Apr-17 13:46 doxstractor/models/__init__.py
--rw-r--r--  2.0 unx     2753 b- defN 24-Apr-17 12:31 doxstractor/models/anthropic.py
+-rw-r--r--  2.0 unx     4258 b- defN 24-Apr-17 14:35 doxstractor/models/anthropic.py
 -rw-r--r--  2.0 unx     1071 b- defN 24-Apr-17 13:50 doxstractor/models/base.py
 -rw-r--r--  2.0 unx     1561 b- defN 24-Apr-17 13:49 doxstractor/models/mock.py
--rw-r--r--  2.0 unx      814 b- defN 24-Apr-17 13:41 doxstractor/models/transformers_classify.py
--rw-r--r--  2.0 unx     1513 b- defN 24-Apr-17 13:59 doxstractor/models/transformers_qa.py
--rw-r--r--  2.0 unx    11356 b- defN 24-Apr-17 13:59 doxstractor-0.0.9.dist-info/LICENSE.md
--rw-r--r--  2.0 unx     5858 b- defN 24-Apr-17 13:59 doxstractor-0.0.9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 13:59 doxstractor-0.0.9.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 24-Apr-17 13:59 doxstractor-0.0.9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1621 b- defN 24-Apr-17 13:59 doxstractor-0.0.9.dist-info/RECORD
-19 files, 42163 bytes uncompressed, 15368 bytes compressed:  63.6%
+-rw-r--r--  2.0 unx     1185 b- defN 24-Apr-17 14:40 doxstractor/models/transformers_classify.py
+-rw-r--r--  2.0 unx     2694 b- defN 24-Apr-17 14:39 doxstractor/models/transformers_qa.py
+-rw-r--r--  2.0 unx    11356 b- defN 24-Apr-17 14:51 doxstractor-0.1.0.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx     7246 b- defN 24-Apr-17 14:51 doxstractor-0.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 14:51 doxstractor-0.1.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       12 b- defN 24-Apr-17 14:51 doxstractor-0.1.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1622 b- defN 24-Apr-17 14:51 doxstractor-0.1.0.dist-info/RECORD
+19 files, 48287 bytes uncompressed, 17193 bytes compressed:  64.4%
```

## zipnote {}

```diff
@@ -36,23 +36,23 @@
 
 Filename: doxstractor/models/transformers_classify.py
 Comment: 
 
 Filename: doxstractor/models/transformers_qa.py
 Comment: 
 
-Filename: doxstractor-0.0.9.dist-info/LICENSE.md
+Filename: doxstractor-0.1.0.dist-info/LICENSE.md
 Comment: 
 
-Filename: doxstractor-0.0.9.dist-info/METADATA
+Filename: doxstractor-0.1.0.dist-info/METADATA
 Comment: 
 
-Filename: doxstractor-0.0.9.dist-info/WHEEL
+Filename: doxstractor-0.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: doxstractor-0.0.9.dist-info/top_level.txt
+Filename: doxstractor-0.1.0.dist-info/top_level.txt
 Comment: 
 
-Filename: doxstractor-0.0.9.dist-info/RECORD
+Filename: doxstractor-0.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## doxstractor/nodes.py

```diff
@@ -4,16 +4,15 @@
 import collections
 
 
 class Node:
     def __init__(
         self, extractor: BaseExtractor, children: Optional[Dict[str, List[Node]]] = None
     ) -> None:
-        """
-        A node is an element of a tree which has one or multiple children. Depending on the results of the extractor,
+        """A node is an element of a tree which has one or multiple children. Depending on the results of the extractor,
         it recursively calls all the child nodes corresponding to the result.
 
         E.g. if you have a `CategoryExtractor` with the categories `rental_contract` and `employment_contract`, you likely
         want to extract different attributes depending on what you are dealing with.
 
         So you would provide a children dictionary as below:
         ```python
@@ -24,22 +23,27 @@
             ],
             "employment_contract": [
                 SalaryExtractor,
                 StockOptionsExtractor
             ]
         }
         ```
+
+        Args:
+            extractor (BaseExtractor): The extractor at the root of the node.
+            children (Optional[Dict[str, List[Node]]], optional): Dictionary where key is a category of the
+                root node and value is a list of nodes. Defaults to None.
         """
 
         self.extractor = extractor
         self.children = children
         self.validate()
 
     def validate(self):
-
+        """Ensures the node is valid."""
         if self.children:
             # Ensure only a category extractor gets children
             if not (isinstance(self.extractor, CategoryExtractor)):
                 raise ValueError("Children are only supported for category extractors")
 
             # Ensure children are only set for categories which exist in the parent
             if not set(self.children.keys()).issubset(set(self.extractor.categories)):
@@ -54,14 +58,22 @@
             ]
             if len(duplicates) > 0:
                 raise ValueError(
                     f"Duplicate node name. All node names need to be unique. Duplicates are {duplicates}"
                 )
 
     def extract(self, doc_text: str) -> Dict:
+        """Recursively runs all extractors
+
+        Args:
+            doc_text (str): Document text from which to extract.
+
+        Returns:
+            Dict: {node_name: node_result}
+        """
 
         # Run Extraction on own extractor
         result = self.extractor.extract(doc_text)
         result_dict = {self.extractor.name: result}
 
         if self.children and (result in self.children.keys()):
             # Fetch the children relevant to the extracted category
```

## doxstractor/extractors/base.py

```diff
@@ -5,35 +5,45 @@
 class BaseExtractor:
     def __init__(
         self,
         name: str,  # Has to be unique within graph as it identifies extractor
         query: str,
         model: BaseModel,
         max_chunk_size: float = 10_000,
-        first_chunk_only: bool = False,
     ) -> None:
+        """Create a new extractor
+
+        Args:
+            name (str): A unique name. This identifies the extractor within a graph and provides the attribute name.
+            model (BaseModel): The natural language model which is used to extract text.
+            max_chunk_size (float, optional): Maximum size to chunk data into.. Defaults to 10_000.
+        """
+        # TODO: This maybe should be a model attribute.
         self.max_chunk_size = max_chunk_size
         self.model = model
         self.query = query
         self.name = name
-        self.first_chunk_only = first_chunk_only
 
     def _chunk_text(self, doc_text: str) -> List[str]:
+        """Splits a document by newlines. Then generates chunks which are shorter than
+        max_chunk_size.
+
+        Args:
+            doc_text (str): The full document to chunk.
+
+        Returns:
+            List[str]: A list of chunks
+        """
         chunks = doc_text.split("\n")
 
         merged_chunks = [""]
         for chunk in chunks:
             prev_chunk = merged_chunks[-1]
             if (len(prev_chunk) + len(chunk)) < (self.max_chunk_size - 1):
                 merged_chunks[-1] = prev_chunk + "\n" + chunk
             else:
                 merged_chunks.append(chunk)
 
-        # In some cases it can be useful to only provide the opening of the document
-        # E.g. when classifying the document
-        if self.first_chunk_only:
-            return [merged_chunks[0]]
-
         return merged_chunks
 
     def extract(self, doc_text: str):
         raise NotImplementedError
```

## doxstractor/extractors/category.py

```diff
@@ -1,72 +1,86 @@
 from ..utils import most_common
 from ..models import BaseModel
 from .base import BaseExtractor
-from typing import List, Optional
-import re
+from typing import List
+
 import numpy as np
 
-# TODO: Need to find a way to pull the task description which depends on the categories up here
+
+TASK_DESCRIPTION = (
+    "Valid categories are: {categories_str} \n Use the information below:"
+)
 SYSTEM_PROMPT = 'Your job is to provide a categorial answer based on provided text. Answer only with the category, and no other text. If there is no relevant information in the text provided, respond with "NA". Do not make things up.'
 
 
 class CategoryExtractor(BaseExtractor):
     def __init__(
         self,
         name: str,
         query: str,
         categories: List[str],
         model: BaseModel,
         max_chunk_size: float = 10_000,
-        first_chunk_only: bool = False,
     ) -> None:
+        """Create a new extractor
+
+        Args:
+            name (str): A unique name. This identifies the extractor within a graph and provides the attribute name.
+            categories (list): Allowed categories.
+            model (BaseModel): The natural language model which is used to extract text.
+            max_chunk_size (float, optional): Maximum size to chunk data into.. Defaults to 10_000.
+        """
         super().__init__(
             name=name,
             query=query,
             max_chunk_size=max_chunk_size,
             model=model,
-            first_chunk_only=first_chunk_only,
         )
         self.categories = categories
 
     def extract(self, doc_text: str) -> str:
+        """Extracts a category from a document, similar to zero shot classification.
+
+        Args:
+            doc_text (str): The document from which to extract
+
+        Returns:
+            str: The extracted category. Guaranteed to be one of the categories provided on init or 'NA'
+        """
 
         merged_chunks = self._chunk_text(doc_text)
         categories_str = "The possible categories are " + ", ".join(
             [f'"{w}"' for w in self.categories]
         )
-        TASK_DESCRIPTION = (
-            f"Valid categories are: {categories_str} \n Use the information below:"
-        )
 
         # Classifier models don't have actual queries, you just provide the possible categories.
         if self.model.model_description()["type"] == "classifier":
             query = self.categories
         else:
             query = self.query
 
         if self.model.model_description()["scores"]:
             results_with_scores = self.model.batch_complete_with_scores(
                 query=query,
                 context=merged_chunks,
-                task_description=TASK_DESCRIPTION,
+                task_description=TASK_DESCRIPTION.format(categories_str=categories_str),
                 system_prompt=SYSTEM_PROMPT,
             )
             filtered = [
                 r for r in results_with_scores if (r["answer"] in self.categories)
             ]
             all_scores = [r["score"] for r in filtered]
             idx = np.argmax(all_scores)
             consensus = results_with_scores[idx]["answer"]
             return consensus
         else:
             results = self.model.batch_complete(
                 query=query,
                 context=merged_chunks,
-                task_description=TASK_DESCRIPTION,
+                task_description=TASK_DESCRIPTION.format(categories_str=categories_str),
                 system_prompt=SYSTEM_PROMPT,
             )
             valid_answers = [
                 m for m in results if (m != "NA") and (m in self.categories)
             ]
 
             if len(valid_answers) > 0:
```

## doxstractor/extractors/numeric.py

```diff
@@ -1,11 +1,11 @@
-from ..utils import parseNumber, most_common
-from ..models import BaseModel
+from ..utils import most_common
+
 from .base import BaseExtractor
-from typing import List, Optional
+
 import re
 import numpy as np
 
 TASK_DESCRIPTION = "Use the information given below."
 SYSTEM_PROMPT = 'Your job is to extract a numerical value from a document. Respond with a single number. Do not explain your answer. Do not provide context. If there is no relevant information in the text provided, respond with "NA". Do not make things up.'
 
 
@@ -14,14 +14,22 @@
     def _numerize(self, answer: str):
         num = "".join(
             re.findall("[-+]?[.]?[\d]+(?:,\d\d\d)*[\.]?\d*(?:[eE][-+]?\d+)?", answer)
         )
         return num
 
     def extract(self, doc_text: str) -> float:
+        """Extracts a number from a document.
+
+        Args:
+            doc_text (str): The document text from which to extract.
+
+        Returns:
+            float: The extracted number.
+        """
 
         merged_chunks = self._chunk_text(doc_text)
 
         if self.model.model_description()["scores"]:
             results_with_scores = self.model.batch_complete_with_scores(
                 query=self.query,
                 context=merged_chunks,
```

## doxstractor/extractors/text.py

```diff
@@ -1,22 +1,27 @@
-from ..utils import parseNumber, most_common
-from ..models import BaseModel
+from ..utils import most_common
 from .base import BaseExtractor
-from typing import List, Optional
-import re
 import numpy as np
 
 TASK_DESCRIPTION = "Use the information given below."
 
 SYSTEM_PROMPT = 'Answer only with the relevant text snippet you have found below, and no other text. Do not explain your answer or provide any context. If there is no relevant information in the text provided, respond with "NA". Do not make things up.'
 
 
 class TextExtractor(BaseExtractor):
 
     def extract(self, doc_text: str) -> str:
+        """Extracts a text snippet.
+
+        Args:
+            doc_text (str): The document text from which to extract.
+
+        Returns:
+            str: The extracted snippet.
+        """
         merged_chunks = self._chunk_text(doc_text)
 
         if self.model.model_description()["scores"]:
             results_with_scores = self.model.batch_complete_with_scores(
                 query=self.query,
                 context=merged_chunks,
                 task_description=TASK_DESCRIPTION,
```

## doxstractor/models/anthropic.py

```diff
@@ -7,20 +7,27 @@
 class AnthropicAPIModel(BaseModel):
     def __init__(
         self,
         model: Optional[str] = "claude-3-haiku-20240307",
         temperature: float = 0.0,
         max_tokens: int = 1_000,
     ) -> None:
+        """Model using the Anthropic python API
+
+        Args:
+            model (Optional[str], optional): Model name. Defaults to "claude-3-haiku-20240307".
+            temperature (float, optional): Defaults to 0.0.
+            max_tokens (int, optional):Defaults to 1_000.
+        """
         super().__init__(model=model, temperature=temperature, max_tokens=max_tokens)
 
         self.client = anthropic.Anthropic()
 
-    def model_type(self):
-        return "text"
+    def model_description(self):
+        return {"type": "text", "scores": False}
 
     def _query_anthropic(self, system_prompt, user_prompt):
         message = self.client.messages.create(
             model=self.model,
             max_tokens=self.max_tokens,
             temperature=self.temperature,
             system=system_prompt,
@@ -41,15 +48,26 @@
 
     def complete(
         self,
         query: str,
         context: str,
         task_description: Optional[str] = None,
         system_prompt: Optional[str] = None,
-    ):
+    ) -> str:
+        """Sends a request to Anthropic and returns the result. Deals with API issues such as overload, timout, etc.
+
+        Args:
+            query (str): The query specifying what we want to extract.
+            context (str): The text from which to extract.
+            task_description (Optional[str], optional): Inserted between the query and the context. Defaults to None.
+            system_prompt (Optional[str], optional): System prompt for model. Defaults to None.
+
+        Returns:
+            str: Model response text.
+        """
         if task_description:
             user_prompt = query + "\n" + task_description + "\n" + context
         else:
             user_prompt = query + "\n" + context
 
         for attempt in range(10):
             try:
@@ -77,14 +95,25 @@
     def batch_complete(
         self,
         query: str,
         context: List[str],
         task_description: Optional[str] = None,
         system_prompt: Optional[str] = None,
     ) -> List[str]:
+        """Sends batch of requests to Anthropic and returns the result. Deals with API issues such as overload, timout, etc.
+
+        Args:
+            query (str): The query specifying what we want to extract.
+            context (List[str]): The text from which to extract. Model will answer query for each element of list.
+            task_description (Optional[str], optional): Inserted between the query and the context. Defaults to None.
+            system_prompt (Optional[str], optional): System prompt for model. Defaults to None.
+
+        Returns:
+            List[str]: Model response text for each context.
+        """
         all_results = []
         for c in context:
             result = self.complete(
                 query=query,
                 context=c,
                 task_description=task_description,
                 system_prompt=system_prompt,
```

## doxstractor/models/transformers_classify.py

```diff
@@ -1,10 +1,10 @@
 from .base import BaseModel
 from transformers import pipeline
-from typing import Optional, List
+from typing import Dict, Optional, List
 import numpy as np
 
 
 class TransformerClassifierModel(BaseModel):
     def __init__(
         self, model: str, temperature: float = 0, max_tokens: int = 1000
     ) -> None:
@@ -21,7 +21,19 @@
         context: str,
         task_description: Optional[str] = None,
         system_prompt: Optional[str] = None,
     ):
         res = self.classifier(context, query)
         best_answer_idx = np.argmax(res["scores"])
         return res["labels"][best_answer_idx]
+
+    def batch_complete_with_scores(
+        self,
+        query: str,
+        context: List[str],
+        task_description: Optional[str] = None,
+        system_prompt: Optional[str] = None,
+    ) -> List[Dict]:
+        # TODO: Implement this
+        return super().batch_complete_with_scores(
+            query, context, task_description, system_prompt
+        )
```

## doxstractor/models/transformers_qa.py

```diff
@@ -1,12 +1,11 @@
 from .base import BaseModel
 from transformers import pipeline
 from typing import Optional, List, Dict
 import torch
-import numpy as np
 
 
 class TransformersQAModel(BaseModel):
 
     def __init__(
         self,
         model: str,
@@ -27,16 +26,26 @@
 
     def complete(
         self,
         query: str,
         context: str,
         task_description: Optional[str] = None,
         system_prompt: Optional[str] = None,
-    ):
+    ) -> str:
+        """Extracts a snippet of text to answer the query.
 
+        Args:
+            query (str): The query specifying what we want to extract.
+            context (List[str]): The text from which to extract.
+            task_description (Optional[str], optional): Not used, only for compatibility. Defaults to None.
+            system_prompt (Optional[str], optional): Not used, only for compatibility. Defaults to None.
+
+        Returns:
+            str: The extracted response.
+        """
         input = {"question": query, "context": context}
         res = self.pipeline(input)
 
         if res["score"] >= self.na_threshold:
             return res["answer"]
         else:
             return "NA"
@@ -44,13 +53,25 @@
     def batch_complete_with_scores(
         self,
         query: str,
         context: List[str],
         task_description: Optional[str] = None,
         system_prompt: Optional[str] = None,
     ) -> List[Dict]:
+        """Extracts a snippet of text to answer the query for each context provided.
+        Returns a dictionary including answers and confidence scores.
+
+        Args:
+            query (str): The query specifying what we want to extract.
+            context (List[str]): The text from which to extract. Model will answer query for each element of list.
+            task_description (Optional[str], optional): Not used, only for compatibility. Defaults to None.
+            system_prompt (Optional[str], optional): Not used, only for compatibility. Defaults to None.
+
+        Returns:
+            List[Dict]: A list of dictionaries like {'score':confidence_score, 'answer':answer_text}
+        """
         all_inputs = []
         for c in context:
             all_inputs.append({"question": query, "context": c})
 
         all_results = self.pipeline(all_inputs)
         return all_results
```

## Comparing `doxstractor-0.0.9.dist-info/LICENSE.md` & `doxstractor-0.1.0.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `doxstractor-0.0.9.dist-info/METADATA` & `doxstractor-0.1.0.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: doxstractor
-Version: 0.0.9
+Version: 0.1.0
 Summary: Doxstractor extracts strutured data from text in an easily configurable way.
 Author: Jannes Klaas
 License: Apache Software License (Apache 2.0)
 Project-URL: Homepage, https://github.com/JannesKlaas/doxstractor
 Project-URL: Issues, https://github.com/JannesKlaas/doxstractor/issues
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: OS Independent
@@ -73,23 +73,29 @@
 )
 ```
 
 From here, we can extract an address from a given text:
 ```python
 address = address_extractor.extract(text)
 ```
+```
+[Out]: 6335 1St – Avenue South, Seattle, Washington.
+```
 
 To get our salary extractor for the employment contracts we do almost the same:
 ```python
 salary_extractor = dxc.NumericExtractor(
     name="salary", 
     query="What is the base salary?", 
     model=model, 
 )
 ```
+```
+[Out]: 575,000
+```
 
 We can use the same model as for the addresses, the extractor will ensure that the response is numeric.
 
 The category extractor takes one extra argument which is the categories. We will set one up with the anthropic model we defined earlier.
 ```python
 doc_classifier = dxc.CategoryExtractor(
     name="doctype", 
@@ -116,7 +122,42 @@
 
 The nesting can go arbitarily deep. Only categorical extractors can be used for conditional child nodes.
 
 Extraction with a chain works just the same as it does with a single extractor.
 ```python
 chain.extract(text)
 ```
+
+```
+[Out]: {'doctype': 'employment', 'salary': '575,000'}
+```
+
+
+### Extracting data from folders
+
+To extract data from folders, you simply loop over the files and apply your chain to all documents.
+```python
+path = "tutorial_data/"
+file_paths = glob.glob(os.path.join(path, '*'))
+
+collector = []
+for fp in file_paths:
+    with open(fp, "r") as f:
+        html = f.read()
+    soup = BeautifulSoup(html, features="html.parser")
+    text = soup.get_text()
+    data = chain.extract(text)
+    data.update({"file_path":fp})
+    collector.append(data)
+
+pd.DataFrame(collector)[["file_path", "doctype", "salary", "address"]].sort_values("doctype")
+```
+
+|index|file\_path|doctype|salary|address|
+|---|---|---|---|---|
+|2|tutorial\_data/EDGAR\_employment\_agreement\_3\.html|employment||NaN|
+|3|tutorial\_data/EDGAR\_employment\_agreement\_2\.html|employment|350,000|NaN|
+|4|tutorial\_data/EDGAR\_employment\_agreement\_1\.html|employment|575,000|NaN|
+|0|tutorial\_data/EDGAR\_lease\_agreement\_2\.html|lease|NaN| 3850 Annapolis Lane,|
+|1|tutorial\_data/EDGAR\_lease\_agreement\_1\.html|lease|NaN| 6335 1St – Avenue South, Seattle, Washington\.|
+
+The table above is correct (I checked the documents), except that it omitted one salary which is actually specified in the document. A better model can fix this.
```

## Comparing `doxstractor-0.0.9.dist-info/RECORD` & `doxstractor-0.1.0.dist-info/RECORD`

 * *Files 17% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 doxstractor/__init__.py,sha256=GdFZodscJktj3UKnDOtQRKirTE3klfIDbJLLgv_MioA,295
-doxstractor/nodes.py,sha256=jd7-8KQ9OAekfzlMZojl-rZQZ2GN2dmY3ZvnGxo04v0,3064
+doxstractor/nodes.py,sha256=7BEAS25yvrElBVJePTfcb1pDjPSghHE5LAdwcVQH7gs,3566
 doxstractor/utils.py,sha256=QakS_yE0x0NN5pvrU1d4xRR-NMTer-VFgnbW66L-orc,3960
 doxstractor/extractors/__init__.py,sha256=i7G8YdDWIm2g1zLpIdt3Eya1THv9IKk2Wr2HErSYkYY,142
-doxstractor/extractors/base.py,sha256=mu7tg-eEg-V0_SSLDaDOMXmslHsDP5BHFiDPbIBqwB4,1204
-doxstractor/extractors/category.py,sha256=wvB8SZNc7Tfg6be7roupTa7PXy-VAJrSulRE-qvKjBA,2734
-doxstractor/extractors/numeric.py,sha256=RDDsU-91h2tkRmNT3Kq7FOXTiYSVY3vIuNee_L4SWO0,2100
-doxstractor/extractors/text.py,sha256=XZrEoRD9zEXQVDYXBh_QaAHG5LCPvJWIVOLXqb2PG3c,1784
+doxstractor/extractors/base.py,sha256=iHMvg-1juts787EovK-oX7mv9xJgl6664xPwdB2SNpg,1587
+doxstractor/extractors/category.py,sha256=mGG1IdYYg8Z6n_SzP4CBNTUTUZaU44-nOEYJouvVTT0,3300
+doxstractor/extractors/numeric.py,sha256=NvtFLPQKBnpIxPvWc8fe4Ve2r1mdW_k2gkmF-CXdwco,2225
+doxstractor/extractors/text.py,sha256=CBC-zpy5JzI411Jk1USNsAM_ttHnqF91reoWa9sYGOY,1886
 doxstractor/models/__init__.py,sha256=lzLPC4LdVkMx4UOOneSnLIWeRK0F-_0enL01JqyFijU,229
-doxstractor/models/anthropic.py,sha256=XWQNBJnzPJU3L-mkVZ6troC13J0VeSrF5e3r9qRVCCc,2753
+doxstractor/models/anthropic.py,sha256=BdgIA_EA02QPmkk3U6P188-5qwLSxQL9EgzUamBcEZU,4258
 doxstractor/models/base.py,sha256=BzrdS95vKKEl9rsDawnwp6_w69QHCkclfOdVdKMmtCY,1071
 doxstractor/models/mock.py,sha256=X6nt2WzywWbbRtCBrKC85LanUqOCTgWvTY_NZ6kjHS4,1561
-doxstractor/models/transformers_classify.py,sha256=bXIUE71ycrR0T1UIXCNc3w_cDV5QB0Yhz_nffFJZREU,814
-doxstractor/models/transformers_qa.py,sha256=srIobgUXTwdtsUPEZ4pyRhfOZ0QSMhcL51d0NZCoPKM,1513
-doxstractor-0.0.9.dist-info/LICENSE.md,sha256=QwcOLU5TJoTeUhuIXzhdCEEDDvorGiC6-3YTOl4TecE,11356
-doxstractor-0.0.9.dist-info/METADATA,sha256=g3AWT8GbeXZQGnXxPE87JcqWAQkxTPaDKvaSzwr1m80,5858
-doxstractor-0.0.9.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-doxstractor-0.0.9.dist-info/top_level.txt,sha256=117yFqQpa8ASAEJmhdT3Fdc3o5J_Tu2GBU6TMZXuGjc,12
-doxstractor-0.0.9.dist-info/RECORD,,
+doxstractor/models/transformers_classify.py,sha256=GAQMyD1K-kxp-klGU19OK9lbkv2bT4n-I46YhA0xZyA,1185
+doxstractor/models/transformers_qa.py,sha256=yVkQsKe6BS457PhVUat1IBXioiK4y-iiNy_c-iF1Ei0,2694
+doxstractor-0.1.0.dist-info/LICENSE.md,sha256=QwcOLU5TJoTeUhuIXzhdCEEDDvorGiC6-3YTOl4TecE,11356
+doxstractor-0.1.0.dist-info/METADATA,sha256=biuuyZfULT_VYpqozIhmQe4Flcwk85fvNP8jLiUnF58,7246
+doxstractor-0.1.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+doxstractor-0.1.0.dist-info/top_level.txt,sha256=117yFqQpa8ASAEJmhdT3Fdc3o5J_Tu2GBU6TMZXuGjc,12
+doxstractor-0.1.0.dist-info/RECORD,,
```


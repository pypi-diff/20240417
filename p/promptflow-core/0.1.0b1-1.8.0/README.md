# Comparing `tmp/promptflow_core-0.1.0b1-py3-none-any.whl.zip` & `tmp/promptflow_core-1.8.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,142 +1,142 @@
-Zip file size: 926579 bytes, number of entries: 140
--rw-r--r--  2.0 unx     7262 b- defN 80-Jan-01 00:00 promptflow/_constants.py
+Zip file size: 930400 bytes, number of entries: 140
+-rw-r--r--  2.0 unx     7708 b- defN 80-Jan-01 00:00 promptflow/_constants.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/_core/__init__.py
 -rw-r--r--  2.0 unx     5431 b- defN 80-Jan-01 00:00 promptflow/_core/_errors.py
 -rw-r--r--  2.0 unx     5190 b- defN 80-Jan-01 00:00 promptflow/_core/cache_manager.py
 -rw-r--r--  2.0 unx     6512 b- defN 80-Jan-01 00:00 promptflow/_core/connection_manager.py
 -rw-r--r--  2.0 unx     8974 b- defN 80-Jan-01 00:00 promptflow/_core/data/tool.schema.json
--rw-r--r--  2.0 unx    10511 b- defN 80-Jan-01 00:00 promptflow/_core/flow_execution_context.py
+-rw-r--r--  2.0 unx    10755 b- defN 80-Jan-01 00:00 promptflow/_core/flow_execution_context.py
 -rw-r--r--  2.0 unx     6242 b- defN 80-Jan-01 00:00 promptflow/_core/log_manager.py
 -rw-r--r--  2.0 unx     2156 b- defN 80-Jan-01 00:00 promptflow/_core/metric_logger.py
 -rw-r--r--  2.0 unx      118 b- defN 80-Jan-01 00:00 promptflow/_core/operation_context.py
--rw-r--r--  2.0 unx    19816 b- defN 80-Jan-01 00:00 promptflow/_core/run_tracker.py
+-rw-r--r--  2.0 unx    20344 b- defN 80-Jan-01 00:00 promptflow/_core/run_tracker.py
 -rw-r--r--  2.0 unx     1537 b- defN 80-Jan-01 00:00 promptflow/_core/token_provider.py
 -rw-r--r--  2.0 unx     9609 b- defN 80-Jan-01 00:00 promptflow/_core/tool.py
--rw-r--r--  2.0 unx    22421 b- defN 80-Jan-01 00:00 promptflow/_core/tool_meta_generator.py
--rw-r--r--  2.0 unx     2960 b- defN 80-Jan-01 00:00 promptflow/_core/tool_settings_parser.py
+-rw-r--r--  2.0 unx    22561 b- defN 80-Jan-01 00:00 promptflow/_core/tool_meta_generator.py
+-rw-r--r--  2.0 unx     2854 b- defN 80-Jan-01 00:00 promptflow/_core/tool_settings_parser.py
 -rw-r--r--  2.0 unx     4274 b- defN 80-Jan-01 00:00 promptflow/_core/tool_validation.py
 -rw-r--r--  2.0 unx    23991 b- defN 80-Jan-01 00:00 promptflow/_core/tools_manager.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/_utils/__init__.py
--rw-r--r--  2.0 unx      512 b- defN 80-Jan-01 00:00 promptflow/_utils/_errors.py
+-rw-r--r--  2.0 unx      649 b- defN 80-Jan-01 00:00 promptflow/_utils/_errors.py
 -rw-r--r--  2.0 unx     1848 b- defN 80-Jan-01 00:00 promptflow/_utils/async_utils.py
 -rw-r--r--  2.0 unx     4407 b- defN 80-Jan-01 00:00 promptflow/_utils/connection_utils.py
 -rw-r--r--  2.0 unx      859 b- defN 80-Jan-01 00:00 promptflow/_utils/context_utils.py
 -rw-r--r--  2.0 unx     1946 b- defN 80-Jan-01 00:00 promptflow/_utils/credential_scrubber.py
 -rw-r--r--  2.0 unx      926 b- defN 80-Jan-01 00:00 promptflow/_utils/credential_utils.py
 -rw-r--r--  2.0 unx     3125 b- defN 80-Jan-01 00:00 promptflow/_utils/dataclass_serializer.py
 -rw-r--r--  2.0 unx    13649 b- defN 80-Jan-01 00:00 promptflow/_utils/exception_utils.py
 -rw-r--r--  2.0 unx     5837 b- defN 80-Jan-01 00:00 promptflow/_utils/execution_utils.py
 -rw-r--r--  2.0 unx     1795 b- defN 80-Jan-01 00:00 promptflow/_utils/feature_utils.py
 -rw-r--r--  2.0 unx    10564 b- defN 80-Jan-01 00:00 promptflow/_utils/flow_utils.py
 -rw-r--r--  2.0 unx     4044 b- defN 80-Jan-01 00:00 promptflow/_utils/inputs_mapping_utils.py
 -rw-r--r--  2.0 unx     5088 b- defN 80-Jan-01 00:00 promptflow/_utils/load_data.py
 -rw-r--r--  2.0 unx    16426 b- defN 80-Jan-01 00:00 promptflow/_utils/logger_utils.py
--rw-r--r--  2.0 unx     6487 b- defN 80-Jan-01 00:00 promptflow/_utils/multimedia_data_converter.py
--rw-r--r--  2.0 unx    11182 b- defN 80-Jan-01 00:00 promptflow/_utils/multimedia_utils.py
+-rw-r--r--  2.0 unx     6470 b- defN 80-Jan-01 00:00 promptflow/_utils/multimedia_data_converter.py
+-rw-r--r--  2.0 unx    22015 b- defN 80-Jan-01 00:00 promptflow/_utils/multimedia_utils.py
 -rw-r--r--  2.0 unx     3625 b- defN 80-Jan-01 00:00 promptflow/_utils/process_utils.py
 -rw-r--r--  2.0 unx     3474 b- defN 80-Jan-01 00:00 promptflow/_utils/retry_utils.py
 -rw-r--r--  2.0 unx      919 b- defN 80-Jan-01 00:00 promptflow/_utils/run_tracker_utils.py
 -rw-r--r--  2.0 unx     2187 b- defN 80-Jan-01 00:00 promptflow/_utils/thread_utils.py
 -rw-r--r--  2.0 unx    20655 b- defN 80-Jan-01 00:00 promptflow/_utils/tool_utils.py
--rw-r--r--  2.0 unx     2266 b- defN 80-Jan-01 00:00 promptflow/_utils/user_agent_utils.py
--rw-r--r--  2.0 unx    14515 b- defN 80-Jan-01 00:00 promptflow/_utils/utils.py
+-rw-r--r--  2.0 unx     2643 b- defN 80-Jan-01 00:00 promptflow/_utils/user_agent_utils.py
+-rw-r--r--  2.0 unx    14729 b- defN 80-Jan-01 00:00 promptflow/_utils/utils.py
 -rw-r--r--  2.0 unx     4141 b- defN 80-Jan-01 00:00 promptflow/_utils/version_hint_utils.py
 -rw-r--r--  2.0 unx     4057 b- defN 80-Jan-01 00:00 promptflow/_utils/yaml_utils.py
 -rw-r--r--  2.0 unx     1352 b- defN 80-Jan-01 00:00 promptflow/connections/__init__.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/contracts/__init__.py
 -rw-r--r--  2.0 unx      170 b- defN 80-Jan-01 00:00 promptflow/contracts/_errors.py
 -rw-r--r--  2.0 unx     1131 b- defN 80-Jan-01 00:00 promptflow/contracts/_run_management.py
--rw-r--r--  2.0 unx    36780 b- defN 80-Jan-01 00:00 promptflow/contracts/flow.py
--rw-r--r--  2.0 unx     2460 b- defN 80-Jan-01 00:00 promptflow/contracts/multimedia.py
--rw-r--r--  2.0 unx     8757 b- defN 80-Jan-01 00:00 promptflow/contracts/run_info.py
+-rw-r--r--  2.0 unx    37511 b- defN 80-Jan-01 00:00 promptflow/contracts/flow.py
+-rw-r--r--  2.0 unx     3088 b- defN 80-Jan-01 00:00 promptflow/contracts/multimedia.py
+-rw-r--r--  2.0 unx     9351 b- defN 80-Jan-01 00:00 promptflow/contracts/run_info.py
 -rw-r--r--  2.0 unx     1001 b- defN 80-Jan-01 00:00 promptflow/contracts/run_mode.py
 -rw-r--r--  2.0 unx    16165 b- defN 80-Jan-01 00:00 promptflow/contracts/tool.py
 -rw-r--r--  2.0 unx     1536 b- defN 80-Jan-01 00:00 promptflow/contracts/types.py
 -rw-r--r--  2.0 unx      610 b- defN 80-Jan-01 00:00 promptflow/core/__init__.py
 -rw-r--r--  2.0 unx    28375 b- defN 80-Jan-01 00:00 promptflow/core/_connection.py
 -rw-r--r--  2.0 unx      262 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/__init__.py
--rw-r--r--  2.0 unx     2400 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_connection_provider.py
+-rw-r--r--  2.0 unx     2355 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_connection_provider.py
 -rw-r--r--  2.0 unx     4283 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_dict_connection_provider.py
 -rw-r--r--  2.0 unx    84939 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_models/__init__.py
 -rw-r--r--  2.0 unx  1637221 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_models/_models.py
 -rw-r--r--  2.0 unx      212 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_models/_version.py
--rw-r--r--  2.0 unx     3038 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_utils.py
--rw-r--r--  2.0 unx    15522 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_workspace_connection_provider.py
--rw-r--r--  2.0 unx     3968 b- defN 80-Jan-01 00:00 promptflow/core/_errors.py
+-rw-r--r--  2.0 unx     3018 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_utils.py
+-rw-r--r--  2.0 unx    15502 b- defN 80-Jan-01 00:00 promptflow/core/_connection_provider/_workspace_connection_provider.py
+-rw-r--r--  2.0 unx     4000 b- defN 80-Jan-01 00:00 promptflow/core/_errors.py
 -rw-r--r--  2.0 unx     6500 b- defN 80-Jan-01 00:00 promptflow/core/_flow.py
 -rw-r--r--  2.0 unx      262 b- defN 80-Jan-01 00:00 promptflow/core/_serving/__init__.py
 -rw-r--r--  2.0 unx     1936 b- defN 80-Jan-01 00:00 promptflow/core/_serving/_errors.py
--rw-r--r--  2.0 unx    12089 b- defN 80-Jan-01 00:00 promptflow/core/_serving/app.py
+-rw-r--r--  2.0 unx    12197 b- defN 80-Jan-01 00:00 promptflow/core/_serving/app.py
 -rw-r--r--  2.0 unx      262 b- defN 80-Jan-01 00:00 promptflow/core/_serving/blueprint/__init__.py
 -rw-r--r--  2.0 unx     1182 b- defN 80-Jan-01 00:00 promptflow/core/_serving/blueprint/monitor_blueprint.py
 -rw-r--r--  2.0 unx     1591 b- defN 80-Jan-01 00:00 promptflow/core/_serving/blueprint/static_web_blueprint.py
 -rw-r--r--  2.0 unx      269 b- defN 80-Jan-01 00:00 promptflow/core/_serving/constants.py
 -rw-r--r--  2.0 unx      262 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/__init__.py
--rw-r--r--  2.0 unx     8933 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/azureml_extension.py
--rw-r--r--  2.0 unx     5899 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/default_extension.py
+-rw-r--r--  2.0 unx     8946 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/azureml_extension.py
+-rw-r--r--  2.0 unx     5912 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/default_extension.py
 -rw-r--r--  2.0 unx     1264 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/extension_factory.py
 -rw-r--r--  2.0 unx      361 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/extension_type.py
 -rw-r--r--  2.0 unx     4405 b- defN 80-Jan-01 00:00 promptflow/core/_serving/extension/otel_exporter_provider_factory.py
--rw-r--r--  2.0 unx    13079 b- defN 80-Jan-01 00:00 promptflow/core/_serving/flow_invoker.py
+-rw-r--r--  2.0 unx    13499 b- defN 80-Jan-01 00:00 promptflow/core/_serving/flow_invoker.py
 -rw-r--r--  2.0 unx      721 b- defN 80-Jan-01 00:00 promptflow/core/_serving/flow_result.py
 -rw-r--r--  2.0 unx      262 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/__init__.py
 -rw-r--r--  2.0 unx     2197 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/data_collector.py
 -rw-r--r--  2.0 unx     6902 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/flow_monitor.py
 -rw-r--r--  2.0 unx     1842 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/mdc_exporter.py
 -rw-r--r--  2.0 unx    13336 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/metrics.py
 -rw-r--r--  2.0 unx     2494 b- defN 80-Jan-01 00:00 promptflow/core/_serving/monitor/streaming_monitor.py
 -rw-r--r--  2.0 unx     1288 b- defN 80-Jan-01 00:00 promptflow/core/_serving/resources/feedback_swagger.json
 -rw-r--r--  2.0 unx     4854 b- defN 80-Jan-01 00:00 promptflow/core/_serving/response_creator.py
 -rw-r--r--  2.0 unx      770 b- defN 80-Jan-01 00:00 promptflow/core/_serving/static/index.html
 -rw-r--r--  2.0 unx  1604403 b- defN 80-Jan-01 00:00 promptflow/core/_serving/static/index.js
 -rw-r--r--  2.0 unx     4822 b- defN 80-Jan-01 00:00 promptflow/core/_serving/swagger.py
 -rw-r--r--  2.0 unx     6509 b- defN 80-Jan-01 00:00 promptflow/core/_serving/utils.py
 -rw-r--r--  2.0 unx     9527 b- defN 80-Jan-01 00:00 promptflow/core/_utils.py
--rw-r--r--  2.0 unx      268 b- defN 80-Jan-01 00:00 promptflow/core/_version.py
--rw-r--r--  2.0 unx    13589 b- defN 80-Jan-01 00:00 promptflow/exceptions.py
+-rw-r--r--  2.0 unx      296 b- defN 80-Jan-01 00:00 promptflow/core/_version.py
+-rw-r--r--  2.0 unx    13665 b- defN 80-Jan-01 00:00 promptflow/exceptions.py
 -rw-r--r--  2.0 unx      278 b- defN 80-Jan-01 00:00 promptflow/executor/__init__.py
 -rw-r--r--  2.0 unx     5447 b- defN 80-Jan-01 00:00 promptflow/executor/_assistant_tool_invoker.py
 -rw-r--r--  2.0 unx    14960 b- defN 80-Jan-01 00:00 promptflow/executor/_async_nodes_scheduler.py
 -rw-r--r--  2.0 unx     7961 b- defN 80-Jan-01 00:00 promptflow/executor/_dag_manager.py
 -rw-r--r--  2.0 unx      926 b- defN 80-Jan-01 00:00 promptflow/executor/_docstring_parser.py
--rw-r--r--  2.0 unx     8210 b- defN 80-Jan-01 00:00 promptflow/executor/_errors.py
+-rw-r--r--  2.0 unx     8898 b- defN 80-Jan-01 00:00 promptflow/executor/_errors.py
 -rw-r--r--  2.0 unx     6739 b- defN 80-Jan-01 00:00 promptflow/executor/_flow_nodes_scheduler.py
 -rw-r--r--  2.0 unx     4571 b- defN 80-Jan-01 00:00 promptflow/executor/_input_assignment_parser.py
--rw-r--r--  2.0 unx    39881 b- defN 80-Jan-01 00:00 promptflow/executor/_line_execution_process_pool.py
--rw-r--r--  2.0 unx    19265 b- defN 80-Jan-01 00:00 promptflow/executor/_process_manager.py
+-rw-r--r--  2.0 unx    40132 b- defN 80-Jan-01 00:00 promptflow/executor/_line_execution_process_pool.py
+-rw-r--r--  2.0 unx    19439 b- defN 80-Jan-01 00:00 promptflow/executor/_process_manager.py
 -rw-r--r--  2.0 unx     1894 b- defN 80-Jan-01 00:00 promptflow/executor/_result.py
--rw-r--r--  2.0 unx     6344 b- defN 80-Jan-01 00:00 promptflow/executor/_script_executor.py
+-rw-r--r--  2.0 unx     7867 b- defN 80-Jan-01 00:00 promptflow/executor/_script_executor.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/executor/_service/__init__.py
 -rw-r--r--  2.0 unx     1170 b- defN 80-Jan-01 00:00 promptflow/executor/_service/_errors.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/__init__.py
--rw-r--r--  2.0 unx     2078 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/batch.py
--rw-r--r--  2.0 unx      742 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/common.py
+-rw-r--r--  2.0 unx     2208 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/batch.py
+-rw-r--r--  2.0 unx      755 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/common.py
 -rw-r--r--  2.0 unx     4724 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/execution.py
 -rw-r--r--  2.0 unx     1711 b- defN 80-Jan-01 00:00 promptflow/executor/_service/apis/tool.py
 -rw-r--r--  2.0 unx     1004 b- defN 80-Jan-01 00:00 promptflow/executor/_service/app.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/executor/_service/contracts/__init__.py
 -rw-r--r--  2.0 unx      413 b- defN 80-Jan-01 00:00 promptflow/executor/_service/contracts/base_request.py
 -rw-r--r--  2.0 unx     1137 b- defN 80-Jan-01 00:00 promptflow/executor/_service/contracts/batch_request.py
 -rw-r--r--  2.0 unx     2762 b- defN 80-Jan-01 00:00 promptflow/executor/_service/contracts/execution_request.py
 -rw-r--r--  2.0 unx      712 b- defN 80-Jan-01 00:00 promptflow/executor/_service/contracts/tool_request.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/__init__.py
--rw-r--r--  2.0 unx     3770 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/batch_coordinator.py
+-rw-r--r--  2.0 unx     3951 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/batch_coordinator.py
 -rw-r--r--  2.0 unx     2115 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/process_manager.py
 -rw-r--r--  2.0 unx     4696 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/process_utils.py
--rw-r--r--  2.0 unx     2831 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/service_utils.py
+-rw-r--r--  2.0 unx     2854 b- defN 80-Jan-01 00:00 promptflow/executor/_service/utils/service_utils.py
 -rw-r--r--  2.0 unx      363 b- defN 80-Jan-01 00:00 promptflow/executor/_tool_invoker.py
--rw-r--r--  2.0 unx    29809 b- defN 80-Jan-01 00:00 promptflow/executor/_tool_resolver.py
--rw-r--r--  2.0 unx    62090 b- defN 80-Jan-01 00:00 promptflow/executor/flow_executor.py
+-rw-r--r--  2.0 unx    30142 b- defN 80-Jan-01 00:00 promptflow/executor/_tool_resolver.py
+-rw-r--r--  2.0 unx    63368 b- defN 80-Jan-01 00:00 promptflow/executor/flow_executor.py
 -rw-r--r--  2.0 unx    19923 b- defN 80-Jan-01 00:00 promptflow/executor/flow_validator.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 promptflow/integrations/__init__.py
 -rw-r--r--  2.0 unx     8657 b- defN 80-Jan-01 00:00 promptflow/integrations/langchain.py
 -rw-r--r--  2.0 unx      413 b- defN 80-Jan-01 00:00 promptflow/storage/__init__.py
 -rw-r--r--  2.0 unx      610 b- defN 80-Jan-01 00:00 promptflow/storage/_cache_storage.py
 -rw-r--r--  2.0 unx      286 b- defN 80-Jan-01 00:00 promptflow/storage/_errors.py
--rw-r--r--  2.0 unx     1981 b- defN 80-Jan-01 00:00 promptflow/storage/_queue_run_storage.py
--rw-r--r--  2.0 unx     7223 b- defN 80-Jan-01 00:00 promptflow/storage/_run_storage.py
+-rw-r--r--  2.0 unx     2178 b- defN 80-Jan-01 00:00 promptflow/storage/_queue_run_storage.py
+-rw-r--r--  2.0 unx     7031 b- defN 80-Jan-01 00:00 promptflow/storage/_run_storage.py
 -rw-r--r--  2.0 unx     3466 b- defN 80-Jan-01 00:00 promptflow/storage/run_records.py
--rw-r--r--  2.0 unx     1387 b- defN 80-Jan-01 00:00 promptflow_core-0.1.0b1.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 promptflow_core-0.1.0b1.dist-info/WHEEL
-?rw-r--r--  2.0 unx    13466 b- defN 16-Jan-01 00:00 promptflow_core-0.1.0b1.dist-info/RECORD
-140 files, 4161161 bytes uncompressed, 904821 bytes compressed:  78.3%
+-rw-r--r--  2.0 unx     2709 b- defN 80-Jan-01 00:00 promptflow_core-1.8.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 promptflow_core-1.8.0.dist-info/WHEEL
+?rw-r--r--  2.0 unx    13460 b- defN 16-Jan-01 00:00 promptflow_core-1.8.0.dist-info/RECORD
+140 files, 4182430 bytes uncompressed, 908654 bytes compressed:  78.3%
```

## zipnote {}

```diff
@@ -405,17 +405,17 @@
 
 Filename: promptflow/storage/_run_storage.py
 Comment: 
 
 Filename: promptflow/storage/run_records.py
 Comment: 
 
-Filename: promptflow_core-0.1.0b1.dist-info/METADATA
+Filename: promptflow_core-1.8.0.dist-info/METADATA
 Comment: 
 
-Filename: promptflow_core-0.1.0b1.dist-info/WHEEL
+Filename: promptflow_core-1.8.0.dist-info/WHEEL
 Comment: 
 
-Filename: promptflow_core-0.1.0b1.dist-info/RECORD
+Filename: promptflow_core-1.8.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## promptflow/_constants.py

```diff
@@ -95,19 +95,21 @@
 STREAMING_ANIMATION_TIME = 0.01
 
 # trace related
 OTEL_RESOURCE_SERVICE_NAME = "promptflow"
 DEFAULT_SPAN_TYPE = "default"
 RUNNING_LINE_RUN_STATUS = "Running"
 OK_LINE_RUN_STATUS = "Ok"
+SPAN_EVENTS_ATTRIBUTES_EVENT_ID = "event.id"
 
 
 class TraceEnvironmentVariableName:
     EXPERIMENT = "PF_TRACE_EXPERIMENT"
-    SESSION_ID = "PF_TRACE_SESSION_ID"
+    COLLECTION = "PF_TRACE_COLLECTION"
+    SESSION_ID = "PF_TRACE_SESSION_ID"  # will be deprecated
     COLLECTION_ID = "PF_TRACE_COLLECTION_ID"
     SUBSCRIPTION_ID = "PF_TRACE_SUBSCRIPTION_ID"
     RESOURCE_GROUP_NAME = "PF_TRACE_RESOURCE_GROUP_NAME"
     WORKSPACE_NAME = "PF_TRACE_WORKSPACE_NAME"
 
 
 class CosmosDBContainerName:
@@ -124,14 +126,15 @@
     START_TIME = "start_time"
     END_TIME = "end_time"
     STATUS = "status"
     ATTRIBUTES = "attributes"
     EVENTS = "events"
     LINKS = "links"
     RESOURCE = "resource"
+    EXTERNAL_EVENT_DATA_URIS = "external_event_data_uris"
 
 
 class SpanContextFieldName:
     TRACE_ID = "trace_id"
     SPAN_ID = "span_id"
     TRACE_STATE = "trace_state"
 
@@ -160,19 +163,22 @@
     BATCH_RUN_ID = "batch_run_id"
     LINE_NUMBER = "line_number"
     REFERENCED_BATCH_RUN_ID = "referenced.batch_run_id"
     COMPLETION_TOKEN_COUNT = "__computed__.cumulative_token_count.completion"
     PROMPT_TOKEN_COUNT = "__computed__.cumulative_token_count.prompt"
     TOTAL_TOKEN_COUNT = "__computed__.cumulative_token_count.total"
 
+    SESSION_ID = "session_id"
+
 
 class SpanResourceAttributesFieldName:
     SERVICE_NAME = "service.name"
     SESSION_ID = "session.id"
-    COLLECTION_ID = "collection.id"
+    COLLECTION = "collection"  # local
+    COLLECTION_ID = "collection.id"  # cloud & local to cloud
     EXPERIMENT_NAME = "experiment.name"
     # local to cloud
     SUBSCRIPTION_ID = "subscription.id"
     RESOURCE_GROUP_NAME = "resource_group.name"
     WORKSPACE_NAME = "workspace.name"
     # batch run
     BATCH_RUN_ID = "batch_run_id"
@@ -194,15 +200,15 @@
 class SpanLinkFieldName:
     CONTEXT = "context"
     ATTRIBUTES = "attributes"
 
 
 class MessageFormatType:
     BASIC = "basic"
-    OPENAI_VISION = "openai_vision"
+    OPENAI_VISION = "openai-vision"
 
 
 DEFAULT_OUTPUT_NAME = "output"
 OUTPUT_FILE_NAME = "output.jsonl"
 
 
 class OutputsFolderName:
@@ -252,10 +258,14 @@
 
 
 class ConnectionProviderConfig:
     LOCAL = "local"
     AZUREML = "azureml"
 
 
+AZURE_WORKSPACE_REGEX_FORMAT = (
+    "^azureml:[/]{1,2}subscriptions/([^/]+)/resource(groups|Groups)/([^/]+)"
+    "(/providers/Microsoft.MachineLearningServices)?/workspaces/([^/]+)$"
+)
 CONNECTION_DATA_CLASS_KEY = "DATA_CLASS"
 
 FLEX_FLOW_PUBLIC_NAME = "flex"
```

## promptflow/_core/flow_execution_context.py

```diff
@@ -9,14 +9,15 @@
 import threading
 import time
 import uuid
 from contextvars import ContextVar
 from logging import WARNING
 from typing import Callable
 
+from promptflow._constants import MessageFormatType
 from promptflow._core._errors import ToolExecutionError, UnexpectedError
 from promptflow._core.cache_manager import AbstractCacheManager, CacheInfo, CacheResult
 from promptflow._utils.logger_utils import flow_logger, logger
 from promptflow._utils.thread_utils import RepeatLogTimer
 from promptflow._utils.utils import generate_elapsed_time_messages, try_get_long_running_logging_interval
 from promptflow.contracts.flow import Node
 from promptflow.contracts.run_info import RunInfo
@@ -39,21 +40,23 @@
         self,
         name,
         run_tracker: RunTracker,
         cache_manager: AbstractCacheManager = None,
         run_id=None,
         flow_id=None,
         line_number=None,
+        message_format=MessageFormatType.BASIC,
     ):
         self._name = name
         self._run_tracker = run_tracker
         self._cache_manager = cache_manager or AbstractCacheManager.init_from_env()
         self._run_id = run_id or str(uuid.uuid4())
         self._flow_id = flow_id or self._run_id
         self._line_number = line_number
+        self._message_format = message_format
 
     def copy(self):
         return FlowExecutionContext(
             name=self._name,
             run_tracker=self._run_tracker,
             cache_manager=self._cache_manager,
             run_id=self._run_id,
@@ -109,14 +112,15 @@
         parent_run_id = f"{self._run_id}_{self._line_number}" if self._line_number is not None else self._run_id
         run_info: RunInfo = self._run_tracker.start_node_run(
             node=node.name,
             flow_run_id=self._run_id,
             parent_run_id=parent_run_id,
             run_id=node_run_id,
             index=self._line_number,
+            message_format=self._message_format,
         )
         run_info.index = self._line_number
         self._run_tracker.set_inputs(node_run_id, {key: value for key, value in kwargs.items() if key != "self"})
         return run_info
 
     async def invoke_tool_async(self, node: Node, f: Callable, kwargs):
         if not inspect.iscoroutinefunction(f):
@@ -208,14 +212,15 @@
         parent_run_id = f"{self._run_id}_{self._line_number}" if self._line_number is not None else self._run_id
         run_info = self._run_tracker.bypass_node_run(
             node=node.name,
             flow_run_id=self._run_id,
             parent_run_id=parent_run_id,
             run_id=node_run_id,
             index=self._line_number,
+            message_format=self._message_format,
         )
         self._run_tracker.persist_node_run(run_info)
 
     def _persist_cache(self, cache_info: CacheInfo, run_info: RunInfo):
         """Record result in cache storage if hash_id is valid."""
         if cache_info and cache_info.hash_id is not None and len(cache_info.hash_id) > 0:
             try:
```

## promptflow/_core/run_tracker.py

```diff
@@ -5,27 +5,29 @@
 import asyncio
 import json
 from contextvars import ContextVar
 from datetime import datetime, timezone
 from types import GeneratorType
 from typing import Any, Dict, List, Mapping, Optional, Union
 
+from promptflow._constants import MessageFormatType
 from promptflow._core._errors import FlowOutputUnserializable, RunRecordNotFound, ToolCanceledError
 from promptflow._core.log_manager import NodeLogManager
 from promptflow._utils.exception_utils import ExceptionPresenter
 from promptflow._utils.logger_utils import flow_logger
 from promptflow._utils.run_tracker_utils import _deep_copy_and_extract_items_from_generator_proxy
 from promptflow._utils.utils import default_json_encoder
 from promptflow.contracts.run_info import FlowRunInfo, RunInfo, Status
 from promptflow.contracts.run_mode import RunMode
 from promptflow.contracts.tool import ConnectionType
 from promptflow.exceptions import ErrorTarget
 from promptflow.storage import AbstractRunStorage
 from promptflow.storage._run_storage import DummyRunStorage
 from promptflow.tracing._openai_utils import OpenAIMetricsCalculator
+from promptflow.tracing._operation_context import OperationContext
 from promptflow.tracing._thread_local_singleton import ThreadLocalSingleton
 from promptflow.tracing._utils import serialize
 
 
 class RunTracker(ThreadLocalSingleton):
     RUN_CONTEXT_NAME = "CurrentRun"
     CONTEXT_VAR_NAME = "RunTracker"
@@ -77,14 +79,15 @@
         self,
         flow_id,
         root_run_id,
         run_id,
         parent_run_id="",
         inputs=None,
         index=None,
+        message_format=MessageFormatType.BASIC,
     ) -> FlowRunInfo:
         """Create a flow run and save to run storage on demand."""
         run_info = FlowRunInfo(
             run_id=run_id,
             status=Status.Running,
             error=None,
             inputs=inputs,
@@ -94,54 +97,58 @@
             parent_run_id=parent_run_id,
             root_run_id=root_run_id,
             source_run_id=None,
             flow_id=flow_id,
             start_time=datetime.utcnow(),
             end_time=None,
             index=index,
+            message_format=message_format,
         )
         self.persist_flow_run(run_info)
         self._flow_runs[run_id] = run_info
         self._current_run_id = run_id
         return run_info
 
     def start_node_run(
         self,
         node,
         flow_run_id,
         parent_run_id,
         run_id,
         index,
+        message_format=MessageFormatType.BASIC,
     ):
         run_info = RunInfo(
             node=node,
             run_id=run_id,
             flow_run_id=flow_run_id,
             status=Status.Running,
             inputs=None,
             output=None,
             metrics=None,
             error=None,
             parent_run_id=parent_run_id,
             start_time=datetime.utcnow(),
             end_time=None,
+            message_format=message_format,
         )
         self._node_runs[run_id] = run_info
         self._current_run_id = run_id
         self.set_current_run_in_context(run_id)
         self.node_log_manager.set_node_context(run_id, node, index)
         return run_info
 
     def bypass_node_run(
         self,
         node,
         flow_run_id,
         parent_run_id,
         run_id,
         index,
+        message_format=MessageFormatType.BASIC,
     ):
         run_info = RunInfo(
             node=node,
             run_id=run_id,
             flow_run_id=flow_run_id,
             parent_run_id=parent_run_id,
             status=Status.Bypassed,
@@ -150,19 +157,22 @@
             metrics=None,
             error=None,
             start_time=datetime.utcnow(),
             end_time=datetime.utcnow(),
             result=None,
             index=index,
             api_calls=[],
+            message_format=message_format,
         )
         self._node_runs[run_id] = run_info
         return run_info
 
     def _flow_run_postprocess(self, run_info: FlowRunInfo, output, ex: Optional[Exception]):
+        #  Try get otel trace id for correlation.
+        run_info.otel_trace_id = OperationContext.get_instance().get("otel_trace_id")
         if output:
             try:
                 self._assert_flow_output_serializable(output)
             except Exception as e:
                 output, ex = None, e
         self._common_postprocess(run_info, output, ex)
```

## promptflow/_core/tool_meta_generator.py

```diff
@@ -114,14 +114,17 @@
 
 
 def collect_flow_entry_in_module(m, entry):
     func_name = entry.split(":")[-1]
     func = getattr(m, func_name, None)
     if isinstance(func, types.FunctionType):
         return func
+    elif inspect.isclass(func) and hasattr(func, "__call__"):
+        # check if the entry is a callable class
+        return func.__call__
     raise PythonLoadError(
         message_format="Failed to collect flow entry '{entry}' in module '{module}'.",
         entry=entry,
         module=m.__name__,
     )
```

## promptflow/_core/tool_settings_parser.py

```diff
@@ -1,15 +1,14 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import io
 from pathlib import Path
 
 from promptflow._constants import ICON, ICON_DARK, ICON_LIGHT
-from promptflow._utils.multimedia_utils import convert_multimedia_data_to_base64
 from promptflow._utils.tool_utils import asdict_without_none
 from promptflow.contracts.multimedia import Image
 from promptflow.exceptions import UserErrorException
 
 
 def _parser_tool_input_settings(tool_inputs, input_settings):
     """
@@ -71,9 +70,9 @@
     # Open the image and resize it
     img = PIL_Image.open(image_data)
     if img.size != (16, 16):
         img = img.resize((16, 16), PIL_Image.Resampling.LANCZOS)
     buffered = io.BytesIO()
     img.save(buffered, format="PNG")
     icon_image = Image(buffered.getvalue(), mime_type="image/png")
-    image_url = convert_multimedia_data_to_base64(icon_image, with_type=True)
+    image_url = icon_image.to_base64(with_type=True)
     return image_url
```

## promptflow/_utils/_errors.py

```diff
@@ -14,7 +14,13 @@
 
     pass
 
 
 class ApplyInputMappingError(ValidationException):
     def __init__(self, target: ErrorTarget = ErrorTarget.CORE, **kwargs):
         super().__init__(target=target, **kwargs)
+
+
+class InvalidMessageFormatType(UserErrorException):
+    """Exception raised when the message format from yaml is invalid."""
+
+    pass
```

## promptflow/_utils/multimedia_data_converter.py

```diff
@@ -1,15 +1,15 @@
 import re
 from dataclasses import dataclass
 from enum import Enum
 from functools import partial
 from pathlib import Path
 from typing import Any, Callable
 
-from promptflow._utils.multimedia_utils import is_multimedia_dict
+from promptflow._utils.multimedia_utils import BasicMultimediaProcessor
 
 
 class ResourceType(Enum):
     """
     Enumeration of different types of multimedia resources.
     We support path, URL, and base64 data.
     """
@@ -73,15 +73,15 @@
     Url format example: {"data:image/jpg;url": "https://example.com/logo.jpg"}
     Base64 format example: {"data:image/jpg;base64": "base64 string"}
     """
 
     MIME_PATTERN = re.compile(r"^data:(.*);(path|base64|url)$")
 
     def is_valid_format(self, original_data: Any):
-        return isinstance(original_data, dict) and is_multimedia_dict(original_data)
+        return isinstance(original_data, dict) and BasicMultimediaProcessor.is_multimedia_dict(original_data)
 
     def extract_info(self, original_data: Any) -> MultimediaInfo:
         if not self.is_valid_format(original_data):
             return None
         for key in original_data:
             match = re.match(self.MIME_PATTERN, key)
             if match:
@@ -112,17 +112,17 @@
     def __init__(self, flow_file: Path):
         """
         Initialize the MultimediaConverter.
 
         :param flow_file: The path to the YAML file. The YAML content will be used to determine the contract version.
         :type flow_file: Path
         """
-        # TODO: check yaml content to determine the current contract version.
-        # Different contract version will have different multimedia format.
-        # The version exists in the yaml file, so we need to load the yaml to get version and init converter.
+        # TODO: read flow.MessageFormatType from flow yaml file.
+        # Implement the format_adapter class for the openai-vision type.
+        # Then initialize the format_adapter for different MessageFormatType.
         self.format_adapter = MultimediaFormatAdapter20231201()
 
     def convert_content_recursively(self, content: Any, client_converter: AbstractMultimediaInfoConverter):
         """
         Recursively converts multimedia data format in content.
 
         :param content: The object that may contain multimedia data.
```

## promptflow/_utils/multimedia_utils.py

```diff
@@ -1,193 +1,29 @@
 import base64
 import os
 import re
 import uuid
+from abc import ABC, abstractmethod, abstractstaticmethod
 from functools import partial
 from pathlib import Path
-from typing import Any, Callable, Dict, Union
+from typing import Any, Callable, Dict, Optional, Union
 from urllib.parse import urlparse
 
 import requests
 
-from promptflow._utils._errors import InvalidImageInput, LoadMultimediaDataError
+from promptflow._constants import MessageFormatType
+from promptflow._utils._errors import InvalidImageInput, InvalidMessageFormatType, LoadMultimediaDataError
+from promptflow._utils.yaml_utils import load_yaml
 from promptflow.contracts.flow import FlowInputDefinition
-from promptflow.contracts.multimedia import Image, PFBytes
+from promptflow.contracts.multimedia import Image, PFBytes, Text
 from promptflow.contracts.run_info import FlowRunInfo
 from promptflow.contracts.run_info import RunInfo as NodeRunInfo
 from promptflow.contracts.tool import ValueType
 from promptflow.exceptions import ErrorTarget
 
-MIME_PATTERN = re.compile(r"^data:image/(.*);(path|base64|url)$")
-
-
-def _get_extension_from_mime_type(mime_type: str):
-    ext = mime_type.split("/")[-1]
-    if ext == "*":
-        return None
-    return ext
-
-
-def is_multimedia_dict(multimedia_dict: dict):
-    if len(multimedia_dict) != 1:
-        return False
-    key = list(multimedia_dict.keys())[0]
-    if re.match(MIME_PATTERN, key):
-        return True
-    return False
-
-
-def _get_multimedia_info(key: str):
-    match = re.match(MIME_PATTERN, key)
-    if match:
-        return match.group(1), match.group(2)
-    return None, None
-
-
-def _is_url(value: str):
-    try:
-        result = urlparse(value)
-        return all([result.scheme, result.netloc])
-    except ValueError:
-        return False
-
-
-def _is_base64(value: str):
-    base64_regex = re.compile(r"^([A-Za-z0-9+/]{4})*(([A-Za-z0-9+/]{2})*(==|[A-Za-z0-9+/]=)?)?$")
-    if re.match(base64_regex, value):
-        return True
-    return False
-
-
-def _create_image_from_file(f: Path, mime_type: str = None):
-    with open(f, "rb") as fin:
-        return Image(fin.read(), mime_type=mime_type)
-
-
-def _create_image_from_base64(base64_str: str, mime_type: str = None):
-    image_bytes = base64.b64decode(base64_str)
-    return Image(image_bytes, mime_type=mime_type)
-
-
-def _create_image_from_url(url: str, mime_type: str = None):
-    response = requests.get(url)
-    if response.status_code == 200:
-        return Image(response.content, mime_type=mime_type, source_url=url)
-    else:
-        raise InvalidImageInput(
-            message_format="Failed to fetch image from URL: {url}. Error code: {error_code}. "
-            "Error message: {error_message}.",
-            target=ErrorTarget.EXECUTOR,
-            url=url,
-            error_code=response.status_code,
-            error_message=response.text,
-        )
-
-
-def _create_image_from_dict(image_dict: dict):
-    for k, v in image_dict.items():
-        format, resource = _get_multimedia_info(k)
-        if resource == "path":
-            return _create_image_from_file(Path(v), mime_type=f"image/{format}")
-        elif resource == "base64":
-            if _is_base64(v):
-                return _create_image_from_base64(v, mime_type=f"image/{format}")
-            else:
-                raise InvalidImageInput(
-                    message_format=f"Invalid base64 image: {v}.",
-                    target=ErrorTarget.EXECUTOR,
-                )
-        elif resource == "url":
-            return _create_image_from_url(v, mime_type=f"image/{format}")
-        else:
-            raise InvalidImageInput(
-                message_format=f"Unsupported image resource: {resource}. "
-                "Supported Resources are [path, base64, url].",
-                target=ErrorTarget.EXECUTOR,
-            )
-
-
-def _create_image_from_string(value: str):
-    if _is_base64(value):
-        return _create_image_from_base64(value)
-    elif _is_url(value):
-        return _create_image_from_url(value)
-    else:
-        return _create_image_from_file(Path(value))
-
-
-def create_image(value: any):
-    if isinstance(value, PFBytes):
-        return value
-    elif isinstance(value, dict):
-        if is_multimedia_dict(value):
-            return _create_image_from_dict(value)
-        else:
-            raise InvalidImageInput(
-                message_format="Invalid image input format. The image input should be a dictionary like: "
-                "{{data:image/<image_type>;[path|base64|url]: <image_data>}}.",
-                target=ErrorTarget.EXECUTOR,
-            )
-    elif isinstance(value, str):
-        if not value:
-            raise InvalidImageInput(message_format="The image input should not be empty.", target=ErrorTarget.EXECUTOR)
-        return _create_image_from_string(value)
-    else:
-        raise InvalidImageInput(
-            message_format=f"Unsupported image input type: {type(value)}. "
-            "The image inputs should be a string or a dictionary.",
-            target=ErrorTarget.EXECUTOR,
-        )
-
-
-def _save_image_to_file(
-    image: Image, file_name: str, folder_path: Path, relative_path: Path = None, use_absolute_path=False
-):
-    ext = _get_extension_from_mime_type(image._mime_type)
-    file_name = f"{file_name}.{ext}" if ext else file_name
-    image_path = (relative_path / file_name).as_posix() if relative_path else file_name
-    if use_absolute_path:
-        image_path = Path(folder_path / image_path).resolve().as_posix()
-    image_reference = {f"data:{image._mime_type};path": image_path}
-    path = folder_path / relative_path if relative_path else folder_path
-    os.makedirs(path, exist_ok=True)
-    with open(os.path.join(path, file_name), "wb") as file:
-        file.write(image)
-    return image_reference
-
-
-def get_file_reference_encoder(folder_path: Path, relative_path: Path = None, use_absolute_path=False) -> Callable:
-    def pfbytes_file_reference_encoder(obj):
-        """Dumps PFBytes to a file and returns its reference."""
-        if obj.source_url:
-            return {f"data:{obj._mime_type};url": obj.source_url}
-        if isinstance(obj, PFBytes):
-            file_name = str(uuid.uuid4())
-            # If use_absolute_path is True, the image file path in image dictionary will be absolute path.
-            return _save_image_to_file(obj, file_name, folder_path, relative_path, use_absolute_path)
-        raise TypeError(f"Not supported to dump type '{type(obj).__name__}'.")
-
-    return pfbytes_file_reference_encoder
-
-
-def persist_multimedia_data(value: Any, base_dir: Path, sub_dir: Path = None, use_absolute_path=False):
-    pfbytes_file_reference_encoder = get_file_reference_encoder(base_dir, sub_dir, use_absolute_path=use_absolute_path)
-    serialization_funcs = {Image: partial(Image.serialize, **{"encoder": pfbytes_file_reference_encoder})}
-    return _process_recursively(value, process_funcs=serialization_funcs)
-
-
-def convert_multimedia_data_to_base64(value: Any, with_type=False, dict_type=False):
-    to_base64_funcs = {PFBytes: partial(PFBytes.to_base64, **{"with_type": with_type, "dict_type": dict_type})}
-    return _process_recursively(value, process_funcs=to_base64_funcs)
-
-
-def convert_multimedia_data_to_string(value: Any, inplace=False):
-    serialization_funcs = {Image: partial(Image.serialize, **{"encoder": None})}
-    return _process_recursively(value, process_funcs=serialization_funcs, inplace=inplace)
-
 
 # TODO: Move this function to a more general place and integrate serialization to this function.
 def _process_recursively(value: Any, process_funcs: Dict[type, Callable] = None, inplace: bool = False) -> dict:
     if process_funcs:
         for cls, f in process_funcs.items():
             if isinstance(value, cls):
                 return f(value)
@@ -202,78 +38,477 @@
             for k, v in value.items():
                 value[k] = _process_recursively(v, process_funcs, inplace)
         else:
             return {k: _process_recursively(v, process_funcs, inplace) for k, v in value.items()}
     return value
 
 
-def load_multimedia_data(inputs: Dict[str, FlowInputDefinition], line_inputs: dict):
-    updated_inputs = dict(line_inputs or {})
-    for key, value in inputs.items():
+MIME_PATTERN = re.compile(r"^data:image/(.*);(path|base64|url)$")
+
+
+class ImageProcessor:
+    @staticmethod
+    def get_extension_from_mime_type(mime_type: str):
+        ext = mime_type.split("/")[-1]
+        if ext == "*":
+            return None
+        return ext
+
+    @staticmethod
+    def get_multimedia_info(key: str):
+        match = re.match(MIME_PATTERN, key)
+        if match:
+            return match.group(1), match.group(2)
+        return None, None
+
+    @staticmethod
+    def is_url(value: str):
         try:
-            if value.type == ValueType.IMAGE:
-                if isinstance(updated_inputs[key], list):
-                    # For aggregation node, the image input is a list.
-                    updated_inputs[key] = [create_image(item) for item in updated_inputs[key]]
-                else:
-                    updated_inputs[key] = create_image(updated_inputs[key])
-            elif value.type == ValueType.LIST or value.type == ValueType.OBJECT:
-                updated_inputs[key] = load_multimedia_data_recursively(updated_inputs[key])
-        except Exception as ex:
-            error_type_and_message = f"({ex.__class__.__name__}) {ex}"
-            raise LoadMultimediaDataError(
-                message_format="Failed to load image for input '{key}': {error_type_and_message}",
-                key=key,
-                error_type_and_message=error_type_and_message,
+            result = urlparse(value)
+            return all([result.scheme, result.netloc])
+        except ValueError:
+            return False
+
+    @staticmethod
+    def is_base64(value: str):
+        prefix_regex = re.compile(r"^data:image/(.*);base64")
+        base64_regex = re.compile(r"^([A-Za-z0-9+/]{4})*(([A-Za-z0-9+/]{2})*(==|[A-Za-z0-9+/]=)?)?$")
+        base64_with_prefix = value.split(",")
+        if len(base64_with_prefix) == 2:
+            if re.match(prefix_regex, base64_with_prefix[0]) and re.match(base64_regex, base64_with_prefix[1]):
+                return True
+        elif len(base64_with_prefix) == 1:
+            if re.match(base64_regex, value):
+                return True
+        return False
+
+    @staticmethod
+    def create_image_from_file(f: Path, mime_type: str = None):
+        with open(f, "rb") as fin:
+            return Image(fin.read(), mime_type=mime_type)
+
+    @staticmethod
+    def create_image_from_base64(base64_str: str, mime_type: str = None):
+        base64_str = base64_str.split(",")[-1]
+        image_bytes = base64.b64decode(base64_str)
+        return Image(image_bytes, mime_type=mime_type)
+
+    @staticmethod
+    def create_image_from_url(url: str, mime_type: str = None):
+        response = requests.get(url)
+        if response.status_code == 200:
+            return Image(response.content, mime_type=mime_type, source_url=url)
+        else:
+            raise InvalidImageInput(
+                message_format=(
+                    "Failed to fetch image from URL: {url}. Error code: {error_code}. "
+                    "Error message: {error_message}."
+                ),
                 target=ErrorTarget.EXECUTOR,
-            ) from ex
-    return updated_inputs
+                url=url,
+                error_code=response.status_code,
+                error_message=response.text,
+            )
 
+    @staticmethod
+    def create_image_from_string(value: str):
+        if ImageProcessor.is_base64(value):
+            return ImageProcessor.create_image_from_base64(value)
+        elif ImageProcessor.is_url(value):
+            return ImageProcessor.create_image_from_url(value)
+        else:
+            return ImageProcessor.create_image_from_file(Path(value))
 
-def load_multimedia_data_recursively(value: Any):
-    return _process_multimedia_dict_recursively(value, _create_image_from_dict)
 
+class TextProcessor:
+    @staticmethod
+    def is_text_dict(text_dict: dict):
+        if len(text_dict) != 2:
+            return False
+        if "type" not in text_dict:
+            return False
+        if text_dict["type"] == "text" and "text" in text_dict:
+            text = text_dict["text"]
+            if isinstance(text, str):
+                return True
+            elif isinstance(text, dict):
+                if "value" in text and isinstance(text["value"], str):
+                    return True
+        return False
 
-def resolve_multimedia_data_recursively(input_dir: Path, value: Any):
-    process_func = partial(resolve_image_path, **{"input_dir": input_dir})
-    return _process_multimedia_dict_recursively(value, process_func)
+    @staticmethod
+    def create_text_from_dict(text_dict: any):
+        return Text.deserialize(text_dict)
+
+
+class MultimediaProcessor(ABC):
+    @staticmethod
+    def create(message_format_type: str = MessageFormatType.BASIC):
+        if not message_format_type or message_format_type.lower() == MessageFormatType.BASIC:
+            return BasicMultimediaProcessor()
+        if message_format_type.lower() == MessageFormatType.OPENAI_VISION:
+            return OpenaiVisionMultimediaProcessor()
+        raise InvalidMessageFormatType(
+            message_format=(
+                f"Invalid message format '{message_format_type}'. "
+                "Supported message formats are ['basic', 'openai-vision']."
+            ),
+        )
 
+    @staticmethod
+    def create_from_yaml(flow_file: Path, working_dir: Optional[Path] = None):
+        if flow_file and Path(flow_file).suffix.lower() in [".yaml", ".yml"]:
+            flow_file = working_dir / flow_file if working_dir else flow_file
+            with open(flow_file, "r", encoding="utf-8") as fin:
+                flow_dag = load_yaml(fin)
+            message_format_type = flow_dag.get("message_format", MessageFormatType.BASIC)
+            return MultimediaProcessor.create(message_format_type)
+        return BasicMultimediaProcessor()
+
+    def create_image(self, value: any):
+        if isinstance(value, PFBytes):
+            return value
+        elif isinstance(value, dict):
+            if self.is_multimedia_dict(value):
+                return self._create_image_from_dict(value)
+            else:
+                raise InvalidImageInput(
+                    message_format=(
+                        "Invalid image input format. The image input should be a dictionary like: "
+                        "{{data:image/<image_type>;[path|base64|url]: <image_data>}}."
+                    ),
+                    target=ErrorTarget.EXECUTOR,
+                )
+        elif isinstance(value, str):
+            if not value:
+                raise InvalidImageInput(
+                    message_format="The image input should not be empty.", target=ErrorTarget.EXECUTOR
+                )
+            return ImageProcessor.create_image_from_string(value)
+        else:
+            raise InvalidImageInput(
+                message_format=(
+                    f"Unsupported image input type: {type(value)}. "
+                    "The image inputs should be a string or a dictionary."
+                ),
+                target=ErrorTarget.EXECUTOR,
+            )
 
-def _process_multimedia_dict_recursively(value: Any, process_func: Callable) -> dict:
-    if isinstance(value, list):
-        return [_process_multimedia_dict_recursively(item, process_func) for item in value]
-    elif isinstance(value, dict):
-        if is_multimedia_dict(value):
-            return process_func(**{"image_dict": value})
+    def _save_image_to_file(
+        self, image: Image, file_name: str, folder_path: Path, relative_path: Path = None, use_absolute_path=False
+    ):
+        ext = ImageProcessor.get_extension_from_mime_type(image._mime_type)
+        file_name = f"{file_name}.{ext}" if ext else file_name
+        image_path = (relative_path / file_name).as_posix() if relative_path else file_name
+        if use_absolute_path:
+            image_path = Path(folder_path / image_path).resolve().as_posix()
+        image_reference = self._generate_image_file_reference(image, image_path)
+        path = folder_path / relative_path if relative_path else folder_path
+        os.makedirs(path, exist_ok=True)
+        with open(os.path.join(path, file_name), "wb") as file:
+            file.write(image)
+        return image_reference
+
+    def get_file_reference_encoder(
+        self, folder_path: Path, relative_path: Path = None, use_absolute_path=False
+    ) -> Callable:
+        def pfbytes_file_reference_encoder(obj):
+            """Dumps PFBytes to a file and returns its reference."""
+            if obj.source_url:
+                return self._generate_image_url_reference(obj)
+            if isinstance(obj, PFBytes):
+                file_name = str(uuid.uuid4())
+                # If use_absolute_path is True, the image file path in image dictionary will be absolute path.
+                return self._save_image_to_file(obj, file_name, folder_path, relative_path, use_absolute_path)
+            raise TypeError(f"Not supported to dump type '{type(obj).__name__}'.")
+
+        return pfbytes_file_reference_encoder
+
+    def load_multimedia_data(self, inputs: Dict[str, FlowInputDefinition], line_inputs: dict):
+        updated_inputs = dict(line_inputs or {})
+        for key, value in inputs.items():
+            try:
+                if value.type == ValueType.IMAGE:
+                    if isinstance(updated_inputs[key], list):
+                        # For aggregation node, the image input is a list.
+                        updated_inputs[key] = [self.create_image(item) for item in updated_inputs[key]]
+                    else:
+                        updated_inputs[key] = self.create_image(updated_inputs[key])
+                elif value.type == ValueType.LIST or value.type == ValueType.OBJECT:
+                    updated_inputs[key] = self.load_multimedia_data_recursively(updated_inputs[key])
+            except Exception as ex:
+                error_type_and_message = f"({ex.__class__.__name__}) {ex}"
+                raise LoadMultimediaDataError(
+                    message_format="Failed to load image for input '{key}': {error_type_and_message}",
+                    key=key,
+                    error_type_and_message=error_type_and_message,
+                    target=ErrorTarget.EXECUTOR,
+                ) from ex
+        return updated_inputs
+
+    @staticmethod
+    def _process_multimedia_dict_recursively(value: Any, process_funcs: Dict[Callable[[dict], bool], Callable]) -> dict:
+        if isinstance(value, list):
+            return [MultimediaProcessor._process_multimedia_dict_recursively(item, process_funcs) for item in value]
+        elif isinstance(value, dict):
+            for check_func, process_func in process_funcs.items():
+                if check_func(value):
+                    return process_func(value)
+            return {
+                k: MultimediaProcessor._process_multimedia_dict_recursively(v, process_funcs) for k, v in value.items()
+            }
         else:
-            return {k: _process_multimedia_dict_recursively(v, process_func) for k, v in value.items()}
-    else:
-        return value
+            return value
 
+    @staticmethod
+    def convert_multimedia_data_to_string(value: Any, inplace=False):
+        serialization_funcs = {Image: partial(Image.serialize, **{"encoder": None})}
+        return _process_recursively(value, process_funcs=serialization_funcs, inplace=inplace)
+
+    def process_multimedia_in_run_info(
+        self, run_info: Union[FlowRunInfo, NodeRunInfo], base_dir: Path, sub_dir: Path = None, use_absolute_path=False
+    ):
+        """Persist multimedia data in run info to file and update the run info with the file path.
+        If sub_dir is not None, the multimedia file path will be sub_dir/file_name, otherwise file_name.
+        If use_absolute_path is True, the multimedia file path will be absolute path.
+        """
+        if run_info.inputs:
+            run_info.inputs = self.persist_multimedia_data(run_info.inputs, base_dir, sub_dir, use_absolute_path)
+        if run_info.output:
+            run_info.output = self.persist_multimedia_data(run_info.output, base_dir, sub_dir, use_absolute_path)
+            run_info.result = None
+        if run_info.api_calls:
+            run_info.api_calls = self.persist_multimedia_data(run_info.api_calls, base_dir, sub_dir, use_absolute_path)
+
+    @abstractstaticmethod
+    def is_multimedia_dict(multimedia_dict: dict):
+        pass
+
+    @abstractstaticmethod
+    def _create_image_from_dict(image_dict: dict):
+        pass
+
+    @abstractmethod
+    def load_multimedia_data_recursively(self, value: Any):
+        pass
+
+    @abstractstaticmethod
+    def _generate_image_file_reference(image: PFBytes, image_path: str):
+        pass
+
+    @abstractstaticmethod
+    def _generate_image_url_reference(image: PFBytes):
+        pass
+
+    @abstractmethod
+    def resolve_multimedia_data_recursively(self, input_dir: Path, value: Any):
+        pass
+
+    @abstractmethod
+    def persist_multimedia_data(
+        self, value: Any, base_dir: Path, sub_dir: Path = None, use_absolute_path=False, inplace: bool = False
+    ):
+        pass
+
+    @abstractstaticmethod
+    def convert_multimedia_data_to_base64_dict(value: Any):
+        pass
+
+
+class BasicMultimediaProcessor(MultimediaProcessor):
+    @staticmethod
+    def is_multimedia_dict(multimedia_dict: dict):
+        if len(multimedia_dict) != 1:
+            return False
+        key = list(multimedia_dict.keys())[0]
+        if re.match(MIME_PATTERN, key):
+            return True
+        return False
 
-def resolve_image_path(input_dir: Path, image_dict: dict):
-    """Resolve image path to absolute path in image dict"""
-
-    input_dir = input_dir.parent if input_dir.is_file() else input_dir
-    if is_multimedia_dict(image_dict):
-        for key in image_dict:
-            _, resource = _get_multimedia_info(key)
+    @staticmethod
+    def _create_image_from_dict(image_dict: dict):
+        for k, v in image_dict.items():
+            format, resource = ImageProcessor.get_multimedia_info(k)
             if resource == "path":
-                image_dict[key] = str(input_dir / image_dict[key])
-    return image_dict
+                return ImageProcessor.create_image_from_file(Path(v), mime_type=f"image/{format}")
+            elif resource == "base64":
+                if ImageProcessor.is_base64(v):
+                    return ImageProcessor.create_image_from_base64(v, mime_type=f"image/{format}")
+                else:
+                    raise InvalidImageInput(
+                        message_format=f"Invalid base64 image: {v}.",
+                        target=ErrorTarget.EXECUTOR,
+                    )
+            elif resource == "url":
+                return ImageProcessor.create_image_from_url(v, mime_type=f"image/{format}")
+            else:
+                raise InvalidImageInput(
+                    message_format=(
+                        f"Unsupported image resource: {resource}. Supported Resources are [path, base64, url]."
+                    ),
+                    target=ErrorTarget.EXECUTOR,
+                )
 
+    def load_multimedia_data_recursively(self, value: Any):
+        process_funcs = {self.is_multimedia_dict: self._create_image_from_dict}
+        return self._process_multimedia_dict_recursively(value, process_funcs)
+
+    @staticmethod
+    def _generate_image_file_reference(obj: PFBytes, image_path: str):
+        return {f"data:{obj._mime_type};path": image_path}
+
+    @staticmethod
+    def _generate_image_url_reference(obj: PFBytes):
+        return {f"data:{obj._mime_type};url": obj.source_url}
+
+    def _resolve_image_path(self, input_dir: Path, image_dict: dict):
+        """Resolve image path to absolute path in image dict"""
+
+        input_dir = input_dir.parent if input_dir.is_file() else input_dir
+        if self.is_multimedia_dict(image_dict):
+            for key in image_dict:
+                _, resource = ImageProcessor.get_multimedia_info(key)
+                if resource == "path":
+                    image_dict[key] = str(input_dir / image_dict[key])
+        return image_dict
+
+    def resolve_multimedia_data_recursively(self, input_dir: Path, value: Any):
+        process_funcs = {self.is_multimedia_dict: partial(self._resolve_image_path, input_dir)}
+        return self._process_multimedia_dict_recursively(value, process_funcs)
+
+    def persist_multimedia_data(
+        self, value: Any, base_dir: Path, sub_dir: Path = None, use_absolute_path=False, inplace: bool = False
+    ):
+        pfbytes_file_reference_encoder = (
+            self.get_file_reference_encoder(base_dir, sub_dir, use_absolute_path=use_absolute_path)
+            if base_dir
+            else None
+        )
+        serialization_funcs = {Image: partial(Image.serialize, **{"encoder": pfbytes_file_reference_encoder})}
+        return _process_recursively(value, process_funcs=serialization_funcs, inplace=inplace)
 
-def process_multimedia_in_run_info(
-    run_info: Union[FlowRunInfo, NodeRunInfo], base_dir: Path, sub_dir: Path = None, use_absolute_path=False
+    @staticmethod
+    def convert_multimedia_data_to_base64_dict(value: Any):
+        def convert_pfbytes_to_base64_dict(obj: PFBytes):
+            return {f"data:{obj._mime_type};base64": obj.to_base64()}
+
+        to_base64_funcs = {PFBytes: convert_pfbytes_to_base64_dict}
+        return _process_recursively(value, process_funcs=to_base64_funcs)
+
+
+class OpenaiVisionMultimediaProcessor(MultimediaProcessor):
+    @staticmethod
+    def is_multimedia_dict(multimedia_dict: dict):
+        if len(multimedia_dict) != 2:
+            return False
+        if "type" not in multimedia_dict:
+            return False
+        image_type = multimedia_dict["type"]
+        if image_type not in multimedia_dict or not isinstance(multimedia_dict[image_type], dict):
+            return False
+        if image_type == "image_url" and "url" in multimedia_dict[image_type]:
+            return True
+        if image_type == "image_file" and "path" in multimedia_dict[image_type]:
+            return True
+        return False
+
+    @staticmethod
+    def _create_image_from_dict(image_dict: dict):
+        image_type = image_dict["type"]
+        if image_type == "image_url":
+            image_url = image_dict["image_url"]["url"]
+            if ImageProcessor.is_base64(image_url):
+                return ImageProcessor.create_image_from_base64(image_url)
+            elif ImageProcessor.is_url(image_url):
+                return ImageProcessor.create_image_from_url(image_url)
+            else:
+                raise InvalidImageInput(
+                    message_format=f"Invalid image url: {image_url}. Should be a valid url or base64 string.",
+                    target=ErrorTarget.EXECUTOR,
+                )
+        elif image_type == "image_file":
+            return ImageProcessor.create_image_from_file(Path(image_dict["image_file"]["path"]))
+        else:
+            raise InvalidImageInput(
+                message_format=f"Unsupported image type: {image_type}. Supported types are [image_url, image_file].",
+                target=ErrorTarget.EXECUTOR,
+            )
+
+    def load_multimedia_data_recursively(self, value: Any):
+        process_funcs = {
+            self.is_multimedia_dict: self._create_image_from_dict,
+            TextProcessor.is_text_dict: TextProcessor.create_text_from_dict,
+        }
+        return self._process_multimedia_dict_recursively(value, process_funcs)
+
+    @staticmethod
+    def _generate_image_file_reference(obj: PFBytes, image_path: str):
+        return {"type": "image_file", "image_file": {"path": image_path}}
+
+    @staticmethod
+    def _generate_image_url_reference(obj: PFBytes):
+        return {"type": "image_url", "image_url": {"url": obj.source_url}}
+
+    def _resolve_image_path(self, input_dir: Path, image_dict: dict):
+        """Resolve image path to absolute path in image dict"""
+
+        input_dir = input_dir.parent if input_dir.is_file() else input_dir
+        if self.is_multimedia_dict(image_dict):
+            image_type = image_dict["type"]
+            if image_type == "image_file" and "path" in image_dict["image_file"]:
+                image_dict["image_file"]["path"] = str(input_dir / image_dict["image_file"]["path"])
+        return image_dict
+
+    def resolve_multimedia_data_recursively(self, input_dir: Path, value: Any):
+        process_funcs = {self.is_multimedia_dict: partial(self._resolve_image_path, input_dir)}
+        return self._process_multimedia_dict_recursively(value, process_funcs)
+
+    def persist_multimedia_data(
+        self, value: Any, base_dir: Path, sub_dir: Path = None, use_absolute_path=False, inplace: bool = False
+    ):
+        pfbytes_file_reference_encoder = (
+            self.get_file_reference_encoder(base_dir, sub_dir, use_absolute_path=use_absolute_path)
+            if base_dir
+            else None
+        )
+        serialization_funcs = {
+            Image: partial(Image.serialize, **{"encoder": pfbytes_file_reference_encoder}),
+            Text: Text.serialize,
+        }
+        return _process_recursively(value, process_funcs=serialization_funcs, inplace=inplace)
+
+    @staticmethod
+    def convert_multimedia_data_to_base64_dict(value: Any):
+        def convert_pfbytes_to_base64_dict(obj: PFBytes):
+            return {"type": "image_url", "image_url": {"url": obj.to_base64(with_type=True)}}
+
+        to_base64_funcs = {PFBytes: convert_pfbytes_to_base64_dict}
+        return _process_recursively(value, process_funcs=to_base64_funcs)
+
+
+# TODORuntime relies on these old interfaces and will be removed in the future.
+def persist_multimedia_data(
+    value: Any,
+    base_dir: Path,
+    sub_dir: Path = None,
+    use_absolute_path=False,
+    multimedia_processor: MultimediaProcessor = None,
 ):
-    """Persist multimedia data in run info to file and update the run info with the file path.
+    if multimedia_processor:
+        return multimedia_processor.persist_multimedia_data(
+            value, base_dir, sub_dir, use_absolute_path=use_absolute_path
+        )
+    return BasicMultimediaProcessor().persist_multimedia_data(
+        value, base_dir, sub_dir, use_absolute_path=use_absolute_path
+    )
+
+
+def load_multimedia_data_recursively(value: Any, multimedia_processor: MultimediaProcessor = None):
+    if multimedia_processor:
+        return multimedia_processor.load_multimedia_data_recursively(value)
+    return BasicMultimediaProcessor().load_multimedia_data_recursively(value)
+
 
-    If sub_dir is not None, the multimedia file path will be sub_dir/file_name, otherwise file_name.
-    If use_absolute_path is True, the multimedia file path will be absolute path.
-    """
-    if run_info.inputs:
-        run_info.inputs = persist_multimedia_data(run_info.inputs, base_dir, sub_dir, use_absolute_path)
-    if run_info.output:
-        run_info.output = persist_multimedia_data(run_info.output, base_dir, sub_dir, use_absolute_path)
-        run_info.result = None
-    if run_info.api_calls:
-        run_info.api_calls = persist_multimedia_data(run_info.api_calls, base_dir, sub_dir, use_absolute_path)
+def resolve_multimedia_data_recursively(input_dir: Path, value: Any, multimedia_processor: MultimediaProcessor = None):
+    if multimedia_processor:
+        return multimedia_processor.resolve_multimedia_data_recursively(input_dir, value)
+    return BasicMultimediaProcessor().resolve_multimedia_data_recursively(input_dir, value)
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## promptflow/_utils/user_agent_utils.py

```diff
@@ -1,11 +1,12 @@
 import os
 from typing import Optional
 
 from promptflow._constants import PF_USER_AGENT, USER_AGENT
+from promptflow.core._version import __version__
 from promptflow.tracing._operation_context import OperationContext
 
 
 class ClientUserAgentUtil:
     """SDK/CLI side user agent utilities."""
 
     @classmethod
@@ -52,7 +53,17 @@
     For serving with promptflow-core only env, ua will be like: promptflow-local-serving/ promptflow-core/
     """
     # add user added UA after SDK/CLI
     ClientUserAgentUtil.append_user_agent(user_agent)
     ClientUserAgentUtil.update_user_agent_from_env_var()
     ClientUserAgentUtil.update_user_agent_from_config()
     return ClientUserAgentUtil.get_user_agent()
+
+
+def append_promptflow_package_ua(operation_context: OperationContext):
+    try:
+        from promptflow._version import VERSION as PF_VERSION
+
+        operation_context.append_user_agent(f"promptflow/{PF_VERSION}")
+    except ImportError:
+        pass
+    operation_context.append_user_agent(f"promptflow-core/{__version__}")
```

## promptflow/_utils/utils.py

```diff
@@ -17,14 +17,15 @@
 import time
 import traceback
 from datetime import datetime
 from pathlib import Path
 from typing import Any, Dict, Iterable, Iterator, List, Optional, TypeVar, Union
 
 from promptflow._constants import DEFAULT_ENCODING, PF_LONG_RUNNING_LOGGING_INTERVAL
+from promptflow._utils.logger_utils import bulk_logger
 from promptflow.contracts.multimedia import PFBytes
 from promptflow.contracts.types import AssistantDefinition
 
 T = TypeVar("T")
 
 
 class AttrDict(dict):
@@ -146,41 +147,43 @@
             logger.info(formatter.format(count=count, total_count=total_count))
 
         yield item
 
 
 def log_progress(
     run_start_time: datetime,
-    logger: logging.Logger,
-    count: int,
     total_count: int,
+    current_count: int,
+    last_log_count: int,
+    logger: logging.Logger = bulk_logger,
     formatter="Finished {count} / {total_count} lines.",
-    *,
-    last_log_count: Optional[int] = None,
 ):
+    """Log progress of the current execution. Return the last_log_count for the next iteration."""
+
     # Calculate log_interval to determine when to log progress.
     # If total_count is less than 100, log every 10% of total_count; otherwise, log every 10 lines.
     log_interval = min(10, max(int(total_count / 10), 1))
 
-    # If last_log_count is not None, determine whether to log based on whether the difference
-    # between the current count and the previous count exceeds log_interval.
-    # Otherwise, decide based on whether the current count is evenly divisible by log_interval.
-    if last_log_count:
-        log_flag = (count - last_log_count) >= log_interval
-    else:
-        log_flag = count % log_interval == 0
-
-    if count > 0 and (log_flag or count == total_count):
-        average_execution_time = round((datetime.utcnow().timestamp() - run_start_time.timestamp()) / count, 2)
-        estimated_execution_time = round(average_execution_time * (total_count - count), 2)
-        logger.info(formatter.format(count=count, total_count=total_count))
+    # There are two situations that we will print the progress log:
+    # 1. The difference between current_count and last_log_count exceeds log_interval.
+    # 2. The current_count is evenly divisible by log_interval.
+    log_flag = (current_count - last_log_count) >= log_interval or (
+        current_count > last_log_count and current_count % log_interval == 0
+    )
+
+    if current_count > 0 and (log_flag or current_count == total_count):
+        average_execution_time = round((datetime.utcnow().timestamp() - run_start_time.timestamp()) / current_count, 2)
+        estimated_execution_time = round(average_execution_time * (total_count - current_count), 2)
+        logger.info(formatter.format(count=current_count, total_count=total_count))
         logger.info(
             f"Average execution time for completed lines: {average_execution_time} seconds. "
             f"Estimated time for incomplete lines: {estimated_execution_time} seconds."
         )
+        return current_count
+    return last_log_count
 
 
 def extract_user_frame_summaries(frame_summaries: List[traceback.FrameSummary]):
     from promptflow import _core
 
     core_folder = os.path.dirname(_core.__file__)
```

## promptflow/contracts/flow.py

```diff
@@ -6,22 +6,21 @@
 import logging
 import sys
 from dataclasses import asdict, dataclass
 from enum import Enum
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
-from promptflow._constants import LANGUAGE_KEY, FlowLanguage, MessageFormatType
+from promptflow._constants import DEFAULT_ENCODING, LANGUAGE_KEY, FlowLanguage, MessageFormatType
 from promptflow._utils.utils import _match_reference, _sanitize_python_variable_name, try_import
 from promptflow._utils.yaml_utils import load_yaml
 from promptflow.contracts._errors import FlowDefinitionError
 from promptflow.exceptions import ErrorTarget
 from promptflow.tracing._utils import serialize
 
-from .._sdk._constants import DEFAULT_ENCODING
 from ._errors import FailedToImportModule
 from .tool import ConnectionType, Tool, ToolType, ValueType
 
 logger = logging.getLogger(__name__)
 
 
 class InputValueType(Enum):
@@ -735,14 +734,23 @@
         with open(working_dir / flow_file, "r", encoding=DEFAULT_ENCODING) as fin:
             flow_dag = load_yaml(fin)
         flow = Flow.deserialize(flow_dag)
         return flow.get_environment_variables_with_overrides(
             environment_variables_overrides=environment_variables_overrides
         )
 
+    @staticmethod
+    def load_message_format_from_yaml(flow_file: Path, working_dir=None) -> str:
+        if flow_file and Path(flow_file).suffix.lower() in [".yaml", ".yml"]:
+            flow_file = working_dir / flow_file if working_dir else flow_file
+            with open(flow_file, "r", encoding="utf-8") as fin:
+                flow_dag = load_yaml(fin)
+            return flow_dag.get("message_format", MessageFormatType.BASIC)
+        return MessageFormatType.BASIC
+
     def _set_tool_loader(self, working_dir):
         package_tool_keys = [node.source.tool for node in self.nodes if node.source and node.source.tool]
         from promptflow._core.tools_manager import ToolLoader
 
         # TODO: consider refactor this. It will raise an error if promptflow-tools
         #  is not installed even for csharp flow.
         self._tool_loader = ToolLoader(working_dir, package_tool_keys)
@@ -925,18 +933,22 @@
     :type inputs: Dict[str, FlowInputDefinition]
     :param outputs: The outputs of the flow.
     :type outputs: Dict[str, FlowOutputDefinition]
     :param program_language: The program language of the flow.
     :type program_language: str
     :param environment_variables: The default environment variables of the flow.
     :type environment_variables: Dict[str, object]
+    :param message_format: The message format type of the flow to represent different multimedia contracts.
+    :type message_format: str
     """
 
     program_language: str = FlowLanguage.Python
     environment_variables: Dict[str, object] = None
+    # eager flow does not support multimedia contract currently, it is set to basic by default.
+    message_format: str = MessageFormatType.BASIC
 
     @staticmethod
     def deserialize(data: dict) -> "EagerFlow":
         """Deserialize the flow from a dict.
 
         :param data: The dict to be deserialized.
         :type data: dict
```

## promptflow/contracts/multimedia.py

```diff
@@ -1,12 +1,13 @@
 import base64
-import filetype
 import hashlib
 from typing import Callable, Optional
 
+import filetype
+
 
 class PFBytes(bytes):
     """This class is used to represent a bytes object in PromptFlow.
     It has all the functionalities of a bytes object,
     and also has some additional methods to help with serialization and deserialization.
     """
 
@@ -25,21 +26,19 @@
         self._mime_type = mime_type.lower()
         self._source_url = source_url
 
     @property
     def source_url(self):
         return self._source_url
 
-    def to_base64(self, with_type: bool = False, dict_type: bool = False):
+    def to_base64(self, with_type: bool = False):
         """Returns the base64 representation of the PFBytes."""
 
         if with_type:
-            if not dict_type:
-                return f"data:{self._mime_type};base64," + base64.b64encode(self).decode("utf-8")
-            return {f"data:{self._mime_type};base64": base64.b64encode(self).decode("utf-8")}
+            return f"data:{self._mime_type};base64," + base64.b64encode(self).decode("utf-8")
         return base64.b64encode(self).decode("utf-8")
 
 
 class Image(PFBytes):
     """This class is used to represent an image in PromptFlow. It is a subclass of
     ~promptflow.contracts.multimedia.PFBytes.
     """
@@ -59,7 +58,32 @@
 
     def serialize(self, encoder: Callable = None):
         """Serialize the image to a dictionary."""
 
         if encoder is None:
             return self.__str__()
         return encoder(self)
+
+
+class Text(str):
+    def __new__(cls, value: str, annotations: list = None):
+        obj = str.__new__(cls, value)
+        obj._annotations = annotations
+        return obj
+
+    @classmethod
+    def deserialize(cls, data: dict):
+        """Deserialize the dictionary to the text object."""
+
+        text = data.get("text", "")
+        if isinstance(text, dict):
+            return cls(value=text.get("value", ""), annotations=text.get("annotations", []))
+        else:
+            return cls(value=text)
+
+    def serialize(self):
+        """Serialize the text to a dictionary."""
+
+        if self._annotations is None:
+            return {"type": "text", "text": self}
+        else:
+            return {"type": "text", "text": {"value": self, "annotations": self._annotations}}
```

## promptflow/contracts/run_info.py

```diff
@@ -5,14 +5,16 @@
 from dataclasses import dataclass
 from datetime import datetime
 from enum import Enum
 from typing import Any, Dict, List, Mapping, Optional
 
 from dateutil import parser
 
+from .._constants import MessageFormatType
+
 
 class Status(Enum):
     """An enumeration class for different types of run status."""
 
     Running = "Running"
     Preparing = "Preparing"
     Completed = "Completed"
@@ -72,14 +74,16 @@
     :type cached_flow_run_id: Optional[str]
     :param logs: Logs of the run
     :type logs: Optional[Dict[str, str]]
     :param system_metrics: System metrics of the run
     :type system_metrics: Optional[Dict[str, Any]]
     :param result: Result of the run
     :type result: Optional[object]
+    :param message_format: The message format type to represent different multimedia contracts.
+    :type message_format: str
     """
 
     node: str
     flow_run_id: str
     run_id: str
     status: Status
     inputs: Mapping[str, Any]
@@ -92,14 +96,15 @@
     index: Optional[int] = None
     api_calls: Optional[List[Dict[str, Any]]] = None
     cached_run_id: str = None
     cached_flow_run_id: str = None
     logs: Optional[Dict[str, str]] = None
     system_metrics: Dict[str, Any] = None
     result: object = None
+    message_format: str = MessageFormatType.BASIC
 
     @staticmethod
     def deserialize(data: dict) -> "RunInfo":
         """Deserialize the RunInfo from a dict."""
         start_time = data.get("start_time", None)
         end_time = data.get("end_time", None)
         run_info = RunInfo(
@@ -117,14 +122,15 @@
             index=data.get("index", None),
             api_calls=data.get("api_calls", None),
             cached_run_id=data.get("cached_run_id", None),
             cached_flow_run_id=data.get("cached_flow_run_id", None),
             logs=data.get("logs", None),
             system_metrics=data.get("system_metrics", None),
             result=data.get("result", None),
+            message_format=data.get("message_format", MessageFormatType.BASIC),
         )
         return run_info
 
 
 @dataclass
 class FlowRunInfo:
     """A dataclass representing the run information.
@@ -167,14 +173,16 @@
     :type tags: Optional[Dict[str, str]]
     :param system_metrics: System metrics of the flow run
     :type system_metrics: Optional[Dict[str, Any]]
     :param result: Result of the flow run
     :type result: Optional[object]
     :param upload_metrics: Flag indicating whether to upload metrics for the flow run
     :type upload_metrics: Optional[bool]
+    :param message_format: The message format type to represent different multimedia contracts.
+    :type message_format: str
     """
 
     run_id: str
     status: Status
     error: object
     inputs: object
     output: object
@@ -190,14 +198,16 @@
     api_calls: Optional[List[Dict[str, Any]]] = None
     name: str = ""
     description: str = ""
     tags: Optional[Mapping[str, str]] = None
     system_metrics: Dict[str, Any] = None
     result: object = None
     upload_metrics: bool = False  # only set as true for root runs in bulk test mode and evaluation mode
+    otel_trace_id: Optional[str] = ""
+    message_format: str = MessageFormatType.BASIC
 
     @staticmethod
     def deserialize(data: dict) -> "FlowRunInfo":
         """Deserialize the FlowRunInfo from a dict."""
         flow_run_info = FlowRunInfo(
             run_id=data.get("run_id"),
             status=Status(data.get("status")),
@@ -216,14 +226,15 @@
             api_calls=data.get("api_calls", None),
             name=data.get("name", ""),
             description=data.get("description", ""),
             tags=data.get("tags", None),
             system_metrics=data.get("system_metrics", None),
             result=data.get("result", None),
             upload_metrics=data.get("upload_metrics", False),
+            message_format=data.get("message_format", MessageFormatType.BASIC),
         )
         return flow_run_info
 
     @staticmethod
     def create_with_error(start_time, inputs, index, run_id, error):
         return FlowRunInfo(
             run_id=run_id,
```

## promptflow/core/_connection_provider/_connection_provider.py

```diff
@@ -24,17 +24,15 @@
         - azureml://subscriptions/<your-subscription>/resourceGroups/<your-resourcegroup>/
             providers/Microsoft.MachineLearningServices/workspaces/<your-workspace>
         """
         if not provider_config or provider_config == ConnectionProviderConfig.LOCAL:
             try:
                 from promptflow._sdk._connection_provider._local_connection_provider import LocalConnectionProvider
             except ImportError as e:
-                raise MissingRequiredPackage(
-                    message="Please install 'promptflow-devkit' to use local connection."
-                ) from e
+                raise MissingRequiredPackage(message="Please install 'promptflow' to use local connection.") from e
             return LocalConnectionProvider()
         if provider_config.startswith(ConnectionProviderConfig.AZUREML):
             from promptflow.core._connection_provider._workspace_connection_provider import WorkspaceConnectionProvider
 
             subscription_id, resource_group, workspace_name = extract_workspace(provider_config)
             return WorkspaceConnectionProvider(subscription_id, resource_group, workspace_name, credential)
         raise UnsupportedConnectionProviderConfig(
```

## promptflow/core/_connection_provider/_utils.py

```diff
@@ -1,27 +1,27 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 import os
 import re
 
 from promptflow._constants import PF_NO_INTERACTIVE_LOGIN
-from promptflow._sdk._constants import AZURE_WORKSPACE_REGEX_FORMAT
+from promptflow._constants import AZURE_WORKSPACE_REGEX_FORMAT
 from promptflow._utils.user_agent_utils import ClientUserAgentUtil
 from promptflow.core._errors import MalformedConnectionProviderConfig, MissingRequiredPackage
 from promptflow.exceptions import ValidationException
 
 
 def check_required_packages():
     try:
         import azure.ai.ml  # noqa: F401
         import azure.identity  # noqa: F401
     except ImportError as e:
         raise MissingRequiredPackage(
-            message="Please install 'azure-identity>=1.12.0,<2.0.0' and 'azure-ai-ml' to use workspace connection."
+            message="Please install 'promptflow-core[azureml-serving]' to use workspace connection."
         ) from e
 
 
 def get_arm_token(credential) -> str:
     check_required_packages()
     from azure.ai.ml._azure_environments import _get_base_url_from_metadata
```

## promptflow/core/_connection_provider/_workspace_connection_provider.py

```diff
@@ -89,15 +89,15 @@
         # TODO: Remove the azure-ai-ml dependency.
         from ._utils import get_arm_token
 
         try:
             from azure.identity import DefaultAzureCredential, DeviceCodeCredential
         except ImportError as e:
             raise MissingRequiredPackage(
-                message="Please install 'azure-identity>=1.12.0,<2.0.0' and 'msrest' to use workspace connection."
+                message="Please install 'promptflow-core[azureml-serving]' to use workspace connection."
             ) from e
 
         if is_from_cli():
             try:
                 # Try getting token for cli without interactive login
                 credential = get_default_azure_credential()
                 get_arm_token(credential=credential)
@@ -283,15 +283,15 @@
 
         try:
             from azure.core.exceptions import ClientAuthenticationError
 
             from ._models import WorkspaceConnectionPropertiesV2BasicResource
         except ImportError as e:
             raise MissingRequiredPackage(
-                message="Please install 'azure-identity>=1.12.0,<2.0.0' and 'msrest' to use workspace connection."
+                message="Please install 'promptflow-core[azureml-serving]' to use workspace connection."
             ) from e
         try:
             rest_obj: WorkspaceConnectionPropertiesV2BasicResource = cls.open_url(
                 get_arm_token(credential=credential),
                 url=url,
                 action="listsecrets",
                 method="POST",
```

## promptflow/core/_errors.py

```diff
@@ -91,17 +91,19 @@
         super().__init__(target=ErrorTarget.CORE, **kwargs)
 
 
 class MalformedConnectionProviderConfig(UserErrorException):
     """Exception raised when connection provider config is malformed."""
 
     def __init__(self, provider_config, **kwargs):
-        message = "Malformed connection provider config, expected azureml://subscriptions/<subscription_id>/"
-        "resourceGroups/<resource_group>/providers/Microsoft.MachineLearningServices/"
-        f"workspaces/<workspace_name>, got {provider_config}"
+        message = (
+            "Malformed connection provider config, expected azureml://subscriptions/<subscription_id>/"
+            "resourceGroups/<resource_group>/providers/Microsoft.MachineLearningServices/"
+            f"workspaces/<workspace_name>, got {provider_config}"
+        )
         super().__init__(target=ErrorTarget.CORE, message=message, **kwargs)
 
 
 class AccessDeniedError(UserErrorException):
     """Exception raised when run info can not be found in storage"""
 
     def __init__(self, operation: str, target: ErrorTarget):
```

## promptflow/core/_serving/app.py

```diff
@@ -6,21 +6,20 @@
 import logging
 import mimetypes
 import os
 from pathlib import Path
 from typing import Dict
 
 from flask import Flask, g, jsonify, request
-from opentelemetry import trace, baggage, context
+from opentelemetry import baggage, context, trace
 from opentelemetry.trace.span import INVALID_SPAN
 
 from promptflow._utils.exception_utils import ErrorResponse
 from promptflow._utils.logger_utils import LoggerFactory
 from promptflow._utils.user_agent_utils import setup_user_agent_to_operation_context
-from promptflow._version import VERSION
 from promptflow.contracts.run_info import Status
 from promptflow.core import Flow
 from promptflow.core._serving.constants import FEEDBACK_TRACE_FIELD_NAME, FEEDBACK_TRACE_SPAN_NAME
 from promptflow.core._serving.extension.extension_factory import ExtensionFactory
 from promptflow.core._serving.flow_invoker import FlowInvoker
 from promptflow.core._serving.response_creator import ResponseCreator
 from promptflow.core._serving.utils import (
@@ -31,22 +30,22 @@
     load_feedback_swagger,
     load_request_data,
     serialize_attribute_value,
     streaming_response_required,
     try_extract_trace_context,
 )
 from promptflow.core._utils import init_executable
+from promptflow.core._version import __version__
 from promptflow.exceptions import SystemErrorException
 from promptflow.storage._run_storage import DummyRunStorage
 from promptflow.tracing._operation_context import OperationContext
 
 from .swagger import generate_swagger
 
 logger = LoggerFactory.get_logger("pfserving-app", target_stdout=True)
-USER_AGENT = f"promptflow-local-serving/{VERSION}"
 
 
 class PromptflowServingApp(Flask):
     def init(self, **kwargs):
         with self.app_context():
             # default to local, can be override when creating the app
             self.extension = ExtensionFactory.create_extension(logger, **kwargs)
@@ -71,14 +70,18 @@
             self.connections_name_override = conn_name_override
 
             self.flow_monitor = self.extension.get_flow_monitor()
 
             self.connection_provider = self.extension.get_connection_provider()
             self.credential = self.extension.get_credential()
             self.sample = get_sample_json(self.project_path, logger)
+
+            self.init = kwargs.get("init", {})
+            logger.info("Init params: " + str(self.init))
+
             self.init_swagger()
             # try to initialize the flow invoker
             try:
                 self.init_invoker_if_not_exist()
             except Exception as e:
                 if self.extension.raise_ex_on_invoker_initialization_failure(e):
                     raise e
@@ -103,14 +106,15 @@
             streaming=streaming_response_required,
             raise_ex=False,
             connections=self.connections_override,
             connections_name_overrides=self.connections_name_override,
             # for serving, we don't need to persist intermediate result, this is to avoid memory leak.
             storage=DummyRunStorage(),
             credential=self.credential,
+            init_kwargs=self.init,
         )
         # why we need to update bonded executable flow?
         self.flow = self.flow_invoker.flow
         # Set the flow name as folder name
         self.flow.name = self.flow_name
         self.response_fields_to_remove = get_output_fields_to_remove(self.flow, logger)
         logger.info("Promptflow executor initializing succeed!")
@@ -202,25 +206,25 @@
     def swagger():
         """Get the swagger object."""
         return jsonify(app.swagger)
 
     @app.route("/health", methods=["GET"])
     def health():
         """Check if the runtime is alive."""
-        return {"status": "Healthy", "version": VERSION}
+        return {"status": "Healthy", "version": __version__}
 
     @app.route("/version", methods=["GET"])
     def version():
         """Check the runtime's version."""
         build_info = os.environ.get("BUILD_INFO", "")
         try:
             build_info_dict = json.loads(build_info)
             version = build_info_dict["build_number"]
         except Exception:
-            version = VERSION
+            version = __version__
         return {"status": "Healthy", "build_info": build_info, "version": version}
 
     @app.route("/feedback", methods=["POST"])
     def feedback():
         ctx = try_extract_trace_context(logger)
         from opentelemetry import trace
```

## promptflow/core/_serving/extension/azureml_extension.py

```diff
@@ -4,23 +4,23 @@
 
 import json
 import os
 import re
 from typing import Any, Tuple
 
 from promptflow._utils.retry_utils import retry
-from promptflow._version import VERSION
 from promptflow.contracts.flow import Flow
 from promptflow.core._serving._errors import InvalidConnectionData, MissingConnectionProvider
 from promptflow.core._serving.extension.default_extension import AppExtension
 from promptflow.core._serving.extension.extension_type import ExtensionType
 from promptflow.core._serving.monitor.data_collector import FlowDataCollector
 from promptflow.core._serving.utils import decode_dict, get_pf_serving_env, normalize_connection_name
+from promptflow.core._version import __version__
 
-USER_AGENT = f"promptflow-cloud-serving/{VERSION}"
+USER_AGENT = f"promptflow-cloud-serving/{__version__}"
 AML_DEPLOYMENT_RESOURCE_ID_REGEX = "/subscriptions/(.*)/resourceGroups/(.*)/providers/Microsoft.MachineLearningServices/workspaces/(.*)/onlineEndpoints/(.*)/deployments/(.*)"  # noqa: E501
 AML_CONNECTION_PROVIDER_TEMPLATE = "azureml://subscriptions/{}/resourceGroups/{}/providers/Microsoft.MachineLearningServices/workspaces/{}"  # noqa: E501
 
 
 class AzureMLExtension(AppExtension):
     """AzureMLExtension is used to create extension for azureml serving."""
```

## promptflow/core/_serving/extension/default_extension.py

```diff
@@ -6,23 +6,23 @@
 import os
 from abc import ABC, abstractmethod
 from pathlib import Path
 from typing import Tuple
 
 from promptflow._constants import DEFAULT_ENCODING
 from promptflow._utils.yaml_utils import load_yaml
-from promptflow._version import VERSION
 from promptflow.contracts.flow import Flow
 from promptflow.core._serving.blueprint.monitor_blueprint import construct_monitor_blueprint
 from promptflow.core._serving.blueprint.static_web_blueprint import construct_staticweb_blueprint
 from promptflow.core._serving.extension.extension_type import ExtensionType
 from promptflow.core._serving.extension.otel_exporter_provider_factory import OTelExporterProviderFactory
 from promptflow.core._serving.monitor.flow_monitor import FlowMonitor
+from promptflow.core._version import __version__
 
-USER_AGENT = f"promptflow-local-serving/{VERSION}"
+USER_AGENT = f"promptflow-local-serving/{__version__}"
 DEFAULT_STATIC_PATH = Path(__file__).parent.parent / "static"
 
 
 class AppExtension(ABC):
     def __init__(self, logger, extension_type: ExtensionType, collector=None, **kwargs):
         self.logger = logger
         self.extension_type = extension_type
```

## promptflow/core/_serving/flow_invoker.py

```diff
@@ -5,15 +5,15 @@
 import os
 from pathlib import Path
 from typing import Callable, Union
 
 from promptflow._utils.dataclass_serializer import convert_eager_flow_output_to_dict
 from promptflow._utils.flow_utils import dump_flow_result, is_executable_chat_flow
 from promptflow._utils.logger_utils import LoggerFactory
-from promptflow._utils.multimedia_utils import convert_multimedia_data_to_base64, persist_multimedia_data
+from promptflow._utils.multimedia_utils import MultimediaProcessor
 from promptflow.core._connection import _Connection
 from promptflow.core._connection_provider._connection_provider import ConnectionProvider
 from promptflow.core._flow import AbstractFlowBase
 from promptflow.core._serving._errors import UnexpectedConnectionProviderReturn, UnsupportedConnectionProvider
 from promptflow.core._serving.flow_result import FlowResult
 from promptflow.core._serving.utils import validate_request_data
 from promptflow.core._utils import (
@@ -40,27 +40,32 @@
     :type connections: dict, optional
     :param connections_name_overrides: The connection name overrides, defaults to None
         Example: ``{"aoai_connection": "azure_open_ai_connection"}``
         The node with reference to connection 'aoai_connection' will be resolved to the actual connection 'azure_open_ai_connection'. # noqa: E501
     :type connections_name_overrides: dict, optional
     :param raise_ex: Whether to raise exception when executing flow, defaults to True
     :type raise_ex: bool, optional
+    :param init_kwargs: Class init arguments for callable class, only supported for flex flow.
+    :type init_kwargs: dict, optional
     """
 
     def __init__(
         self,
         flow: AbstractFlowBase,
         connection_provider: [str, Callable] = None,
         streaming: Union[Callable[[], bool], bool] = False,
         connections: dict = None,
         connections_name_overrides: dict = None,
         raise_ex: bool = True,
+        init_kwargs: dict = None,
         **kwargs,
     ):
         self.logger = kwargs.get("logger", LoggerFactory.get_logger("flowinvoker"))
+        self._init_kwargs = init_kwargs or {}
+        self.logger.debug(f"Init flow invoker with init kwargs: {self._init_kwargs}")
         # TODO: avoid to use private attribute after we finalize the inheritance
         self.flow = init_executable(working_dir=flow._code, flow_path=flow._path)
         self.connections = connections or {}
         self.connections_name_overrides = connections_name_overrides or {}
         self.raise_ex = raise_ex
         self.storage = kwargs.get("storage", None)
         self.streaming = streaming if isinstance(streaming, Callable) else lambda: streaming
@@ -70,14 +75,15 @@
         # DefaultAzureCredential when using workspace connection provider
         self._credential = kwargs.get("credential", None)
 
         self._init_connections(connection_provider)
         # TODO: avoid to use private attribute after we finalize the inheritance
         self._init_executor(flow._path, flow._code)
         self._dump_file_prefix = "chat" if self._is_chat_flow else "flow"
+        self._multimedia_processor = MultimediaProcessor.create(self.flow.message_format)
 
     def resolve_connections(
         self,
         connection_names,
         provider,
         *,
         raise_error=False,
@@ -161,14 +167,15 @@
             storage = self.storage
         self.executor = FlowExecutor.create(
             flow_file=flow_path,
             working_dir=working_dir,
             connections=self.connections,
             raise_ex=self.raise_ex,
             storage=storage,
+            init_kwargs=self._init_kwargs,
         )
         self.executor.enable_streaming_for_llm_flow(self.streaming)
         self.logger.info("Promptflow executor initiated successfully.")
 
     def _invoke_context(self, data: dict, disable_input_output_logging=False):
         log_data = "<REDACTED>" if disable_input_output_logging else data
         self.logger.info(f"Validating flow input with data {log_data!r}")
@@ -218,21 +225,21 @@
                 node_run_infos=result.node_run_infos,
                 response_original_value=returned_non_dict_output,
             )
         return resolved_outputs
 
     def _convert_multimedia_data_to_base64(self, output_dict):
         resolved_outputs = {
-            k: convert_multimedia_data_to_base64(v, with_type=True, dict_type=True) for k, v in output_dict.items()
+            k: self._multimedia_processor.convert_multimedia_data_to_base64_dict(v) for k, v in output_dict.items()
         }
         return resolved_outputs
 
     def _dump_invoke_result(self, invoke_result):
         if self._dump_to:
-            invoke_result.output = persist_multimedia_data(
+            invoke_result.output = self._multimedia_processor.persist_multimedia_data(
                 invoke_result.output, base_dir=self._dump_to, sub_dir=Path(".promptflow/output")
             )
 
             dump_flow_result(flow_folder=self._dump_to, flow_result=invoke_result, prefix=self._dump_file_prefix)
 
 
 class AsyncFlowInvoker(FlowInvoker):
```

## promptflow/core/_version.py

```diff
@@ -1,7 +1,9 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 import importlib.metadata
 
 __version__ = importlib.metadata.version("promptflow-core")
+
+VERSION: str = __version__
```

## promptflow/exceptions.py

```diff
@@ -4,16 +4,14 @@
 import inspect
 import string
 import traceback
 from enum import Enum
 from functools import cached_property
 from typing import Dict, List
 
-from azure.core.exceptions import HttpResponseError
-
 
 class ErrorCategory(str, Enum):
     USER_ERROR = "UserError"
     SYSTEM_ERROR = "SystemError"
     UNKNOWN = "Unknown"
 
 
@@ -255,14 +253,18 @@
             cls._error_detail(e),
         )
 
     @classmethod
     def _is_system_error(cls, e: BaseException):
         if isinstance(e, SystemErrorException):
             return True
+        try:
+            from azure.core.exceptions import HttpResponseError
+        except ImportError:
+            return True
         if isinstance(e, HttpResponseError):
             status_code = str(e.status_code)
             # Except for 429, 400-499 are all client errors.
             if not status_code.startswith("4") and status_code != "429":
                 return True
 
         return False
```

## promptflow/executor/_errors.py

```diff
@@ -164,14 +164,25 @@
     pass
 
 
 class SingleNodeValidationError(UserErrorException):
     pass
 
 
+class AggregationNodeExecutionTimeoutError(UserErrorException):
+    """Exception raised when aggregation node execution timeout"""
+
+    def __init__(self, timeout):
+        super().__init__(
+            message_format="Aggregation node execution timeout for exceeding {timeout} seconds",
+            timeout=timeout,
+            target=ErrorTarget.EXECUTOR,
+        )
+
+
 class LineExecutionTimeoutError(UserErrorException):
     """Exception raised when single line execution timeout"""
 
     def __init__(self, line_number, timeout):
         super().__init__(
             message_format="Line {line_number} execution timeout for exceeding {timeout} seconds",
             line_number=line_number,
@@ -297,7 +308,17 @@
     """Exception raised when failed to parse assistant tool from docstring."""
 
     def __init__(self, func_name):
         super().__init__(
             message_format="Failed to get assistant tool by parsing the docstring of function '{func_name}'.",
             func_name=func_name,
         )
+
+
+class FlowEntryInitializationError(UserErrorException):
+    """Exception raised when failed to initialize flow entry."""
+
+    def __init__(self, init_kwargs):
+        super().__init__(
+            message_format="Failed to initialize flow entry with '{init_kwargs}'.",
+            init_kwargs=init_kwargs,
+        )
```

## promptflow/executor/_line_execution_process_pool.py

```diff
@@ -25,15 +25,14 @@
 
 from promptflow._constants import LINE_NUMBER_KEY, LINE_TIMEOUT_SEC
 from promptflow._core._errors import ProcessPoolError, UnexpectedError
 from promptflow._core.run_tracker import RunTracker
 from promptflow._utils.dataclass_serializer import convert_eager_flow_output_to_dict
 from promptflow._utils.exception_utils import ExceptionPresenter
 from promptflow._utils.logger_utils import bulk_logger
-from promptflow._utils.multimedia_utils import convert_multimedia_data_to_string, persist_multimedia_data
 from promptflow._utils.process_utils import (
     get_available_max_worker_count,
     get_manager_process_log_path,
     get_subprocess_log_path,
     log_errors_from_file,
 )
 from promptflow._utils.thread_utils import RepeatLogTimer
@@ -130,17 +129,20 @@
             self._storage = flow_executor._run_tracker._storage
         self._flow_create_kwargs = {
             "flow_file": flow_executor._flow_file,
             "connections": flow_executor._connections,
             "working_dir": flow_executor._working_dir,
             "line_timeout_sec": self._line_timeout_sec,
             "raise_ex": False,
+            # only script executor has init
+            "init_kwargs": getattr(flow_executor, "_init_kwargs", None),
         }
         # Will set to True if the batch run is timeouted.
         self._is_timeout = False
+        self._multimedia_processor = flow_executor._multimedia_processor
 
     def __enter__(self):
         self.start()
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self.close()
@@ -277,25 +279,23 @@
                         (
                             self._run_id,
                             index,
                             inputs,
                         )
                     )
                 # Wait for batch run to complete or timeout
-                completed_line = 0
+                last_log_count = 0
                 while not self._batch_timeout_expired(self._batch_start_time):
                     # Print the progress logs of the batch run.
-                    log_progress(
+                    last_log_count = log_progress(
                         run_start_time=self._batch_start_time,
-                        logger=bulk_logger,
-                        count=len(self._result_dict),
                         total_count=self._nlines,
-                        last_log_count=completed_line,
+                        current_count=len(self._result_dict),
+                        last_log_count=last_log_count,
                     )
-                    completed_line = len(self._result_dict)
                     # If the batch run is completed, break the loop.
                     if self._is_batch_run_completed():
                         break
                     # Check monitor status every 1 second
                     self._monitor_thread_pool_status()
                     await asyncio.sleep(1)
             except PromptflowException:
@@ -604,36 +604,38 @@
         self._serialize_multimedia(result.run_info)
         # Serialize multimedia data in node run infos to string
         for node_run_info in result.node_run_infos.values():
             self._serialize_multimedia(node_run_info)
         # Persist multimedia data in the aggregation_inputs of line result to output_dir
         # if _serialize_multimedia_during_execution is True.
         if self._serialize_multimedia_during_execution:
-            result.aggregation_inputs = persist_multimedia_data(
+            result.aggregation_inputs = self._multimedia_processor.persist_multimedia_data(
                 result.aggregation_inputs, Path(mkdtemp()), use_absolute_path=True
             )
         # Persist multimedia data in the outputs of line result to output_dir
-        result.output = persist_multimedia_data(result.output, self._output_dir)
+        result.output = self._multimedia_processor.persist_multimedia_data(result.output, self._output_dir)
         return result
 
     def _serialize_multimedia(self, run_info: Union[FlowRunInfo, NodeRunInfo]):
         if run_info.inputs:
-            run_info.inputs = convert_multimedia_data_to_string(run_info.inputs)
+            run_info.inputs = self._multimedia_processor.convert_multimedia_data_to_string(run_info.inputs)
 
         if run_info.output:
-            serialized_output = convert_multimedia_data_to_string(run_info.output)
+            serialized_output = self._multimedia_processor.convert_multimedia_data_to_string(run_info.output)
             run_info.output = serialized_output
             run_info.result = None
 
         # The `inplace=True` parameter is used here to ensure that the original list structure holding generator outputs
         # is maintained. This allows us to keep tracking the list as it dynamically changes when the generator is
         # consumed. It is crucial to process the api_calls list in place to avoid losing the reference to the list that
         # holds the generator items, which is essential for tracing generator execution.
         if run_info.api_calls:
-            run_info.api_calls = convert_multimedia_data_to_string(run_info.api_calls, inplace=True)
+            run_info.api_calls = self._multimedia_processor.convert_multimedia_data_to_string(
+                run_info.api_calls, inplace=True
+            )
 
     def _generate_line_result_for_exception(
         self,
         inputs,
         run_id,
         line_number,
         flow_id,
@@ -793,21 +795,22 @@
         if line_result is not None and line_result.run_info.status == Status.Failed:
             line_result.output = {}
         return line_result
     except Exception as e:
         bulk_logger.error(f"Line {index}, Process {os.getpid()} failed with exception: {e}")
         flow_id = executor._flow_id
         line_run_id = run_id if index is None else f"{run_id}_{index}"
+        message_format = executor._message_format
         # If line execution failed before start, there is no flow information in the run_tracker.
         # So we call start_flow_run before handling exception to make sure the run_tracker has flow info.
         if isinstance(executor, ScriptExecutor):
             run_tracker = RunTracker(executor._storage)
         else:
             run_tracker = executor._run_tracker
-        run_tracker.start_flow_run(flow_id, run_id, line_run_id, run_id, index=index)
+        run_tracker.start_flow_run(flow_id, run_id, line_run_id, run_id, index=index, message_format=message_format)
         run_info = run_tracker.end_run(f"{run_id}_{index}", ex=e)
         output_queue.put(run_info)
         result = LineResult(
             output={},
             aggregation_inputs={},
             run_info=run_info,
             node_run_infos={},
```

## promptflow/executor/_process_manager.py

```diff
@@ -170,21 +170,23 @@
     def _terminate_process(self, i, pid):
         warning_msg = "Unexpected error occurred while end process for index {i} and process id {pid}. Exception: {e}"
         try:
             process = psutil.Process(pid)
             # The subprocess will get terminate signal from input queue, so we need to wait for the process to exit.
             # If the process is still running after 10 seconds, it will raise psutil.TimeoutExpired exception.
             process.wait(timeout=10)
+            bulk_logger.info(f"Process {pid} terminated.")
         except psutil.NoSuchProcess:
             bulk_logger.warning(f"Process {pid} had been terminated.")
         except psutil.TimeoutExpired:
             try:
                 # If the process is still running after waiting 10 seconds, terminate it.
                 process.terminate()
                 process.wait()
+                bulk_logger.info(f"Process {pid} terminated.")
             except Exception as e:
                 bulk_logger.warning(warning_msg.format(i=i, pid=pid, e=e))
         except Exception as e:
             bulk_logger.warning(warning_msg.format(i=i, pid=pid, e=e))
 
 
 class SpawnProcessManager(AbstractProcessManager):
@@ -509,14 +511,15 @@
 def _create_executor_fork(*, flow_executor: FlowExecutor, storage: AbstractRunStorage):
     if isinstance(flow_executor, ScriptExecutor):
         return ScriptExecutor(
             flow_file=flow_executor._flow_file,
             connections=flow_executor._connections,
             working_dir=flow_executor._working_dir,
             storage=storage,
+            init_kwargs=flow_executor._init_kwargs,
         )
     else:
         run_tracker = RunTracker(run_storage=storage)
         return FlowExecutor(
             flow=flow_executor._flow,
             connections=flow_executor._connections,
             run_tracker=run_tracker,
```

## promptflow/executor/_script_executor.py

```diff
@@ -2,52 +2,59 @@
 import dataclasses
 import importlib
 import inspect
 import uuid
 from dataclasses import is_dataclass
 from pathlib import Path
 from types import GeneratorType
-from typing import Any, Callable, Mapping, Optional
+from typing import Any, Callable, Dict, Mapping, Optional
 
-from promptflow._constants import LINE_NUMBER_KEY
+from promptflow._constants import LINE_NUMBER_KEY, MessageFormatType
 from promptflow._core.run_tracker import RunTracker
 from promptflow._core.tool_meta_generator import PythonLoadError
 from promptflow._utils.dataclass_serializer import convert_eager_flow_output_to_dict
 from promptflow._utils.logger_utils import logger
+from promptflow._utils.multimedia_utils import BasicMultimediaProcessor
 from promptflow._utils.tool_utils import function_to_interface
 from promptflow._utils.yaml_utils import load_yaml
 from promptflow.contracts.flow import Flow
 from promptflow.executor._result import LineResult
 from promptflow.storage import AbstractRunStorage
 from promptflow.storage._run_storage import DefaultRunStorage
 from promptflow.tracing._trace import _traced
 from promptflow.tracing._tracer import Tracer
 
+from ._errors import FlowEntryInitializationError
 from .flow_executor import FlowExecutor
 
 
 class ScriptExecutor(FlowExecutor):
     def __init__(
         self,
         flow_file: Path,
         connections: Optional[dict] = None,
         working_dir: Optional[Path] = None,
         *,
         storage: Optional[AbstractRunStorage] = None,
+        init_kwargs: Optional[Dict[str, Any]] = None,
     ):
         logger.debug(f"Start initializing the executor with {flow_file}.")
+        logger.debug(f"Init params for script executor: {init_kwargs}")
 
         self._flow_file = flow_file
+        self._init_kwargs = init_kwargs or {}
         self._working_dir = Flow._resolve_working_dir(flow_file, working_dir)
         self._initialize_function()
         self._connections = connections
         self._storage = storage or DefaultRunStorage()
         self._flow_id = "default_flow_id"
         self._log_interval = 60
         self._line_timeout_sec = 600
+        self._message_format = MessageFormatType.BASIC
+        self._multimedia_processor = BasicMultimediaProcessor()
 
     def exec_line(
         self,
         inputs: Mapping[str, Any],
         index: Optional[int] = None,
         run_id: Optional[str] = None,
         allow_generator_output: bool = False,
@@ -70,14 +77,15 @@
         run_info = run_tracker.start_flow_run(
             flow_id=self._flow_id,
             root_run_id=run_id,
             run_id=line_run_id,
             parent_run_id=run_id,
             inputs=inputs,
             index=index,
+            message_format=self._message_format,
         )
         # Executor will add line_number to batch inputs if there is no line_number in the original inputs,
         # which should be removed, so, we only preserve the inputs that are contained in self._inputs.
         inputs = {k: inputs[k] for k in self._inputs if k in inputs}
         output = None
         traces = []
         try:
@@ -122,18 +130,41 @@
         # no need to inject streaming here, user can directly pass the param to the function
         return
 
     def get_inputs_definition(self):
         return self._inputs
 
     def _initialize_function(self):
-        module_name, func_name = self._parse_flow_file()
-        module = importlib.import_module(module_name)
+        try:
+            module_name, func_name = self._parse_flow_file()
+            module = importlib.import_module(module_name)
+        except Exception as e:
+            raise PythonLoadError(
+                message_format="Failed to load python module for {entry_file}",
+                entry_file=self._flow_file,
+            ) from e
         func = getattr(module, func_name, None)
-        if func is None or not inspect.isfunction(func):
+        # check if func is a callable class
+        if inspect.isclass(func):
+            if hasattr(func, "__call__"):
+                logger.debug(
+                    f"Python class entry '{func_name}' has __call__ method, initializing it with {self._init_kwargs}"
+                )
+                try:
+                    obj = func(**self._init_kwargs)
+                except Exception as e:
+                    raise FlowEntryInitializationError(init_kwargs=self._init_kwargs) from e
+                func = getattr(obj, "__call__")
+            else:
+                raise PythonLoadError(
+                    message_format="Python class entry '{func_name}' does not have __call__ method.",
+                    func_name=func_name,
+                    module_name=module_name,
+                )
+        elif func is None or not inspect.isfunction(func):
             raise PythonLoadError(
                 message_format="Failed to load python function '{func_name}' from file '{module_name}'.",
                 func_name=func_name,
                 module_name=module_name,
             )
         # If the function is not decorated with trace, add trace for it.
         if not hasattr(func, "__original_function"):
```

## promptflow/executor/_service/apis/batch.py

```diff
@@ -52,9 +52,11 @@
 @router.post("/aggregation")
 def aggregation(request: AggregationRequest):
     return BatchCoordinator.get_instance().exec_aggregation(request)
 
 
 @router.post("/finalize")
 def finalize():
-    BatchCoordinator.get_instance().close()
-    return {"status": "finalized"}
+    with BatchCoordinator.get_instance().get_log_context():
+        service_logger.info("Received the finalize request.")
+        BatchCoordinator.get_instance().close()
+        return {"status": "finalized"}
```

## promptflow/executor/_service/apis/common.py

```diff
@@ -2,26 +2,26 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 from fastapi import APIRouter
 from fastapi.responses import PlainTextResponse
 
 from promptflow._utils.feature_utils import get_feature_list
-from promptflow._version import VERSION
+from promptflow.core._version import __version__
 from promptflow.executor._service.utils.service_utils import get_commit_id
 
 router = APIRouter()
 
 
 @router.get("/health")
 def health_check():
     return PlainTextResponse("healthy")
 
 
 @router.get("/version")
 def version():
     return {
         "status": "healthy",
-        "version": VERSION,
+        "version": __version__,
         "commit_id": get_commit_id(),
         "feature_list": get_feature_list(),
     }
```

## promptflow/executor/_service/utils/batch_coordinator.py

```diff
@@ -2,15 +2,15 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 from pathlib import Path
 from typing import Any, Mapping, Optional
 
 from promptflow._constants import OutputsFolderName
-from promptflow._utils.multimedia_utils import process_multimedia_in_run_info
+from promptflow._utils.logger_utils import LogContext
 from promptflow.executor import FlowExecutor
 from promptflow.executor._line_execution_process_pool import LineExecutionProcessPool
 from promptflow.executor._service._errors import UninitializedError
 from promptflow.executor._service.contracts.batch_request import AggregationRequest, LineExecutionRequest
 from promptflow.storage._run_storage import DummyRunStorage
 
 
@@ -30,14 +30,17 @@
         output_dir: Path,
         connections: Optional[Mapping[str, Any]] = None,
         worker_count: Optional[int] = None,
         line_timeout_sec: Optional[int] = None,
     ):
         if self._init:
             return
+        # Save log context for close method
+        self._log_context = LogContext.get_current()
+
         # Init flow executor and validate flow
         self._output_dir = output_dir
 
         # The storage of FlowExecutor will be passed to LineExecutionProcessPool
         # and responsible for persisting the run info during line execution.
 
         # So we pass DummyRunStorage to FlowExecutor because we don't need to
@@ -61,14 +64,17 @@
     def get_instance(cls):
         if cls._instance is None:
             raise UninitializedError(
                 "Please initialize the executor service with the '/initialize' api before sending execution requests."
             )
         return cls._instance
 
+    def get_log_context(self):
+        return self._log_context
+
     def start(self):
         """Start the process pool."""
         self._process_pool.start()
 
     async def exec_line(self, request: LineExecutionRequest):
         """Execute a line in the process pool."""
         return await self._process_pool.submit(request.run_id, request.line_number, request.inputs)
@@ -78,15 +84,15 @@
         with self._flow_executor._run_tracker.node_log_manager:
             aggregation_result = self._flow_executor._exec_aggregation(
                 request.batch_inputs, request.aggregation_inputs, request.run_id
             )
             # Serialize the multimedia data of the node run infos under the mode artifacts folder.
             for node_run_info in aggregation_result.node_run_infos.values():
                 base_dir = self._output_dir / OutputsFolderName.NODE_ARTIFACTS / node_run_info.node
-                process_multimedia_in_run_info(node_run_info, base_dir)
+                self._flow_executor._multimedia_processor.process_multimedia_in_run_info(node_run_info, base_dir)
         return aggregation_result
 
     def close(self):
         """Close the process pool."""
         self._process_pool.close()
         self._init = False
         self._instance = None
```

## promptflow/executor/_service/utils/service_utils.py

```diff
@@ -5,15 +5,15 @@
 import json
 import os
 from typing import Any, Mapping, Union
 
 from promptflow._core.connection_manager import ConnectionManager
 from promptflow._utils.exception_utils import ErrorResponse, ExceptionPresenter, JsonSerializedPromptflowException
 from promptflow._utils.logger_utils import LogContext, service_logger
-from promptflow._version import VERSION
+from promptflow._utils.user_agent_utils import append_promptflow_package_ua
 from promptflow.executor._service.contracts.execution_request import BaseExecutionRequest
 from promptflow.tracing._operation_context import OperationContext
 
 
 def get_log_context(request: BaseExecutionRequest, enable_service_logger: bool = False) -> LogContext:
     run_mode = request.get_run_mode()
     credential_list = ConnectionManager(request.connections).get_secret_list()
@@ -26,15 +26,15 @@
 def update_and_get_operation_context(context_dict: Mapping[str, Any]) -> OperationContext:
     operation_context = OperationContext.get_instance()
     if not context_dict:
         return operation_context
     # update operation context with context_dict
     operation_context.update(context_dict)
     # update promptflow version to operation context
-    operation_context.append_user_agent(f"promptflow/{VERSION}")
+    append_promptflow_package_ua(operation_context)
     return operation_context
 
 
 def get_commit_id():
     """Get commit id from BUILD_INFO environment variable.
 
     BUILD_INFO is a json string in the promptflow-python image, like
```

## promptflow/executor/_tool_resolver.py

```diff
@@ -6,19 +6,20 @@
 import inspect
 import types
 from dataclasses import dataclass
 from functools import partial
 from pathlib import Path
 from typing import Callable, List, Optional
 
+from promptflow._constants import MessageFormatType
 from promptflow._core._errors import InvalidSource
 from promptflow._core.connection_manager import ConnectionManager
 from promptflow._core.tool import STREAMING_OPTION_PARAMETER_ATTR
 from promptflow._core.tools_manager import BuiltinsManager, ToolLoader, connection_type_to_api_mapping
-from promptflow._utils.multimedia_utils import create_image, load_multimedia_data_recursively
+from promptflow._utils.multimedia_utils import MultimediaProcessor
 from promptflow._utils.tool_utils import get_inputs_for_prompt_template, get_prompt_param_name_from_func
 from promptflow._utils.yaml_utils import load_yaml
 from promptflow.contracts.flow import InputAssignment, InputValueType, Node, ToolSource, ToolSourceType
 from promptflow.contracts.tool import ConnectionType, Tool, ToolType, ValueType
 from promptflow.contracts.types import AssistantDefinition, PromptTemplate
 from promptflow.exceptions import ErrorTarget, PromptflowException, UserErrorException
 from promptflow.executor._assistant_tool_invoker import (
@@ -51,23 +52,25 @@
 
 class ToolResolver:
     def __init__(
         self,
         working_dir: Path,
         connections: Optional[dict] = None,
         package_tool_keys: Optional[List[str]] = None,
+        message_format: str = MessageFormatType.BASIC,
     ):
         try:
             # Import openai and aoai for llm tool
             from promptflow.tools import aoai, openai  # noqa: F401
         except ImportError:
             pass
         self._tool_loader = ToolLoader(working_dir, package_tool_keys=package_tool_keys)
         self._working_dir = working_dir
         self._connection_manager = ConnectionManager(connections)
+        self._multimedia_processor = MultimediaProcessor.create(message_format)
 
     @classmethod
     def start_resolver(
         cls, working_dir: Path, connections: Optional[dict] = None, package_tool_keys: Optional[List[str]] = None
     ):
         resolver = cls(working_dir, connections, package_tool_keys)
         resolver._activate_in_context(force=True)
@@ -271,15 +274,15 @@
                     updated_inputs[k].value = self._convert_to_custom_strong_type_connection_value(
                         k, v, node_name, source, tool, tool_input.custom_type, module=module
                     )
                 else:
                     updated_inputs[k].value = self._convert_to_connection_value(k, v, node_name, tool_input.type)
             elif value_type == ValueType.IMAGE:
                 try:
-                    updated_inputs[k].value = create_image(v.value)
+                    updated_inputs[k].value = self._multimedia_processor.create_image(v.value)
                 except Exception as e:
                     error_type_and_message = f"({e.__class__.__name__}) {e}"
                     raise NodeInputValidationError(
                         message_format="Failed to load image for input '{key}': {error_type_and_message}",
                         key=k,
                         error_type_and_message=error_type_and_message,
                         target=ErrorTarget.EXECUTOR,
@@ -306,15 +309,17 @@
                         key=k,
                         node_name=node_name,
                         value=v.value,
                         value_type=value_type.value,
                         target=ErrorTarget.EXECUTOR,
                     ) from e
                 try:
-                    updated_inputs[k].value = load_multimedia_data_recursively(updated_inputs[k].value)
+                    updated_inputs[k].value = self._multimedia_processor.load_multimedia_data_recursively(
+                        updated_inputs[k].value
+                    )
                 except Exception as e:
                     error_type_and_message = f"({e.__class__.__name__}) {e}"
                     raise NodeInputValidationError(
                         message_format="Failed to load image for input '{key}': {error_type_and_message}",
                         key=k,
                         error_type_and_message=error_type_and_message,
                         target=ErrorTarget.EXECUTOR,
@@ -403,15 +408,17 @@
                 target=ErrorTarget.EXECUTOR,
             )
 
     def _load_images_for_prompt_tpl(self, prompt_tpl_inputs_mapping: dict, node_inputs: dict):
         for input_name, input in prompt_tpl_inputs_mapping.items():
             if ValueType.IMAGE in input.type and input_name in node_inputs:
                 if node_inputs[input_name].value_type == InputValueType.LITERAL:
-                    node_inputs[input_name].value = create_image(node_inputs[input_name].value)
+                    node_inputs[input_name].value = self._multimedia_processor.create_image(
+                        node_inputs[input_name].value
+                    )
         return node_inputs
 
     def _resolve_prompt_node(self, node: Node) -> ResolvedTool:
         prompt_tpl = self._load_source_content(node)
         prompt_tpl_inputs_mapping = get_inputs_for_prompt_template(prompt_tpl)
         from promptflow.tools.template_rendering import render_template_jinja2
```

## promptflow/executor/flow_executor.py

```diff
@@ -31,22 +31,18 @@
     apply_default_value_for_input,
     collect_lines,
     extract_aggregation_inputs,
     get_aggregation_inputs_properties,
 )
 from promptflow._utils.flow_utils import is_flex_flow
 from promptflow._utils.logger_utils import flow_logger, logger
-from promptflow._utils.multimedia_utils import (
-    load_multimedia_data,
-    load_multimedia_data_recursively,
-    persist_multimedia_data,
-)
+from promptflow._utils.multimedia_utils import MultimediaProcessor
+from promptflow._utils.user_agent_utils import append_promptflow_package_ua
 from promptflow._utils.utils import get_int_env_var, transpose
 from promptflow._utils.yaml_utils import load_yaml
-from promptflow._version import VERSION
 from promptflow.contracts.flow import Flow, FlowInputDefinition, InputAssignment, InputValueType, Node
 from promptflow.contracts.run_info import FlowRunInfo, Status
 from promptflow.contracts.run_mode import RunMode
 from promptflow.exceptions import PromptflowException
 from promptflow.executor import _input_assignment_parser
 from promptflow.executor._async_nodes_scheduler import AsyncNodesScheduler
 from promptflow.executor._errors import NodeOutputNotFound, OutputReferenceNotExist, SingleNodeValidationError
@@ -161,27 +157,30 @@
             self._tools_manager.assert_loaded(node.name)
         self._raise_ex = raise_ex
         self._log_interval = 60
         self._processing_idx = None
         self._completed_idx = None
         # TODO: Improve the experience about configuring node concurrency.
         self._node_concurrency = DEFAULT_CONCURRENCY_BULK
+        self._message_format = flow.message_format
+        self._multimedia_processor = MultimediaProcessor.create(flow.message_format)
 
     @classmethod
     def create(
         cls,
         flow_file: Path,
         connections: dict,
         working_dir: Optional[Path] = None,
         *,
         entry: Optional[str] = None,
         storage: Optional[AbstractRunStorage] = None,
         raise_ex: bool = True,
         node_override: Optional[Dict[str, Dict[str, Any]]] = None,
         line_timeout_sec: Optional[int] = None,
+        init_kwargs: Optional[Dict[str, Any]] = None,
     ) -> "FlowExecutor":
         """Create a new instance of FlowExecutor.
 
         :param flow_file: The path to the flow file.
         :type flow_file: Path
         :param connections: The connections to be used for the flow.
         :type connections: dict
@@ -193,27 +192,29 @@
         :type storage: Optional[~promptflow.storage.AbstractRunStorage]
         :param raise_ex: Whether to raise exceptions or not. Default is True.
         :type raise_ex: Optional[bool]
         :param node_override: The node overrides to be used for the flow. Default is None.
         :type node_override: Optional[Dict[str, Dict[str, Any]]]
         :param line_timeout_sec: The line timeout in seconds to be used for the flow. Default is LINE_TIMEOUT_SEC.
         :type line_timeout_sec: Optional[int]
+        :param init_kwargs: Class init arguments for callable class, only supported for flex flow.
+        :type init_kwargs: Optional[Dict[str, Any]]
         :return: A new instance of FlowExecutor.
         :rtype: ~promptflow.executor.flow_executor.FlowExecutor
         """
         setup_exporter_from_environ()
         if is_flex_flow(file_path=flow_file, working_dir=working_dir):
             from ._script_executor import ScriptExecutor
 
             return ScriptExecutor(
-                flow_file=Path(flow_file),
-                working_dir=working_dir,
-                storage=storage,
+                flow_file=Path(flow_file), working_dir=working_dir, storage=storage, init_kwargs=init_kwargs
             )
         else:
+            if init_kwargs:
+                logger.warning(f"Got unexpected init args {init_kwargs} for non-script flow. Ignoring them.")
             flow = Flow.from_yaml(flow_file, working_dir=working_dir)
             return cls._create_from_flow(
                 flow_file=flow_file,
                 flow=flow,
                 connections=connections,
                 working_dir=working_dir,
                 storage=storage,
@@ -236,26 +237,28 @@
         line_timeout_sec: Optional[int] = None,
     ):
         logger.debug("Start initializing the flow executor.")
         working_dir = Flow._resolve_working_dir(flow_file, working_dir)
         if node_override:
             flow = flow._apply_node_overrides(node_override)
         flow = flow._apply_default_node_variants()
+
         package_tool_keys = [node.source.tool for node in flow.nodes if node.source and node.source.tool]
-        tool_resolver = ToolResolver(working_dir, connections, package_tool_keys)
+        tool_resolver = ToolResolver(working_dir, connections, package_tool_keys, message_format=flow.message_format)
 
         with _change_working_dir(working_dir):
             resolved_tools = [tool_resolver.resolve_tool_by_node(node) for node in flow.nodes]
         flow = Flow(
             id=flow.id,
             name=flow.name,
             nodes=[r.node for r in resolved_tools],
             inputs=flow.inputs,
             outputs=flow.outputs,
             tools=[],
+            message_format=flow.message_format,
         )
         # ensure_flow_valid including validation + resolve
         # Todo: 1) split pure validation + resolve from below method 2) provide completed validation()
         flow = FlowValidator._validate_nodes_topology(flow)
         flow.outputs = FlowValidator._ensure_outputs_valid(flow)
 
         if storage is None:
@@ -315,15 +318,15 @@
         """
 
         @contextlib.contextmanager
         def update_operation_context():
             operation_context = OperationContext.get_instance()
             original_context = operation_context.copy()
             try:
-                operation_context.append_user_agent(f"promptflow/{VERSION}")
+                append_promptflow_package_ua(operation_context)
                 operation_context.set_default_tracing_keys({"run_mode", "root_run_id", "flow_id", "batch_input_source"})
                 operation_context["run_mode"] = RunMode.SingleNode.name
                 # Inject OpenAI API to make sure traces and headers injection works and
                 # update OpenAI API configs from environment variables.
                 inject_openai_api()
                 yield
             finally:
@@ -362,18 +365,20 @@
             )
         # Only load the node's referenced flow inputs
         node_referenced_flow_inputs = FlowExecutor._get_node_referenced_flow_inputs(node, flow.inputs)
         inputs_with_default_value = apply_default_value_for_input(node_referenced_flow_inputs, flow_inputs)
         converted_flow_inputs_for_node = FlowValidator.convert_flow_inputs_for_node(
             flow, node, inputs_with_default_value
         )
-        inputs = load_multimedia_data(node_referenced_flow_inputs, converted_flow_inputs_for_node)
-        dependency_nodes_outputs = load_multimedia_data_recursively(dependency_nodes_outputs)
+
+        multimedia_processor = MultimediaProcessor.create(flow.message_format)
+        inputs = multimedia_processor.load_multimedia_data(node_referenced_flow_inputs, converted_flow_inputs_for_node)
+        dependency_nodes_outputs = multimedia_processor.load_multimedia_data_recursively(dependency_nodes_outputs)
         package_tool_keys = [node.source.tool] if node.source and node.source.tool else []
-        tool_resolver = ToolResolver(working_dir, connections, package_tool_keys)
+        tool_resolver = ToolResolver(working_dir, connections, package_tool_keys, message_format=flow.message_format)
         resolved_node = tool_resolver.resolve_tool_by_node(node)
 
         # Prepare callable and real inputs here
 
         resolved_inputs = {}
         for k, v in resolved_node.node.inputs.items():
             value = _input_assignment_parser.parse_value(v, dependency_nodes_outputs, inputs)
@@ -390,21 +395,23 @@
         # Note that the init args are only used when resolving the tool,
         # so we need to remove them from the inputs before invoking.
         resolved_inputs = {k: v for k, v in resolved_inputs.items() if k not in resolved_node.init_args}
 
         if storage is None:
             sub_dir = "." if output_sub_dir is None else output_sub_dir
             storage = DefaultRunStorage(base_dir=working_dir, sub_dir=Path(sub_dir))
+
         run_tracker = RunTracker(storage)
         with run_tracker.node_log_manager, update_operation_context():
             # Will generate node run in context
             context = FlowExecutionContext(
                 name=flow.name,
                 run_tracker=run_tracker,
                 cache_manager=AbstractCacheManager.init_from_env(),
+                message_format=flow.message_format,
             )
 
             try:
                 if inspect.iscoroutinefunction(resolved_node.callable):
                     asyncio.run(
                         context.invoke_tool_async(resolved_node.node, resolved_node.callable, kwargs=resolved_inputs),
                     )
@@ -606,31 +613,32 @@
         run_id=None,
     ) -> AggregationResult:
         if not self._flow.has_aggregation_node:
             return AggregationResult({}, {}, {})
         run_id = run_id or str(uuid.uuid4())
         nodes = [copy.deepcopy(node) for node in self._flow.nodes if node.aggregation]
         # Load multimedia data from aggregation_inputs
-        aggregation_inputs = load_multimedia_data_recursively(aggregation_inputs)
+        aggregation_inputs = self._multimedia_processor.load_multimedia_data_recursively(aggregation_inputs)
         # Update the inputs of the aggregation nodes with the aggregation inputs.
         for node in nodes:
             node.inputs = {
                 k: FlowExecutor._try_get_aggregation_input(v, aggregation_inputs) for k, v in node.inputs.items()
             }
         # Load multimedia data for the flow inputs of aggregation nodes.
-        inputs = load_multimedia_data(self._flow.inputs, inputs)
+        inputs = self._multimedia_processor.load_multimedia_data(self._flow.inputs, inputs)
 
         # TODO: Use a new run tracker to avoid memory increase infinitely.
         run_tracker = self._run_tracker
         context = FlowExecutionContext(
             name=self._flow.name,
             run_tracker=run_tracker,
             cache_manager=self._cache_manager,
             run_id=run_id,
             flow_id=self._flow_id,
+            message_format=self._message_format,
         )
         metrics = {}
 
         def _log_metric(key, value):
             metrics[key] = value
 
         add_metric_logger(_log_metric)
@@ -784,15 +792,15 @@
             values_for_otel = {
                 "batch_run_id": run_id,
                 "line_number": line_number,
             }
         else:
             values_for_otel = {"line_run_id": run_id}
         try:
-            operation_context.append_user_agent(f"promptflow/{VERSION}")
+            append_promptflow_package_ua(operation_context)
             operation_context.set_default_tracing_keys({"run_mode", "root_run_id", "flow_id", "batch_input_source"})
             operation_context.run_mode = original_mode or RunMode.Test.name
             operation_context.update(values_for_context)
             for k, v in values_for_otel.items():
                 operation_context._add_otel_attributes(k, v)
             # Inject OpenAI API to make sure traces and headers injection works and
             # update OpenAI API configs from environment variables.
@@ -830,14 +838,16 @@
         run_info: FlowRunInfo,
         run_tracker: RunTracker,
         context: FlowExecutionContext,
         validate_inputs=False,
         allow_generator_output=False,
     ):
         with open_telemetry_tracer.start_as_current_span(self._flow.name) as span:
+            # Store otel trace id in context for correlation
+            OperationContext.get_instance()["otel_trace_id"] = f"{span.get_span_context().trace_id:032x}"
             # initialize span
             span.set_attributes(
                 {
                     "framework": "promptflow",
                     "span_type": TraceType.FLOW.value,
                 }
             )
@@ -866,15 +876,15 @@
         run_tracker: RunTracker,
         context: FlowExecutionContext,
         validate_inputs=False,
         allow_generator_output=False,
     ):
         if validate_inputs:
             inputs = FlowValidator.ensure_flow_inputs_type(flow=self._flow, inputs=inputs, idx=run_info.index)
-        inputs = load_multimedia_data(self._flow.inputs, inputs)
+        inputs = self._multimedia_processor.load_multimedia_data(self._flow.inputs, inputs)
         # Inputs are assigned after validation and multimedia data loading, instead of at the start of the flow run.
         # This way, if validation or multimedia data loading fails, we avoid persisting invalid inputs.
         run_info.inputs = inputs
         output, nodes_outputs = self._traverse_nodes(inputs, context)
         output = self._stringify_generator_output(output) if not allow_generator_output else output
         # Persist the node runs for the nodes that have a generator output
         generator_output_nodes = [
@@ -919,22 +929,24 @@
         run_tracker.allow_generator_types = self._run_tracker.allow_generator_types
         run_info: FlowRunInfo = run_tracker.start_flow_run(
             flow_id=self._flow_id,
             root_run_id=run_id,
             run_id=line_run_id,
             parent_run_id=run_id,
             index=line_number,
+            message_format=self._message_format,
         )
         context = FlowExecutionContext(
             name=self._flow.name,
             run_tracker=run_tracker,
             cache_manager=self._cache_manager,
             run_id=run_id,
             flow_id=self._flow_id,
             line_number=line_number,
+            message_format=self._message_format,
         )
         output = {}
         aggregation_inputs = {}
         try:
             output, aggregation_inputs = self._exec_inner_with_trace(
                 inputs,
                 run_info,
@@ -1000,30 +1012,32 @@
         run_info: FlowRunInfo = run_tracker.start_flow_run(
             flow_id=self._flow_id,
             root_run_id=run_id,
             run_id=line_run_id,
             parent_run_id=run_id,
             inputs={k: inputs[k] for k in self._flow.inputs if k in inputs},
             index=line_number,
+            message_format=self._message_format,
         )
         context = FlowExecutionContext(
             name=self._flow.name,
             run_tracker=run_tracker,
             cache_manager=self._cache_manager,
             run_id=run_id,
             flow_id=self._flow_id,
             line_number=line_number,
+            message_format=self._message_format,
         )
         output = {}
         aggregation_inputs = {}
         try:
             if validate_inputs:
                 inputs = FlowValidator.ensure_flow_inputs_type(flow=self._flow, inputs=inputs, idx=line_number)
             # TODO: Consider async implementation for load_multimedia_data
-            inputs = load_multimedia_data(self._flow.inputs, inputs)
+            inputs = self._multimedia_processor.load_multimedia_data(self._flow.inputs, inputs)
             # Make sure the run_info with converted inputs results rather than original inputs
             run_info.inputs = inputs
             output, nodes_outputs = await self._traverse_nodes_async(inputs, context)
             # TODO: Consider async implementation for _stringify_generator_output
             output = self._stringify_generator_output(output) if not allow_generator_output else output
             # Persist the node runs for the nodes that have a generator output
             generator_output_nodes = [
@@ -1324,16 +1338,18 @@
     with _change_working_dir(working_dir):
         # Execute nodes in the flow except the aggregation nodes
         # TODO: remove index=0 after UX no longer requires a run id similar to batch runs
         # (run_id_index, eg. xxx_0) for displaying the interface
         line_result = flow_executor.exec_line(
             inputs, index=0, allow_generator_output=allow_generator_output, run_id=run_id
         )
-        # Persist the output to the output directory
-        line_result.output = persist_multimedia_data(line_result.output, base_dir=working_dir, sub_dir=output_dir)
+        # persist the output to the output directory
+        line_result.output = flow_executor._multimedia_processor.persist_multimedia_data(
+            line_result.output, base_dir=working_dir, sub_dir=output_dir
+        )
         if run_aggregation and line_result.aggregation_inputs:
             # Convert inputs of aggregation to list type
             flow_inputs = {k: [v] for k, v in inputs.items()}
             aggregation_inputs = {k: [v] for k, v in line_result.aggregation_inputs.items()}
             aggregation_results = flow_executor.exec_aggregation(
                 flow_inputs, aggregation_inputs=aggregation_inputs, run_id=run_id
             )
```

## promptflow/storage/_queue_run_storage.py

```diff
@@ -2,15 +2,15 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 from multiprocessing import Queue
 from pathlib import Path
 
 from promptflow._constants import OutputsFolderName
-from promptflow._utils.multimedia_utils import process_multimedia_in_run_info
+from promptflow._utils.multimedia_utils import MultimediaProcessor
 from promptflow.contracts.run_info import FlowRunInfo
 from promptflow.contracts.run_info import RunInfo as NodeRunInfo
 from promptflow.storage import AbstractRunStorage
 
 
 class QueueRunStorage(AbstractRunStorage):
     """This storage is used in line_execution_process_pool, where the run infos are put into the
@@ -35,13 +35,15 @@
         self._flow_outputs_path = output_dir / OutputsFolderName.FLOW_OUTPUTS
         self._flow_artifacts_path = output_dir / OutputsFolderName.FLOW_ARTIFACTS
         self._node_artifacts_path = output_dir / OutputsFolderName.NODE_ARTIFACTS
 
     def persist_node_run(self, run_info: NodeRunInfo):
         super().persist_node_run(run_info)
         node_folder = self._node_artifacts_path / str(run_info.index) / run_info.node
-        process_multimedia_in_run_info(run_info, node_folder)
+        multimedia_processor = MultimediaProcessor.create(run_info.message_format)
+        multimedia_processor.process_multimedia_in_run_info(run_info, node_folder)
 
     def persist_flow_run(self, run_info: FlowRunInfo):
         super().persist_flow_run(run_info)
         flow_folder = self._flow_artifacts_path / str(run_info.index)
-        process_multimedia_in_run_info(run_info, flow_folder)
+        multimedia_processor = MultimediaProcessor.create(run_info.message_format)
+        multimedia_processor.process_multimedia_in_run_info(run_info, flow_folder)
```

## promptflow/storage/_run_storage.py

```diff
@@ -1,17 +1,15 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
-from functools import partial
 from pathlib import Path
 from typing import Union
 
-from promptflow._utils.multimedia_utils import _process_recursively, get_file_reference_encoder
-from promptflow.contracts.multimedia import Image
+from promptflow._utils.multimedia_utils import MultimediaProcessor
 from promptflow.contracts.run_info import FlowRunInfo
 from promptflow.contracts.run_info import RunInfo as NodeRunInfo
 
 
 class AbstractRunStorage:
     def persist_node_run(self, run_info: NodeRunInfo):
         """Write the node run info to somewhere immediately after the node is executed.
@@ -74,33 +72,36 @@
 
     def persist_run_info(self, run_info: Union[FlowRunInfo, NodeRunInfo]):
         """Persist the multimedia data in run info after execution.
 
         :param run_info: The run info of the node or flow.
         :type run_info: ~promptflow.contracts.run_info.RunInfo or ~promptflow.contracts.run_info.FlowRunInfo
         """
+        multimedia_processor = MultimediaProcessor.create(run_info.message_format)
         # Persist and convert images in inputs to path dictionaries.
         # This replaces any image objects with their corresponding file path dictionaries.
         if run_info.inputs:
-            run_info.inputs = self._persist_and_convert_images_to_path_dicts(run_info.inputs)
+            run_info.inputs = self._persist_and_convert_images_to_path_dicts(multimedia_processor, run_info.inputs)
 
         # Persist and convert images in output to path dictionaries.
         # This replaces any image objects with their corresponding file path dictionaries.
         if run_info.output:
-            serialized_output = self._persist_and_convert_images_to_path_dicts(run_info.output)
+            serialized_output = self._persist_and_convert_images_to_path_dicts(multimedia_processor, run_info.output)
             run_info.output = serialized_output
             run_info.result = serialized_output
 
         # Persist and convert images in api_calls to path dictionaries.
         # The `inplace=True` parameter is used here to ensure that the original list structure holding generator outputs
         # is maintained. This allows us to keep tracking the list as it dynamically changes when the generator is
         # consumed. It is crucial to process the api_calls list in place to avoid losing the reference to the list that
         # holds the generator items, which is essential for tracing generator execution.
         if run_info.api_calls:
-            run_info.api_calls = self._persist_and_convert_images_to_path_dicts(run_info.api_calls, inplace=True)
+            run_info.api_calls = self._persist_and_convert_images_to_path_dicts(
+                multimedia_processor, run_info.api_calls, inplace=True
+            )
 
     def persist_node_run(self, run_info: NodeRunInfo):
         """Persist the multimedia data in node run info after the node is executed.
         This method now delegates to the shared persist_run_info method.
 
         :param run_info: The run info of the node.
         :type run_info: NodeRunInfo
@@ -112,15 +113,17 @@
         This method now delegates to the shared persist_run_info method.
 
         :param run_info: The run info of the flow.
         :type run_info: FlowRunInfo
         """
         self.persist_run_info(run_info)
 
-    def _persist_and_convert_images_to_path_dicts(self, value, inplace=False):
+    def _persist_and_convert_images_to_path_dicts(
+        self, multimedia_processor: MultimediaProcessor, value, inplace=False
+    ):
         """Persist image objects within a Python object to disk and convert them to path dictionaries.
 
         This function recursively processes a given Python object, which can be a list, a dictionary, or a nested
         combination of these, searching for image objects. Each image object encountered is serialized and saved to
         disk in a pre-defined location using the `_base_dir` and `_sub_dir` attributes. The image object within the
         original data structure is then replaced with a dictionary that indicates the file path of the serialized
         image, following the format: `{'data:image/<ext>;path': '.promptflow/intermediate/<image_uuid>.<ext>'}`.
@@ -134,16 +137,10 @@
         :param inplace: Whether to modify the original object in place (True) or to create a new object with converted
                         path dictionaries (False).
         :type inplace: bool
         :return: The original object with converted path dictionaries if `inplace` is True, otherwise a new object with
                  the conversions.
         :rtype: Any
         """
-        if self._base_dir:
-            pfbytes_file_reference_encoder = get_file_reference_encoder(
-                folder_path=self._base_dir,
-                relative_path=self._sub_dir,
-            )
-        else:
-            pfbytes_file_reference_encoder = None
-        serialization_funcs = {Image: partial(Image.serialize, **{"encoder": pfbytes_file_reference_encoder})}
-        return _process_recursively(value, process_funcs=serialization_funcs, inplace=inplace)
+        return multimedia_processor.persist_multimedia_data(
+            value, base_dir=self._base_dir, sub_dir=self._sub_dir, inplace=inplace
+        )
```

## Comparing `promptflow_core-0.1.0b1.dist-info/RECORD` & `promptflow_core-1.8.0.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,140 +1,140 @@
-promptflow/_constants.py,sha256=M7JG25OyF8t3fmgDcY9ie_DQDKdD0Bsg406CH31u2yI,7262
+promptflow/_constants.py,sha256=uFnIRyVRu1YT1P6C8VWtC1P41o-fxN5Fla-q7jXYbVA,7708
 promptflow/_core/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
 promptflow/_core/_errors.py,sha256=Q54VNl6Y46ARyJ7TMa64AIt8SfZEB3vvg4FSdGUNG_A,5431
 promptflow/_core/cache_manager.py,sha256=TlBL_zJPO_AmBM0N-JoTdE2n0aw9PjPTFtfWz1YDJuY,5190
 promptflow/_core/connection_manager.py,sha256=u4JHk3DVwznmOxD1F8YYAqMnMaOsPNQx8VQ1ZU24PCA,6512
 promptflow/_core/data/tool.schema.json,sha256=5wOEWTqyc9zjz6vnENfXJW-LoU1c5-YfFAdajt1nHf4,8974
-promptflow/_core/flow_execution_context.py,sha256=9o5-6jn_pUEENUhuCNOwASznn5bTE9MwSpGzEFsUhnE,10511
+promptflow/_core/flow_execution_context.py,sha256=C8GEAPVuLRvL5PNw8pJe7IvYOy5YWueqlLjGO3VLbxQ,10755
 promptflow/_core/log_manager.py,sha256=A-x_QCCijInSKSUdOHyhD-gKDyb6RthumjDzic6d1DI,6242
 promptflow/_core/metric_logger.py,sha256=4tyh9CfsfQlhcb36jT32CZbLrcgl_1fGZZWo_chnVB0,2156
 promptflow/_core/operation_context.py,sha256=IY_kF4yaNAz2AcnsvgmVAzWrLJMEPjJAvHuVo24cpDY,118
-promptflow/_core/run_tracker.py,sha256=Jm6p6TNyH4NeUP9k-cxnEG-VrYY3-nlazu-BpbIsP5c,19816
+promptflow/_core/run_tracker.py,sha256=r-5rwomEKv6nxL4axfAdzqiuQ5z_pjhKm5ESMnPun_k,20344
 promptflow/_core/token_provider.py,sha256=bUyUOudZBSszqmzzQt6q3I0OkWG2gw1_O7D5uY5LGa0,1537
 promptflow/_core/tool.py,sha256=NT2Pe69Rr7_NFWt-3iksRxEiw-leASav3oCkwbPgz9k,9609
-promptflow/_core/tool_meta_generator.py,sha256=tjyUPmf76_GFoqp4kI6xVthpdQOADFFQevCRsWrms5Y,22421
-promptflow/_core/tool_settings_parser.py,sha256=exSIxwDJQglasFdSngtPcAPEvwjHQ_FqeA0pxEXpRoc,2960
+promptflow/_core/tool_meta_generator.py,sha256=TXmY97oceynszVbfr8OpKHcwMV9BJV8qdIMBTzR_Y4g,22561
+promptflow/_core/tool_settings_parser.py,sha256=X5oXqnfXOoWOBBrQwD-sEI-E8j671puCJjVNUc_LU80,2854
 promptflow/_core/tool_validation.py,sha256=W1J0Y3MnAY6EYAyNez2_4Tz050XBCb7UWdPE_fSj6CY,4274
 promptflow/_core/tools_manager.py,sha256=Tqb7snb0G_EBdi1_yZI3zMTFOdR7eruNSEoJ_MphY24,23991
 promptflow/_utils/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
-promptflow/_utils/_errors.py,sha256=U5sd8UJ_k48JqT00FD2vSm7o0h6foPmGeyUijuvaP_Y,512
+promptflow/_utils/_errors.py,sha256=Ibnv3aVw8PI8FSJwkhv704fzUHdi5TFAzQCzIxnxDnk,649
 promptflow/_utils/async_utils.py,sha256=Bg7PO_5gR5m0LblBoibR1il2x-SD2sUs6_r21szI3zI,1848
 promptflow/_utils/connection_utils.py,sha256=T95lr55Z2RSjDqW2MrOEo29cSw2iX9xs-vuJ1Jcx2yo,4407
 promptflow/_utils/context_utils.py,sha256=o0GP5H13YvgD5enFeUXWxMyGTh3MhYEJyjgNV18tAU0,859
 promptflow/_utils/credential_scrubber.py,sha256=8clyzlun9MLWVIfuo8yjctggQ8l3_pO6o4zrrov3WdU,1946
 promptflow/_utils/credential_utils.py,sha256=8X-QniweMVzGwFyxaIQ0ogIXS1u6ACSqWFeRS10mp-A,926
 promptflow/_utils/dataclass_serializer.py,sha256=hIYGKHuAJLJQHbt69rewa_1GKYiFCboBto-rOQ-Ag28,3125
 promptflow/_utils/exception_utils.py,sha256=tflG5JdYxgnWUuVUXhBZm59ff4-JLGNk8MBgvZxIVtY,13649
 promptflow/_utils/execution_utils.py,sha256=i4L_085Fz-UxoULHjuquc_OUuRLdKi5wurtB5oDeF1o,5837
 promptflow/_utils/feature_utils.py,sha256=I0OJ7l6ZpyYpKa08V40zGvRknBfjjq0tswpPwzOMRJI,1795
 promptflow/_utils/flow_utils.py,sha256=R5N7PqGvIQMJS8zjrUwbER1EFUm_DsK_GU2DHqkvzoc,10564
 promptflow/_utils/inputs_mapping_utils.py,sha256=9oYaAL6f5cjxcRNpeSb118YEwXoc4EQkOyH8jSboDBM,4044
 promptflow/_utils/load_data.py,sha256=sw4ngoIYw3Q1ckZ0qadaTtekd_Hefcb-OU34pKnlY6k,5088
 promptflow/_utils/logger_utils.py,sha256=hyhWiWQ3pAC9k1-xvoO9mAofxPKuAThc3Gj8ubuXG50,16426
-promptflow/_utils/multimedia_data_converter.py,sha256=P8pf2bRfvcAJTwVJ0QAsZSOSCkQ7smPBw9lhiPWZGg4,6487
-promptflow/_utils/multimedia_utils.py,sha256=wCWAu3vWzLZ5xa_I1Rr_q9ddjt1cLK4Y6spAKPDjtoQ,11182
+promptflow/_utils/multimedia_data_converter.py,sha256=kg_P70kRtQJ613-EZ44x7l5wrRVAYibiBDRzj-LLxHE,6470
+promptflow/_utils/multimedia_utils.py,sha256=y-qG9wMA9wemJ54Bs1a_pzDv1X0RNEsgWIGlv-neSDk,22015
 promptflow/_utils/process_utils.py,sha256=UbfojsryK1aCbU7XNjMNhgEMViNc3uKAuGcT8ReT8F4,3625
 promptflow/_utils/retry_utils.py,sha256=4QbHv8CIXFX45FlsKau4cru4JsOVJWUvN3F7JjpC_B0,3474
 promptflow/_utils/run_tracker_utils.py,sha256=3h-TQj7ddbNkd9HV-POjl0h--aHdeFKz1NykZlW1MRc,919
 promptflow/_utils/thread_utils.py,sha256=mQSUebQpwaKAVykeIKC91RAzT1cIr7nQk3wplEkzE7M,2187
 promptflow/_utils/tool_utils.py,sha256=E2DJlxY85_FJtd4nw1OYUD6PC21a3ixxgq7RKqjWe9c,20655
-promptflow/_utils/user_agent_utils.py,sha256=0bgA8hlOvhNijA430yhGtgj_Rt1-Y-BHfb5VYdD8mhw,2266
-promptflow/_utils/utils.py,sha256=5fNv0FqLaB76V82sp0ivbyws6FTzZQN2dZwrAvbJf6Y,14515
+promptflow/_utils/user_agent_utils.py,sha256=CuEW6qJEmXqIUIy0LjDulgAQI9PljxwyP8z-tHwL1VM,2643
+promptflow/_utils/utils.py,sha256=c9SXMFwm83ilnR692UR5Ru75Kx-gcBIhmre8MYjBaq8,14729
 promptflow/_utils/version_hint_utils.py,sha256=sbfOh_inWw5pJGPxPWVF_JaecUaTwe7D1zjSX1Y5X4U,4141
 promptflow/_utils/yaml_utils.py,sha256=uvu8LSHhK6TQppLSdCzfFXmfEqSiDAimuJlb0jo3vYQ,4057
 promptflow/connections/__init__.py,sha256=4ayYOHO28BsLHISzk6fEKvS_IYc47zel0uIwInfBSt8,1352
 promptflow/contracts/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
 promptflow/contracts/_errors.py,sha256=ZqNsU-PlwICUACTsW5JLC9B4h0l9LCr66Ply2g2FTtM,170
 promptflow/contracts/_run_management.py,sha256=YlNNq_DEKZrGeQEuNU5A8Fz2BKXk9uFXaEd7KtlLPeE,1131
-promptflow/contracts/flow.py,sha256=RAYE7VobIjxY2LvUI4xHY8DieR3oGkNBHN6XnBJfu8o,36780
-promptflow/contracts/multimedia.py,sha256=TeKZxR-OKfj3J-9vE2HZaFVT18oXXtOq7LkOlXTerro,2460
-promptflow/contracts/run_info.py,sha256=O-iVJjAGUV0xx1XzO4bVhd99tECt9DvnRCkx98TxDn4,8757
+promptflow/contracts/flow.py,sha256=NMs88elUaLcj7LFUejIpmuO1vqzFtGnOP0DwHAUDuKU,37511
+promptflow/contracts/multimedia.py,sha256=LFtdkPNKhQ9QfL7ZjBI9-cQm7NElbbIvyOEEfTmr-p8,3088
+promptflow/contracts/run_info.py,sha256=VewnP-XkLNe8JpazqhD2acXJJTY7BB8vyatWosQw-mg,9351
 promptflow/contracts/run_mode.py,sha256=fgRRoolFi7HhDC9Noyis0QkE1ZibhTvMR25HosnG1uA,1001
 promptflow/contracts/tool.py,sha256=uv-V8Y2wDQVTR3IyH1tdP7SZ11DHy7ma8REChHBgxjA,16165
 promptflow/contracts/types.py,sha256=80oQY5pGgPIslDfEMdxBw7WsvtDOSMtddzYcG-_xUEM,1536
 promptflow/core/__init__.py,sha256=Y1RZck3pVcVhpIJQus-oDiHAudjo9PSN94sASjbNapc,610
 promptflow/core/_connection.py,sha256=h3EWgblpgKTV2Ti-m-sJiQITYA5i26a0ZxS6UwoXgL8,28375
 promptflow/core/_connection_provider/__init__.py,sha256=vV8bhHRJHrJVbMOhR8jvnWF0_ZwCRQiSsUwf0X04gtg,262
-promptflow/core/_connection_provider/_connection_provider.py,sha256=7LEUUuijI5Kfh_SStRPL66B320dZOSSr9iezSKdfHkg,2400
+promptflow/core/_connection_provider/_connection_provider.py,sha256=hMuNa5vs6xg8HM9U-48Ld6fpWlTfwWA3W8DKI4dGgFA,2355
 promptflow/core/_connection_provider/_dict_connection_provider.py,sha256=oSvO4RQDQtLY3AvL-dhiSPr9mJ8H4qloA3-7EzlQK6U,4283
 promptflow/core/_connection_provider/_models/__init__.py,sha256=AHWsN7NwE_VZsMp_mYWx7OkzQekhxjJBkCmSLRunFTI,84939
 promptflow/core/_connection_provider/_models/_models.py,sha256=ZUjC-dqFdkByIyjAGydmtLie_mN8S4hnYINDeJ2m8Rg,1637221
 promptflow/core/_connection_provider/_models/_version.py,sha256=IXD2-_BI41VEN4R-g9RSt1YG32ByK7N_cwStxbXdR0M,212
-promptflow/core/_connection_provider/_utils.py,sha256=AQbbuocgPSyI2GLRnp_hcLTR8YUEPAyF5HBEz7_qIsw,3038
-promptflow/core/_connection_provider/_workspace_connection_provider.py,sha256=iCxcRQDeQEe20JJu8BP9-BfYPjl3MABWm3NkEFQ1KO0,15522
-promptflow/core/_errors.py,sha256=BiNanOMhcMcnNcCc_pDNDQR1ihQJLNl3l-mrldNX6I8,3968
+promptflow/core/_connection_provider/_utils.py,sha256=X-oM0uOMEpe8_PSKe6bFNYl29RLz1wEaTzw_Ynm2uEw,3018
+promptflow/core/_connection_provider/_workspace_connection_provider.py,sha256=0fcOtNEAX4Mm_SOK7cjxqvdPEWKj1RhVCKuhlKE5JUY,15502
+promptflow/core/_errors.py,sha256=yPkUOssKAem1Gq9hRLYxFEO6HmQ8fTbFpwhhdi-7mjQ,4000
 promptflow/core/_flow.py,sha256=hoJsulwpTjKdmU0oHH8m1vCvpyY83fsrGYRKNBDPcUg,6500
 promptflow/core/_serving/__init__.py,sha256=vV8bhHRJHrJVbMOhR8jvnWF0_ZwCRQiSsUwf0X04gtg,262
 promptflow/core/_serving/_errors.py,sha256=gTc7E7-DkfcMnw5VJHAXRTNMb35Q3tDrG5NGXHQmyVA,1936
-promptflow/core/_serving/app.py,sha256=EWMbbXAI-ov8E1kG0VO_qbAPNh5DXHZs7O_P3KIHx7U,12089
+promptflow/core/_serving/app.py,sha256=0DAIXXf5wJJ1FW8mRhZ68Mwo4pnSeKTTjjN0nN_G62c,12197
 promptflow/core/_serving/blueprint/__init__.py,sha256=vV8bhHRJHrJVbMOhR8jvnWF0_ZwCRQiSsUwf0X04gtg,262
 promptflow/core/_serving/blueprint/monitor_blueprint.py,sha256=sFXId6jStaNXKRtLl84FzQ55nw5P4j2g9-X2gBnNCkk,1182
 promptflow/core/_serving/blueprint/static_web_blueprint.py,sha256=CwAwehx-RORAiJhVfC7ilrScnoHeFQRV6Dguy3XQp8c,1591
 promptflow/core/_serving/constants.py,sha256=CcNDEEXkvdznwHX62aODPxaELjPIPxrt7NF0vnhcX_w,269
 promptflow/core/_serving/extension/__init__.py,sha256=vV8bhHRJHrJVbMOhR8jvnWF0_ZwCRQiSsUwf0X04gtg,262
-promptflow/core/_serving/extension/azureml_extension.py,sha256=JN4vi8wuLYT804CyLdZnztkHiHgyZyRgn-ArUDvoUHE,8933
-promptflow/core/_serving/extension/default_extension.py,sha256=XzgUXinh50az4kmdLmB7ECsdp6GaTuDoiNJEfHeUrGw,5899
+promptflow/core/_serving/extension/azureml_extension.py,sha256=voLVfmDb1Lexc3Q2uYRuBoiXqSyFhK4zt5ovlUM7SJQ,8946
+promptflow/core/_serving/extension/default_extension.py,sha256=_cTuevrc04ZddiDSvzuQ5IB-l_vErmSVOUU7bJrlAtE,5912
 promptflow/core/_serving/extension/extension_factory.py,sha256=95QiGgAGLBe3X1Ca4VzGydCF8p9NA_fOh79_PAALAUw,1264
 promptflow/core/_serving/extension/extension_type.py,sha256=X6Fvxfpm6ciVL7pKia0KnTcytvHenRCZno8O8ttFuGc,361
 promptflow/core/_serving/extension/otel_exporter_provider_factory.py,sha256=xNWYg0-D_iwKrkZzF4arYvKM5gD67_D-Wq_NuSKuNZE,4405
-promptflow/core/_serving/flow_invoker.py,sha256=nP1H0YLpJEhAhVUn6oLJDyLBKEhdUynJv1rl26SUmY4,13079
+promptflow/core/_serving/flow_invoker.py,sha256=-nIezWMEQG6s2CAuoBvvojXQjLi3p0N8_yZhdArNkLo,13499
 promptflow/core/_serving/flow_result.py,sha256=nb1_vZXkpPkjn8fZSK9UAcsqnEid_GyO8T3ROgbGqIk,721
 promptflow/core/_serving/monitor/__init__.py,sha256=vV8bhHRJHrJVbMOhR8jvnWF0_ZwCRQiSsUwf0X04gtg,262
 promptflow/core/_serving/monitor/data_collector.py,sha256=bP3p-CfESiiYlSfPUDrCq87YC9hFkQKzL6HiLeOzYK4,2197
 promptflow/core/_serving/monitor/flow_monitor.py,sha256=iPcg8EvJN0Gyq674viA3LnQlZjoaS-Ofy5QIcPsC97E,6902
 promptflow/core/_serving/monitor/mdc_exporter.py,sha256=v0X-LZVHIGb0V4HeLzMs37UX8w8Dg4-pwYuXX_GkNUE,1842
 promptflow/core/_serving/monitor/metrics.py,sha256=ep1FKG2FQz_RM-AyTYhJWjDRsLjl6qCtLh30M-ptr2s,13336
 promptflow/core/_serving/monitor/streaming_monitor.py,sha256=ydAjoyE-ouyYBexgt2bZ-ULrBBWmXo6dJcHfoCIzsik,2494
 promptflow/core/_serving/resources/feedback_swagger.json,sha256=KFPZlfyUS3KjRDAckBQCMFagmBhXFaUMXY7DFPsck4o,1288
 promptflow/core/_serving/response_creator.py,sha256=G0IFL7xfMukSEcU8VMIz3o9TsslDhhVwQ9ipgJDnf70,4854
 promptflow/core/_serving/static/index.html,sha256=UeaMK6VTvv9WIFdARR7y_LnNifbfmIfpDBsNWB2Nkh8,770
 promptflow/core/_serving/static/index.js,sha256=R1_P7L6kopJGHEKVoW-g2zcAtuBtwSB-QaxFtnSPgj0,1604403
 promptflow/core/_serving/swagger.py,sha256=_FbAojCVA77SQ0Mx1wF_w6rJHQC0WzToHR_fFoLbGA0,4822
 promptflow/core/_serving/utils.py,sha256=GdPSjfkMYTWDcmuJ1bHAstbJS-gmJFY6KBR1apzcf0A,6509
 promptflow/core/_utils.py,sha256=HH5yDvohVj23vhM4inRFb4rTFj6zn2eJLi7XNV7Rrgs,9527
-promptflow/core/_version.py,sha256=EsRgoZeMcnrsSYuh268S4sjO-iuMRUewiGWVGPnwJZ0,268
-promptflow/exceptions.py,sha256=TPmEIS2Bm4Og_kjEcCJqgVs4H0JYC8eMtNEJmHCWzUA,13589
+promptflow/core/_version.py,sha256=tfOQ_5qtj4wRF6gpL3ETf4jWGHTivFAHOCsfonPEtGY,296
+promptflow/exceptions.py,sha256=pULHfOv8hPergBKikhWoxABFovK_DZSI-4BEfXddRXE,13665
 promptflow/executor/__init__.py,sha256=zb4PvuYJ9eOVFfSJxsnO7YHAonXlpJgf5pTPTFxwdcA,278
 promptflow/executor/_assistant_tool_invoker.py,sha256=_2K_Ee8w0K4ezU7HKgAtsSOKGVqB4I-bePeos2MVgyY,5447
 promptflow/executor/_async_nodes_scheduler.py,sha256=7BgE6GueIgr6i3pkxxucA797PlI9FsklOkIht9v4HjI,14960
 promptflow/executor/_dag_manager.py,sha256=YYdwYxzzCpP6VQaJdZX6kPpWBPymgj6dQC1lRUmw_JY,7961
 promptflow/executor/_docstring_parser.py,sha256=8wxlNxR_hkBie_Obj5Q_gmSGlWKskOJDgbdTy__EPlM,926
-promptflow/executor/_errors.py,sha256=hRd7UMcQz9kMvz86gQU_E_D3xtk3PnDBB-SoT91HKqY,8210
+promptflow/executor/_errors.py,sha256=V2-IgJGUCIZs8MfW-oAkgXGFctnvcMt5tndAAPA0JCo,8898
 promptflow/executor/_flow_nodes_scheduler.py,sha256=jF4semGpuC4489oYGZ883R0EW7RvPb6q6tE1iQQaxiI,6739
 promptflow/executor/_input_assignment_parser.py,sha256=GNwszWuJ_4CqGpc3ZIe6RbW0hREZ6_F4L_fzP_H61OM,4571
-promptflow/executor/_line_execution_process_pool.py,sha256=WoANxkFs6MpT7U2Vh-l4JRLvJEnqW4ryNxEItIN7s-4,39881
-promptflow/executor/_process_manager.py,sha256=b95kAuDyRTfuUfKLda9-656-M5daUie8be_llHAiW7Y,19265
+promptflow/executor/_line_execution_process_pool.py,sha256=7-sBgVlImnrl0u_QjOaNR-n2_5FOl9Zjeqsdhex4d0s,40132
+promptflow/executor/_process_manager.py,sha256=Ij5J7kQhIU393WfRuGPvcK5-QwpkIb9ipsJvIsvzHfg,19439
 promptflow/executor/_result.py,sha256=SUlWjkBE6XhEhDiHPC7Axq9KF0a1VMrVRw5Ja3Wx_BM,1894
-promptflow/executor/_script_executor.py,sha256=d0O4S2gmOb_OVTsNW5EM8BqOUzSr3aar7zX8Awci0eA,6344
+promptflow/executor/_script_executor.py,sha256=PgbyHyXiEUgGHuPNUVa4cO4Zqo-u-lUncgLOG7CDmoM,7867
 promptflow/executor/_service/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
 promptflow/executor/_service/_errors.py,sha256=TPjb6OBBKfCUwd8L5pyLZsxXFRPAPfL9iTlpwtNTaGk,1170
 promptflow/executor/_service/apis/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
-promptflow/executor/_service/apis/batch.py,sha256=2kGiHAnlsiwJ2eFVmR-wndRvpeQdZRD4eADSqnOTXi8,2078
-promptflow/executor/_service/apis/common.py,sha256=MouyYQTL_3ifPrSqjSEVx5QUB3-1GykQkOzxZNoYQws,742
+promptflow/executor/_service/apis/batch.py,sha256=1Gk_5LPGHMe9RI_H1Q3NNf0bBZdzOHzYEUvpToC2pKI,2208
+promptflow/executor/_service/apis/common.py,sha256=6IamSRhWUMYdKmQ0coqrlstZCAnsobnHBefszDDD3XE,755
 promptflow/executor/_service/apis/execution.py,sha256=nNAlegRDU-3is7JibY1FC5Yzt3s8xgrr-uzVnlzB6Lk,4724
 promptflow/executor/_service/apis/tool.py,sha256=7h3Fv-V19oAfSIZCOmSk_CnPYxVUJ-Bxez1vgnI3DMU,1711
 promptflow/executor/_service/app.py,sha256=AusZDuFpuBe7TtgVWsMBLyl6_mgfFiWPBzuOOF9cO88,1004
 promptflow/executor/_service/contracts/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
 promptflow/executor/_service/contracts/base_request.py,sha256=ghWzQfnkdjWTnK_m-dQLachCe6-me5N3huXA1MWwVSk,413
 promptflow/executor/_service/contracts/batch_request.py,sha256=hbd_SipD4VcXpeeofpIFfQfrpTZf_NjvlA_08X_xq6c,1137
 promptflow/executor/_service/contracts/execution_request.py,sha256=8SuAxP-ohcoOQNaDX5K2r9xlTUYCjZICM5DMtALMwCI,2762
 promptflow/executor/_service/contracts/tool_request.py,sha256=QTkx2FnGyC-6iFQNFT3w8Olx9SkVp_ht-A01wQfY9Hw,712
 promptflow/executor/_service/utils/__init__.py,sha256=Yx1Iq2GNKQ5lYxTotvPwkPL4u0cm6YVxUe-iVbu1clI,180
-promptflow/executor/_service/utils/batch_coordinator.py,sha256=x0wfvLOdKctJiPLWueHEfKhc6j7NAZiSeBaZ8XBx26k,3770
+promptflow/executor/_service/utils/batch_coordinator.py,sha256=E6I9z_pAPoEaDizQjcnaD0vZaM2z1k1g4UKok9F1MlU,3951
 promptflow/executor/_service/utils/process_manager.py,sha256=zi9WBFd2cPKvsOpw9gkO0pfYfpQR0LiMX1u2gyxlM0A,2115
 promptflow/executor/_service/utils/process_utils.py,sha256=QBg-TEdAXh3YAAveiNdk8JUysa7r1tX7KxsQs1UkC-w,4696
-promptflow/executor/_service/utils/service_utils.py,sha256=vkv4VFG6uUwjkudfg52C7b5U2jh3fn2FK0g-uJXN0mc,2831
+promptflow/executor/_service/utils/service_utils.py,sha256=Kxj6eys58KzVGUxojxcJPYXFRz-ITqeSAsHlZEz0vCs,2854
 promptflow/executor/_tool_invoker.py,sha256=pvqQJ27HVPnU6AWleEwNgm3rKb2FMR9bNODfgDPwaC8,363
-promptflow/executor/_tool_resolver.py,sha256=0tjL4OSvUjhaa8JQmwjpG67ZQhOdqHGwE_tynU6UWJ8,29809
-promptflow/executor/flow_executor.py,sha256=eyogZN_kTYv_FNpAU4wViMC7kOXt8FIP-UwCLlc93CI,62090
+promptflow/executor/_tool_resolver.py,sha256=p2X2aRFUclR3fk7Mmfr1qrY6zhTK29001BMeWMcYq-c,30142
+promptflow/executor/flow_executor.py,sha256=DbWxXAJZJLXjECw5yMO_rR-xjcSK_eo_CJ4lvCHOpDs,63368
 promptflow/executor/flow_validator.py,sha256=Zy7BhGvLYsKFVtSvgEf_nTp6jNJHfUXEfQvhOdvE__Y,19923
 promptflow/integrations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 promptflow/integrations/langchain.py,sha256=qdOGKDp0HYNX3cZe0VKbTBhwvaNrT1zReeD8H_K4gaw,8657
 promptflow/storage/__init__.py,sha256=gRNwPOta6nf5vQp8eZR91niUZ9TTqjuuJLvyO6kAXVA,413
 promptflow/storage/_cache_storage.py,sha256=dz5LBR_yTqMbKloF88ZT7i7iMXcboEbVZ73dWdOuWZc,610
 promptflow/storage/_errors.py,sha256=0xKZaQWnWS7RIi0p338_PG5Jsu4eHHMeBYKFwFKGdu0,286
-promptflow/storage/_queue_run_storage.py,sha256=N5imFbJkFw5Y4a50jx-2hvKEHHM4VG8Orksb9sLszN4,1981
-promptflow/storage/_run_storage.py,sha256=w1OLHaEcvGJ4DM2WzzqCWFdmpYvzzATv4c3Jf67LiNQ,7223
+promptflow/storage/_queue_run_storage.py,sha256=arZOAy4OLB3FQ55KupfPn34A8VaOtv7226wGzt8mabs,2178
+promptflow/storage/_run_storage.py,sha256=tl39fy09-KIuEPcZ5jNu7aO38MUHh-vyM4Wp_we-Qes,7031
 promptflow/storage/run_records.py,sha256=2S6x1u_uZFn8gBN7jr1boIqo6bTdj9MFdQDudyE1lNM,3466
-promptflow_core-0.1.0b1.dist-info/METADATA,sha256=Sl6i-t02s4HqAnMMHvJlFbcUXnij1i8KqEso8yGnAlI,1387
-promptflow_core-0.1.0b1.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
-promptflow_core-0.1.0b1.dist-info/RECORD,,
+promptflow_core-1.8.0.dist-info/METADATA,sha256=f-DukcB0WBiEJgNcyF-MkNcSrC_dW0WgIadj2VN65WU,2709
+promptflow_core-1.8.0.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
+promptflow_core-1.8.0.dist-info/RECORD,,
```


# Comparing `tmp/qai_hub_models-0.4.1-py3-none-any.whl.zip` & `tmp/qai_hub_models-0.5.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,905 +1,926 @@
-Zip file size: 961398 bytes, number of entries: 903
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/__init__.py
--rw-r--r--  2.0 unx      281 b- defN 24-Apr-02 22:37 qai_hub_models/_version.py
--rw-r--r--  2.0 unx      620 b- defN 24-Apr-02 22:41 qai_hub_models/asset_bases.yaml
--rw-r--r--  2.0 unx      734 b- defN 24-Apr-02 22:37 qai_hub_models/conftest.py
--rw-r--r--  2.0 unx      877 b- defN 24-Apr-02 22:37 qai_hub_models/global_requirements.txt
--rw-r--r--  2.0 unx      395 b- defN 24-Apr-02 22:37 qai_hub_models/requirements-dev.txt
--rw-r--r--  2.0 unx      426 b- defN 24-Apr-02 22:37 qai_hub_models/requirements.txt
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/datasets/__init__.py
--rw-r--r--  2.0 unx     4757 b- defN 24-Apr-02 22:37 qai_hub_models/datasets/bsd300.py
--rw-r--r--  2.0 unx     4054 b- defN 24-Apr-02 22:37 qai_hub_models/datasets/coco.py
--rw-r--r--  2.0 unx     1546 b- defN 24-Apr-02 22:37 qai_hub_models/datasets/common.py
--rw-r--r--  2.0 unx     3203 b- defN 24-Apr-02 22:37 qai_hub_models/datasets/imagenette.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/__init__.py
--rw-r--r--  2.0 unx     6212 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/base_evaluators.py
--rw-r--r--  2.0 unx     1326 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/classification_evaluator.py
--rw-r--r--  2.0 unx     3355 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/detection_evaluator.py
--rw-r--r--  2.0 unx     2434 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/image_evaluator.py
--rw-r--r--  2.0 unx     2181 b- defN 24-Apr-02 22:37 qai_hub_models/evaluators/superres_evaluator.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/__init__.py
--rw-r--r--  2.0 unx      571 b- defN 24-Apr-02 22:37 qai_hub_models/models/common.py
--rw-r--r--  2.0 unx     7882 b- defN 24-Apr-02 22:37 qai_hub_models/models/protocols.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/__init__.py
--rw-r--r--  2.0 unx     1655 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/common.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/__init__.py
--rw-r--r--  2.0 unx     4346 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/app.py
--rw-r--r--  2.0 unx     2904 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/demo.py
--rw-r--r--  2.0 unx      890 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/evaluator.py
--rw-r--r--  2.0 unx     2888 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/model.py
--rw-r--r--  2.0 unx     8565 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/cityscapes_segmentation/patches/move_datasets.diff
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/deeplab/__init__.py
--rw-r--r--  2.0 unx     2651 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/deeplab/app.py
--rw-r--r--  2.0 unx     2252 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/deeplab/demo.py
--rw-r--r--  2.0 unx      915 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/deeplab/evaluator.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/detr/__init__.py
--rw-r--r--  2.0 unx     4243 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/detr/app.py
--rw-r--r--  2.0 unx     3565 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/detr/coco_label_map.py
--rw-r--r--  2.0 unx     1944 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/detr/demo.py
--rw-r--r--  2.0 unx     2152 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/detr/model.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/fastsam/__init__.py
--rw-r--r--  2.0 unx     4883 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/fastsam/app.py
--rw-r--r--  2.0 unx     2022 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/fastsam/demo.py
--rw-r--r--  2.0 unx     1935 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/fastsam/model.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet/__init__.py
--rw-r--r--  2.0 unx     4548 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet/model.py
--rw-r--r--  2.0 unx     1569 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet/test_utils.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet_quantized/__init__.py
--rw-r--r--  2.0 unx     1165 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet_quantized/aimet_config.json
--rw-r--r--  2.0 unx     2372 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/ffnet_quantized/model.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/imagenet_classifier/__init__.py
--rw-r--r--  2.0 unx     2272 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/imagenet_classifier/app.py
--rw-r--r--  2.0 unx     2432 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/imagenet_classifier/demo.py
--rw-r--r--  2.0 unx     3404 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/imagenet_classifier/model.py
--rw-r--r--  2.0 unx     3781 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/imagenet_classifier/test_utils.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/mediapipe/__init__.py
--rw-r--r--  2.0 unx    30293 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/mediapipe/app.py
--rw-r--r--  2.0 unx     4394 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/mediapipe/utils.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/quicksrnet/__init__.py
--rw-r--r--  2.0 unx      985 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/quicksrnet/common.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/repaint/__init__.py
--rw-r--r--  2.0 unx     3366 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/repaint/app.py
--rw-r--r--  2.0 unx     2229 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/repaint/demo.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/sesr/__init__.py
--rw-r--r--  2.0 unx     1029 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/sesr/common.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/super_resolution/__init__.py
--rw-r--r--  2.0 unx     2143 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/super_resolution/app.py
--rw-r--r--  2.0 unx     2775 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/super_resolution/demo.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/swin/__init__.py
--rw-r--r--  2.0 unx     9175 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/swin/swin_transformer.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/video_classifier/__init__.py
--rw-r--r--  2.0 unx    11183 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/video_classifier/app.py
--rw-r--r--  2.0 unx     1581 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/video_classifier/demo.py
--rw-r--r--  2.0 unx     1969 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/video_classifier/model.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/whisper/__init__.py
--rw-r--r--  2.0 unx    10188 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/whisper/app.py
--rw-r--r--  2.0 unx     1302 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/whisper/demo.py
--rw-r--r--  2.0 unx    14119 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/whisper/model.py
--rw-r--r--  2.0 unx     2848 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/whisper/test_utils.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/yolo/__init__.py
--rw-r--r--  2.0 unx     7069 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/yolo/app.py
--rw-r--r--  2.0 unx     2475 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/yolo/demo.py
--rw-r--r--  2.0 unx     4190 b- defN 24-Apr-02 22:37 qai_hub_models/models/_shared/yolo/utils.py
--rw-r--r--  2.0 unx      450 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/__init__.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/conftest.py
--rw-r--r--  2.0 unx      597 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/demo.py
--rw-r--r--  2.0 unx     8156 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/export.py
--rw-r--r--  2.0 unx     1023 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/info.yaml
--rw-r--r--  2.0 unx     4838 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/model.py
--rw-r--r--  2.0 unx     2768 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/perf.yaml
--rw-r--r--  2.0 unx     2006 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/test.py
--rw-r--r--  2.0 unx      532 b- defN 24-Apr-02 22:37 qai_hub_models/models/aotgan/patches/layer_norm.diff
--rw-r--r--  2.0 unx     1983 b- defN 24-Apr-02 22:37 qai_hub_models/models/baichuan_7b_quantized/info.yaml
--rw-r--r--  2.0 unx     2036 b- defN 24-Apr-02 22:37 qai_hub_models/models/baichuan_7b_quantized/perf.yaml
--rw-r--r--  2.0 unx      559 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/__init__.py
--rw-r--r--  2.0 unx     9705 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/app.py
--rw-r--r--  2.0 unx     6397 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/demo.py
--rw-r--r--  2.0 unx     7622 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/export.py
--rw-r--r--  2.0 unx     1329 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/info.yaml
--rw-r--r--  2.0 unx     5426 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/model.py
--rw-r--r--  2.0 unx     8427 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/perf.yaml
--rw-r--r--  2.0 unx       46 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/requirements.txt
--rw-r--r--  2.0 unx     1556 b- defN 24-Apr-02 22:37 qai_hub_models/models/controlnet_quantized/test.py
--rw-r--r--  2.0 unx      475 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/__init__.py
--rw-r--r--  2.0 unx      798 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/conftest.py
--rw-r--r--  2.0 unx      543 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/demo.py
--rw-r--r--  2.0 unx     7915 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/export.py
--rw-r--r--  2.0 unx     1287 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/info.yaml
--rw-r--r--  2.0 unx      708 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/model.py
--rw-r--r--  2.0 unx     2707 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/perf.yaml
--rw-r--r--  2.0 unx      857 b- defN 24-Apr-02 22:37 qai_hub_models/models/convnext_tiny/test.py
--rw-r--r--  2.0 unx      398 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/__init__.py
--rw-r--r--  2.0 unx     3750 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/app.py
--rw-r--r--  2.0 unx      884 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/conftest.py
--rw-r--r--  2.0 unx     2128 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/demo.py
--rw-r--r--  2.0 unx     8193 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/export.py
--rw-r--r--  2.0 unx     1334 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/info.yaml
--rw-r--r--  2.0 unx     3831 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/model.py
--rw-r--r--  2.0 unx     2707 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/perf.yaml
--rw-r--r--  2.0 unx     1790 b- defN 24-Apr-02 22:37 qai_hub_models/models/ddrnet23_slim/test.py
--rw-r--r--  2.0 unx      451 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/__init__.py
--rw-r--r--  2.0 unx      894 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/conftest.py
--rw-r--r--  2.0 unx     1026 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/demo.py
--rw-r--r--  2.0 unx     8068 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/export.py
--rw-r--r--  2.0 unx     1278 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/info.yaml
--rw-r--r--  2.0 unx     2886 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/model.py
--rw-r--r--  2.0 unx     2761 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/perf.yaml
--rw-r--r--  2.0 unx     2086 b- defN 24-Apr-02 22:37 qai_hub_models/models/deeplabv3_resnet50/test.py
--rw-r--r--  2.0 unx      471 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/__init__.py
--rw-r--r--  2.0 unx      794 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/conftest.py
--rw-r--r--  2.0 unx      533 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/demo.py
--rw-r--r--  2.0 unx     7888 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/export.py
--rw-r--r--  2.0 unx     1310 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/info.yaml
--rw-r--r--  2.0 unx      698 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/model.py
--rw-r--r--  2.0 unx     2758 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/perf.yaml
--rw-r--r--  2.0 unx      841 b- defN 24-Apr-02 22:37 qai_hub_models/models/densenet121/test.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/__init__.py
--rw-r--r--  2.0 unx      800 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/conftest.py
--rw-r--r--  2.0 unx      896 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/demo.py
--rw-r--r--  2.0 unx     7905 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/export.py
--rw-r--r--  2.0 unx     1188 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/info.yaml
--rw-r--r--  2.0 unx      661 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/model.py
--rw-r--r--  2.0 unx     2711 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/perf.yaml
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/requirements.txt
--rw-r--r--  2.0 unx     1316 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101/test.py
--rw-r--r--  2.0 unx      490 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/__init__.py
--rw-r--r--  2.0 unx      808 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/conftest.py
--rw-r--r--  2.0 unx      906 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/demo.py
--rw-r--r--  2.0 unx     7921 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/export.py
--rw-r--r--  2.0 unx     1215 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/info.yaml
--rw-r--r--  2.0 unx      668 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/model.py
--rw-r--r--  2.0 unx     2719 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/perf.yaml
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/requirements.txt
--rw-r--r--  2.0 unx     1373 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet101_dc5/test.py
--rw-r--r--  2.0 unx      481 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/__init__.py
--rw-r--r--  2.0 unx      798 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/conftest.py
--rw-r--r--  2.0 unx      893 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/demo.py
--rw-r--r--  2.0 unx     7901 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/export.py
--rw-r--r--  2.0 unx     1185 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/info.yaml
--rw-r--r--  2.0 unx      659 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/model.py
--rw-r--r--  2.0 unx     2713 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/perf.yaml
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/requirements.txt
--rw-r--r--  2.0 unx     1636 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50/test.py
--rw-r--r--  2.0 unx      488 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/__init__.py
--rw-r--r--  2.0 unx      806 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/conftest.py
--rw-r--r--  2.0 unx      903 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/demo.py
--rw-r--r--  2.0 unx     7917 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/export.py
--rw-r--r--  2.0 unx     1212 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/info.yaml
--rw-r--r--  2.0 unx      666 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/model.py
--rw-r--r--  2.0 unx     2718 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/perf.yaml
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/requirements.txt
--rw-r--r--  2.0 unx     1344 b- defN 24-Apr-02 22:37 qai_hub_models/models/detr_resnet50_dc5/test.py
--rw-r--r--  2.0 unx      477 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/__init__.py
--rw-r--r--  2.0 unx      802 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/conftest.py
--rw-r--r--  2.0 unx      549 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/demo.py
--rw-r--r--  2.0 unx     7903 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/export.py
--rw-r--r--  2.0 unx     1361 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/info.yaml
--rw-r--r--  2.0 unx      714 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/model.py
--rw-r--r--  2.0 unx     2756 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/perf.yaml
--rw-r--r--  2.0 unx      867 b- defN 24-Apr-02 22:37 qai_hub_models/models/efficientnet_b0/test.py
--rw-r--r--  2.0 unx      463 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/__init__.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/conftest.py
--rw-r--r--  2.0 unx      939 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/demo.py
--rw-r--r--  2.0 unx     8002 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/export.py
--rw-r--r--  2.0 unx     1117 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/info.yaml
--rw-r--r--  2.0 unx     3473 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/model.py
--rw-r--r--  2.0 unx     2772 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/perf.yaml
--rw-r--r--  2.0 unx     1831 b- defN 24-Apr-02 22:37 qai_hub_models/models/esrgan/test.py
--rw-r--r--  2.0 unx      418 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/__init__.py
--rw-r--r--  2.0 unx     3207 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/app.py
--rw-r--r--  2.0 unx      892 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/conftest.py
--rw-r--r--  2.0 unx     3172 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/demo.py
--rw-r--r--  2.0 unx     7670 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/export.py
--rw-r--r--  2.0 unx     1070 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/info.yaml
--rw-r--r--  2.0 unx     2414 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/model.py
--rw-r--r--  2.0 unx     2724 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/perf.yaml
--rw-r--r--  2.0 unx       74 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/requirements.txt
--rw-r--r--  2.0 unx     2492 b- defN 24-Apr-02 22:37 qai_hub_models/models/facebook_denoiser/test.py
--rw-r--r--  2.0 unx      440 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/conftest.py
--rw-r--r--  2.0 unx      762 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/demo.py
--rw-r--r--  2.0 unx     8264 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/export.py
--rw-r--r--  2.0 unx     1301 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/info.yaml
--rw-r--r--  2.0 unx      683 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/model.py
--rw-r--r--  2.0 unx     2706 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/perf.yaml
--rw-r--r--  2.0 unx       64 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/requirements.txt
--rw-r--r--  2.0 unx     1332 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_s/test.py
--rw-r--r--  2.0 unx      440 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/conftest.py
--rw-r--r--  2.0 unx      762 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/demo.py
--rw-r--r--  2.0 unx     8264 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/export.py
--rw-r--r--  2.0 unx     1300 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/info.yaml
--rw-r--r--  2.0 unx      683 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/model.py
--rw-r--r--  2.0 unx     2707 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/perf.yaml
--rw-r--r--  2.0 unx       64 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/requirements.txt
--rw-r--r--  2.0 unx     1332 b- defN 24-Apr-02 22:37 qai_hub_models/models/fastsam_x/test.py
--rw-r--r--  2.0 unx      410 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/__init__.py
--rw-r--r--  2.0 unx     2683 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/app.py
--rw-r--r--  2.0 unx      882 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/conftest.py
--rw-r--r--  2.0 unx     2315 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/demo.py
--rw-r--r--  2.0 unx     8169 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/export.py
--rw-r--r--  2.0 unx     1241 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/info.yaml
--rw-r--r--  2.0 unx     1989 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/model.py
--rw-r--r--  2.0 unx     2761 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/perf.yaml
--rw-r--r--  2.0 unx     1637 b- defN 24-Apr-02 22:37 qai_hub_models/models/fcn_resnet50/test.py
--rw-r--r--  2.0 unx      487 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/__init__.py
--rw-r--r--  2.0 unx      894 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/conftest.py
--rw-r--r--  2.0 unx      607 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/demo.py
--rw-r--r--  2.0 unx     8050 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/export.py
--rw-r--r--  2.0 unx     1322 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/info.yaml
--rw-r--r--  2.0 unx      648 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/model.py
--rw-r--r--  2.0 unx     2771 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/requirements.txt
--rw-r--r--  2.0 unx      804 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_122ns_lowres/test.py
--rw-r--r--  2.0 unx      479 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/__init__.py
--rw-r--r--  2.0 unx      876 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/conftest.py
--rw-r--r--  2.0 unx      582 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/demo.py
--rw-r--r--  2.0 unx     8014 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/export.py
--rw-r--r--  2.0 unx     1298 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/info.yaml
--rw-r--r--  2.0 unx      580 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/model.py
--rw-r--r--  2.0 unx     2764 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/requirements.txt
--rw-r--r--  2.0 unx      746 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s/test.py
--rw-r--r--  2.0 unx      490 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/__init__.py
--rw-r--r--  2.0 unx      896 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/conftest.py
--rw-r--r--  2.0 unx      627 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/demo.py
--rw-r--r--  2.0 unx     8467 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/export.py
--rw-r--r--  2.0 unx     1347 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/info.yaml
--rw-r--r--  2.0 unx     1169 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/model.py
--rw-r--r--  2.0 unx     2710 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/requirements.txt
--rw-r--r--  2.0 unx      840 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_40s_quantized/test.py
--rw-r--r--  2.0 unx      479 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/__init__.py
--rw-r--r--  2.0 unx      876 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/conftest.py
--rw-r--r--  2.0 unx      582 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/demo.py
--rw-r--r--  2.0 unx     8014 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/export.py
--rw-r--r--  2.0 unx     1275 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/info.yaml
--rw-r--r--  2.0 unx      580 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/model.py
--rw-r--r--  2.0 unx     2772 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/requirements.txt
--rw-r--r--  2.0 unx      746 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s/test.py
--rw-r--r--  2.0 unx      490 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/__init__.py
--rw-r--r--  2.0 unx      896 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/conftest.py
--rw-r--r--  2.0 unx      627 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/demo.py
--rw-r--r--  2.0 unx     8467 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/export.py
--rw-r--r--  2.0 unx     1347 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/info.yaml
--rw-r--r--  2.0 unx     1156 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/model.py
--rw-r--r--  2.0 unx     2714 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/requirements.txt
--rw-r--r--  2.0 unx      840 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_54s_quantized/test.py
--rw-r--r--  2.0 unx      479 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/__init__.py
--rw-r--r--  2.0 unx      876 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/conftest.py
--rw-r--r--  2.0 unx      582 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/demo.py
--rw-r--r--  2.0 unx     8014 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/export.py
--rw-r--r--  2.0 unx     1279 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/info.yaml
--rw-r--r--  2.0 unx      580 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/model.py
--rw-r--r--  2.0 unx     2772 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/requirements.txt
--rw-r--r--  2.0 unx      746 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s/test.py
--rw-r--r--  2.0 unx      485 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/__init__.py
--rw-r--r--  2.0 unx      890 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/conftest.py
--rw-r--r--  2.0 unx      601 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/demo.py
--rw-r--r--  2.0 unx     8042 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/export.py
--rw-r--r--  2.0 unx     1327 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/info.yaml
--rw-r--r--  2.0 unx      640 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/model.py
--rw-r--r--  2.0 unx     2767 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/requirements.txt
--rw-r--r--  2.0 unx      794 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_lowres/test.py
--rw-r--r--  2.0 unx      490 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/__init__.py
--rw-r--r--  2.0 unx      896 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/conftest.py
--rw-r--r--  2.0 unx      627 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/demo.py
--rw-r--r--  2.0 unx     8467 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/export.py
--rw-r--r--  2.0 unx     1347 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/info.yaml
--rw-r--r--  2.0 unx     1156 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/model.py
--rw-r--r--  2.0 unx     2713 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/perf.yaml
--rw-r--r--  2.0 unx       21 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/requirements.txt
--rw-r--r--  2.0 unx      840 b- defN 24-Apr-02 22:37 qai_hub_models/models/ffnet_78s_quantized/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/conftest.py
--rw-r--r--  2.0 unx      533 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/demo.py
--rw-r--r--  2.0 unx     7879 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/export.py
--rw-r--r--  2.0 unx     1295 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/info.yaml
--rw-r--r--  2.0 unx      743 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/model.py
--rw-r--r--  2.0 unx     2748 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/perf.yaml
--rw-r--r--  2.0 unx      840 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet/test.py
--rw-r--r--  2.0 unx      573 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/__init__.py
--rw-r--r--  2.0 unx      810 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/conftest.py
--rw-r--r--  2.0 unx      578 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/demo.py
--rw-r--r--  2.0 unx     8359 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/export.py
--rw-r--r--  2.0 unx     1325 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/info.yaml
--rw-r--r--  2.0 unx     4079 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/model.py
--rw-r--r--  2.0 unx     2753 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/perf.yaml
--rw-r--r--  2.0 unx      885 b- defN 24-Apr-02 22:37 qai_hub_models/models/googlenet_quantized/test.py
--rw-r--r--  2.0 unx      430 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/__init__.py
--rw-r--r--  2.0 unx     5644 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/app.py
--rw-r--r--  2.0 unx      878 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/conftest.py
--rw-r--r--  2.0 unx     1739 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/demo.py
--rw-r--r--  2.0 unx     8160 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/export.py
--rw-r--r--  2.0 unx     1195 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/info.yaml
--rw-r--r--  2.0 unx     2801 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/model.py
--rw-r--r--  2.0 unx     2755 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/perf.yaml
--rw-r--r--  2.0 unx       51 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/requirements.txt
--rw-r--r--  2.0 unx     1420 b- defN 24-Apr-02 22:37 qai_hub_models/models/hrnet_pose/test.py
--rw-r--r--  2.0 unx      434 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/__init__.py
--rw-r--r--  2.0 unx     2133 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/app.py
--rw-r--r--  2.0 unx      912 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/conftest.py
--rw-r--r--  2.0 unx     1517 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/demo.py
--rw-r--r--  2.0 unx     7567 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/export.py
--rw-r--r--  2.0 unx     1248 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/info.yaml
--rw-r--r--  2.0 unx     7587 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/model.py
--rw-r--r--  2.0 unx     2735 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/perf.yaml
--rw-r--r--  2.0 unx       72 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/requirements.txt
--rw-r--r--  2.0 unx     2560 b- defN 24-Apr-02 22:37 qai_hub_models/models/huggingface_wavlm_base_plus/test.py
--rw-r--r--  2.0 unx      477 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/__init__.py
--rw-r--r--  2.0 unx      796 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/conftest.py
--rw-r--r--  2.0 unx      546 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/demo.py
--rw-r--r--  2.0 unx     7891 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/export.py
--rw-r--r--  2.0 unx     1359 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/info.yaml
--rw-r--r--  2.0 unx      756 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/model.py
--rw-r--r--  2.0 unx     2760 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/perf.yaml
--rw-r--r--  2.0 unx      861 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3/test.py
--rw-r--r--  2.0 unx      584 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/__init__.py
--rw-r--r--  2.0 unx      816 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/conftest.py
--rw-r--r--  2.0 unx      591 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/demo.py
--rw-r--r--  2.0 unx     8392 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/export.py
--rw-r--r--  2.0 unx     1556 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/info.yaml
--rw-r--r--  2.0 unx     7543 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/model.py
--rw-r--r--  2.0 unx     2712 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/perf.yaml
--rw-r--r--  2.0 unx      901 b- defN 24-Apr-02 22:37 qai_hub_models/models/inception_v3_quantized/test.py
--rw-r--r--  2.0 unx      455 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/__init__.py
--rw-r--r--  2.0 unx      882 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/conftest.py
--rw-r--r--  2.0 unx      911 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/demo.py
--rw-r--r--  2.0 unx     8179 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/export.py
--rw-r--r--  2.0 unx     1082 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/info.yaml
--rw-r--r--  2.0 unx     4977 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/model.py
--rw-r--r--  2.0 unx     2776 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/perf.yaml
--rw-r--r--  2.0 unx      171 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/requirements.txt
--rw-r--r--  2.0 unx     2074 b- defN 24-Apr-02 22:37 qai_hub_models/models/lama_dilated/test.py
--rw-r--r--  2.0 unx      404 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/__init__.py
--rw-r--r--  2.0 unx     3986 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/app.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/conftest.py
--rw-r--r--  2.0 unx     2072 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/demo.py
--rw-r--r--  2.0 unx     7638 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/export.py
--rw-r--r--  2.0 unx     1112 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/info.yaml
--rw-r--r--  2.0 unx     3788 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/model.py
--rw-r--r--  2.0 unx     2711 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/perf.yaml
--rw-r--r--  2.0 unx       39 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/requirements.txt
--rw-r--r--  2.0 unx     1714 b- defN 24-Apr-02 22:37 qai_hub_models/models/litehrnet/test.py
--rw-r--r--  2.0 unx     1993 b- defN 24-Apr-02 22:37 qai_hub_models/models/llama_v2_7b_chat_quantized/info.yaml
--rw-r--r--  2.0 unx     2037 b- defN 24-Apr-02 22:37 qai_hub_models/models/llama_v2_7b_chat_quantized/perf.yaml
--rw-r--r--  2.0 unx      412 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/__init__.py
--rw-r--r--  2.0 unx     2099 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/app.py
--rw-r--r--  2.0 unx      886 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/conftest.py
--rw-r--r--  2.0 unx     2862 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/demo.py
--rw-r--r--  2.0 unx     9755 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/export.py
--rw-r--r--  2.0 unx     1469 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/info.yaml
--rw-r--r--  2.0 unx     7669 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/model.py
--rw-r--r--  2.0 unx     4857 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/perf.yaml
--rw-r--r--  2.0 unx     1441 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_face/test.py
--rw-r--r--  2.0 unx      412 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/__init__.py
--rw-r--r--  2.0 unx     9819 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/app.py
--rw-r--r--  2.0 unx      886 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/conftest.py
--rw-r--r--  2.0 unx     2832 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/demo.py
--rw-r--r--  2.0 unx     9755 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/export.py
--rw-r--r--  2.0 unx     1374 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/info.yaml
--rw-r--r--  2.0 unx     6017 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/model.py
--rw-r--r--  2.0 unx     4858 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/perf.yaml
--rw-r--r--  2.0 unx     1442 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_hand/test.py
--rw-r--r--  2.0 unx      412 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/__init__.py
--rw-r--r--  2.0 unx     4430 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/app.py
--rw-r--r--  2.0 unx      886 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/conftest.py
--rw-r--r--  2.0 unx     2889 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/demo.py
--rw-r--r--  2.0 unx     9756 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/export.py
--rw-r--r--  2.0 unx     1387 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/info.yaml
--rw-r--r--  2.0 unx     5801 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/model.py
--rw-r--r--  2.0 unx     4849 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/perf.yaml
--rw-r--r--  2.0 unx     1443 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_pose/test.py
--rw-r--r--  2.0 unx      362 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/__init__.py
--rw-r--r--  2.0 unx     1411 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/app.py
--rw-r--r--  2.0 unx      804 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/conftest.py
--rw-r--r--  2.0 unx     2674 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/demo.py
--rw-r--r--  2.0 unx     8198 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/export.py
--rw-r--r--  2.0 unx     1455 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/info.yaml
--rw-r--r--  2.0 unx    12352 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/model.py
--rw-r--r--  2.0 unx     2775 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/perf.yaml
--rw-r--r--  2.0 unx       15 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/requirements.txt
--rw-r--r--  2.0 unx     1396 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/test.py
--rw-r--r--  2.0 unx     2492 b- defN 24-Apr-02 22:37 qai_hub_models/models/mediapipe_selfie/utils.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/conftest.py
--rw-r--r--  2.0 unx      533 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/demo.py
--rw-r--r--  2.0 unx     7879 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/export.py
--rw-r--r--  2.0 unx     1333 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/info.yaml
--rw-r--r--  2.0 unx      699 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/model.py
--rw-r--r--  2.0 unx     2751 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/perf.yaml
--rw-r--r--  2.0 unx      882 b- defN 24-Apr-02 22:37 qai_hub_models/models/mnasnet05/test.py
--rw-r--r--  2.0 unx      474 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/__init__.py
--rw-r--r--  2.0 unx      882 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/conftest.py
--rw-r--r--  2.0 unx      540 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/demo.py
--rw-r--r--  2.0 unx     7891 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/export.py
--rw-r--r--  2.0 unx     1380 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/info.yaml
--rw-r--r--  2.0 unx     2595 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/model.py
--rw-r--r--  2.0 unx     2755 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/perf.yaml
--rw-r--r--  2.0 unx     1091 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2/test.py
--rw-r--r--  2.0 unx      485 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/__init__.py
--rw-r--r--  2.0 unx      902 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/conftest.py
--rw-r--r--  2.0 unx      585 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/demo.py
--rw-r--r--  2.0 unx     8372 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/export.py
--rw-r--r--  2.0 unx     1362 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/info.yaml
--rw-r--r--  2.0 unx     3760 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/model.py
--rw-r--r--  2.0 unx     2759 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/perf.yaml
--rw-r--r--  2.0 unx     1002 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v2_quantized/test.py
--rw-r--r--  2.0 unx      479 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/__init__.py
--rw-r--r--  2.0 unx      808 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/conftest.py
--rw-r--r--  2.0 unx      556 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/demo.py
--rw-r--r--  2.0 unx     7935 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/export.py
--rw-r--r--  2.0 unx     1340 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/info.yaml
--rw-r--r--  2.0 unx      721 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/model.py
--rw-r--r--  2.0 unx     2708 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/perf.yaml
--rw-r--r--  2.0 unx      879 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large/test.py
--rw-r--r--  2.0 unx      607 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/__init__.py
--rw-r--r--  2.0 unx      828 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/conftest.py
--rw-r--r--  2.0 unx      748 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/demo.py
--rw-r--r--  2.0 unx     8104 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/export.py
--rw-r--r--  2.0 unx     1374 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/info.yaml
--rw-r--r--  2.0 unx     2865 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/model.py
--rw-r--r--  2.0 unx     2723 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/perf.yaml
--rw-r--r--  2.0 unx      917 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_large_quantized/test.py
--rw-r--r--  2.0 unx      479 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/__init__.py
--rw-r--r--  2.0 unx      808 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/conftest.py
--rw-r--r--  2.0 unx      556 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/demo.py
--rw-r--r--  2.0 unx     7935 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/export.py
--rw-r--r--  2.0 unx     1338 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/info.yaml
--rw-r--r--  2.0 unx      721 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/model.py
--rw-r--r--  2.0 unx     2707 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/perf.yaml
--rw-r--r--  2.0 unx      879 b- defN 24-Apr-02 22:37 qai_hub_models/models/mobilenet_v3_small/test.py
--rw-r--r--  2.0 unx      394 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/__init__.py
--rw-r--r--  2.0 unx     3958 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/app.py
--rw-r--r--  2.0 unx      880 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/conftest.py
--rw-r--r--  2.0 unx     3262 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/demo.py
--rw-r--r--  2.0 unx     9666 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/export.py
--rw-r--r--  2.0 unx     1494 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/info.yaml
--rw-r--r--  2.0 unx     5295 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/model.py
--rw-r--r--  2.0 unx     4855 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/perf.yaml
--rw-r--r--  2.0 unx       29 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/requirements.txt
--rw-r--r--  2.0 unx     2118 b- defN 24-Apr-02 22:37 qai_hub_models/models/openai_clip/test.py
--rw-r--r--  2.0 unx      402 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/__init__.py
--rw-r--r--  2.0 unx    12008 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/app.py
--rw-r--r--  2.0 unx      874 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/conftest.py
--rw-r--r--  2.0 unx     2053 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/demo.py
--rw-r--r--  2.0 unx     8171 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/export.py
--rw-r--r--  2.0 unx     1246 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/info.yaml
--rw-r--r--  2.0 unx     5084 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/model.py
--rw-r--r--  2.0 unx     2762 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/perf.yaml
--rw-r--r--  2.0 unx       31 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/requirements.txt
--rw-r--r--  2.0 unx     1321 b- defN 24-Apr-02 22:37 qai_hub_models/models/openpose/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/__init__.py
--rw-r--r--  2.0 unx      888 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/conftest.py
--rw-r--r--  2.0 unx      972 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/demo.py
--rw-r--r--  2.0 unx     8181 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/export.py
--rw-r--r--  2.0 unx     1248 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/info.yaml
--rw-r--r--  2.0 unx     3170 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/model.py
--rw-r--r--  2.0 unx     2753 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/perf.yaml
--rw-r--r--  2.0 unx     1422 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge/test.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/__init__.py
--rw-r--r--  2.0 unx      908 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/conftest.py
--rw-r--r--  2.0 unx      891 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/demo.py
--rw-r--r--  2.0 unx     8634 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/export.py
--rw-r--r--  2.0 unx     1274 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/info.yaml
--rw-r--r--  2.0 unx     4587 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/model.py
--rw-r--r--  2.0 unx     2712 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/perf.yaml
--rw-r--r--  2.0 unx     2921 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetlarge_quantized/test.py
--rw-r--r--  2.0 unx      473 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/__init__.py
--rw-r--r--  2.0 unx      890 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/conftest.py
--rw-r--r--  2.0 unx      976 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/demo.py
--rw-r--r--  2.0 unx     8185 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/export.py
--rw-r--r--  2.0 unx     1242 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/info.yaml
--rw-r--r--  2.0 unx     3177 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/model.py
--rw-r--r--  2.0 unx     2754 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/perf.yaml
--rw-r--r--  2.0 unx     1428 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium/test.py
--rw-r--r--  2.0 unx      484 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/__init__.py
--rw-r--r--  2.0 unx      910 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/conftest.py
--rw-r--r--  2.0 unx      900 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/demo.py
--rw-r--r--  2.0 unx     8638 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/export.py
--rw-r--r--  2.0 unx     1282 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/info.yaml
--rw-r--r--  2.0 unx     4597 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/model.py
--rw-r--r--  2.0 unx     2711 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/perf.yaml
--rw-r--r--  2.0 unx     2912 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetmedium_quantized/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/__init__.py
--rw-r--r--  2.0 unx      888 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/conftest.py
--rw-r--r--  2.0 unx      972 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/demo.py
--rw-r--r--  2.0 unx     8181 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/export.py
--rw-r--r--  2.0 unx     1238 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/info.yaml
--rw-r--r--  2.0 unx     3170 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/model.py
--rw-r--r--  2.0 unx     2752 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/perf.yaml
--rw-r--r--  2.0 unx     1422 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall/test.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/__init__.py
--rw-r--r--  2.0 unx      908 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/conftest.py
--rw-r--r--  2.0 unx      891 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/demo.py
--rw-r--r--  2.0 unx     8634 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/export.py
--rw-r--r--  2.0 unx     1278 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/info.yaml
--rw-r--r--  2.0 unx     4577 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/model.py
--rw-r--r--  2.0 unx     2710 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/perf.yaml
--rw-r--r--  2.0 unx     2859 b- defN 24-Apr-02 22:37 qai_hub_models/models/quicksrnetsmall_quantized/test.py
--rw-r--r--  2.0 unx      481 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/__init__.py
--rw-r--r--  2.0 unx      906 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/conftest.py
--rw-r--r--  2.0 unx     1280 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/demo.py
--rw-r--r--  2.0 unx     8217 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/export.py
--rw-r--r--  2.0 unx     1206 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/info.yaml
--rw-r--r--  2.0 unx     5226 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/model.py
--rw-r--r--  2.0 unx     2765 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/perf.yaml
--rw-r--r--  2.0 unx       44 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/requirements.txt
--rw-r--r--  2.0 unx     1480 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_general_x4v3/test.py
--rw-r--r--  2.0 unx      475 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/__init__.py
--rw-r--r--  2.0 unx      894 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/conftest.py
--rw-r--r--  2.0 unx     1256 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/demo.py
--rw-r--r--  2.0 unx     7654 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/export.py
--rw-r--r--  2.0 unx     1330 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/info.yaml
--rw-r--r--  2.0 unx     4443 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/model.py
--rw-r--r--  2.0 unx     2720 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/perf.yaml
--rw-r--r--  2.0 unx       44 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/requirements.txt
--rw-r--r--  2.0 unx     1440 b- defN 24-Apr-02 22:37 qai_hub_models/models/real_esrgan_x4plus/test.py
--rw-r--r--  2.0 unx      469 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/__init__.py
--rw-r--r--  2.0 unx      784 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/conftest.py
--rw-r--r--  2.0 unx      524 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/demo.py
--rw-r--r--  2.0 unx     7867 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/export.py
--rw-r--r--  2.0 unx     1291 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/info.yaml
--rw-r--r--  2.0 unx      635 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/model.py
--rw-r--r--  2.0 unx     2755 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/perf.yaml
--rw-r--r--  2.0 unx      984 b- defN 24-Apr-02 22:37 qai_hub_models/models/regnet/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/conftest.py
--rw-r--r--  2.0 unx      533 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/demo.py
--rw-r--r--  2.0 unx     7879 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/export.py
--rw-r--r--  2.0 unx     1312 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/info.yaml
--rw-r--r--  2.0 unx      609 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/model.py
--rw-r--r--  2.0 unx     2759 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/perf.yaml
--rw-r--r--  2.0 unx      961 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101/test.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/__init__.py
--rw-r--r--  2.0 unx      810 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/conftest.py
--rw-r--r--  2.0 unx      578 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/demo.py
--rw-r--r--  2.0 unx     8359 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/export.py
--rw-r--r--  2.0 unx     1346 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/info.yaml
--rw-r--r--  2.0 unx     3000 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/model.py
--rw-r--r--  2.0 unx     2765 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/perf.yaml
--rw-r--r--  2.0 unx      921 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet101_quantized/test.py
--rw-r--r--  2.0 unx      471 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/__init__.py
--rw-r--r--  2.0 unx      788 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/conftest.py
--rw-r--r--  2.0 unx      530 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/demo.py
--rw-r--r--  2.0 unx     7875 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/export.py
--rw-r--r--  2.0 unx     1310 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/info.yaml
--rw-r--r--  2.0 unx      607 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/model.py
--rw-r--r--  2.0 unx     2746 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/perf.yaml
--rw-r--r--  2.0 unx      955 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18/test.py
--rw-r--r--  2.0 unx      482 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/__init__.py
--rw-r--r--  2.0 unx      808 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/conftest.py
--rw-r--r--  2.0 unx      562 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/demo.py
--rw-r--r--  2.0 unx     8355 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/export.py
--rw-r--r--  2.0 unx     1343 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/info.yaml
--rw-r--r--  2.0 unx     2802 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/model.py
--rw-r--r--  2.0 unx     2748 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/perf.yaml
--rw-r--r--  2.0 unx      917 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet18_quantized/test.py
--rw-r--r--  2.0 unx      471 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/__init__.py
--rw-r--r--  2.0 unx      788 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/conftest.py
--rw-r--r--  2.0 unx      530 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/demo.py
--rw-r--r--  2.0 unx     7875 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/export.py
--rw-r--r--  2.0 unx     1303 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/info.yaml
--rw-r--r--  2.0 unx      607 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/model.py
--rw-r--r--  2.0 unx     2748 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/perf.yaml
--rw-r--r--  2.0 unx      955 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnet50/test.py
--rw-r--r--  2.0 unx      473 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/__init__.py
--rw-r--r--  2.0 unx      792 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/conftest.py
--rw-r--r--  2.0 unx      536 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/demo.py
--rw-r--r--  2.0 unx     7883 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/export.py
--rw-r--r--  2.0 unx     1324 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/info.yaml
--rw-r--r--  2.0 unx      617 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/model.py
--rw-r--r--  2.0 unx     2761 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/perf.yaml
--rw-r--r--  2.0 unx      897 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101/test.py
--rw-r--r--  2.0 unx      484 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/__init__.py
--rw-r--r--  2.0 unx      812 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/conftest.py
--rw-r--r--  2.0 unx      581 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/demo.py
--rw-r--r--  2.0 unx     8383 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/export.py
--rw-r--r--  2.0 unx     1365 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/info.yaml
--rw-r--r--  2.0 unx     2807 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/model.py
--rw-r--r--  2.0 unx     2708 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/perf.yaml
--rw-r--r--  2.0 unx      925 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext101_quantized/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/conftest.py
--rw-r--r--  2.0 unx      533 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/demo.py
--rw-r--r--  2.0 unx     7879 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/export.py
--rw-r--r--  2.0 unx     1322 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/info.yaml
--rw-r--r--  2.0 unx      704 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/model.py
--rw-r--r--  2.0 unx     2754 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/perf.yaml
--rw-r--r--  2.0 unx      840 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50/test.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/__init__.py
--rw-r--r--  2.0 unx      810 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/conftest.py
--rw-r--r--  2.0 unx      578 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/demo.py
--rw-r--r--  2.0 unx     8379 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/export.py
--rw-r--r--  2.0 unx     1362 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/info.yaml
--rw-r--r--  2.0 unx     2798 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/model.py
--rw-r--r--  2.0 unx     2705 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/perf.yaml
--rw-r--r--  2.0 unx      921 b- defN 24-Apr-02 22:37 qai_hub_models/models/resnext50_quantized/test.py
--rw-r--r--  2.0 unx      404 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/__init__.py
--rw-r--r--  2.0 unx     5101 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/app.py
--rw-r--r--  2.0 unx      905 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/conftest.py
--rw-r--r--  2.0 unx     3088 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/demo.py
--rw-r--r--  2.0 unx    10152 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/export.py
--rw-r--r--  2.0 unx     1391 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/info.yaml
--rw-r--r--  2.0 unx    12000 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/model.py
--rw-r--r--  2.0 unx     2708 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/perf.yaml
--rw-r--r--  2.0 unx       37 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/requirements.txt
--rw-r--r--  2.0 unx     3062 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/test.py
--rw-r--r--  2.0 unx      826 b- defN 24-Apr-02 22:37 qai_hub_models/models/sam/utils.py
--rw-r--r--  2.0 unx      464 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/__init__.py
--rw-r--r--  2.0 unx      872 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/conftest.py
--rw-r--r--  2.0 unx      923 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/demo.py
--rw-r--r--  2.0 unx     8006 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/export.py
--rw-r--r--  2.0 unx     1104 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/info.yaml
--rw-r--r--  2.0 unx     2984 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/model.py
--rw-r--r--  2.0 unx     2745 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/perf.yaml
--rw-r--r--  2.0 unx     1471 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5/test.py
--rw-r--r--  2.0 unx      475 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/__init__.py
--rw-r--r--  2.0 unx      892 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/conftest.py
--rw-r--r--  2.0 unx      990 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/demo.py
--rw-r--r--  2.0 unx     8167 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/export.py
--rw-r--r--  2.0 unx     1151 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/info.yaml
--rw-r--r--  2.0 unx     4269 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/model.py
--rw-r--r--  2.0 unx     2704 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/perf.yaml
--rw-r--r--  2.0 unx     2927 b- defN 24-Apr-02 22:37 qai_hub_models/models/sesr_m5_quantized/test.py
--rw-r--r--  2.0 unx      475 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/__init__.py
--rw-r--r--  2.0 unx      798 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/conftest.py
--rw-r--r--  2.0 unx      543 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/demo.py
--rw-r--r--  2.0 unx     7895 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/export.py
--rw-r--r--  2.0 unx     1353 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/info.yaml
--rw-r--r--  2.0 unx      713 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/model.py
--rw-r--r--  2.0 unx     2757 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/perf.yaml
--rw-r--r--  2.0 unx      857 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2/test.py
--rw-r--r--  2.0 unx      584 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/__init__.py
--rw-r--r--  2.0 unx      818 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/conftest.py
--rw-r--r--  2.0 unx      588 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/demo.py
--rw-r--r--  2.0 unx     8375 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/export.py
--rw-r--r--  2.0 unx     1383 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/info.yaml
--rw-r--r--  2.0 unx     5779 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/model.py
--rw-r--r--  2.0 unx     2767 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/perf.yaml
--rw-r--r--  2.0 unx      899 b- defN 24-Apr-02 22:37 qai_hub_models/models/shufflenet_v2_quantized/test.py
--rw-r--r--  2.0 unx      396 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/__init__.py
--rw-r--r--  2.0 unx     3793 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/app.py
--rw-r--r--  2.0 unx      868 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/conftest.py
--rw-r--r--  2.0 unx     1657 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/demo.py
--rw-r--r--  2.0 unx     8141 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/export.py
--rw-r--r--  2.0 unx     1260 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/info.yaml
--rw-r--r--  2.0 unx     4770 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/model.py
--rw-r--r--  2.0 unx     2746 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/perf.yaml
--rw-r--r--  2.0 unx     1355 b- defN 24-Apr-02 22:37 qai_hub_models/models/sinet/test.py
--rw-r--r--  2.0 unx      473 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/__init__.py
--rw-r--r--  2.0 unx      798 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/conftest.py
--rw-r--r--  2.0 unx      539 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/demo.py
--rw-r--r--  2.0 unx     7896 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/export.py
--rw-r--r--  2.0 unx     1325 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/info.yaml
--rw-r--r--  2.0 unx      696 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/model.py
--rw-r--r--  2.0 unx     2748 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/perf.yaml
--rw-r--r--  2.0 unx      851 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1/test.py
--rw-r--r--  2.0 unx      582 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/__init__.py
--rw-r--r--  2.0 unx      818 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/conftest.py
--rw-r--r--  2.0 unx      584 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/demo.py
--rw-r--r--  2.0 unx     8328 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/export.py
--rw-r--r--  2.0 unx     1358 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/info.yaml
--rw-r--r--  2.0 unx     2813 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/model.py
--rw-r--r--  2.0 unx     2757 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/perf.yaml
--rw-r--r--  2.0 unx      895 b- defN 24-Apr-02 22:37 qai_hub_models/models/squeezenet1_1_quantized/test.py
--rw-r--r--  2.0 unx      540 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/__init__.py
--rw-r--r--  2.0 unx     7966 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/app.py
--rw-r--r--  2.0 unx     5765 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/demo.py
--rw-r--r--  2.0 unx     7432 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/export.py
--rw-r--r--  2.0 unx     1355 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/info.yaml
--rw-r--r--  2.0 unx     3604 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/model.py
--rw-r--r--  2.0 unx     6384 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/perf.yaml
--rw-r--r--  2.0 unx       46 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/requirements.txt
--rw-r--r--  2.0 unx     1599 b- defN 24-Apr-02 22:37 qai_hub_models/models/stable_diffusion_quantized/test.py
--rw-r--r--  2.0 unx      404 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/__init__.py
--rw-r--r--  2.0 unx     4155 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/app.py
--rw-r--r--  2.0 unx      876 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/conftest.py
--rw-r--r--  2.0 unx     2847 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/demo.py
--rw-r--r--  2.0 unx     7762 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/export.py
--rw-r--r--  2.0 unx     1102 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/info.yaml
--rw-r--r--  2.0 unx     8406 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/model.py
--rw-r--r--  2.0 unx     2722 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/perf.yaml
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/requirements.txt
--rw-r--r--  2.0 unx     2497 b- defN 24-Apr-02 22:37 qai_hub_models/models/stylegan2/test.py
--rw-r--r--  2.0 unx      471 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/conftest.py
--rw-r--r--  2.0 unx      531 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/demo.py
--rw-r--r--  2.0 unx     7899 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/export.py
--rw-r--r--  2.0 unx     1383 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/info.yaml
--rw-r--r--  2.0 unx     1241 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/model.py
--rw-r--r--  2.0 unx     2709 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/perf.yaml
--rw-r--r--  2.0 unx     1251 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_base/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/__init__.py
--rw-r--r--  2.0 unx      792 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/conftest.py
--rw-r--r--  2.0 unx      534 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/demo.py
--rw-r--r--  2.0 unx     7903 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/export.py
--rw-r--r--  2.0 unx     1378 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/info.yaml
--rw-r--r--  2.0 unx     1242 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/model.py
--rw-r--r--  2.0 unx     2709 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/perf.yaml
--rw-r--r--  2.0 unx     1257 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_small/test.py
--rw-r--r--  2.0 unx      471 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/__init__.py
--rw-r--r--  2.0 unx      790 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/conftest.py
--rw-r--r--  2.0 unx      531 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/demo.py
--rw-r--r--  2.0 unx     7899 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/export.py
--rw-r--r--  2.0 unx     1376 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/info.yaml
--rw-r--r--  2.0 unx     1241 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/model.py
--rw-r--r--  2.0 unx     2703 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/perf.yaml
--rw-r--r--  2.0 unx     1369 b- defN 24-Apr-02 22:37 qai_hub_models/models/swin_tiny/test.py
--rw-r--r--  2.0 unx      396 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/__init__.py
--rw-r--r--  2.0 unx    10207 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/app.py
--rw-r--r--  2.0 unx      782 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/conftest.py
--rw-r--r--  2.0 unx     1779 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/demo.py
--rw-r--r--  2.0 unx     9655 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/export.py
--rw-r--r--  2.0 unx     1370 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/info.yaml
--rw-r--r--  2.0 unx    10482 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/model.py
--rw-r--r--  2.0 unx     4735 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/perf.yaml
--rw-r--r--  2.0 unx       42 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/requirements.txt
--rw-r--r--  2.0 unx     2357 b- defN 24-Apr-02 22:37 qai_hub_models/models/trocr/test.py
--rw-r--r--  2.0 unx      348 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/__init__.py
--rw-r--r--  2.0 unx     1305 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/app.py
--rw-r--r--  2.0 unx      806 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/conftest.py
--rw-r--r--  2.0 unx     2509 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/demo.py
--rw-r--r--  2.0 unx     8189 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/export.py
--rw-r--r--  2.0 unx     1310 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/info.yaml
--rw-r--r--  2.0 unx     2666 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/model.py
--rw-r--r--  2.0 unx     2774 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/perf.yaml
--rw-r--r--  2.0 unx     1215 b- defN 24-Apr-02 22:37 qai_hub_models/models/unet_segmentation/test.py
--rw-r--r--  2.0 unx      466 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/__init__.py
--rw-r--r--  2.0 unx      778 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/conftest.py
--rw-r--r--  2.0 unx      515 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/demo.py
--rw-r--r--  2.0 unx     7908 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/export.py
--rw-r--r--  2.0 unx     1342 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/info.yaml
--rw-r--r--  2.0 unx      685 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/model.py
--rw-r--r--  2.0 unx     2701 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/perf.yaml
--rw-r--r--  2.0 unx      807 b- defN 24-Apr-02 22:37 qai_hub_models/models/vit/test.py
--rw-r--r--  2.0 unx      444 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/__init__.py
--rw-r--r--  2.0 unx      802 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/conftest.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/demo.py
--rw-r--r--  2.0 unx     9707 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/export.py
--rw-r--r--  2.0 unx     1849 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/info.yaml
--rw-r--r--  2.0 unx      558 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/model.py
--rw-r--r--  2.0 unx     4743 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/perf.yaml
--rw-r--r--  2.0 unx       31 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/requirements.txt
--rw-r--r--  2.0 unx      696 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_base_en/test.py
--rw-r--r--  2.0 unx      445 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/__init__.py
--rw-r--r--  2.0 unx      804 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/conftest.py
--rw-r--r--  2.0 unx      486 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/demo.py
--rw-r--r--  2.0 unx     9711 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/export.py
--rw-r--r--  2.0 unx     1848 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/info.yaml
--rw-r--r--  2.0 unx      560 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/model.py
--rw-r--r--  2.0 unx     4753 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/perf.yaml
--rw-r--r--  2.0 unx       38 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/requirements.txt
--rw-r--r--  2.0 unx      696 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_small_en/test.py
--rw-r--r--  2.0 unx      444 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/__init__.py
--rw-r--r--  2.0 unx      802 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/conftest.py
--rw-r--r--  2.0 unx      483 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/demo.py
--rw-r--r--  2.0 unx     9707 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/export.py
--rw-r--r--  2.0 unx     1849 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/info.yaml
--rw-r--r--  2.0 unx      558 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/model.py
--rw-r--r--  2.0 unx     4733 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/perf.yaml
--rw-r--r--  2.0 unx       31 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/requirements.txt
--rw-r--r--  2.0 unx      696 b- defN 24-Apr-02 22:37 qai_hub_models/models/whisper_tiny_en/test.py
--rw-r--r--  2.0 unx      475 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/__init__.py
--rw-r--r--  2.0 unx      796 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/conftest.py
--rw-r--r--  2.0 unx      542 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/demo.py
--rw-r--r--  2.0 unx     7891 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/export.py
--rw-r--r--  2.0 unx     1298 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/info.yaml
--rw-r--r--  2.0 unx      710 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/model.py
--rw-r--r--  2.0 unx     2760 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/perf.yaml
--rw-r--r--  2.0 unx      855 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50/test.py
--rw-r--r--  2.0 unx      582 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/__init__.py
--rw-r--r--  2.0 unx      816 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/conftest.py
--rw-r--r--  2.0 unx      587 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/demo.py
--rw-r--r--  2.0 unx     8324 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/export.py
--rw-r--r--  2.0 unx     1333 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/info.yaml
--rw-r--r--  2.0 unx     3004 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/model.py
--rw-r--r--  2.0 unx     2760 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/perf.yaml
--rw-r--r--  2.0 unx      932 b- defN 24-Apr-02 22:37 qai_hub_models/models/wideresnet50_quantized/test.py
--rw-r--r--  2.0 unx      461 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/__init__.py
--rw-r--r--  2.0 unx      866 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/conftest.py
--rw-r--r--  2.0 unx      742 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/demo.py
--rw-r--r--  2.0 unx     7994 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/export.py
--rw-r--r--  2.0 unx     1156 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/info.yaml
--rw-r--r--  2.0 unx     3403 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/model.py
--rw-r--r--  2.0 unx     2743 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/perf.yaml
--rw-r--r--  2.0 unx     1402 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr/test.py
--rw-r--r--  2.0 unx      472 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/__init__.py
--rw-r--r--  2.0 unx      886 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/conftest.py
--rw-r--r--  2.0 unx      956 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/demo.py
--rw-r--r--  2.0 unx     8447 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/export.py
--rw-r--r--  2.0 unx     1191 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/info.yaml
--rw-r--r--  2.0 unx     3915 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/model.py
--rw-r--r--  2.0 unx     2701 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/perf.yaml
--rw-r--r--  2.0 unx     1607 b- defN 24-Apr-02 22:37 qai_hub_models/models/xlsr_quantized/test.py
--rw-r--r--  2.0 unx      436 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/__init__.py
--rw-r--r--  2.0 unx     1071 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/app.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/conftest.py
--rw-r--r--  2.0 unx     1027 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/demo.py
--rw-r--r--  2.0 unx     7897 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/export.py
--rw-r--r--  2.0 unx     1168 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/info.yaml
--rw-r--r--  2.0 unx     4686 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/model.py
--rw-r--r--  2.0 unx     2760 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/perf.yaml
--rw-r--r--  2.0 unx     1845 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov6/test.py
--rw-r--r--  2.0 unx      436 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/__init__.py
--rw-r--r--  2.0 unx     1071 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/app.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/conftest.py
--rw-r--r--  2.0 unx      909 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/demo.py
--rw-r--r--  2.0 unx     7917 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/export.py
--rw-r--r--  2.0 unx     1131 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/info.yaml
--rw-r--r--  2.0 unx     9640 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/model.py
--rw-r--r--  2.0 unx     2707 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/perf.yaml
--rw-r--r--  2.0 unx       47 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/requirements.txt
--rw-r--r--  2.0 unx     2323 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov7/test.py
--rw-r--r--  2.0 unx      415 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/__init__.py
--rw-r--r--  2.0 unx      892 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/app.py
--rw-r--r--  2.0 unx      792 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/conftest.py
--rw-r--r--  2.0 unx      926 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/demo.py
--rw-r--r--  2.0 unx     7951 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/export.py
--rw-r--r--  2.0 unx     1163 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/info.yaml
--rw-r--r--  2.0 unx     4637 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/model.py
--rw-r--r--  2.0 unx     2768 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/perf.yaml
--rw-r--r--  2.0 unx       64 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/requirements.txt
--rw-r--r--  2.0 unx     2080 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_det/test.py
--rw-r--r--  2.0 unx      419 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/__init__.py
--rw-r--r--  2.0 unx     7698 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/app.py
--rw-r--r--  2.0 unx      792 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/conftest.py
--rw-r--r--  2.0 unx     3155 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/demo.py
--rw-r--r--  2.0 unx     7974 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/export.py
--rw-r--r--  2.0 unx     1273 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/info.yaml
--rw-r--r--  2.0 unx     4663 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/model.py
--rw-r--r--  2.0 unx     2710 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/perf.yaml
--rw-r--r--  2.0 unx       64 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/requirements.txt
--rw-r--r--  2.0 unx     2536 b- defN 24-Apr-02 22:37 qai_hub_models/models/yolov8_seg/test.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/test/__init__.py
--rw-r--r--  2.0 unx     1043 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_async_compile_jobs.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/test/e2e/__init__.py
--rw-r--r--  2.0 unx     1661 b- defN 24-Apr-02 22:37 qai_hub_models/test/e2e/test_aimet_compile.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_utils/__init__.py
--rw-r--r--  2.0 unx     1493 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_utils/perf.yaml
--rw-r--r--  2.0 unx     3229 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_utils/test_info_specs.py
--rw-r--r--  2.0 unx     6515 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_utils/test_perf_summary.py
--rw-r--r--  2.0 unx     3295 b- defN 24-Apr-02 22:37 qai_hub_models/test/test_utils/test_qai_hub_helpers.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/utils/__init__.py
--rw-r--r--  2.0 unx    16452 b- defN 24-Apr-02 22:37 qai_hub_models/utils/args.py
--rw-r--r--  2.0 unx    33565 b- defN 24-Apr-02 22:37 qai_hub_models/utils/asset_loaders.py
--rw-r--r--  2.0 unx     6052 b- defN 24-Apr-02 22:37 qai_hub_models/utils/base_model.py
--rw-r--r--  2.0 unx     8707 b- defN 24-Apr-02 22:37 qai_hub_models/utils/bounding_box_processing.py
--rw-r--r--  2.0 unx     1771 b- defN 24-Apr-02 22:37 qai_hub_models/utils/camera_capture.py
--rw-r--r--  2.0 unx     5222 b- defN 24-Apr-02 22:37 qai_hub_models/utils/compare.py
--rw-r--r--  2.0 unx    32743 b- defN 24-Apr-02 22:37 qai_hub_models/utils/config_loaders.py
--rw-r--r--  2.0 unx     3066 b- defN 24-Apr-02 22:37 qai_hub_models/utils/display.py
--rw-r--r--  2.0 unx     6403 b- defN 24-Apr-02 22:37 qai_hub_models/utils/draw.py
--rw-r--r--  2.0 unx     1549 b- defN 24-Apr-02 22:37 qai_hub_models/utils/huggingface.py
--rw-r--r--  2.0 unx    12490 b- defN 24-Apr-02 22:37 qai_hub_models/utils/image_processing.py
--rw-r--r--  2.0 unx    12482 b- defN 24-Apr-02 22:37 qai_hub_models/utils/inference.py
--rw-r--r--  2.0 unx     1308 b- defN 24-Apr-02 22:37 qai_hub_models/utils/input_spec.py
--rw-r--r--  2.0 unx     4559 b- defN 24-Apr-02 22:37 qai_hub_models/utils/measurement.py
--rw-r--r--  2.0 unx     1577 b- defN 24-Apr-02 22:37 qai_hub_models/utils/model_adapters.py
--rw-r--r--  2.0 unx    12621 b- defN 24-Apr-02 22:37 qai_hub_models/utils/model_card.py
--rw-r--r--  2.0 unx     1406 b- defN 24-Apr-02 22:37 qai_hub_models/utils/path_helpers.py
--rw-r--r--  2.0 unx    11378 b- defN 24-Apr-02 22:37 qai_hub_models/utils/perf_summary.py
--rw-r--r--  2.0 unx     4858 b- defN 24-Apr-02 22:37 qai_hub_models/utils/printing.py
--rw-r--r--  2.0 unx     5365 b- defN 24-Apr-02 22:37 qai_hub_models/utils/qai_hub_helpers.py
--rw-r--r--  2.0 unx     1463 b- defN 24-Apr-02 22:37 qai_hub_models/utils/qnn_helpers.py
--rw-r--r--  2.0 unx     2170 b- defN 24-Apr-02 22:37 qai_hub_models/utils/quantization.py
--rw-r--r--  2.0 unx    11791 b- defN 24-Apr-02 22:37 qai_hub_models/utils/quantization_aimet.py
--rw-r--r--  2.0 unx      754 b- defN 24-Apr-02 22:37 qai_hub_models/utils/test_compare.py
--rw-r--r--  2.0 unx     3173 b- defN 24-Apr-02 22:37 qai_hub_models/utils/testing.py
--rw-r--r--  2.0 unx      259 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/__init__.py
--rw-r--r--  2.0 unx      876 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/config_loader.py
--rw-r--r--  2.0 unx      993 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/default_config.json
--rw-r--r--  2.0 unx      946 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/default_config_legacy_v1.json
--rw-r--r--  2.0 unx      955 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/default_config_legacy_v2.json
--rw-r--r--  2.0 unx      919 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/default_config_per_channel_qnn.json
--rw-r--r--  2.0 unx     1187 b- defN 24-Apr-02 22:37 qai_hub_models/utils/aimet/repo.py
--rw-r--r--  2.0 unx     1481 b- defN 24-Apr-02 22:41 qai_hub_models-0.4.1.dist-info/LICENSE
--rw-r--r--  2.0 unx    40686 b- defN 24-Apr-02 22:41 qai_hub_models-0.4.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-02 22:41 qai_hub_models-0.4.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       15 b- defN 24-Apr-02 22:41 qai_hub_models-0.4.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    92338 b- defN 24-Apr-02 22:41 qai_hub_models-0.4.1.dist-info/RECORD
-903 files, 2444307 bytes uncompressed, 810084 bytes compressed:  66.9%
+Zip file size: 1012491 bytes, number of entries: 924
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/__init__.py
+-rw-r--r--  2.0 unx      281 b- defN 24-Apr-16 23:38 qai_hub_models/_version.py
+-rw-r--r--  2.0 unx      620 b- defN 24-Apr-16 23:40 qai_hub_models/asset_bases.yaml
+-rw-r--r--  2.0 unx      734 b- defN 24-Apr-16 23:38 qai_hub_models/conftest.py
+-rw-r--r--  2.0 unx      913 b- defN 24-Apr-16 23:38 qai_hub_models/global_requirements.txt
+-rw-r--r--  2.0 unx      395 b- defN 24-Apr-16 23:38 qai_hub_models/requirements-dev.txt
+-rw-r--r--  2.0 unx      427 b- defN 24-Apr-16 23:38 qai_hub_models/requirements.txt
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/datasets/__init__.py
+-rw-r--r--  2.0 unx     4757 b- defN 24-Apr-16 23:38 qai_hub_models/datasets/bsd300.py
+-rw-r--r--  2.0 unx     4109 b- defN 24-Apr-16 23:38 qai_hub_models/datasets/coco.py
+-rw-r--r--  2.0 unx     1614 b- defN 24-Apr-16 23:38 qai_hub_models/datasets/common.py
+-rw-r--r--  2.0 unx     3203 b- defN 24-Apr-16 23:38 qai_hub_models/datasets/imagenette.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/__init__.py
+-rw-r--r--  2.0 unx     6212 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/base_evaluators.py
+-rw-r--r--  2.0 unx     1326 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/classification_evaluator.py
+-rw-r--r--  2.0 unx     3699 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/detection_evaluator.py
+-rw-r--r--  2.0 unx     2434 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/image_evaluator.py
+-rw-r--r--  2.0 unx     2181 b- defN 24-Apr-16 23:38 qai_hub_models/evaluators/superres_evaluator.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/__init__.py
+-rw-r--r--  2.0 unx      666 b- defN 24-Apr-16 23:38 qai_hub_models/models/common.py
+-rw-r--r--  2.0 unx     7882 b- defN 24-Apr-16 23:38 qai_hub_models/models/protocols.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/__init__.py
+-rw-r--r--  2.0 unx     1655 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/common.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/__init__.py
+-rw-r--r--  2.0 unx     4346 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/app.py
+-rw-r--r--  2.0 unx     2904 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/demo.py
+-rw-r--r--  2.0 unx      890 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/evaluator.py
+-rw-r--r--  2.0 unx     2888 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/model.py
+-rw-r--r--  2.0 unx     8565 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/cityscapes_segmentation/patches/move_datasets.diff
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/deeplab/__init__.py
+-rw-r--r--  2.0 unx     2651 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/deeplab/app.py
+-rw-r--r--  2.0 unx     2252 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/deeplab/demo.py
+-rw-r--r--  2.0 unx      915 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/deeplab/evaluator.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/detr/__init__.py
+-rw-r--r--  2.0 unx     4604 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/detr/app.py
+-rw-r--r--  2.0 unx     3565 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/detr/coco_label_map.py
+-rw-r--r--  2.0 unx     2091 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/detr/demo.py
+-rw-r--r--  2.0 unx     2050 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/detr/model.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/fastsam/__init__.py
+-rw-r--r--  2.0 unx     4883 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/fastsam/app.py
+-rw-r--r--  2.0 unx     2022 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/fastsam/demo.py
+-rw-r--r--  2.0 unx     1935 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/fastsam/model.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet/__init__.py
+-rw-r--r--  2.0 unx     4548 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet/model.py
+-rw-r--r--  2.0 unx     1569 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet/test_utils.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet_quantized/__init__.py
+-rw-r--r--  2.0 unx     1165 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet_quantized/aimet_config.json
+-rw-r--r--  2.0 unx     2475 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/ffnet_quantized/model.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/imagenet_classifier/__init__.py
+-rw-r--r--  2.0 unx     3041 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/imagenet_classifier/app.py
+-rw-r--r--  2.0 unx     2432 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/imagenet_classifier/demo.py
+-rw-r--r--  2.0 unx     4661 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/imagenet_classifier/model.py
+-rw-r--r--  2.0 unx     3781 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/imagenet_classifier/test_utils.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/mediapipe/__init__.py
+-rw-r--r--  2.0 unx    30293 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/mediapipe/app.py
+-rw-r--r--  2.0 unx     4394 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/mediapipe/utils.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/quicksrnet/__init__.py
+-rw-r--r--  2.0 unx      985 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/quicksrnet/common.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/repaint/__init__.py
+-rw-r--r--  2.0 unx     3366 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/repaint/app.py
+-rw-r--r--  2.0 unx     2229 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/repaint/demo.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/sesr/__init__.py
+-rw-r--r--  2.0 unx     1029 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/sesr/common.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/super_resolution/__init__.py
+-rw-r--r--  2.0 unx     2143 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/super_resolution/app.py
+-rw-r--r--  2.0 unx     2775 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/super_resolution/demo.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/swin/__init__.py
+-rw-r--r--  2.0 unx     9175 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/swin/swin_transformer.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/video_classifier/__init__.py
+-rw-r--r--  2.0 unx    11183 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/video_classifier/app.py
+-rw-r--r--  2.0 unx     1581 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/video_classifier/demo.py
+-rw-r--r--  2.0 unx     1969 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/video_classifier/model.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/whisper/__init__.py
+-rw-r--r--  2.0 unx    10188 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/whisper/app.py
+-rw-r--r--  2.0 unx     1302 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/whisper/demo.py
+-rw-r--r--  2.0 unx    14119 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/whisper/model.py
+-rw-r--r--  2.0 unx     2848 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/whisper/test_utils.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/yolo/__init__.py
+-rw-r--r--  2.0 unx     7354 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/yolo/app.py
+-rw-r--r--  2.0 unx     2432 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/yolo/demo.py
+-rw-r--r--  2.0 unx     5643 b- defN 24-Apr-16 23:38 qai_hub_models/models/_shared/yolo/utils.py
+-rw-r--r--  2.0 unx      450 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/__init__.py
+-rw-r--r--  2.0 unx      980 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/conftest.py
+-rw-r--r--  2.0 unx      597 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/demo.py
+-rw-r--r--  2.0 unx     8156 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/export.py
+-rw-r--r--  2.0 unx     1023 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/info.yaml
+-rw-r--r--  2.0 unx     4838 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/model.py
+-rw-r--r--  2.0 unx     4412 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/perf.yaml
+-rw-r--r--  2.0 unx     2006 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/test.py
+-rw-r--r--  2.0 unx      532 b- defN 24-Apr-16 23:38 qai_hub_models/models/aotgan/patches/layer_norm.diff
+-rw-r--r--  2.0 unx     1983 b- defN 24-Apr-16 23:38 qai_hub_models/models/baichuan_7b_quantized/info.yaml
+-rw-r--r--  2.0 unx     2036 b- defN 24-Apr-16 23:38 qai_hub_models/models/baichuan_7b_quantized/perf.yaml
+-rw-r--r--  2.0 unx      559 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/__init__.py
+-rw-r--r--  2.0 unx     9705 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/app.py
+-rw-r--r--  2.0 unx     6397 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/demo.py
+-rw-r--r--  2.0 unx     7622 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/export.py
+-rw-r--r--  2.0 unx     1329 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/info.yaml
+-rw-r--r--  2.0 unx     5426 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/model.py
+-rw-r--r--  2.0 unx     8427 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/perf.yaml
+-rw-r--r--  2.0 unx       46 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/requirements.txt
+-rw-r--r--  2.0 unx     1556 b- defN 24-Apr-16 23:38 qai_hub_models/models/controlnet_quantized/test.py
+-rw-r--r--  2.0 unx      475 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/__init__.py
+-rw-r--r--  2.0 unx      908 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/conftest.py
+-rw-r--r--  2.0 unx      543 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/demo.py
+-rw-r--r--  2.0 unx     7915 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/export.py
+-rw-r--r--  2.0 unx     1287 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/info.yaml
+-rw-r--r--  2.0 unx      708 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/model.py
+-rw-r--r--  2.0 unx     2707 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/perf.yaml
+-rw-r--r--  2.0 unx      857 b- defN 24-Apr-16 23:38 qai_hub_models/models/convnext_tiny/test.py
+-rw-r--r--  2.0 unx      398 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/__init__.py
+-rw-r--r--  2.0 unx     3750 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/app.py
+-rw-r--r--  2.0 unx      994 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/conftest.py
+-rw-r--r--  2.0 unx     2128 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/demo.py
+-rw-r--r--  2.0 unx     8193 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/export.py
+-rw-r--r--  2.0 unx     1334 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/info.yaml
+-rw-r--r--  2.0 unx     3831 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/model.py
+-rw-r--r--  2.0 unx     3617 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/perf.yaml
+-rw-r--r--  2.0 unx     1790 b- defN 24-Apr-16 23:38 qai_hub_models/models/ddrnet23_slim/test.py
+-rw-r--r--  2.0 unx      451 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/__init__.py
+-rw-r--r--  2.0 unx     1004 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/conftest.py
+-rw-r--r--  2.0 unx     1026 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/demo.py
+-rw-r--r--  2.0 unx     8068 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/export.py
+-rw-r--r--  2.0 unx     1278 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/info.yaml
+-rw-r--r--  2.0 unx     2886 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/model.py
+-rw-r--r--  2.0 unx     4374 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/perf.yaml
+-rw-r--r--  2.0 unx     2086 b- defN 24-Apr-16 23:38 qai_hub_models/models/deeplabv3_resnet50/test.py
+-rw-r--r--  2.0 unx      471 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/__init__.py
+-rw-r--r--  2.0 unx      904 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/conftest.py
+-rw-r--r--  2.0 unx      533 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/demo.py
+-rw-r--r--  2.0 unx     7888 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/export.py
+-rw-r--r--  2.0 unx     1310 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/info.yaml
+-rw-r--r--  2.0 unx      698 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/model.py
+-rw-r--r--  2.0 unx     4399 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/perf.yaml
+-rw-r--r--  2.0 unx      841 b- defN 24-Apr-16 23:38 qai_hub_models/models/densenet121/test.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/__init__.py
+-rw-r--r--  2.0 unx      910 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/conftest.py
+-rw-r--r--  2.0 unx      896 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/demo.py
+-rw-r--r--  2.0 unx     7905 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/export.py
+-rw-r--r--  2.0 unx     1188 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/info.yaml
+-rw-r--r--  2.0 unx      661 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/model.py
+-rw-r--r--  2.0 unx     3658 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/perf.yaml
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/requirements.txt
+-rw-r--r--  2.0 unx     1316 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101/test.py
+-rw-r--r--  2.0 unx      490 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/__init__.py
+-rw-r--r--  2.0 unx      918 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/conftest.py
+-rw-r--r--  2.0 unx      906 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/demo.py
+-rw-r--r--  2.0 unx     7921 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/export.py
+-rw-r--r--  2.0 unx     1215 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/info.yaml
+-rw-r--r--  2.0 unx      668 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/model.py
+-rw-r--r--  2.0 unx     3677 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/perf.yaml
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/requirements.txt
+-rw-r--r--  2.0 unx     1373 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet101_dc5/test.py
+-rw-r--r--  2.0 unx      481 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/__init__.py
+-rw-r--r--  2.0 unx      908 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/conftest.py
+-rw-r--r--  2.0 unx      893 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/demo.py
+-rw-r--r--  2.0 unx     7901 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/export.py
+-rw-r--r--  2.0 unx     1185 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/info.yaml
+-rw-r--r--  2.0 unx      659 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/model.py
+-rw-r--r--  2.0 unx     3662 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/perf.yaml
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/requirements.txt
+-rw-r--r--  2.0 unx     1636 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50/test.py
+-rw-r--r--  2.0 unx      488 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/__init__.py
+-rw-r--r--  2.0 unx      916 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/conftest.py
+-rw-r--r--  2.0 unx      903 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/demo.py
+-rw-r--r--  2.0 unx     7917 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/export.py
+-rw-r--r--  2.0 unx     1212 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/info.yaml
+-rw-r--r--  2.0 unx      666 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/model.py
+-rw-r--r--  2.0 unx     3670 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/perf.yaml
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/requirements.txt
+-rw-r--r--  2.0 unx     1344 b- defN 24-Apr-16 23:38 qai_hub_models/models/detr_resnet50_dc5/test.py
+-rw-r--r--  2.0 unx      477 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/__init__.py
+-rw-r--r--  2.0 unx      912 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/conftest.py
+-rw-r--r--  2.0 unx      549 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/demo.py
+-rw-r--r--  2.0 unx     7903 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/export.py
+-rw-r--r--  2.0 unx     1361 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/info.yaml
+-rw-r--r--  2.0 unx      714 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/model.py
+-rw-r--r--  2.0 unx     4428 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/perf.yaml
+-rw-r--r--  2.0 unx      867 b- defN 24-Apr-16 23:38 qai_hub_models/models/efficientnet_b0/test.py
+-rw-r--r--  2.0 unx      463 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/__init__.py
+-rw-r--r--  2.0 unx      980 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/conftest.py
+-rw-r--r--  2.0 unx      939 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/demo.py
+-rw-r--r--  2.0 unx     8002 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/export.py
+-rw-r--r--  2.0 unx     1117 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/info.yaml
+-rw-r--r--  2.0 unx     3473 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/model.py
+-rw-r--r--  2.0 unx     4460 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/perf.yaml
+-rw-r--r--  2.0 unx     1831 b- defN 24-Apr-16 23:38 qai_hub_models/models/esrgan/test.py
+-rw-r--r--  2.0 unx      418 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/__init__.py
+-rw-r--r--  2.0 unx     3207 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/app.py
+-rw-r--r--  2.0 unx     1002 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/conftest.py
+-rw-r--r--  2.0 unx     3172 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/demo.py
+-rw-r--r--  2.0 unx     7670 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/export.py
+-rw-r--r--  2.0 unx     1070 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/info.yaml
+-rw-r--r--  2.0 unx     2414 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/model.py
+-rw-r--r--  2.0 unx     3685 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/perf.yaml
+-rw-r--r--  2.0 unx       74 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/requirements.txt
+-rw-r--r--  2.0 unx     2492 b- defN 24-Apr-16 23:38 qai_hub_models/models/facebook_denoiser/test.py
+-rw-r--r--  2.0 unx      440 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/conftest.py
+-rw-r--r--  2.0 unx      762 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/demo.py
+-rw-r--r--  2.0 unx     8264 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/export.py
+-rw-r--r--  2.0 unx     1301 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/info.yaml
+-rw-r--r--  2.0 unx      683 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/model.py
+-rw-r--r--  2.0 unx     3660 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/perf.yaml
+-rw-r--r--  2.0 unx       64 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/requirements.txt
+-rw-r--r--  2.0 unx     1332 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_s/test.py
+-rw-r--r--  2.0 unx      440 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/conftest.py
+-rw-r--r--  2.0 unx      762 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/demo.py
+-rw-r--r--  2.0 unx     8264 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/export.py
+-rw-r--r--  2.0 unx     1300 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/info.yaml
+-rw-r--r--  2.0 unx      683 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/model.py
+-rw-r--r--  2.0 unx     3668 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/perf.yaml
+-rw-r--r--  2.0 unx       64 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/requirements.txt
+-rw-r--r--  2.0 unx     1332 b- defN 24-Apr-16 23:38 qai_hub_models/models/fastsam_x/test.py
+-rw-r--r--  2.0 unx      410 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/__init__.py
+-rw-r--r--  2.0 unx     2683 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/app.py
+-rw-r--r--  2.0 unx      992 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/conftest.py
+-rw-r--r--  2.0 unx     2315 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/demo.py
+-rw-r--r--  2.0 unx     8169 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/export.py
+-rw-r--r--  2.0 unx     1241 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/info.yaml
+-rw-r--r--  2.0 unx     1989 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/model.py
+-rw-r--r--  2.0 unx     4442 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/perf.yaml
+-rw-r--r--  2.0 unx     1637 b- defN 24-Apr-16 23:38 qai_hub_models/models/fcn_resnet50/test.py
+-rw-r--r--  2.0 unx      487 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/__init__.py
+-rw-r--r--  2.0 unx     1004 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/conftest.py
+-rw-r--r--  2.0 unx      607 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/demo.py
+-rw-r--r--  2.0 unx     8050 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/export.py
+-rw-r--r--  2.0 unx     1322 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/info.yaml
+-rw-r--r--  2.0 unx      648 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/model.py
+-rw-r--r--  2.0 unx     4455 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/requirements.txt
+-rw-r--r--  2.0 unx      804 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_122ns_lowres/test.py
+-rw-r--r--  2.0 unx      479 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/__init__.py
+-rw-r--r--  2.0 unx      986 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/conftest.py
+-rw-r--r--  2.0 unx      582 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/demo.py
+-rw-r--r--  2.0 unx     8014 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/export.py
+-rw-r--r--  2.0 unx     1298 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/info.yaml
+-rw-r--r--  2.0 unx      580 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/model.py
+-rw-r--r--  2.0 unx     4437 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/requirements.txt
+-rw-r--r--  2.0 unx      746 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s/test.py
+-rw-r--r--  2.0 unx      490 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/__init__.py
+-rw-r--r--  2.0 unx     1006 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/conftest.py
+-rw-r--r--  2.0 unx      627 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/demo.py
+-rw-r--r--  2.0 unx     8467 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/export.py
+-rw-r--r--  2.0 unx     1347 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/info.yaml
+-rw-r--r--  2.0 unx     1169 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/model.py
+-rw-r--r--  2.0 unx     3661 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/requirements.txt
+-rw-r--r--  2.0 unx      840 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_40s_quantized/test.py
+-rw-r--r--  2.0 unx      479 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/__init__.py
+-rw-r--r--  2.0 unx      986 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/conftest.py
+-rw-r--r--  2.0 unx      582 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/demo.py
+-rw-r--r--  2.0 unx     8014 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/export.py
+-rw-r--r--  2.0 unx     1275 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/info.yaml
+-rw-r--r--  2.0 unx      580 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/model.py
+-rw-r--r--  2.0 unx     4454 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/requirements.txt
+-rw-r--r--  2.0 unx      746 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s/test.py
+-rw-r--r--  2.0 unx      490 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/__init__.py
+-rw-r--r--  2.0 unx     1006 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/conftest.py
+-rw-r--r--  2.0 unx      627 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/demo.py
+-rw-r--r--  2.0 unx     8467 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/export.py
+-rw-r--r--  2.0 unx     1347 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/info.yaml
+-rw-r--r--  2.0 unx     1156 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/model.py
+-rw-r--r--  2.0 unx     3668 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/requirements.txt
+-rw-r--r--  2.0 unx      840 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_54s_quantized/test.py
+-rw-r--r--  2.0 unx      479 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/__init__.py
+-rw-r--r--  2.0 unx      986 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/conftest.py
+-rw-r--r--  2.0 unx      582 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/demo.py
+-rw-r--r--  2.0 unx     8014 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/export.py
+-rw-r--r--  2.0 unx     1279 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/info.yaml
+-rw-r--r--  2.0 unx      580 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/model.py
+-rw-r--r--  2.0 unx     4450 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/requirements.txt
+-rw-r--r--  2.0 unx      746 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s/test.py
+-rw-r--r--  2.0 unx      485 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/conftest.py
+-rw-r--r--  2.0 unx      601 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/demo.py
+-rw-r--r--  2.0 unx     8042 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/export.py
+-rw-r--r--  2.0 unx     1327 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/info.yaml
+-rw-r--r--  2.0 unx      640 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/model.py
+-rw-r--r--  2.0 unx     4446 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/requirements.txt
+-rw-r--r--  2.0 unx      794 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_lowres/test.py
+-rw-r--r--  2.0 unx      490 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/__init__.py
+-rw-r--r--  2.0 unx     1006 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/conftest.py
+-rw-r--r--  2.0 unx      627 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/demo.py
+-rw-r--r--  2.0 unx     8467 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/export.py
+-rw-r--r--  2.0 unx     1347 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/info.yaml
+-rw-r--r--  2.0 unx     1156 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/model.py
+-rw-r--r--  2.0 unx     3666 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/perf.yaml
+-rw-r--r--  2.0 unx       21 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/requirements.txt
+-rw-r--r--  2.0 unx      840 b- defN 24-Apr-16 23:38 qai_hub_models/models/ffnet_78s_quantized/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/conftest.py
+-rw-r--r--  2.0 unx      533 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/demo.py
+-rw-r--r--  2.0 unx     7879 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/export.py
+-rw-r--r--  2.0 unx     1295 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/info.yaml
+-rw-r--r--  2.0 unx      743 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/model.py
+-rw-r--r--  2.0 unx     4409 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/perf.yaml
+-rw-r--r--  2.0 unx      840 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet/test.py
+-rw-r--r--  2.0 unx      573 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/__init__.py
+-rw-r--r--  2.0 unx      920 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/conftest.py
+-rw-r--r--  2.0 unx      578 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/demo.py
+-rw-r--r--  2.0 unx     8359 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/export.py
+-rw-r--r--  2.0 unx     1325 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/info.yaml
+-rw-r--r--  2.0 unx     4298 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/model.py
+-rw-r--r--  2.0 unx     4423 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/perf.yaml
+-rw-r--r--  2.0 unx      885 b- defN 24-Apr-16 23:38 qai_hub_models/models/googlenet_quantized/test.py
+-rw-r--r--  2.0 unx      430 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/__init__.py
+-rw-r--r--  2.0 unx     8134 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/app.py
+-rw-r--r--  2.0 unx      988 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/conftest.py
+-rw-r--r--  2.0 unx     1739 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/demo.py
+-rw-r--r--  2.0 unx     8160 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/export.py
+-rw-r--r--  2.0 unx     1195 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/info.yaml
+-rw-r--r--  2.0 unx     2801 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/model.py
+-rw-r--r--  2.0 unx     4426 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/perf.yaml
+-rw-r--r--  2.0 unx       51 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/requirements.txt
+-rw-r--r--  2.0 unx     1420 b- defN 24-Apr-16 23:38 qai_hub_models/models/hrnet_pose/test.py
+-rw-r--r--  2.0 unx      434 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/__init__.py
+-rw-r--r--  2.0 unx     2133 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/app.py
+-rw-r--r--  2.0 unx     1022 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/conftest.py
+-rw-r--r--  2.0 unx     1517 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/demo.py
+-rw-r--r--  2.0 unx     7567 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/export.py
+-rw-r--r--  2.0 unx     1248 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/info.yaml
+-rw-r--r--  2.0 unx     7587 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/model.py
+-rw-r--r--  2.0 unx     3698 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/perf.yaml
+-rw-r--r--  2.0 unx       72 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/requirements.txt
+-rw-r--r--  2.0 unx     2560 b- defN 24-Apr-16 23:38 qai_hub_models/models/huggingface_wavlm_base_plus/test.py
+-rw-r--r--  2.0 unx      477 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/__init__.py
+-rw-r--r--  2.0 unx      906 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/conftest.py
+-rw-r--r--  2.0 unx      546 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/demo.py
+-rw-r--r--  2.0 unx     7891 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/export.py
+-rw-r--r--  2.0 unx     1359 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/info.yaml
+-rw-r--r--  2.0 unx      756 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/model.py
+-rw-r--r--  2.0 unx     4432 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/perf.yaml
+-rw-r--r--  2.0 unx      861 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3/test.py
+-rw-r--r--  2.0 unx      584 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/__init__.py
+-rw-r--r--  2.0 unx      926 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/conftest.py
+-rw-r--r--  2.0 unx      591 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/demo.py
+-rw-r--r--  2.0 unx     8392 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/export.py
+-rw-r--r--  2.0 unx     1556 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/info.yaml
+-rw-r--r--  2.0 unx     7762 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/model.py
+-rw-r--r--  2.0 unx     3656 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/perf.yaml
+-rw-r--r--  2.0 unx      901 b- defN 24-Apr-16 23:38 qai_hub_models/models/inception_v3_quantized/test.py
+-rw-r--r--  2.0 unx      455 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/__init__.py
+-rw-r--r--  2.0 unx      992 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/conftest.py
+-rw-r--r--  2.0 unx      911 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/demo.py
+-rw-r--r--  2.0 unx     8179 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/export.py
+-rw-r--r--  2.0 unx     1082 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/info.yaml
+-rw-r--r--  2.0 unx     4977 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/model.py
+-rw-r--r--  2.0 unx     4407 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/perf.yaml
+-rw-r--r--  2.0 unx      171 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/requirements.txt
+-rw-r--r--  2.0 unx     2074 b- defN 24-Apr-16 23:38 qai_hub_models/models/lama_dilated/test.py
+-rw-r--r--  2.0 unx      404 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/__init__.py
+-rw-r--r--  2.0 unx     3986 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/app.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/conftest.py
+-rw-r--r--  2.0 unx     2072 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/demo.py
+-rw-r--r--  2.0 unx     7638 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/export.py
+-rw-r--r--  2.0 unx     1112 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/info.yaml
+-rw-r--r--  2.0 unx     3788 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/model.py
+-rw-r--r--  2.0 unx     3620 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/perf.yaml
+-rw-r--r--  2.0 unx       39 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/requirements.txt
+-rw-r--r--  2.0 unx     1714 b- defN 24-Apr-16 23:38 qai_hub_models/models/litehrnet/test.py
+-rw-r--r--  2.0 unx     1993 b- defN 24-Apr-16 23:38 qai_hub_models/models/llama_v2_7b_chat_quantized/info.yaml
+-rw-r--r--  2.0 unx     2037 b- defN 24-Apr-16 23:38 qai_hub_models/models/llama_v2_7b_chat_quantized/perf.yaml
+-rw-r--r--  2.0 unx      412 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/__init__.py
+-rw-r--r--  2.0 unx     2099 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/app.py
+-rw-r--r--  2.0 unx      996 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/conftest.py
+-rw-r--r--  2.0 unx     2862 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/demo.py
+-rw-r--r--  2.0 unx     9755 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/export.py
+-rw-r--r--  2.0 unx     1469 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/info.yaml
+-rw-r--r--  2.0 unx     7669 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/model.py
+-rw-r--r--  2.0 unx     8096 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/perf.yaml
+-rw-r--r--  2.0 unx     1441 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_face/test.py
+-rw-r--r--  2.0 unx      412 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/__init__.py
+-rw-r--r--  2.0 unx     9819 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/app.py
+-rw-r--r--  2.0 unx      996 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/conftest.py
+-rw-r--r--  2.0 unx     2832 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/demo.py
+-rw-r--r--  2.0 unx     9755 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/export.py
+-rw-r--r--  2.0 unx     1374 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/info.yaml
+-rw-r--r--  2.0 unx     6017 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/model.py
+-rw-r--r--  2.0 unx     8118 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/perf.yaml
+-rw-r--r--  2.0 unx     1442 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_hand/test.py
+-rw-r--r--  2.0 unx      412 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/__init__.py
+-rw-r--r--  2.0 unx     4430 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/app.py
+-rw-r--r--  2.0 unx      996 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/conftest.py
+-rw-r--r--  2.0 unx     2889 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/demo.py
+-rw-r--r--  2.0 unx     9756 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/export.py
+-rw-r--r--  2.0 unx     1387 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/info.yaml
+-rw-r--r--  2.0 unx     5801 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/model.py
+-rw-r--r--  2.0 unx     8103 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/perf.yaml
+-rw-r--r--  2.0 unx     1443 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_pose/test.py
+-rw-r--r--  2.0 unx      362 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/__init__.py
+-rw-r--r--  2.0 unx     1411 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/app.py
+-rw-r--r--  2.0 unx      914 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/conftest.py
+-rw-r--r--  2.0 unx     2674 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/demo.py
+-rw-r--r--  2.0 unx     8198 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/export.py
+-rw-r--r--  2.0 unx     1455 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/info.yaml
+-rw-r--r--  2.0 unx    12352 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/model.py
+-rw-r--r--  2.0 unx     4449 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/perf.yaml
+-rw-r--r--  2.0 unx       15 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/requirements.txt
+-rw-r--r--  2.0 unx     1396 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/test.py
+-rw-r--r--  2.0 unx     2492 b- defN 24-Apr-16 23:38 qai_hub_models/models/mediapipe_selfie/utils.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/conftest.py
+-rw-r--r--  2.0 unx      533 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/demo.py
+-rw-r--r--  2.0 unx     7879 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/export.py
+-rw-r--r--  2.0 unx     1333 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/info.yaml
+-rw-r--r--  2.0 unx      699 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/model.py
+-rw-r--r--  2.0 unx     4393 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/perf.yaml
+-rw-r--r--  2.0 unx      882 b- defN 24-Apr-16 23:38 qai_hub_models/models/mnasnet05/test.py
+-rw-r--r--  2.0 unx      474 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/__init__.py
+-rw-r--r--  2.0 unx      992 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/conftest.py
+-rw-r--r--  2.0 unx      540 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/demo.py
+-rw-r--r--  2.0 unx     7891 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/export.py
+-rw-r--r--  2.0 unx     1380 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/info.yaml
+-rw-r--r--  2.0 unx     2457 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/model.py
+-rw-r--r--  2.0 unx     4419 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/perf.yaml
+-rw-r--r--  2.0 unx     1091 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2/test.py
+-rw-r--r--  2.0 unx      485 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/__init__.py
+-rw-r--r--  2.0 unx     1012 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/conftest.py
+-rw-r--r--  2.0 unx      585 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/demo.py
+-rw-r--r--  2.0 unx     8372 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/export.py
+-rw-r--r--  2.0 unx     1362 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/info.yaml
+-rw-r--r--  2.0 unx     3429 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/model.py
+-rw-r--r--  2.0 unx     4423 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/perf.yaml
+-rw-r--r--  2.0 unx     1002 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v2_quantized/test.py
+-rw-r--r--  2.0 unx      479 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/__init__.py
+-rw-r--r--  2.0 unx      918 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/conftest.py
+-rw-r--r--  2.0 unx      556 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/demo.py
+-rw-r--r--  2.0 unx     7935 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/export.py
+-rw-r--r--  2.0 unx     1340 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/info.yaml
+-rw-r--r--  2.0 unx      721 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/model.py
+-rw-r--r--  2.0 unx     3644 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/perf.yaml
+-rw-r--r--  2.0 unx      879 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large/test.py
+-rw-r--r--  2.0 unx      607 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/__init__.py
+-rw-r--r--  2.0 unx      938 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/conftest.py
+-rw-r--r--  2.0 unx      748 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/demo.py
+-rw-r--r--  2.0 unx     8104 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/export.py
+-rw-r--r--  2.0 unx     1374 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/info.yaml
+-rw-r--r--  2.0 unx     3075 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/model.py
+-rw-r--r--  2.0 unx     3673 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/perf.yaml
+-rw-r--r--  2.0 unx      917 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_large_quantized/test.py
+-rw-r--r--  2.0 unx      479 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/__init__.py
+-rw-r--r--  2.0 unx      918 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/conftest.py
+-rw-r--r--  2.0 unx      556 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/demo.py
+-rw-r--r--  2.0 unx     7935 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/export.py
+-rw-r--r--  2.0 unx     1338 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/info.yaml
+-rw-r--r--  2.0 unx      721 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/model.py
+-rw-r--r--  2.0 unx     3648 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/perf.yaml
+-rw-r--r--  2.0 unx      879 b- defN 24-Apr-16 23:38 qai_hub_models/models/mobilenet_v3_small/test.py
+-rw-r--r--  2.0 unx      394 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/__init__.py
+-rw-r--r--  2.0 unx     3958 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/app.py
+-rw-r--r--  2.0 unx      990 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/conftest.py
+-rw-r--r--  2.0 unx     3404 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/demo.py
+-rw-r--r--  2.0 unx     9711 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/export.py
+-rw-r--r--  2.0 unx     1494 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/info.yaml
+-rw-r--r--  2.0 unx     5374 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/model.py
+-rw-r--r--  2.0 unx     6529 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/perf.yaml
+-rw-r--r--  2.0 unx       29 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/requirements.txt
+-rw-r--r--  2.0 unx     2118 b- defN 24-Apr-16 23:38 qai_hub_models/models/openai_clip/test.py
+-rw-r--r--  2.0 unx      402 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/__init__.py
+-rw-r--r--  2.0 unx    12008 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/app.py
+-rw-r--r--  2.0 unx      984 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/conftest.py
+-rw-r--r--  2.0 unx     2053 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/demo.py
+-rw-r--r--  2.0 unx     8171 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/export.py
+-rw-r--r--  2.0 unx     1246 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/info.yaml
+-rw-r--r--  2.0 unx     5084 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/model.py
+-rw-r--r--  2.0 unx     4438 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/perf.yaml
+-rw-r--r--  2.0 unx       31 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/requirements.txt
+-rw-r--r--  2.0 unx     1321 b- defN 24-Apr-16 23:38 qai_hub_models/models/openpose/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/__init__.py
+-rw-r--r--  2.0 unx      998 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/conftest.py
+-rw-r--r--  2.0 unx      972 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/demo.py
+-rw-r--r--  2.0 unx     8181 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/export.py
+-rw-r--r--  2.0 unx     1248 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/info.yaml
+-rw-r--r--  2.0 unx     3170 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/model.py
+-rw-r--r--  2.0 unx     4422 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/perf.yaml
+-rw-r--r--  2.0 unx     1422 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge/test.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/__init__.py
+-rw-r--r--  2.0 unx     1018 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/conftest.py
+-rw-r--r--  2.0 unx      891 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/demo.py
+-rw-r--r--  2.0 unx     8634 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/export.py
+-rw-r--r--  2.0 unx     1274 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/info.yaml
+-rw-r--r--  2.0 unx     4587 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/model.py
+-rw-r--r--  2.0 unx     2485 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/perf.yaml
+-rw-r--r--  2.0 unx     2921 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetlarge_quantized/test.py
+-rw-r--r--  2.0 unx      473 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/conftest.py
+-rw-r--r--  2.0 unx      976 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/demo.py
+-rw-r--r--  2.0 unx     8185 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/export.py
+-rw-r--r--  2.0 unx     1242 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/info.yaml
+-rw-r--r--  2.0 unx     3177 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/model.py
+-rw-r--r--  2.0 unx     4419 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/perf.yaml
+-rw-r--r--  2.0 unx     1428 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium/test.py
+-rw-r--r--  2.0 unx      484 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/__init__.py
+-rw-r--r--  2.0 unx     1020 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/conftest.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/demo.py
+-rw-r--r--  2.0 unx     8638 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/export.py
+-rw-r--r--  2.0 unx     1282 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/info.yaml
+-rw-r--r--  2.0 unx     4597 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/model.py
+-rw-r--r--  2.0 unx     2488 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/perf.yaml
+-rw-r--r--  2.0 unx     2912 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetmedium_quantized/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/__init__.py
+-rw-r--r--  2.0 unx      998 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/conftest.py
+-rw-r--r--  2.0 unx      972 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/demo.py
+-rw-r--r--  2.0 unx     8181 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/export.py
+-rw-r--r--  2.0 unx     1238 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/info.yaml
+-rw-r--r--  2.0 unx     3170 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/model.py
+-rw-r--r--  2.0 unx     4413 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/perf.yaml
+-rw-r--r--  2.0 unx     1422 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall/test.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/__init__.py
+-rw-r--r--  2.0 unx     1018 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/conftest.py
+-rw-r--r--  2.0 unx      891 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/demo.py
+-rw-r--r--  2.0 unx     8634 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/export.py
+-rw-r--r--  2.0 unx     1278 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/info.yaml
+-rw-r--r--  2.0 unx     4577 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/model.py
+-rw-r--r--  2.0 unx     2484 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/perf.yaml
+-rw-r--r--  2.0 unx     2859 b- defN 24-Apr-16 23:38 qai_hub_models/models/quicksrnetsmall_quantized/test.py
+-rw-r--r--  2.0 unx      481 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/__init__.py
+-rw-r--r--  2.0 unx     1016 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/conftest.py
+-rw-r--r--  2.0 unx     1280 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/demo.py
+-rw-r--r--  2.0 unx     8217 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/export.py
+-rw-r--r--  2.0 unx     1206 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/info.yaml
+-rw-r--r--  2.0 unx     5226 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/model.py
+-rw-r--r--  2.0 unx     4443 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/perf.yaml
+-rw-r--r--  2.0 unx       44 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/requirements.txt
+-rw-r--r--  2.0 unx     1480 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_general_x4v3/test.py
+-rw-r--r--  2.0 unx      475 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/__init__.py
+-rw-r--r--  2.0 unx     1004 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/conftest.py
+-rw-r--r--  2.0 unx     1256 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/demo.py
+-rw-r--r--  2.0 unx     7654 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/export.py
+-rw-r--r--  2.0 unx     1330 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/info.yaml
+-rw-r--r--  2.0 unx     4443 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/model.py
+-rw-r--r--  2.0 unx     3673 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/perf.yaml
+-rw-r--r--  2.0 unx       44 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/requirements.txt
+-rw-r--r--  2.0 unx     1440 b- defN 24-Apr-16 23:38 qai_hub_models/models/real_esrgan_x4plus/test.py
+-rw-r--r--  2.0 unx      469 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/__init__.py
+-rw-r--r--  2.0 unx      894 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/conftest.py
+-rw-r--r--  2.0 unx      524 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/demo.py
+-rw-r--r--  2.0 unx     7867 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/export.py
+-rw-r--r--  2.0 unx     1291 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/info.yaml
+-rw-r--r--  2.0 unx      635 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/model.py
+-rw-r--r--  2.0 unx     4424 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/perf.yaml
+-rw-r--r--  2.0 unx      984 b- defN 24-Apr-16 23:38 qai_hub_models/models/regnet/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/conftest.py
+-rw-r--r--  2.0 unx      533 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/demo.py
+-rw-r--r--  2.0 unx     7879 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/export.py
+-rw-r--r--  2.0 unx     1312 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/info.yaml
+-rw-r--r--  2.0 unx      609 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/model.py
+-rw-r--r--  2.0 unx     4436 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/perf.yaml
+-rw-r--r--  2.0 unx      961 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101/test.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/__init__.py
+-rw-r--r--  2.0 unx      920 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/conftest.py
+-rw-r--r--  2.0 unx      578 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/demo.py
+-rw-r--r--  2.0 unx     8359 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/export.py
+-rw-r--r--  2.0 unx     1346 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/info.yaml
+-rw-r--r--  2.0 unx     3210 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/model.py
+-rw-r--r--  2.0 unx     4437 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/perf.yaml
+-rw-r--r--  2.0 unx      921 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet101_quantized/test.py
+-rw-r--r--  2.0 unx      471 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/__init__.py
+-rw-r--r--  2.0 unx      898 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/conftest.py
+-rw-r--r--  2.0 unx      530 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/demo.py
+-rw-r--r--  2.0 unx     7875 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/export.py
+-rw-r--r--  2.0 unx     1310 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/info.yaml
+-rw-r--r--  2.0 unx      607 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/model.py
+-rw-r--r--  2.0 unx     4408 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/perf.yaml
+-rw-r--r--  2.0 unx      955 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18/test.py
+-rw-r--r--  2.0 unx      482 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/__init__.py
+-rw-r--r--  2.0 unx      918 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/conftest.py
+-rw-r--r--  2.0 unx      562 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/demo.py
+-rw-r--r--  2.0 unx     8355 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/export.py
+-rw-r--r--  2.0 unx     1343 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/info.yaml
+-rw-r--r--  2.0 unx     3012 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/model.py
+-rw-r--r--  2.0 unx     4411 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/perf.yaml
+-rw-r--r--  2.0 unx      917 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet18_quantized/test.py
+-rw-r--r--  2.0 unx      471 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/__init__.py
+-rw-r--r--  2.0 unx      898 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/conftest.py
+-rw-r--r--  2.0 unx      530 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/demo.py
+-rw-r--r--  2.0 unx     7875 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/export.py
+-rw-r--r--  2.0 unx     1303 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/info.yaml
+-rw-r--r--  2.0 unx      607 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/model.py
+-rw-r--r--  2.0 unx     4418 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/perf.yaml
+-rw-r--r--  2.0 unx      955 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnet50/test.py
+-rw-r--r--  2.0 unx      473 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/__init__.py
+-rw-r--r--  2.0 unx      902 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/conftest.py
+-rw-r--r--  2.0 unx      536 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/demo.py
+-rw-r--r--  2.0 unx     7883 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/export.py
+-rw-r--r--  2.0 unx     1324 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/info.yaml
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/model.py
+-rw-r--r--  2.0 unx     4436 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/perf.yaml
+-rw-r--r--  2.0 unx      897 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101/test.py
+-rw-r--r--  2.0 unx      484 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/__init__.py
+-rw-r--r--  2.0 unx      922 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/conftest.py
+-rw-r--r--  2.0 unx      581 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/demo.py
+-rw-r--r--  2.0 unx     8383 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/export.py
+-rw-r--r--  2.0 unx     1365 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/info.yaml
+-rw-r--r--  2.0 unx     3017 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/model.py
+-rw-r--r--  2.0 unx     3658 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/perf.yaml
+-rw-r--r--  2.0 unx      925 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext101_quantized/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/conftest.py
+-rw-r--r--  2.0 unx      533 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/demo.py
+-rw-r--r--  2.0 unx     7879 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/export.py
+-rw-r--r--  2.0 unx     1322 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/info.yaml
+-rw-r--r--  2.0 unx      704 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/model.py
+-rw-r--r--  2.0 unx     4421 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/perf.yaml
+-rw-r--r--  2.0 unx      840 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50/test.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/__init__.py
+-rw-r--r--  2.0 unx      920 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/conftest.py
+-rw-r--r--  2.0 unx      578 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/demo.py
+-rw-r--r--  2.0 unx     8379 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/export.py
+-rw-r--r--  2.0 unx     1362 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/info.yaml
+-rw-r--r--  2.0 unx     3008 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/model.py
+-rw-r--r--  2.0 unx     3642 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/perf.yaml
+-rw-r--r--  2.0 unx      921 b- defN 24-Apr-16 23:38 qai_hub_models/models/resnext50_quantized/test.py
+-rw-r--r--  2.0 unx      404 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/__init__.py
+-rw-r--r--  2.0 unx     5101 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/app.py
+-rw-r--r--  2.0 unx     1015 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/conftest.py
+-rw-r--r--  2.0 unx     3088 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/demo.py
+-rw-r--r--  2.0 unx    10152 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/export.py
+-rw-r--r--  2.0 unx     1391 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/info.yaml
+-rw-r--r--  2.0 unx    12000 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/model.py
+-rw-r--r--  2.0 unx     3667 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/perf.yaml
+-rw-r--r--  2.0 unx       37 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/requirements.txt
+-rw-r--r--  2.0 unx     3062 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/test.py
+-rw-r--r--  2.0 unx      826 b- defN 24-Apr-16 23:38 qai_hub_models/models/sam/utils.py
+-rw-r--r--  2.0 unx      464 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/__init__.py
+-rw-r--r--  2.0 unx      982 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/conftest.py
+-rw-r--r--  2.0 unx      923 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/demo.py
+-rw-r--r--  2.0 unx     8006 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/export.py
+-rw-r--r--  2.0 unx     1104 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/info.yaml
+-rw-r--r--  2.0 unx     2984 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/model.py
+-rw-r--r--  2.0 unx     4418 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/perf.yaml
+-rw-r--r--  2.0 unx     1471 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5/test.py
+-rw-r--r--  2.0 unx      475 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/__init__.py
+-rw-r--r--  2.0 unx     1002 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/conftest.py
+-rw-r--r--  2.0 unx      990 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/demo.py
+-rw-r--r--  2.0 unx     8167 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/export.py
+-rw-r--r--  2.0 unx     1151 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/info.yaml
+-rw-r--r--  2.0 unx     4269 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/model.py
+-rw-r--r--  2.0 unx     2477 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/perf.yaml
+-rw-r--r--  2.0 unx     2927 b- defN 24-Apr-16 23:38 qai_hub_models/models/sesr_m5_quantized/test.py
+-rw-r--r--  2.0 unx      475 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/__init__.py
+-rw-r--r--  2.0 unx      908 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/conftest.py
+-rw-r--r--  2.0 unx      543 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/demo.py
+-rw-r--r--  2.0 unx     7895 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/export.py
+-rw-r--r--  2.0 unx     1353 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/info.yaml
+-rw-r--r--  2.0 unx      713 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/model.py
+-rw-r--r--  2.0 unx     4427 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/perf.yaml
+-rw-r--r--  2.0 unx      857 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2/test.py
+-rw-r--r--  2.0 unx      584 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/__init__.py
+-rw-r--r--  2.0 unx      928 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/conftest.py
+-rw-r--r--  2.0 unx      588 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/demo.py
+-rw-r--r--  2.0 unx     8375 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/export.py
+-rw-r--r--  2.0 unx     1383 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/info.yaml
+-rw-r--r--  2.0 unx     5989 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/model.py
+-rw-r--r--  2.0 unx     3269 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/perf.yaml
+-rw-r--r--  2.0 unx      899 b- defN 24-Apr-16 23:38 qai_hub_models/models/shufflenet_v2_quantized/test.py
+-rw-r--r--  2.0 unx      396 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/__init__.py
+-rw-r--r--  2.0 unx     3793 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/app.py
+-rw-r--r--  2.0 unx      978 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/conftest.py
+-rw-r--r--  2.0 unx     1657 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/demo.py
+-rw-r--r--  2.0 unx     8141 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/export.py
+-rw-r--r--  2.0 unx     1260 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/info.yaml
+-rw-r--r--  2.0 unx     4770 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/model.py
+-rw-r--r--  2.0 unx     4384 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/perf.yaml
+-rw-r--r--  2.0 unx     1355 b- defN 24-Apr-16 23:38 qai_hub_models/models/sinet/test.py
+-rw-r--r--  2.0 unx      473 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/__init__.py
+-rw-r--r--  2.0 unx      908 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/conftest.py
+-rw-r--r--  2.0 unx      539 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/demo.py
+-rw-r--r--  2.0 unx     7896 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/export.py
+-rw-r--r--  2.0 unx     1325 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/info.yaml
+-rw-r--r--  2.0 unx      696 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/model.py
+-rw-r--r--  2.0 unx     4420 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/perf.yaml
+-rw-r--r--  2.0 unx      851 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1/test.py
+-rw-r--r--  2.0 unx      582 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/__init__.py
+-rw-r--r--  2.0 unx      928 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/conftest.py
+-rw-r--r--  2.0 unx      584 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/demo.py
+-rw-r--r--  2.0 unx     8328 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/export.py
+-rw-r--r--  2.0 unx     1358 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/info.yaml
+-rw-r--r--  2.0 unx     3023 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/model.py
+-rw-r--r--  2.0 unx     4420 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/perf.yaml
+-rw-r--r--  2.0 unx      895 b- defN 24-Apr-16 23:38 qai_hub_models/models/squeezenet1_1_quantized/test.py
+-rw-r--r--  2.0 unx      540 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/__init__.py
+-rw-r--r--  2.0 unx     7966 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/app.py
+-rw-r--r--  2.0 unx     5765 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/demo.py
+-rw-r--r--  2.0 unx     7432 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/export.py
+-rw-r--r--  2.0 unx     1355 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/info.yaml
+-rw-r--r--  2.0 unx     3604 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/model.py
+-rw-r--r--  2.0 unx     6384 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/perf.yaml
+-rw-r--r--  2.0 unx       46 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/requirements.txt
+-rw-r--r--  2.0 unx     1599 b- defN 24-Apr-16 23:38 qai_hub_models/models/stable_diffusion_quantized/test.py
+-rw-r--r--  2.0 unx      404 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/__init__.py
+-rw-r--r--  2.0 unx     4155 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/app.py
+-rw-r--r--  2.0 unx      986 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/conftest.py
+-rw-r--r--  2.0 unx     2847 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/demo.py
+-rw-r--r--  2.0 unx     7762 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/export.py
+-rw-r--r--  2.0 unx     1084 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/info.yaml
+-rw-r--r--  2.0 unx     8406 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/model.py
+-rw-r--r--  2.0 unx     3607 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/perf.yaml
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/requirements.txt
+-rw-r--r--  2.0 unx     2497 b- defN 24-Apr-16 23:38 qai_hub_models/models/stylegan2/test.py
+-rw-r--r--  2.0 unx      471 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/conftest.py
+-rw-r--r--  2.0 unx      531 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/demo.py
+-rw-r--r--  2.0 unx     7899 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/export.py
+-rw-r--r--  2.0 unx     1383 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/info.yaml
+-rw-r--r--  2.0 unx     1241 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/model.py
+-rw-r--r--  2.0 unx     3665 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/perf.yaml
+-rw-r--r--  2.0 unx     1358 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_base/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/__init__.py
+-rw-r--r--  2.0 unx      902 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/conftest.py
+-rw-r--r--  2.0 unx      534 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/demo.py
+-rw-r--r--  2.0 unx     7903 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/export.py
+-rw-r--r--  2.0 unx     1378 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/info.yaml
+-rw-r--r--  2.0 unx     1242 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/model.py
+-rw-r--r--  2.0 unx     3663 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/perf.yaml
+-rw-r--r--  2.0 unx     1364 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_small/test.py
+-rw-r--r--  2.0 unx      471 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/conftest.py
+-rw-r--r--  2.0 unx      531 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/demo.py
+-rw-r--r--  2.0 unx     7899 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/export.py
+-rw-r--r--  2.0 unx     1376 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/info.yaml
+-rw-r--r--  2.0 unx     1241 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/model.py
+-rw-r--r--  2.0 unx     3657 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/perf.yaml
+-rw-r--r--  2.0 unx     1476 b- defN 24-Apr-16 23:38 qai_hub_models/models/swin_tiny/test.py
+-rw-r--r--  2.0 unx      396 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/__init__.py
+-rw-r--r--  2.0 unx    10207 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/app.py
+-rw-r--r--  2.0 unx      892 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/conftest.py
+-rw-r--r--  2.0 unx     1779 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/demo.py
+-rw-r--r--  2.0 unx     9655 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/export.py
+-rw-r--r--  2.0 unx     1370 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/info.yaml
+-rw-r--r--  2.0 unx    10482 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/model.py
+-rw-r--r--  2.0 unx     6534 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/perf.yaml
+-rw-r--r--  2.0 unx       42 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/requirements.txt
+-rw-r--r--  2.0 unx     2357 b- defN 24-Apr-16 23:38 qai_hub_models/models/trocr/test.py
+-rw-r--r--  2.0 unx      348 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/__init__.py
+-rw-r--r--  2.0 unx     1305 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/app.py
+-rw-r--r--  2.0 unx      916 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/conftest.py
+-rw-r--r--  2.0 unx     2509 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/demo.py
+-rw-r--r--  2.0 unx     8189 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/export.py
+-rw-r--r--  2.0 unx     1310 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/info.yaml
+-rw-r--r--  2.0 unx     2666 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/model.py
+-rw-r--r--  2.0 unx     4464 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/perf.yaml
+-rw-r--r--  2.0 unx     1215 b- defN 24-Apr-16 23:38 qai_hub_models/models/unet_segmentation/test.py
+-rw-r--r--  2.0 unx      466 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/__init__.py
+-rw-r--r--  2.0 unx      888 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/conftest.py
+-rw-r--r--  2.0 unx      515 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/demo.py
+-rw-r--r--  2.0 unx     7908 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/export.py
+-rw-r--r--  2.0 unx     1342 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/info.yaml
+-rw-r--r--  2.0 unx      685 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/model.py
+-rw-r--r--  2.0 unx     3652 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/perf.yaml
+-rw-r--r--  2.0 unx      807 b- defN 24-Apr-16 23:38 qai_hub_models/models/vit/test.py
+-rw-r--r--  2.0 unx      444 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/__init__.py
+-rw-r--r--  2.0 unx      912 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/conftest.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/demo.py
+-rw-r--r--  2.0 unx     9707 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/export.py
+-rw-r--r--  2.0 unx     1849 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/info.yaml
+-rw-r--r--  2.0 unx      558 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/model.py
+-rw-r--r--  2.0 unx     6521 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/perf.yaml
+-rw-r--r--  2.0 unx       31 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/requirements.txt
+-rw-r--r--  2.0 unx      696 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_base_en/test.py
+-rw-r--r--  2.0 unx      445 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/__init__.py
+-rw-r--r--  2.0 unx      914 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/conftest.py
+-rw-r--r--  2.0 unx      486 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/demo.py
+-rw-r--r--  2.0 unx     9711 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/export.py
+-rw-r--r--  2.0 unx     1848 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/info.yaml
+-rw-r--r--  2.0 unx      560 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/model.py
+-rw-r--r--  2.0 unx     6509 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/perf.yaml
+-rw-r--r--  2.0 unx       38 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/requirements.txt
+-rw-r--r--  2.0 unx      696 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_small_en/test.py
+-rw-r--r--  2.0 unx      444 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/__init__.py
+-rw-r--r--  2.0 unx      912 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/conftest.py
+-rw-r--r--  2.0 unx      483 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/demo.py
+-rw-r--r--  2.0 unx     9707 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/export.py
+-rw-r--r--  2.0 unx     1849 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/info.yaml
+-rw-r--r--  2.0 unx      558 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/model.py
+-rw-r--r--  2.0 unx     6514 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/perf.yaml
+-rw-r--r--  2.0 unx       31 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/requirements.txt
+-rw-r--r--  2.0 unx      696 b- defN 24-Apr-16 23:38 qai_hub_models/models/whisper_tiny_en/test.py
+-rw-r--r--  2.0 unx      475 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/__init__.py
+-rw-r--r--  2.0 unx      906 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/conftest.py
+-rw-r--r--  2.0 unx      542 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/demo.py
+-rw-r--r--  2.0 unx     7891 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/export.py
+-rw-r--r--  2.0 unx     1298 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/info.yaml
+-rw-r--r--  2.0 unx      710 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/model.py
+-rw-r--r--  2.0 unx     4431 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/perf.yaml
+-rw-r--r--  2.0 unx      855 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50/test.py
+-rw-r--r--  2.0 unx      582 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/__init__.py
+-rw-r--r--  2.0 unx      926 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/conftest.py
+-rw-r--r--  2.0 unx      587 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/demo.py
+-rw-r--r--  2.0 unx     8324 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/export.py
+-rw-r--r--  2.0 unx     1333 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/info.yaml
+-rw-r--r--  2.0 unx     3214 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/model.py
+-rw-r--r--  2.0 unx     4425 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/perf.yaml
+-rw-r--r--  2.0 unx      932 b- defN 24-Apr-16 23:38 qai_hub_models/models/wideresnet50_quantized/test.py
+-rw-r--r--  2.0 unx      461 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/__init__.py
+-rw-r--r--  2.0 unx      976 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/conftest.py
+-rw-r--r--  2.0 unx      742 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/demo.py
+-rw-r--r--  2.0 unx     7994 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/export.py
+-rw-r--r--  2.0 unx     1156 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/info.yaml
+-rw-r--r--  2.0 unx     3403 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/model.py
+-rw-r--r--  2.0 unx     4411 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/perf.yaml
+-rw-r--r--  2.0 unx     1402 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr/test.py
+-rw-r--r--  2.0 unx      472 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/__init__.py
+-rw-r--r--  2.0 unx      996 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/conftest.py
+-rw-r--r--  2.0 unx      956 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/demo.py
+-rw-r--r--  2.0 unx     8447 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/export.py
+-rw-r--r--  2.0 unx     1191 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/info.yaml
+-rw-r--r--  2.0 unx     3915 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/model.py
+-rw-r--r--  2.0 unx     2474 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/perf.yaml
+-rw-r--r--  2.0 unx     1607 b- defN 24-Apr-16 23:38 qai_hub_models/models/xlsr_quantized/test.py
+-rw-r--r--  2.0 unx      436 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/__init__.py
+-rw-r--r--  2.0 unx     1071 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/app.py
+-rw-r--r--  2.0 unx      980 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/conftest.py
+-rw-r--r--  2.0 unx     1027 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/demo.py
+-rw-r--r--  2.0 unx     7897 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/export.py
+-rw-r--r--  2.0 unx     1168 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/info.yaml
+-rw-r--r--  2.0 unx     4686 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/model.py
+-rw-r--r--  2.0 unx     4431 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/perf.yaml
+-rw-r--r--  2.0 unx     1845 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov6/test.py
+-rw-r--r--  2.0 unx      436 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/__init__.py
+-rw-r--r--  2.0 unx     2033 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/app.py
+-rw-r--r--  2.0 unx      980 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/conftest.py
+-rw-r--r--  2.0 unx      909 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/demo.py
+-rw-r--r--  2.0 unx     7917 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/export.py
+-rw-r--r--  2.0 unx     1131 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/info.yaml
+-rw-r--r--  2.0 unx    11831 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/model.py
+-rw-r--r--  2.0 unx     3664 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/perf.yaml
+-rw-r--r--  2.0 unx       83 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/requirements.txt
+-rw-r--r--  2.0 unx     2322 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7/test.py
+-rw-r--r--  2.0 unx      447 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/conftest.py
+-rw-r--r--  2.0 unx      853 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/demo.py
+-rw-r--r--  2.0 unx     8330 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/export.py
+-rw-r--r--  2.0 unx     1318 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/info.yaml
+-rw-r--r--  2.0 unx     4728 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/model.py
+-rw-r--r--  2.0 unx     3270 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/perf.yaml
+-rw-r--r--  2.0 unx       83 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/requirements.txt
+-rw-r--r--  2.0 unx     1558 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov7_quantized/test.py
+-rw-r--r--  2.0 unx      415 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/__init__.py
+-rw-r--r--  2.0 unx      892 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/app.py
+-rw-r--r--  2.0 unx      988 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/conftest.py
+-rw-r--r--  2.0 unx      926 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/demo.py
+-rw-r--r--  2.0 unx     7951 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/export.py
+-rw-r--r--  2.0 unx     1171 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/info.yaml
+-rw-r--r--  2.0 unx     7721 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/model.py
+-rw-r--r--  2.0 unx     2768 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/perf.yaml
+-rw-r--r--  2.0 unx      100 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/requirements.txt
+-rw-r--r--  2.0 unx     2270 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det/test.py
+-rw-r--r--  2.0 unx      459 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/__init__.py
+-rw-r--r--  2.0 unx     1008 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/conftest.py
+-rw-r--r--  2.0 unx      804 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/demo.py
+-rw-r--r--  2.0 unx     8351 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/export.py
+-rw-r--r--  2.0 unx     1354 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/info.yaml
+-rw-r--r--  2.0 unx     3540 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/model.py
+-rw-r--r--  2.0 unx     3279 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/perf.yaml
+-rw-r--r--  2.0 unx      100 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/requirements.txt
+-rw-r--r--  2.0 unx     1542 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_det_quantized/test.py
+-rw-r--r--  2.0 unx      419 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/__init__.py
+-rw-r--r--  2.0 unx     7698 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/app.py
+-rw-r--r--  2.0 unx      902 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/conftest.py
+-rw-r--r--  2.0 unx     3155 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/demo.py
+-rw-r--r--  2.0 unx     7974 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/export.py
+-rw-r--r--  2.0 unx     1287 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/info.yaml
+-rw-r--r--  2.0 unx     4663 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/model.py
+-rw-r--r--  2.0 unx     3665 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/perf.yaml
+-rw-r--r--  2.0 unx       64 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/requirements.txt
+-rw-r--r--  2.0 unx     2536 b- defN 24-Apr-16 23:38 qai_hub_models/models/yolov8_seg/test.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/test/__init__.py
+-rw-r--r--  2.0 unx     1043 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_async_compile_jobs.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/test/e2e/__init__.py
+-rw-r--r--  2.0 unx     1661 b- defN 24-Apr-16 23:38 qai_hub_models/test/e2e/test_aimet_compile.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_utils/__init__.py
+-rw-r--r--  2.0 unx     1493 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_utils/perf.yaml
+-rw-r--r--  2.0 unx     3229 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_utils/test_info_specs.py
+-rw-r--r--  2.0 unx     6525 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_utils/test_perf_summary.py
+-rw-r--r--  2.0 unx     3295 b- defN 24-Apr-16 23:38 qai_hub_models/test/test_utils/test_qai_hub_helpers.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/utils/__init__.py
+-rw-r--r--  2.0 unx    16452 b- defN 24-Apr-16 23:38 qai_hub_models/utils/args.py
+-rw-r--r--  2.0 unx    34094 b- defN 24-Apr-16 23:38 qai_hub_models/utils/asset_loaders.py
+-rw-r--r--  2.0 unx     6052 b- defN 24-Apr-16 23:38 qai_hub_models/utils/base_model.py
+-rw-r--r--  2.0 unx     9261 b- defN 24-Apr-16 23:38 qai_hub_models/utils/bounding_box_processing.py
+-rw-r--r--  2.0 unx     1771 b- defN 24-Apr-16 23:38 qai_hub_models/utils/camera_capture.py
+-rw-r--r--  2.0 unx     5222 b- defN 24-Apr-16 23:38 qai_hub_models/utils/compare.py
+-rw-r--r--  2.0 unx    32743 b- defN 24-Apr-16 23:38 qai_hub_models/utils/config_loaders.py
+-rw-r--r--  2.0 unx     3066 b- defN 24-Apr-16 23:38 qai_hub_models/utils/display.py
+-rw-r--r--  2.0 unx     6403 b- defN 24-Apr-16 23:38 qai_hub_models/utils/draw.py
+-rw-r--r--  2.0 unx     1549 b- defN 24-Apr-16 23:38 qai_hub_models/utils/huggingface.py
+-rw-r--r--  2.0 unx    13246 b- defN 24-Apr-16 23:38 qai_hub_models/utils/image_processing.py
+-rw-r--r--  2.0 unx    12482 b- defN 24-Apr-16 23:38 qai_hub_models/utils/inference.py
+-rw-r--r--  2.0 unx     1308 b- defN 24-Apr-16 23:38 qai_hub_models/utils/input_spec.py
+-rw-r--r--  2.0 unx     4559 b- defN 24-Apr-16 23:38 qai_hub_models/utils/measurement.py
+-rw-r--r--  2.0 unx     1577 b- defN 24-Apr-16 23:38 qai_hub_models/utils/model_adapters.py
+-rw-r--r--  2.0 unx     1406 b- defN 24-Apr-16 23:38 qai_hub_models/utils/path_helpers.py
+-rw-r--r--  2.0 unx     5007 b- defN 24-Apr-16 23:38 qai_hub_models/utils/printing.py
+-rw-r--r--  2.0 unx     5365 b- defN 24-Apr-16 23:38 qai_hub_models/utils/qai_hub_helpers.py
+-rw-r--r--  2.0 unx     1463 b- defN 24-Apr-16 23:38 qai_hub_models/utils/qnn_helpers.py
+-rw-r--r--  2.0 unx     2170 b- defN 24-Apr-16 23:38 qai_hub_models/utils/quantization.py
+-rw-r--r--  2.0 unx    17774 b- defN 24-Apr-16 23:38 qai_hub_models/utils/quantization_aimet.py
+-rw-r--r--  2.0 unx      754 b- defN 24-Apr-16 23:38 qai_hub_models/utils/test_compare.py
+-rw-r--r--  2.0 unx     3173 b- defN 24-Apr-16 23:38 qai_hub_models/utils/testing.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/__init__.py
+-rw-r--r--  2.0 unx      876 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/config_loader.py
+-rw-r--r--  2.0 unx     1233 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/default_config.json
+-rw-r--r--  2.0 unx      946 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/default_config_legacy_v1.json
+-rw-r--r--  2.0 unx      955 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/default_config_legacy_v2.json
+-rw-r--r--  2.0 unx      919 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/default_config_per_channel_qnn.json
+-rw-r--r--  2.0 unx     1187 b- defN 24-Apr-16 23:38 qai_hub_models/utils/aimet/repo.py
+-rw-r--r--  2.0 unx      259 b- defN 24-Apr-16 23:38 qai_hub_models/utils/scorecard/__init__.py
+-rw-r--r--  2.0 unx     1468 b- defN 24-Apr-16 23:38 qai_hub_models/utils/scorecard/common.py
+-rw-r--r--  2.0 unx    12269 b- defN 24-Apr-16 23:38 qai_hub_models/utils/scorecard/job_summary.py
+-rw-r--r--  2.0 unx    13385 b- defN 24-Apr-16 23:38 qai_hub_models/utils/scorecard/model_card.py
+-rw-r--r--  2.0 unx    11415 b- defN 24-Apr-16 23:38 qai_hub_models/utils/scorecard/perf_summary.py
+-rw-r--r--  2.0 unx     1481 b- defN 24-Apr-16 23:40 qai_hub_models-0.5.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    42594 b- defN 24-Apr-16 23:40 qai_hub_models-0.5.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-16 23:40 qai_hub_models-0.5.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       15 b- defN 24-Apr-16 23:40 qai_hub_models-0.5.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    94607 b- defN 24-Apr-16 23:40 qai_hub_models-0.5.0.dist-info/RECORD
+924 files, 2655325 bytes uncompressed, 857463 bytes compressed:  67.7%
```

## zipnote {}

```diff
@@ -2502,14 +2502,41 @@
 
 Filename: qai_hub_models/models/yolov7/requirements.txt
 Comment: 
 
 Filename: qai_hub_models/models/yolov7/test.py
 Comment: 
 
+Filename: qai_hub_models/models/yolov7_quantized/__init__.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/conftest.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/demo.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/export.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/info.yaml
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/model.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/perf.yaml
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/requirements.txt
+Comment: 
+
+Filename: qai_hub_models/models/yolov7_quantized/test.py
+Comment: 
+
 Filename: qai_hub_models/models/yolov8_det/__init__.py
 Comment: 
 
 Filename: qai_hub_models/models/yolov8_det/app.py
 Comment: 
 
 Filename: qai_hub_models/models/yolov8_det/conftest.py
@@ -2532,14 +2559,41 @@
 
 Filename: qai_hub_models/models/yolov8_det/requirements.txt
 Comment: 
 
 Filename: qai_hub_models/models/yolov8_det/test.py
 Comment: 
 
+Filename: qai_hub_models/models/yolov8_det_quantized/__init__.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/conftest.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/demo.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/export.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/info.yaml
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/model.py
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/perf.yaml
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/requirements.txt
+Comment: 
+
+Filename: qai_hub_models/models/yolov8_det_quantized/test.py
+Comment: 
+
 Filename: qai_hub_models/models/yolov8_seg/__init__.py
 Comment: 
 
 Filename: qai_hub_models/models/yolov8_seg/app.py
 Comment: 
 
 Filename: qai_hub_models/models/yolov8_seg/conftest.py
@@ -2637,23 +2691,17 @@
 
 Filename: qai_hub_models/utils/measurement.py
 Comment: 
 
 Filename: qai_hub_models/utils/model_adapters.py
 Comment: 
 
-Filename: qai_hub_models/utils/model_card.py
-Comment: 
-
 Filename: qai_hub_models/utils/path_helpers.py
 Comment: 
 
-Filename: qai_hub_models/utils/perf_summary.py
-Comment: 
-
 Filename: qai_hub_models/utils/printing.py
 Comment: 
 
 Filename: qai_hub_models/utils/qai_hub_helpers.py
 Comment: 
 
 Filename: qai_hub_models/utils/qnn_helpers.py
@@ -2688,23 +2736,38 @@
 
 Filename: qai_hub_models/utils/aimet/default_config_per_channel_qnn.json
 Comment: 
 
 Filename: qai_hub_models/utils/aimet/repo.py
 Comment: 
 
-Filename: qai_hub_models-0.4.1.dist-info/LICENSE
+Filename: qai_hub_models/utils/scorecard/__init__.py
+Comment: 
+
+Filename: qai_hub_models/utils/scorecard/common.py
+Comment: 
+
+Filename: qai_hub_models/utils/scorecard/job_summary.py
+Comment: 
+
+Filename: qai_hub_models/utils/scorecard/model_card.py
+Comment: 
+
+Filename: qai_hub_models/utils/scorecard/perf_summary.py
+Comment: 
+
+Filename: qai_hub_models-0.5.0.dist-info/LICENSE
 Comment: 
 
-Filename: qai_hub_models-0.4.1.dist-info/METADATA
+Filename: qai_hub_models-0.5.0.dist-info/METADATA
 Comment: 
 
-Filename: qai_hub_models-0.4.1.dist-info/WHEEL
+Filename: qai_hub_models-0.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: qai_hub_models-0.4.1.dist-info/top_level.txt
+Filename: qai_hub_models-0.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: qai_hub_models-0.4.1.dist-info/RECORD
+Filename: qai_hub_models-0.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## qai_hub_models/_version.py

```diff
@@ -1,5 +1,5 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
-__version__ = "0.4.1"
+__version__ = "0.5.0"
```

## qai_hub_models/global_requirements.txt

```diff
@@ -18,14 +18,15 @@
 imageio[ffmpeg]==2.31.5
 kornia==0.5.0
 librosa==0.10.1
 matplotlib==3.7.4
 mmcv==2.1.0
 mmdet==3.2.0
 mmpose==1.2.0
+object-detection-metrics==0.4.post1
 openai-whisper==20230314
 pycocotools==2.0.7
 pytorch-lightning==1.6.0
 regex==2023.12.25
 scikit-image==0.21.0
 scikit-learn==1.1.3
 scipy==1.8.1
```

## qai_hub_models/requirements.txt

```diff
@@ -18,8 +18,8 @@
 scipy==1.8.1
 tabulate==0.9.0
 torch==1.13.1
 torchvision==0.14.1
 typing-extensions==4.5.0
 tqdm==4.66.2
 urllib3==1.26.18
-qai_hub>=0.9.0
+qai_hub>=0.10.0
```

## qai_hub_models/datasets/coco.py

```diff
@@ -78,36 +78,40 @@
         )
 
     def __getitem__(self, item):
         image, target = super(CocoDataset, self).__getitem__(item)
         width, height = image.size
         boxes = []
         labels = []
-        if len(target) == 0:
-            return None, (None, None)
         for annotation in target:
             bbox = annotation.get("bbox")
             boxes.append(
                 [
                     bbox[0] / width,
                     bbox[1] / height,
                     (bbox[0] + bbox[2]) / width,
                     (bbox[1] + bbox[3]) / height,
                 ]
             )
             labels.append(self.label_map[annotation.get("category_id")])
         boxes = torch.tensor(boxes)
         labels = torch.tensor(labels)
         image = image.resize(self.target_image_size)
-        image = app_to_net_image_inputs(image)[1]
-        return image, (target[0]["image_id"], height, width, boxes, labels)
+        image = app_to_net_image_inputs(image)[1].squeeze(0)
+        return image, (
+            target[0]["image_id"] if len(target) > 0 else 0,
+            height,
+            width,
+            boxes,
+            labels,
+        )
 
     def _validate_data(self) -> bool:
         # Check validation data exists
-        if not COCO_DATASET.path().exists():
+        if not (COCO_DATASET.path() / "val2017").exists():
             return False
 
         # Check annotations exist
         if not COCO_ANNOTATIONS.path().exists():
             return False
 
         # Ensure there are 5000 samples
```

## qai_hub_models/datasets/common.py

```diff
@@ -28,15 +28,17 @@
         if os.path.exists(self.dataset_path):
             # Data is corrupted, delete and re-download
             if os.path.isdir(self.dataset_path):
                 shutil.rmtree(self.dataset_path)
             else:
                 os.remove(self.dataset_path)
 
+        print("Downloading data")
         self._download_data()
+        print("Done downloading")
         if not self._validate_data():
             raise ValueError("Something went wrong during download.")
 
     @abstractmethod
     def _download_data(self) -> None:
         """
         Method to download necessary data to disk. To be implemented by subclass.
```

## qai_hub_models/evaluators/detection_evaluator.py

```diff
@@ -34,14 +34,23 @@
         self.scale_y = 1 / image_width
 
     def add_batch(self, output: Collection[torch.Tensor], gt: Collection[torch.Tensor]):
         # This evaluator supports 1 output tensor at a time.
         image_id, _, _, bboxes, classes = gt
         pred_boxes, pred_scores, pred_class_idx = output
 
+        if bboxes.numel() == 0:
+            return
+
+        # The number of boxes can be variable, so dataloader doesn't like shapes
+        # mismatching across samples in the batch.
+        assert bboxes.shape[0] == 1, "Detection evaluator only supports batch size 1."
+        bboxes = bboxes.squeeze(0)
+        classes = classes.squeeze(0)
+
         # Seeing memory issues, initentionally deleting these variables to free memory.
         del gt
         del output
 
         # Reuse NMS utility
         (
             after_nms_pred_boxes,
```

## qai_hub_models/models/common.py

```diff
@@ -12,14 +12,18 @@
     TFLITE = 0
     QNN = 1
     ORT = 2
 
     def __str__(self):
         return self.name.lower()
 
+    @property
+    def long_name(self):
+        return f"torchscript_onnx_{self.name.lower()}"
+
 
 class SourceModelFormat(Enum):
     ONNX = 0
     TORCHSCRIPT = 1
 
 
 SampleInputsType = Dict[str, List[np.ndarray]]
```

## qai_hub_models/models/_shared/detr/app.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
-from typing import Callable, Tuple
+from typing import Callable, Optional
 
 import numpy as np
 import torch
-from PIL import Image
-from transformers import DetrImageProcessor
+from PIL.Image import Image, Resampling
 
 from qai_hub_models.models._shared.detr.coco_label_map import LABEL_MAP
 from qai_hub_models.utils.bounding_box_processing import box_xywh_to_xyxy
 from qai_hub_models.utils.draw import draw_box_from_xyxy
-from qai_hub_models.utils.image_processing import app_to_net_image_inputs
+from qai_hub_models.utils.image_processing import (
+    app_to_net_image_inputs,
+    normalize_image_torchvision,
+    preprocess_PIL_image,
+)
 
 
 class DETRApp:
     """
     This class consists of light-weight "app code" that is required to
     perform end to end inference with DETR.
 
@@ -27,22 +30,24 @@
         * Run DETR Inference
         * Convert the raw output into box coordinates and corresponding label and confidence.
     """
 
     def __init__(
         self,
         model: Callable[[torch.Tensor], torch.Tensor],
-        model_image_input_size: Tuple[int, int] | None = None,
+        model_image_height: Optional[int] = None,
+        model_image_width: Optional[int] = None,
     ):
         self.model = model
-        self.model_image_input_size = model_image_input_size
+        self.model_image_height = model_image_height
+        self.model_image_width = model_image_width
 
     def predict(
         self,
-        image: Image.Image,
+        image: Image,
         default_weights: str,
         threshold: float = 0.9,
     ) -> np.ndarray:
         """
         From the provided image or tensor, generate the segmented mask.
 
         Parameters:
@@ -61,26 +66,27 @@
                    Shape is [Number of predictions above threshold]
             label: Labels (class number) for the predicted class.
                    Shape is [Number of predictions above threshold]
             box: Box coordinates (top left and bottom right)
                  Shape is [Number of predictions above threshold x top_left_x, top_left_y, bottom_right_x, bottom_right_y]
 
         """
-        size = (
-            {
-                "width": self.model_image_input_size[1],
-                "height": self.model_image_input_size[0],
-            }
-            if self.model_image_input_size
-            else None
-        )
-
-        image_processor = DetrImageProcessor.from_pretrained(default_weights, size=size)
-        encoding = image_processor(image, return_tensors="pt")
-        outputs = self.model(encoding["pixel_values"], encoding["pixel_mask"].float())
+        # The official detr demo uses resize instead of padding. There is an option
+        # to do padding instead and pass a pixel mask to the model, but we opted for
+        # the simpler route.
+        # https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_attention.ipynb#scrollTo=ZRluxbQYYTEe
+        if self.model_image_height is not None and self.model_image_width is not None:
+            image = image.resize(
+                (self.model_image_width, self.model_image_height),
+                resample=Resampling.BILINEAR,
+            )
+        image_array = normalize_image_torchvision(preprocess_PIL_image(image))
+
+        with torch.no_grad():
+            outputs = self.model(image_array)
         target_sizes = torch.tensor(image.size[::-1]).unsqueeze(0)
 
         out_logits, out_bbox = outputs[0], outputs[1]
         prob = torch.nn.functional.softmax(out_logits, -1)
         scores, labels = prob[..., :-1].max(-1)
 
         # Convert to [x0, y0, x1, y1] format
@@ -93,15 +99,15 @@
         boxes = boxes * scale_fct[:, None, :]
 
         for s, l, b in zip(scores, labels, boxes):
             score = s[s > threshold]
             label = l[s > threshold]
             box = b[s > threshold]
 
-        NHWC_int_numpy_frames, NCHW_fp32_torch_frames = app_to_net_image_inputs(image)
+        NHWC_int_numpy_frames, _ = app_to_net_image_inputs(image)
         for p, (xmin, ymin, xmax, ymax), l in zip(score, box.tolist(), label):
             draw_box_from_xyxy(
                 NHWC_int_numpy_frames[0],
                 (int(xmin), int(ymin)),
                 (int(xmax), int(ymax)),
                 color=(0, 255, 0),
                 size=2,
```

## qai_hub_models/models/_shared/detr/demo.py

```diff
@@ -19,38 +19,43 @@
 from qai_hub_models.utils.base_model import BaseModel
 from qai_hub_models.utils.display import display_or_save_image
 
 
 # Run DETR app end-to-end on a sample image.
 # The demo will display the predicted mask in a window.
 def detr_demo(
-    model: Type[BaseModel],
+    model_cls: Type[BaseModel],
     model_id: str,
     default_weights: str,
     default_image: str | CachedWebAsset,
     is_test: bool = False,
 ):
     # Demo parameters
-    parser = get_model_cli_parser(model)
+    parser = get_model_cli_parser(model_cls)
     parser = get_on_device_demo_parser(parser, add_output_dir=True)
     parser.add_argument(
         "--image",
         type=str,
         default=default_image,
         help="test image file path or URL",
     )
     args = parser.parse_args([] if is_test else None)
     validate_on_device_demo_args(args, model_id)
 
     # Load image & model
-    detr = demo_model_from_cli_args(model, model_id, args)
+    detr = demo_model_from_cli_args(model_cls, model_id, args)
+    if isinstance(detr, model_cls):
+        input_spec = detr.get_input_spec()
+    else:
+        input_spec = model_cls.get_input_spec()
+    (h, w) = input_spec["image"][0][2:]
 
     # Run app to scores, labels and boxes
     img = load_image(args.image)
-    app = DETRApp(detr, model_image_input_size=[img.height, img.width])
+    app = DETRApp(detr, h, w)
     pred_images, _, _, _ = app.predict(img, default_weights)
     pred_image = Image.fromarray(pred_images[0])
 
     # Show the predicted boxes, scores and class names on the image.
     if is_test:
         assert isinstance(pred_image, Image.Image)
     else:
```

## qai_hub_models/models/_shared/detr/model.py

```diff
@@ -26,31 +26,29 @@
 
     @classmethod
     def from_pretrained(cls, ckpt_name: str):
         model = DetrForObjectDetection.from_pretrained(ckpt_name)
         model.eval()
         return cls(model)
 
-    def forward(
-        self, image: torch.Tensor, mask: torch.Tensor
-    ) -> Tuple[torch.Tensor, torch.Tensor]:
+    def forward(self, image: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
         """
         Run DETR on `image` and `mask`, and produce high quality detection results.
 
         Parameters:
             image: Image tensor to run detection on.
             mask: This represents the padding mask. True if padding was applied on that pixel else False.
 
         Returns:
             predictions: Tuple of tensors (logits and coordinates)
                Shape of logit tensor: [1, 100 (number of predictions), 92 (number of classes)]
                Shape of coordinates: [1, 100, 4]
 
         """
-        predictions = self.model(image, mask, return_dict=False)
+        predictions = self.model(image, return_dict=False)
         return predictions
 
     @staticmethod
     def get_input_spec(
         batch_size: int = 1,
         num_channels: int = 3,
         height: int = 480,
@@ -58,9 +56,8 @@
     ) -> InputSpec:
         """
         Returns the input specification (name -> (shape, type). This can be
         used to submit profiling job on Qualcomm AI Hub.
         """
         return {
             "image": ((batch_size, num_channels, height, width), "float32"),
-            "mask": ((batch_size, height, width), "float32"),
         }
```

## qai_hub_models/models/_shared/ffnet_quantized/model.py

```diff
@@ -4,14 +4,15 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import os
 from typing import Type, TypeVar
 
@@ -66,14 +67,16 @@
             ffnet,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=FFNET_AIMET_CONFIG,
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
+
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = cls.default_aimet_encodings()
             load_encodings_to_sim(sim, aimet_encodings)
 
         sim.model.eval()
         return cls(sim)
```

## qai_hub_models/models/_shared/imagenet_classifier/app.py

```diff
@@ -4,68 +4,84 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 import torch
 from PIL.Image import Image
 from torchvision import transforms
 
-from qai_hub_models.models._shared.imagenet_classifier.model import (
-    IMAGENET_DIM,
-    ImagenetClassifier,
-)
+from qai_hub_models.models._shared.imagenet_classifier.model import IMAGENET_DIM
+from qai_hub_models.models.protocols import ExecutableModelProtocol
 from qai_hub_models.utils.image_processing import normalize_image_transform
 
 IMAGENET_TRANSFORM = transforms.Compose(
     [
         transforms.Resize(256),
         transforms.CenterCrop(IMAGENET_DIM),
         transforms.ToTensor(),
-        normalize_image_transform(),
     ]
 )
 
 
-def preprocess_image(image: Image) -> torch.Tensor:
+def preprocess_image(image: Image, normalize: bool = False) -> torch.Tensor:
     """
     Preprocesses images to be run through torch imagenet classifiers
     as prescribed here:
     https://pytorch.org/hub/pytorch_vision_resnet/
     Parameters:
         image: Input image to be run through the classifier model.
+
+        normalize: bool
+            Perform normalization to the standard imagenet mean and standard deviation.
     Returns:
         torch tensor to be directly passed to the model.
     """
     out_tensor: torch.Tensor = IMAGENET_TRANSFORM(image)  # type: ignore
+    if normalize:
+        out_tensor = normalize_image_transform()(out_tensor)
+
     return out_tensor.unsqueeze(0)
 
 
 class ImagenetClassifierApp:
     """
     This class consists of light-weight "app code" that is required to
     perform end to end inference with an ImagenetClassifier.
 
     For a given image input, the app will:
         * Pre-process the image (resize and normalize)
         * Run Imagnet Classification
         * Convert the raw output into probabilities using softmax
     """
 
-    def __init__(self, model: ImagenetClassifier):
+    def __init__(
+        self,
+        model: ExecutableModelProtocol,
+        normalization_in_network: bool = True,
+    ):
+        """
+        Parameters:
+            model: ExecutableModelProtocol
+                The imagenet classifier.
+
+            normalization_in_network: bool
+                Whether the classifier normalizes the input using the standard imagenet mean and standard deviation.
+                If false, the app will preform the normalization in a preprocessing step.
+        """
         self.model = model
+        self.normalization_in_network = normalization_in_network
 
     def predict(self, image: Image) -> torch.Tensor:
         """
         From the provided image or tensor, predict probability distribution
         over the 1k Imagenet classes.
 
         Parameters:
             image: A PIL Image in RGB format.
 
         Returns:
             A (1000,) size torch tensor of probabilities, each one corresponding
             to a different Imagenet1K class.
         """
-
-        input_tensor = preprocess_image(image)
+        input_tensor = preprocess_image(image, not self.normalization_in_network)
         with torch.no_grad():
             output = self.model(input_tensor)
         return torch.softmax(output[0], dim=0)
```

## qai_hub_models/models/_shared/imagenet_classifier/model.py

```diff
@@ -8,14 +8,15 @@
 
 import numpy as np
 import torch
 
 from qai_hub_models.evaluators.base_evaluators import BaseEvaluator
 from qai_hub_models.evaluators.classification_evaluator import ClassificationEvaluator
 from qai_hub_models.utils.base_model import BaseModel
+from qai_hub_models.utils.image_processing import normalize_image_torchvision
 from qai_hub_models.utils.input_spec import InputSpec
 from qai_hub_models.utils.quantization import get_image_quantization_samples
 
 MODEL_ASSET_VERSION = 1
 MODEL_ID = __name__.split(".")[-2]
 IMAGENET_DIM = 224
 
@@ -25,51 +26,73 @@
     Base class for all Imagenet Classifier models within QAI Hub Models.
     """
 
     def __init__(
         self,
         net: torch.nn.Module,
         transform_input: bool = False,
+        normalize_input: bool = True,
     ):
         """
         Basic initializer which takes in a pretrained classifier network.
         Subclasses can choose to implement their own __init__ and forward methods.
+
+        Parameters:
+            net: torch.nn.Module
+                Imagenet classifier network.
+
+            transform_input: bool
+                If True, preprocesses the input according to the method with which it was trained on ImageNet.
+
+            normalize_input: bool
+                Normalize input of the imagenet classifier inside the network
+                instead of requiring it to be done beforehand in a preprocessing step. If set to true, the dynamic
+                range of the image input is [0, 1], which is the standard mapping for floating point images.
+
         """
         super().__init__()
+        self.normalize_input = normalize_input
         self.transform_input = transform_input
         self.net = net
         self.eval()
 
     # Type annotation on image_tensor causes aimet onnx export failure
     def forward(self, image_tensor):
         """
         Predict class probabilities for an input `image`.
 
         Parameters:
             image: A [1, 3, 224, 224] image.
-                   Assumes image has been resized and normalized using the
-                   standard preprocessing method for PyTorch Imagenet models.
-
                    Pixel values pre-processed for encoder consumption.
-                   Range: float[0, 1]
+                   Range: float[0, 1] if self.normalize_input, else ~[-2.5, 2.5]
                    3-channel Color Space: RGB
 
         Returns:
             A [1, 1000] where each value is the log-likelihood of
             the image belonging to the corresponding Imagenet class.
         """
-        if self.transform_input:
-            # This is equivalent but converts better than the built-in.
-            # transform_input should be turned off in torchvision model.
+        if self.normalize_input and self.transform_input:
+            # Combining the norm and transform is mathematically equivalent to: 2(image_tensor) - 1
+            image_tensor = image_tensor * 2 - 1
+        elif self.normalize_input:
+            # Image normalization required before images of range [0, 1] are passed
+            # to a torchvision model.
+            image_tensor = normalize_image_torchvision(image_tensor)
+        elif self.transform_input:
+            # Some torchvision models set parameter transform_input to true by default when they are initialized.
+            #
+            # This is mathematically equivalent to the parameter, but converts better than the built-in.
+            # transform_input should be turned off in torchvision model if this transform is used.
             shape = (1, 3, 1, 1)
             scale = torch.tensor([0.229 / 0.5, 0.224 / 0.5, 0.225 / 0.5]).reshape(shape)
             bias = torch.tensor(
                 [(0.485 - 0.5) / 0.5, (0.456 - 0.5) / 0.5, (0.406 - 0.5) / 0.5]
             ).reshape(shape)
             image_tensor = image_tensor * scale + bias
+
         return self.net(image_tensor)
 
     def get_evaluator(self) -> BaseEvaluator:
         return ClassificationEvaluator()
 
     @staticmethod
     def get_input_spec() -> InputSpec:
```

## qai_hub_models/models/_shared/yolo/app.py

```diff
@@ -122,20 +122,26 @@
         # Input Prep
         NHWC_int_numpy_frames, NCHW_fp32_torch_frames = app_to_net_image_inputs(
             pixel_values_or_image
         )
         self.check_image_size(NCHW_fp32_torch_frames)
 
         # Run prediction
-        if self.model_includes_postprocessing:
-            pred_boxes, pred_scores, pred_class_idx = self.model(NCHW_fp32_torch_frames)
-        else:
-            pred_boxes, pred_scores, pred_class_idx = self.pre_nms_postprocess(
-                self.model(NCHW_fp32_torch_frames)
-            )
+        with torch.no_grad():
+            if self.model_includes_postprocessing:
+                pred_boxes, pred_scores, pred_class_idx = self.model(
+                    NCHW_fp32_torch_frames
+                )
+            else:
+                model_output = self.model(NCHW_fp32_torch_frames)
+                if isinstance(model_output, torch.Tensor):
+                    model_output = (model_output,)
+                pred_boxes, pred_scores, pred_class_idx = self.pre_nms_postprocess(
+                    *model_output
+                )
 
         # Non Maximum Suppression on each batch
         pred_boxes, pred_scores, pred_class_idx = batched_nms(
             self.nms_iou_threshold,
             self.nms_score_threshold,
             pred_boxes,
             pred_scores,
@@ -157,25 +163,26 @@
                     color=(0, 255, 0),
                     size=2,
                 )
 
         return NHWC_int_numpy_frames
 
     def pre_nms_postprocess(
-        self, prediction: torch.Tensor
+        self, *predictions: torch.Tensor
     ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
         """
         Process the output of the YOLO detector for input to NMS.
 
         Parameters:
-            detector_output: torch.Tensor
-                The output of Yolo detection model. Tensor shape varies by model implementation.
+            predictions: torch.Tensor
+                A tuple of tensor outputs from the Yolo detection model.
+                Tensor shapes vary by model implementation.
 
         Returns:
             boxes: torch.Tensor
                 Bounding box locations. Shape is [batch, num preds, 4] where 4 == (x1, y1, x2, y2)
             scores: torch.Tensor
                 class scores multiplied by confidence: Shape is [batch, num_preds]
-            class_idx: torch.tensor
+            class_idx: torch.Tensor
                 Shape is [batch, num_preds] where the last dim is the index of the most probable class of the prediction.
         """
-        return detect_postprocess(prediction)
+        return detect_postprocess(predictions[0])
```

## qai_hub_models/models/_shared/yolo/demo.py

```diff
@@ -45,26 +45,25 @@
     )
     parser.add_argument(
         "--iou-threshold",
         type=float,
         default=0.7,
         help="Intersection over Union (IoU) threshold for NonMaximumSuppression",
     )
-    pargs = parser.parse_args([] if is_test else None)
-    args = pargs
+    args = parser.parse_args([] if is_test else None)
 
     validate_on_device_demo_args(args, model_id)
 
     model = demo_model_from_cli_args(model_type, model_id, args)
 
     app = app_type(
         model,
         args.score_threshold,
         args.iou_threshold,
-        args.include_postprocessing if not is_test else True,
+        args.include_postprocessing,
     )
 
     print("Model Loaded")
     image = load_image(args.image)
     pred_images = app.predict_boxes_from_image(image)
     out = Image.fromarray(pred_images[0])
     if not is_test:
```

## qai_hub_models/models/_shared/yolo/utils.py

```diff
@@ -7,14 +7,38 @@
 import torch
 
 from qai_hub_models.models.common import SampleInputsType
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset, load_image
 from qai_hub_models.utils.image_processing import app_to_net_image_inputs
 
 
+def box_transform_xywh2xyxy_split_input(xy: torch.Tensor, wh: torch.Tensor):
+    """
+    Convert boxes with (xy, wh) layout to (xyxy)
+
+    Parameters:
+        boxes (torch.Tensor): Input boxes with layout (xywh)
+
+    Returns:
+        torch.Tensor: Output box with layout (xyxy)
+            i.e. [top_left_x | top_left_y | bot_right_x | bot_right_y]
+    """
+    cx = xy[..., 0]
+    cy = xy[..., 1]
+    w_2 = wh[..., 0] / 2
+    h_2 = wh[..., 1] / 2
+    # TODO(10344) torch.stack doesn't play nicely with torch.fx.Graph
+    # For now replace with unsqueeze + cat, but long-term would be nice to support it
+    top_left_x = (cx - w_2).unsqueeze(-1)
+    top_left_y = (cy - h_2).unsqueeze(-1)
+    bot_right_x = (cx + w_2).unsqueeze(-1)
+    bot_right_y = (cy + h_2).unsqueeze(-1)
+    return torch.cat((top_left_x, top_left_y, bot_right_x, bot_right_y), -1)
+
+
 def transform_box_layout_xywh2xyxy(boxes: torch.Tensor) -> torch.Tensor:
     """
     Convert boxes with (xywh) layout to (xyxy)
 
     Parameters:
         boxes (torch.Tensor): Input boxes with layout (xywh)
 
@@ -73,14 +97,34 @@
 
     # Get class ID of most likely score.
     scores, class_idx = get_most_likely_score(scores)
 
     return boxes, scores, class_idx
 
 
+def detect_postprocess_split_input(
+    xy: torch.Tensor, wh: torch.Tensor, scores: torch.Tensor
+):
+    """
+    Same as `detect_postprocess` with inputs split into separate tensors.
+    """
+    boxes = box_transform_xywh2xyxy_split_input(xy, wh)
+    conf = scores[:, :, 0:1]
+    scores = scores[:, :, 1:]
+
+    # Combine confidence and scores.
+    scores *= conf
+
+    # Get class ID of most likely score.
+    # (#10357) QNN has a bug where passing a result of Mul into ReduceMax returns all 0s
+    scores, class_idx = torch.max(scores + 1e-10, -1, keepdim=False)
+
+    return boxes, scores, class_idx
+
+
 def get_most_likely_score(scores: torch.Tensor):
     """
     Returns most likely score and class id
 
     Args:
         scores (torch.tensor): final score after post-processing predictions
```

## qai_hub_models/models/aotgan/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.aotgan import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.aotgan.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/aotgan/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: AOT-GAN
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 172572.0
-      throughput: 5.79468279906358
+      inference_time: 172218.0
+      throughput: 5.806593968110186
       estimated_peak_memory_range:
-        min: 2220032
-        max: 5310760
+        min: 3301376
+        max: 6608312
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 235
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 235
-      job_id: jw562w2vg
+      job_id: jlpeelxop
       job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 162527.0
+      throughput: 6.15282383850068
+      estimated_peak_memory_range:
+        min: 4247552
+        max: 34036840
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 275
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 275
+      job_id: jz5w21z35
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jnp1yv18p
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:05:49.549048Z'
-    torchscript_onnx_qnn:
-      inference_time: 162522.0
-      throughput: 6.15301313053002
+    timestamp: '2024-04-16T20:17:31.715297Z'
+  - torchscript_onnx_tflite:
+      inference_time: 126778.0
+      throughput: 7.887803877644386
       estimated_peak_memory_range:
-        min: 3313664
-        max: 38238512
+        min: 2174976
+        max: 256099504
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 275
+        layers_on_npu: 235
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 275
-      job_id: j1pvq7q7g
+        total_layers: 235
+      job_id: jygzo4yo5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 126409.0
-      throughput: 7.910829134001535
+    torchscript_onnx_qnn:
+      inference_time: 119306.0
+      throughput: 8.381808123648433
       estimated_peak_memory_range:
-        min: 2404352
-        max: 254900160
+        min: 3887104
+        max: 166111904
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 235
+        layers_on_npu: 275
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 235
-      job_id: jwgoz8z4p
+        total_layers: 275
+      job_id: jmg9jx2w5
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jvgdez4r5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:07:27.833498Z'
-    torchscript_onnx_qnn:
-      inference_time: 119294.0
-      throughput: 8.382651264942076
+    timestamp: '2024-04-16T20:17:31.716207Z'
+  - torchscript_onnx_ort:
+      inference_time: 6132971.0
+      throughput: 0.16305311080062176
       estimated_peak_memory_range:
-        min: 3862528
-        max: 165145744
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 252043264
+        max: 358570048
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 275
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 275
-      job_id: j7gjdqd7g
+        layers_on_cpu: 234
+        total_layers: 234
+      job_id: jz5w21zm5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.716494Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.716522Z'
```

## qai_hub_models/models/convnext_tiny/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.convnext_tiny import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.convnext_tiny.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ddrnet23_slim/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ddrnet23_slim import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ddrnet23_slim.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ddrnet23_slim/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DDRNet23-Slim
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 6702.0
-      throughput: 149.20919128618323
+      inference_time: 6651.0
+      throughput: 150.35333032626673
       estimated_peak_memory_range:
-        min: 1003520
-        max: 2797288
+        min: 1007616
+        max: 2683032
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 131
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 131
-      job_id: jz5ww4wz5
+      job_id: j0pxndrl5
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:51:44.265591Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jegnl7qq5
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:31.847278Z'
   - torchscript_onnx_tflite:
-      inference_time: 4785.0
-      throughput: 208.9864158829676
+      inference_time: 4569.0
+      throughput: 218.8662727073758
       estimated_peak_memory_range:
-        min: 36864
-        max: 71748864
+        min: 16384
+        max: 71802832
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 131
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 131
-      job_id: jmg90d0qg
+      job_id: jo5mqdk9p
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:51:44.265604Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jopr8nd75
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:31.847348Z'
+  - torchscript_onnx_ort:
+      inference_time: 269630.0
+      throughput: 3.708786114304788
+      estimated_peak_memory_range:
+        min: 28385280
+        max: 79610080
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 105
+        total_layers: 105
+      job_id: jep20vdqg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.847391Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.847396Z'
```

## qai_hub_models/models/deeplabv3_resnet50/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.deeplabv3_resnet50 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.deeplabv3_resnet50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/deeplabv3_resnet50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DeepLabV3-ResNet50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 58066.0
-      throughput: 17.221782110012743
+      inference_time: 58164.0
+      throughput: 17.19276528436834
       estimated_peak_memory_range:
-        min: 12288
-        max: 171781856
+        min: 0
+        max: 172023904
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 96
         layers_on_cpu: 0
         total_layers: 96
-      job_id: jqpyzmrrg
+      job_id: j1pv09nr5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 145136.0
+      throughput: 6.890089295557271
+      estimated_peak_memory_range:
+        min: 770048
+        max: 8676784
+      primary_compute_unit: GPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 82
+        layers_on_cpu: 0
+        total_layers: 82
+      job_id: jlpeelnvp
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jz5w21rm5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:34.908612Z'
+    timestamp: '2024-04-16T20:17:31.913298Z'
+  - torchscript_onnx_tflite:
+      inference_time: 40277.0
+      throughput: 24.828065645405566
+      estimated_peak_memory_range:
+        min: 4358144
+        max: 31124640
+      primary_compute_unit: GPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 96
+        layers_on_cpu: 0
+        total_layers: 96
+      job_id: j7gjzw8e5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 145873.0
-      throughput: 6.855278221466619
+      inference_time: 105275.0
+      throughput: 9.49893137022085
       estimated_peak_memory_range:
-        min: 811008
-        max: 9257648
+        min: 704512
+        max: 27029136
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 82
         layers_on_cpu: 0
         total_layers: 82
-      job_id: j1p8210zp
+      job_id: jygzo40x5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 40355.0
-      throughput: 24.780076818238136
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
       estimated_peak_memory_range:
         min: 0
-        max: 28183312
-      primary_compute_unit: GPU
-      precision: fp16
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 96
+        layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 96
-      job_id: j2p04632g
-      job_status: Passed
+        total_layers: 0
+      job_id: jmg9jxq85
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:14.249826Z'
-    torchscript_onnx_qnn:
-      inference_time: 104946.0
-      throughput: 9.52871000323976
+    timestamp: '2024-04-16T20:17:31.913393Z'
+  - torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
       estimated_peak_memory_range:
-        min: 700416
-        max: 26619552
-      primary_compute_unit: GPU
-      precision: fp16
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 82
+        layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 82
-      job_id: jogkv87yp
-      job_status: Passed
+        total_layers: 0
+      job_id: jnp1yvm7p
+      job_status: Failed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.913409Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.913414Z'
```

## qai_hub_models/models/densenet121/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.densenet121 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.densenet121.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/densenet121/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DenseNet-121
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1615.0
-      throughput: 619.1950464396285
+      inference_time: 1945.0
+      throughput: 514.1388174807198
       estimated_peak_memory_range:
-        min: 20480
-        max: 2339568
+        min: 16384
+        max: 2306688
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 310
+        layers_on_npu: 312
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 310
-      job_id: jn5q0ve7p
+        total_layers: 312
+      job_id: jvgdezmz5
       job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2005.0
+      throughput: 498.75311720698255
+      estimated_peak_memory_range:
+        min: 12288
+        max: 40807680
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 372
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 372
+      job_id: jqp4k921g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jo5mqdl9p
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:44.466434Z'
-    torchscript_onnx_qnn:
-      inference_time: 1442.0
-      throughput: 693.4812760055479
+    timestamp: '2024-04-16T20:17:31.936971Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1282.0
+      throughput: 780.0312012480499
       estimated_peak_memory_range:
-        min: 20480
-        max: 9456304
+        min: 12288
+        max: 95228096
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 370
+        layers_on_npu: 312
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 370
-      job_id: jw562wevg
+        total_layers: 312
+      job_id: jz570789g
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1112.0
-      throughput: 899.2805755395683
+    torchscript_onnx_qnn:
+      inference_time: 1330.0
+      throughput: 751.8796992481203
       estimated_peak_memory_range:
-        min: 12288
-        max: 95054176
+        min: 618496
+        max: 155690704
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 310
+        layers_on_npu: 372
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 310
-      job_id: j1gl4l6e5
+        total_layers: 372
+      job_id: j0pxndzl5
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jegnl7wq5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:29.601699Z'
-    torchscript_onnx_qnn:
-      inference_time: 977.0
-      throughput: 1023.5414534288639
+    timestamp: '2024-04-16T20:17:31.937210Z'
+  - torchscript_onnx_ort:
+      inference_time: 71373.0
+      throughput: 14.010900480573886
       estimated_peak_memory_range:
-        min: 618496
-        max: 148303712
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 12173312
+        max: 150873232
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 370
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 370
-      job_id: j1p3n6vx5
+        layers_on_cpu: 311
+        total_layers: 311
+      job_id: jopr8n775
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.937310Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.937315Z'
```

## qai_hub_models/models/detr_resnet101/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.detr_resnet101 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.detr_resnet101.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/detr_resnet101/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DETR-ResNet101
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 53317.0
-      throughput: 18.755743946583642
+      inference_time: 47978.0
+      throughput: 20.842886322897996
       estimated_peak_memory_range:
-        min: 77824
-        max: 8355272
+        min: 94208
+        max: 9060976
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 954
+        layers_on_npu: 910
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 957
-      job_id: j1pvq707g
+        layers_on_cpu: 0
+        total_layers: 912
+      job_id: jep20vzqg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 26243.0
+      throughput: 38.105399535114124
+      estimated_peak_memory_range:
+        min: 0
+        max: 299546600
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: j2p03vxnp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:52:17.373948Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:31.961967Z'
   - torchscript_onnx_tflite:
-      inference_time: 39536.0
-      throughput: 25.29340348037232
+      inference_time: 35573.0
+      throughput: 28.111207938605123
       estimated_peak_memory_range:
-        min: 1413120
-        max: 263608576
+        min: 28672
+        max: 261178736
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 954
+        layers_on_npu: 910
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 957
-      job_id: j7gjdqz7g
+        layers_on_cpu: 0
+        total_layers: 912
+      job_id: jqpyr7yl5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 19779.0
+      throughput: 50.558673340411545
+      estimated_peak_memory_range:
+        min: 3723264
+        max: 90043392
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: j1p804kog
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:17.373962Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:31.962230Z'
+  - torchscript_onnx_ort:
+      inference_time: 739045.0
+      throughput: 1.353097578631883
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 73416704
+        max: 380529712
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 715
+        total_layers: 715
+      job_id: jogk79knp
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.962413Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.962419Z'
```

## qai_hub_models/models/detr_resnet101_dc5/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.detr_resnet101_dc5 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.detr_resnet101_dc5.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/detr_resnet101_dc5/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DETR-ResNet101-DC5
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 439506.0
-      throughput: 2.2752817936501435
+      inference_time: 407929.0
+      throughput: 2.451406985039063
       estimated_peak_memory_range:
-        min: 8531968
-        max: 17800792
+        min: 7622656
+        max: 15500416
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 955
+        layers_on_npu: 911
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 958
-      job_id: jlpeoye7g
+        layers_on_cpu: 0
+        total_layers: 913
+      job_id: jn5qemdo5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 179129.0
+      throughput: 5.582568986596252
+      estimated_peak_memory_range:
+        min: 2637824
+        max: 309754336
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: jw56ed9yg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:53:12.170672Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:31.985333Z'
   - torchscript_onnx_tflite:
-      inference_time: 331401.0
-      throughput: 3.017492403462874
+      inference_time: 311354.0
+      throughput: 3.2117782331365583
       estimated_peak_memory_range:
-        min: 106496
-        max: 457171760
+        min: 90112
+        max: 447334464
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 955
+        layers_on_npu: 911
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 958
-      job_id: jygz2nozg
+        layers_on_cpu: 0
+        total_layers: 913
+      job_id: j1gl619mg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 135318.0
+      throughput: 7.3899998522000026
+      estimated_peak_memory_range:
+        min: 10055680
+        max: 190681632
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: j1p3vwlng
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:53:12.170686Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:31.985607Z'
+  - torchscript_onnx_ort:
+      inference_time: 1115990.0
+      throughput: 0.8960653769299008
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 74452992
+        max: 382260256
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 715
+        total_layers: 715
+      job_id: jwgok47kp
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:31.985802Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:31.985807Z'
```

## qai_hub_models/models/detr_resnet101_dc5/test.py

```diff
@@ -20,20 +20,20 @@
 )
 
 
 def test_task():
     net = DETRResNet101DC5.from_pretrained(DEFAULT_WEIGHTS)
     img = load_image(IMAGE_ADDRESS)
     _, _, label, _ = DETRApp(net).predict(img, DEFAULT_WEIGHTS)
-    assert set(list(label.numpy())) == {75, 63, 17}
+    assert set(list(label.numpy())) == {75, 65, 17}
 
 
 @pytest.mark.trace
 def test_trace():
     net = DETRResNet101DC5.from_pretrained(DEFAULT_WEIGHTS).convert_to_torchscript()
     img = load_image(IMAGE_ADDRESS)
     _, _, label, _ = DETRApp(net).predict(img, DEFAULT_WEIGHTS)
-    assert set(list(label.numpy())) == {75, 63, 17}
+    assert set(list(label.numpy())) == {75, 65, 17}
 
 
 def test_demo():
     demo_main(is_test=True)
```

## qai_hub_models/models/detr_resnet50/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.detr_resnet50 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.detr_resnet50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/detr_resnet50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DETR-ResNet50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 49534.0
-      throughput: 20.188153591472524
+      inference_time: 39035.0
+      throughput: 25.618035096708084
       estimated_peak_memory_range:
-        min: 1585152
-        max: 11362840
+        min: 1327104
+        max: 9193440
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 886
+        layers_on_npu: 842
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 889
-      job_id: jz5ww42z5
+        layers_on_cpu: 0
+        total_layers: 844
+      job_id: j1pv09yr5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 22280.0
+      throughput: 44.88330341113106
+      estimated_peak_memory_range:
+        min: 1789952
+        max: 205559344
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: jlpeel0vp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:30:45.384076Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:32.016941Z'
   - torchscript_onnx_tflite:
-      inference_time: 36491.0
-      throughput: 27.404017428955086
+      inference_time: 28469.0
+      throughput: 35.12592644631002
       estimated_peak_memory_range:
-        min: 135168
-        max: 216736992
+        min: 1241088
+        max: 215942624
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 886
+        layers_on_npu: 842
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 889
-      job_id: jmg90djqg
+        layers_on_cpu: 0
+        total_layers: 844
+      job_id: j7gjzw6e5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 17238.0
+      throughput: 58.0113702285648
+      estimated_peak_memory_range:
+        min: 3723264
+        max: 80445392
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: jygzo4qx5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:45.384090Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.017229Z'
+  - torchscript_onnx_ort:
+      inference_time: 436940.0
+      throughput: 2.2886437497139194
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 184320
+        max: 280725376
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 664
+        total_layers: 664
+      job_id: jz5w210m5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.017429Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.017434Z'
```

## qai_hub_models/models/detr_resnet50_dc5/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.detr_resnet50_dc5 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.detr_resnet50_dc5.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/detr_resnet50_dc5/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: DETR-ResNet50-DC5
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 428409.0
-      throughput: 2.3342180019560748
+      inference_time: 405395.0
+      throughput: 2.4667299794028046
       estimated_peak_memory_range:
-        min: 6443008
-        max: 14635248
+        min: 339968
+        max: 8125832
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 887
+        layers_on_npu: 843
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 890
-      job_id: jnp126ykg
+        layers_on_cpu: 0
+        total_layers: 845
+      job_id: jmg9jx785
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 174726.0
+      throughput: 5.723246683378547
+      estimated_peak_memory_range:
+        min: 7774208
+        max: 210473208
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: jvgdezyz5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:36:20.165124Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:32.040136Z'
   - torchscript_onnx_tflite:
-      inference_time: 326693.0
-      throughput: 3.060977737508915
+      inference_time: 306266.0
+      throughput: 3.26513553577609
       estimated_peak_memory_range:
-        min: 147456
-        max: 420422096
+        min: 16384
+        max: 412400848
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 887
+        layers_on_npu: 843
         layers_on_gpu: 2
-        layers_on_cpu: 1
-        total_layers: 890
-      job_id: jvgdn2ek5
+        layers_on_cpu: 0
+        total_layers: 845
+      job_id: jnp1yvk7p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 130531.0
+      throughput: 7.66101539097992
+      estimated_peak_memory_range:
+        min: 10014720
+        max: 184574640
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 3
+        layers_on_gpu: 0
+        layers_on_cpu: 5
+        total_layers: 8
+      job_id: jz570719g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:36:20.165138Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.040372Z'
+  - torchscript_onnx_ort:
+      inference_time: 822481.0
+      throughput: 1.2158335572493468
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 83013632
+        max: 364885312
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 664
+        total_layers: 664
+      job_id: jqp4k961g
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.040531Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.040536Z'
```

## qai_hub_models/models/efficientnet_b0/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.efficientnet_b0 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.efficientnet_b0.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/efficientnet_b0/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: EfficientNet-B0
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1218.0
-      throughput: 821.0180623973728
+      inference_time: 1637.0
+      throughput: 610.8735491753207
+      estimated_peak_memory_range:
+        min: 24576
+        max: 18330576
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 245
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 245
+      job_id: j0pxnd8l5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1692.0
+      throughput: 591.016548463357
       estimated_peak_memory_range:
         min: 16384
-        max: 2283088
+        max: 89136624
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 243
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 243
-      job_id: jz57290qp
+      job_id: jegnl7dq5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1847.0
+      throughput: 541.4185165132648
+      estimated_peak_memory_range:
+        min: 12288
+        max: 80485720
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jep20vqqg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:50:13.918223Z'
-    torchscript_onnx_qnn:
-      inference_time: 1223.0
-      throughput: 817.6614881439084
+    timestamp: '2024-04-16T20:17:32.062096Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1177.0
+      throughput: 849.6176720475786
       estimated_peak_memory_range:
-        min: 622592
-        max: 7343432
+        min: 16384
+        max: 70869408
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 241
+        layers_on_npu: 245
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 241
-      job_id: j0px9xnjp
+        total_layers: 245
+      job_id: jo5mqd19p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 907.0
-      throughput: 1102.5358324145534
+    torchscript_onnx_qnn:
+      inference_time: 1180.0
+      throughput: 847.457627118644
       estimated_peak_memory_range:
-        min: 12288
-        max: 70459040
+        min: 0
+        max: 70362624
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 243
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 243
-      job_id: jqp4n3kqg
+      job_id: jopr8nm75
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1299.0
+      throughput: 769.8229407236336
+      estimated_peak_memory_range:
+        min: 761856
+        max: 28745360
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jqpyr7kl5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:57.259137Z'
-    torchscript_onnx_qnn:
-      inference_time: 886.0
-      throughput: 1128.6681715575621
+    timestamp: '2024-04-16T20:17:32.062267Z'
+  - torchscript_onnx_ort:
+      inference_time: 34902.0
+      throughput: 28.651653200389664
       estimated_peak_memory_range:
-        min: 0
-        max: 70990016
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 17244160
+        max: 92564240
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 241
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 241
-      job_id: jo5me8qyp
+        layers_on_cpu: 167
+        total_layers: 167
+      job_id: j2p03v8np
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.062317Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.062323Z'
```

## qai_hub_models/models/esrgan/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.esrgan import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.esrgan.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/esrgan/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ESRGAN
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 73806.0
-      throughput: 13.54903395387909
+      inference_time: 65051.0
+      throughput: 15.372553842369832
       estimated_peak_memory_range:
-        min: 3256320
-        max: 5857168
+        min: 3252224
+        max: 6824744
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 1024
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 1024
-      job_id: jegn0kmv5
+      job_id: j1p804dog
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 65381.0
+      throughput: 15.294963368562732
+      estimated_peak_memory_range:
+        min: 102400
+        max: 104823816
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1026
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1026
+      job_id: jn5qemxo5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 70770.0
+      throughput: 14.130281192595733
+      estimated_peak_memory_range:
+        min: 3174400
+        max: 141778696
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jw56edxyg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:50:06.444234Z'
+    timestamp: '2024-04-16T20:17:32.085976Z'
+  - torchscript_onnx_tflite:
+      inference_time: 51233.0
+      throughput: 19.518669607479556
+      estimated_peak_memory_range:
+        min: 94208
+        max: 579142256
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1024
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1024
+      job_id: jogk79wnp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 69637.0
-      throughput: 14.360182087108864
+      inference_time: 50830.0
+      throughput: 19.673421207948063
       estimated_peak_memory_range:
-        min: 143360
-        max: 108258128
+        min: 102400
+        max: 255173680
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 1026
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 1026
-      job_id: j2p04622g
+      job_id: j1gl61dmg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 50712.0
-      throughput: 19.71919861176842
+    torchscript_onnx_ort:
+      inference_time: 51607.0
+      throughput: 19.37721626911078
       estimated_peak_memory_range:
-        min: 77824
-        max: 582298832
+        min: 6688768
+        max: 197563712
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 1024
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 1024
-      job_id: jqpyzmjrg
+        total_layers: 1
+      job_id: j1p3vwdng
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:55.582636Z'
-    torchscript_onnx_qnn:
-      inference_time: 49723.0
-      throughput: 20.11141725157372
+    timestamp: '2024-04-16T20:17:32.086528Z'
+  - torchscript_onnx_ort:
+      inference_time: 7783834.0
+      throughput: 0.12847139340330227
       estimated_peak_memory_range:
-        min: 1306624
-        max: 256079456
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 140189696
+        max: 373477056
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 1026
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 1026
-      job_id: j1p821mzp
+        layers_on_cpu: 675
+        total_layers: 675
+      job_id: jwgok4xkp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.086691Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.086696Z'
```

## qai_hub_models/models/facebook_denoiser/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.facebook_denoiser import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.facebook_denoiser.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/facebook_denoiser/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Facebook-Denoiser
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 746968.0
-      throughput: 1.338745434878067
+      inference_time: 683713.0
+      throughput: 1.4626019982068499
       estimated_peak_memory_range:
-        min: 379867136
-        max: 382919144
+        min: 380928
+        max: 375423608
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 209
         total_layers: 209
-      job_id: jogkv8qyp
+      job_id: j1pv098r5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 14433398.0
+      throughput: 0.0692837542483066
+      estimated_peak_memory_range:
+        min: 1519616
+        max: 86092704
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 4
+        layers_on_gpu: 0
+        layers_on_cpu: 3
+        total_layers: 7
+      job_id: jlpeelqvp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:25:02.878241Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:32.120738Z'
   - torchscript_onnx_tflite:
-      inference_time: 692152.0
-      throughput: 1.4447693570198454
+      inference_time: 677141.0
+      throughput: 1.476797299233099
       estimated_peak_memory_range:
-        min: 372510720
-        max: 393584320
+        min: 363802624
+        max: 387318224
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 209
         total_layers: 209
-      job_id: jn5q0vr7p
+      job_id: j7gjzw9e5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 10716749.0
+      throughput: 0.09331188030997087
+      estimated_peak_memory_range:
+        min: 19521536
+        max: 273877616
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 4
+        layers_on_gpu: 0
+        layers_on_cpu: 3
+        total_layers: 7
+      job_id: jygzo46x5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:25:02.878255Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.120831Z'
+  - torchscript_onnx_ort:
+      inference_time: 900208.0
+      throughput: 1.1108543803209925
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 297889792
+        max: 352368240
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 107
+        total_layers: 107
+      job_id: jz5w21km5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.120881Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.120888Z'
```

## qai_hub_models/models/fastsam_s/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.fastsam_s import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.fastsam_s.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/fastsam_s/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FastSam-S
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 8735.0
-      throughput: 114.48196908986834
+      inference_time: 8729.0
+      throughput: 114.56065986940085
       estimated_peak_memory_range:
-        min: 7831552
-        max: 10552872
+        min: 7823360
+        max: 10576056
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 288
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 288
-      job_id: jw562wzvg
+      job_id: jmg9jxr85
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 10386.0
+      throughput: 96.28345850182939
+      estimated_peak_memory_range:
+        min: 20791296
+        max: 84541352
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jvgdezkz5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:06:17.970106Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.143732Z'
+  - torchscript_onnx_tflite:
+      inference_time: 6438.0
+      throughput: 155.32774153463808
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 6541312
+        max: 77737344
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 288
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 6461.0
-      throughput: 154.7748026621266
+        total_layers: 288
+      job_id: jnp1yv97p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 7468.0
+      throughput: 133.9046598821639
       estimated_peak_memory_range:
-        min: 6328320
-        max: 76883760
+        min: 24322048
+        max: 63913008
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 288
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 288
-      job_id: j1p3n61x5
+        total_layers: 1
+      job_id: jz5707m9g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:06:17.970119Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.143846Z'
+  - torchscript_onnx_ort:
+      inference_time: 413910.0
+      throughput: 2.4159841511439684
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 66248704
+        max: 155909472
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 201
+        total_layers: 201
+      job_id: jqp4k971g
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.143910Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.143916Z'
```

## qai_hub_models/models/fastsam_x/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.fastsam_x import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.fastsam_x.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/fastsam_x/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FastSam-X
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 51073.0
-      throughput: 19.579817124508057
+      inference_time: 50012.0
+      throughput: 19.995201151723585
       estimated_peak_memory_range:
-        min: 9240576
-        max: 13971912
+        min: 9154560
+        max: 13813200
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 420
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 420
-      job_id: jwgoz8n4p
+      job_id: j0pxndql5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 50171.0
+      throughput: 19.93183313069303
+      estimated_peak_memory_range:
+        min: 24637440
+        max: 351124872
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jegnl74q5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:25:26.476231Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.166599Z'
+  - torchscript_onnx_tflite:
+      inference_time: 36802.0
+      throughput: 27.172436280636923
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 8462336
+        max: 149995872
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 420
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 36142.0
-      throughput: 27.66864036301256
+        total_layers: 420
+      job_id: jo5mqd79p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 36880.0
+      throughput: 27.114967462039047
       estimated_peak_memory_range:
-        min: 98304
-        max: 142182032
+        min: 26107904
+        max: 93739104
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 420
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 420
-      job_id: j1pvq7r7g
+        total_layers: 1
+      job_id: jopr8nr75
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:25:26.476245Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.166760Z'
+  - torchscript_onnx_ort:
+      inference_time: 3463164.0
+      throughput: 0.2887532903437435
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 151404544
+        max: 281837296
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 293
+        total_layers: 293
+      job_id: jep20v1qg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.166866Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.166871Z'
```

## qai_hub_models/models/fcn_resnet50/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.fcn_resnet50 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.fcn_resnet50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/fcn_resnet50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FCN_ResNet50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 8557.0
-      throughput: 116.86338670094659
+      inference_time: 8481.0
+      throughput: 117.91062374719962
       estimated_peak_memory_range:
-        min: 159744
-        max: 7109192
+        min: 4251648
+        max: 6673424
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 84
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 84
-      job_id: jygz2njzg
+      job_id: jqpyr7ll5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 7915.0
+      throughput: 126.34238787113077
+      estimated_peak_memory_range:
+        min: 32768
+        max: 14371224
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 125
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 125
+      job_id: j1p804nog
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 434382.0
+      throughput: 2.3021211744501384
+      estimated_peak_memory_range:
+        min: 229376
+        max: 157385104
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jn5qemno5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:38:36.923072Z'
+    timestamp: '2024-04-16T20:17:32.189836Z'
+  - torchscript_onnx_tflite:
+      inference_time: 6385.0
+      throughput: 156.61707126076743
+      estimated_peak_memory_range:
+        min: 4259840
+        max: 81999104
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 84
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 84
+      job_id: j2p03vwnp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 7883.0
-      throughput: 126.85525815045034
+      inference_time: 5804.0
+      throughput: 172.2949689869056
       estimated_peak_memory_range:
-        min: 20480
-        max: 10311800
+        min: 618496
+        max: 57524672
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 125
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 125
-      job_id: jmg90dyqg
+      job_id: jogk791np
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 6324.0
-      throughput: 158.12776723592663
+    torchscript_onnx_ort:
+      inference_time: 334126.0
+      throughput: 2.9928829244057633
       estimated_peak_memory_range:
-        min: 2187264
-        max: 78458400
+        min: 3608576
+        max: 48710400
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 84
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 84
-      job_id: jz5ww43z5
+        total_layers: 1
+      job_id: j1gl61jmg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:20.209217Z'
-    torchscript_onnx_qnn:
-      inference_time: 5820.0
-      throughput: 171.82130584192439
+    timestamp: '2024-04-16T20:17:32.189943Z'
+  - torchscript_onnx_ort:
+      inference_time: 582919.0
+      throughput: 1.7155042124205937
       estimated_peak_memory_range:
-        min: 618496
-        max: 59720272
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 21987328
+        max: 53068064
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 125
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 125
-      job_id: jnp126wkg
+        layers_on_cpu: 57
+        total_layers: 57
+      job_id: jw56edkyg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.189971Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.189976Z'
```

## qai_hub_models/models/ffnet_122ns_lowres/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_122ns_lowres import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_122ns_lowres.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_122ns_lowres/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-122NS-LowRes
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 9649.0
-      throughput: 103.6376826614157
+      inference_time: 9669.0
+      throughput: 103.42331161443789
       estimated_peak_memory_range:
-        min: 647168
-        max: 2901040
+        min: 675840
+        max: 2991672
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 216
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 216
-      job_id: jvgdn2qk5
+      job_id: j1p3vwyng
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 10768.0
+      throughput: 92.86775631500743
+      estimated_peak_memory_range:
+        min: 6320128
+        max: 41702576
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 348
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 348
+      job_id: j1pv09jr5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 7374.0
+      throughput: 135.61160835367508
+      estimated_peak_memory_range:
+        min: 1433600
+        max: 142206056
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jlpeeljvp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:46.197377Z'
+    timestamp: '2024-04-16T20:17:32.214242Z'
+  - torchscript_onnx_tflite:
+      inference_time: 6839.0
+      throughput: 146.22020763269484
+      estimated_peak_memory_range:
+        min: 569344
+        max: 59671696
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 216
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 216
+      job_id: jwgok4jkp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 10810.0
-      throughput: 92.50693802035153
+      inference_time: 7605.0
+      throughput: 131.49243918474687
       estimated_peak_memory_range:
-        min: 6344704
-        max: 40462128
+        min: 6307840
+        max: 88354272
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 348
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 348
-      job_id: jqp4n3dqg
+      job_id: j7gjzwje5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 6923.0
-      throughput: 144.4460494005489
+    torchscript_onnx_ort:
+      inference_time: 5809.0
+      throughput: 172.14666896195558
       estimated_peak_memory_range:
-        min: 405504
-        max: 60494448
+        min: 61464576
+        max: 106276496
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 216
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 216
-      job_id: jz5729lqp
+        total_layers: 1
+      job_id: jygzo41x5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:30.896664Z'
-    torchscript_onnx_qnn:
-      inference_time: 7600.0
-      throughput: 131.57894736842104
+    timestamp: '2024-04-16T20:17:32.214416Z'
+  - torchscript_onnx_ort:
+      inference_time: 284999.0
+      throughput: 3.508784241348215
       estimated_peak_memory_range:
-        min: 6307840
-        max: 86339936
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 27045888
+        max: 100533632
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 348
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 348
-      job_id: j0px9x6jp
+        layers_on_cpu: 151
+        total_layers: 151
+      job_id: jz5w21jm5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.214474Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.214480Z'
```

## qai_hub_models/models/ffnet_40s/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_40s import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_40s.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_40s/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-40S
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 22812.0
-      throughput: 43.836577240049095
+      inference_time: 23048.0
+      throughput: 43.38771259979174
       estimated_peak_memory_range:
-        min: 2555904
-        max: 5191296
+        min: 0
+        max: 30911488
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 92
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 92
-      job_id: jo5me86yp
+      job_id: jmg9jx685
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 17363.0
+      throughput: 57.59373380176237
+      estimated_peak_memory_range:
+        min: 25214976
+        max: 44166488
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 140
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 140
+      job_id: jvgdezjz5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 28590.0
+      throughput: 34.97726477789437
+      estimated_peak_memory_range:
+        min: 30191616
+        max: 118917360
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jx6m5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:28.301836Z'
+    timestamp: '2024-04-16T20:17:32.239491Z'
+  - torchscript_onnx_tflite:
+      inference_time: 16867.0
+      throughput: 59.28736586233474
+      estimated_peak_memory_range:
+        min: 32768
+        max: 105460576
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 92
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 92
+      job_id: jnp1yvr7p
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 17334.0
-      throughput: 57.69008884273682
+      inference_time: 12552.0
+      throughput: 79.66857871255577
       estimated_peak_memory_range:
-        min: 25214976
-        max: 45212320
+        min: 25202688
+        max: 84533840
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 140
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 140
-      job_id: jep2xelxg
+      job_id: jz5w21j45
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 16599.0
-      throughput: 60.24459304777396
+    torchscript_onnx_ort:
+      inference_time: 20354.0
+      throughput: 49.13039206052864
       estimated_peak_memory_range:
-        min: 16384
-        max: 106444032
+        min: 352256
+        max: 45279760
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 92
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 92
-      job_id: jopr6wevp
+        total_layers: 1
+      job_id: jnp1yvrnp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:52.508368Z'
-    torchscript_onnx_qnn:
-      inference_time: 12563.0
-      throughput: 79.59882193743533
+    timestamp: '2024-04-16T20:17:32.239587Z'
+  - torchscript_onnx_ort:
+      inference_time: 1282872.0
+      throughput: 0.7795009946432692
       estimated_peak_memory_range:
-        min: 25210880
-        max: 86653840
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 14479360
+        max: 54572560
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 140
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 140
-      job_id: jqpyzm6rg
+        layers_on_cpu: 67
+        total_layers: 67
+      job_id: jvgdezj65
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.239615Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.239621Z'
```

## qai_hub_models/models/ffnet_40s_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_40s_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_40s_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_40s_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-40S-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 6451.0
-      throughput: 155.0147263990079
+      inference_time: 6424.0
+      throughput: 155.6662515566625
       estimated_peak_memory_range:
-        min: 872448
-        max: 25600304
+        min: 651264
+        max: 25140680
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 97
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 97
-      job_id: jogkv83yp
+      job_id: jz5707qng
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 50173.0
+      throughput: 19.93103860642178
+      estimated_peak_memory_range:
+        min: 29384704
+        max: 58656168
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j0pxndw85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:52:22.278215Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.269874Z'
+  - torchscript_onnx_tflite:
+      inference_time: 4623.0
+      throughput: 216.3097555699762
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 20480
+        max: 67550048
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 97
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 4634.0
-      throughput: 215.79628830384118
+        total_layers: 97
+      job_id: jqp4k9z2g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 31095.0
+      throughput: 32.15951117543013
       estimated_peak_memory_range:
-        min: 180224
-        max: 67612432
+        min: 31465472
+        max: 65073664
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 97
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 97
-      job_id: jn5q0v37p
+        total_layers: 1
+      job_id: jo5mqdj7p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:22.278229Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.269932Z'
+  - torchscript_onnx_ort:
+      inference_time: 362244.0
+      throughput: 2.7605702233853426
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 159432704
+        max: 207613904
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 92
+        total_layers: 92
+      job_id: jegnl7jj5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.269964Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.269969Z'
```

## qai_hub_models/models/ffnet_54s/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_54s import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_54s.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_54s/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-54S
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 25516.0
-      throughput: 39.191095783038094
+      inference_time: 25024.0
+      throughput: 39.9616368286445
       estimated_peak_memory_range:
-        min: 3219456
-        max: 5162680
+        min: 2580480
+        max: 5287928
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 113
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 113
-      job_id: jw562wnvg
+      job_id: jopr8nzk5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 19758.0
+      throughput: 50.61241016297196
+      estimated_peak_memory_range:
+        min: 25214976
+        max: 48724312
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 175
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 175
+      job_id: jqpyr7905
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 30799.0
+      throughput: 32.46858664242345
+      estimated_peak_memory_range:
+        min: 30203904
+        max: 103625272
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p804oqg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:41.754790Z'
+    timestamp: '2024-04-16T20:17:32.293297Z'
+  - torchscript_onnx_tflite:
+      inference_time: 18446.0
+      throughput: 54.21229534858506
+      estimated_peak_memory_range:
+        min: 1429504
+        max: 120768592
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 113
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 113
+      job_id: jep20v26g
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 20433.0
-      throughput: 48.94043948514658
+      inference_time: 14552.0
+      throughput: 68.71907641561297
       estimated_peak_memory_range:
-        min: 25186304
-        max: 50574640
+        min: 180420608
+        max: 252953088
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 175
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 175
-      job_id: jwgoz834p
+      job_id: j2p03vy0p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 18562.0
-      throughput: 53.87350501023597
+    torchscript_onnx_ort:
+      inference_time: 23498.0
+      throughput: 42.556813345816664
       estimated_peak_memory_range:
-        min: 2244608
-        max: 122307680
+        min: 30953472
+        max: 85531952
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 113
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 113
-      job_id: j1p3n6ex5
+        total_layers: 1
+      job_id: jogk79zvp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:03:03.931513Z'
-    torchscript_onnx_qnn:
-      inference_time: 14524.0
-      throughput: 68.85155604516662
+    timestamp: '2024-04-16T20:17:32.293402Z'
+  - torchscript_onnx_ort:
+      inference_time: 1491103.0
+      throughput: 0.6706444826413736
       estimated_peak_memory_range:
-        min: 231440384
-        max: 301103936
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 131444736
+        max: 181106624
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 175
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 175
-      job_id: j1pvq7v7g
+        layers_on_cpu: 81
+        total_layers: 81
+      job_id: jn5qem8e5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.293435Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.293440Z'
```

## qai_hub_models/models/ffnet_54s_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_54s_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_54s_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_54s_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-54S-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 7122.0
-      throughput: 140.40999719180004
+      inference_time: 7125.0
+      throughput: 140.35087719298247
       estimated_peak_memory_range:
-        min: 823296
-        max: 9540112
+        min: 647168
+        max: 2562192
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 118
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 118
-      job_id: j7gjdqe7g
+      job_id: j1gl61n2g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 51385.0
+      throughput: 19.46093217865136
+      estimated_peak_memory_range:
+        min: 29982720
+        max: 70964288
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p3vwkmg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:24:42.915036Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.317104Z'
+  - torchscript_onnx_tflite:
+      inference_time: 5099.0
+      throughput: 196.11688566385567
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 16384
+        max: 75082320
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 118
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 5147.0
-      throughput: 194.28793471925394
+        total_layers: 118
+      job_id: jw56ed6ng
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 31008.0
+      throughput: 32.24974200206398
       estimated_peak_memory_range:
-        min: 233472
-        max: 74819648
+        min: 15433728
+        max: 55696624
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 118
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 118
-      job_id: jz5ww4qz5
+        total_layers: 1
+      job_id: jwgok4y1p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:24:42.915050Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.317196Z'
+  - torchscript_onnx_ort:
+      inference_time: 420355.0
+      throughput: 2.3789416088782103
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 187011072
+        max: 248380464
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 113
+        total_layers: 113
+      job_id: j1pv093z5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.317235Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.317241Z'
```

## qai_hub_models/models/ffnet_78s/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_78s import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_78s.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_78s/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-78S
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 29260.0
-      throughput: 34.17634996582365
+      inference_time: 29177.0
+      throughput: 34.27357164890153
       estimated_peak_memory_range:
-        min: 2568192
-        max: 5238920
+        min: 2576384
+        max: 5205816
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 149
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 149
-      job_id: jmg90dwqg
+      job_id: j7gjzwx15
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 23420.0
+      throughput: 42.69854824935952
+      estimated_peak_memory_range:
+        min: 24846336
+        max: 48603008
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 235
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 235
+      job_id: jygzo4e45
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 35439.0
+      throughput: 28.21750049380626
+      estimated_peak_memory_range:
+        min: 30183424
+        max: 150703648
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jxvm5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:40.352259Z'
+    timestamp: '2024-04-16T20:17:32.338018Z'
+  - torchscript_onnx_tflite:
+      inference_time: 21728.0
+      throughput: 46.02356406480118
+      estimated_peak_memory_range:
+        min: 0
+        max: 133794256
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 149
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 149
+      job_id: jlpeel98p
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 23452.0
-      throughput: 42.64028654272557
+      inference_time: 17745.0
+      throughput: 56.353902507748664
       estimated_peak_memory_range:
-        min: 24997888
-        max: 45509104
+        min: 25317376
+        max: 101665296
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 235
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 235
-      job_id: jvgdn2ok5
+      job_id: jz5w21o45
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 21325.0
-      throughput: 46.893317702227435
+    torchscript_onnx_ort:
+      inference_time: 26731.0
+      throughput: 37.40974898058434
       estimated_peak_memory_range:
-        min: 1220608
-        max: 135944608
+        min: 29417472
+        max: 90195264
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 149
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 149
-      job_id: jnp126ekg
+        total_layers: 1
+      job_id: jnp1yv0np
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:22.141498Z'
-    torchscript_onnx_qnn:
-      inference_time: 17797.0
-      throughput: 56.18924537843457
+    timestamp: '2024-04-16T20:17:32.338159Z'
+  - torchscript_onnx_ort:
+      inference_time: 1954272.0
+      throughput: 0.5116994973064138
       estimated_peak_memory_range:
-        min: 228487168
-        max: 306923024
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 148189184
+        max: 208699488
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 235
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 235
-      job_id: jz5ww4qj5
+        layers_on_cpu: 105
+        total_layers: 105
+      job_id: jvgdezw65
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.338194Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.338199Z'
```

## qai_hub_models/models/ffnet_78s_lowres/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_78s_lowres import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_78s_lowres.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_78s_lowres/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-78S-LowRes
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 10717.0
-      throughput: 93.30969487729774
+      inference_time: 10805.0
+      throughput: 92.5497454881999
       estimated_peak_memory_range:
-        min: 663552
-        max: 2911376
+        min: 667648
+        max: 2943392
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 149
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 149
-      job_id: jmg90dwvg
+      job_id: jz5707zng
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 11389.0
+      throughput: 87.80402142418123
+      estimated_peak_memory_range:
+        min: 32768
+        max: 63143120
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 236
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 236
+      job_id: j0pxndv85
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 7820.0
+      throughput: 127.8772378516624
+      estimated_peak_memory_range:
+        min: 2232320
+        max: 124968440
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jegnl72j5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:39.163437Z'
+    timestamp: '2024-04-16T20:17:32.360398Z'
+  - torchscript_onnx_tflite:
+      inference_time: 7620.0
+      throughput: 131.23359580052494
+      estimated_peak_memory_range:
+        min: 299008
+        max: 53659920
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 149
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 149
+      job_id: jqp4k9q2g
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 11424.0
-      throughput: 87.53501400560224
+      inference_time: 7996.0
+      throughput: 125.06253126563281
       estimated_peak_memory_range:
-        min: 40960
-        max: 53367328
+        min: 6324224
+        max: 70041552
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 236
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 236
-      job_id: jvgdn2ol5
+      job_id: jo5mqdr7p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 7571.0
-      throughput: 132.0829480914014
+    torchscript_onnx_ort:
+      inference_time: 5925.0
+      throughput: 168.77637130801688
       estimated_peak_memory_range:
-        min: 45056
-        max: 50924912
+        min: 6332416
+        max: 48029072
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 149
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 149
-      job_id: jnp126elg
+        total_layers: 1
+      job_id: jopr8nkk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:20.871561Z'
-    torchscript_onnx_qnn:
-      inference_time: 7980.0
-      throughput: 125.31328320802005
+    timestamp: '2024-04-16T20:17:32.360526Z'
+  - torchscript_onnx_ort:
+      inference_time: 393606.0
+      throughput: 2.540611677667515
       estimated_peak_memory_range:
-        min: 6307840
-        max: 71292128
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 18964480
+        max: 72131520
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 236
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 236
-      job_id: jz5729drp
+        layers_on_cpu: 106
+        total_layers: 106
+      job_id: jep20v86g
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.360568Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.360574Z'
```

## qai_hub_models/models/ffnet_78s_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.ffnet_78s_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.ffnet_78s_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/ffnet_78s_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: FFNet-78S-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 8383.0
-      throughput: 119.28903733746868
+      inference_time: 8382.0
+      throughput: 119.30326890956812
       estimated_peak_memory_range:
-        min: 692224
-        max: 40285240
+        min: 688128
+        max: 2625256
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 154
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 154
-      job_id: jqp4n3wlg
+      job_id: jqpyr7e05
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 53059.0
+      throughput: 18.846943968035582
+      estimated_peak_memory_range:
+        min: 30326784
+        max: 75211072
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p8049qg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:19:19.002436Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.383420Z'
+  - torchscript_onnx_tflite:
+      inference_time: 5988.0
+      throughput: 167.000668002672
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 20480
+        max: 87117952
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 154
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 5978.0
-      throughput: 167.2800267648043
+        total_layers: 154
+      job_id: j2p03vq0p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 31534.0
+      throughput: 31.71180313312615
       estimated_peak_memory_range:
-        min: 28672
-        max: 87145904
+        min: 31961088
+        max: 77114832
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 154
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 154
-      job_id: j0px9x19p
+        total_layers: 1
+      job_id: jogk79nvp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:19.002449Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.383520Z'
+  - torchscript_onnx_ort:
+      inference_time: 547799.0
+      throughput: 1.825487085591613
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 166916096
+        max: 242608960
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 149
+        total_layers: 149
+      job_id: jn5qemke5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.383573Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.383578Z'
```

## qai_hub_models/models/googlenet/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.googlenet import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.googlenet.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/googlenet/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: GoogLeNet
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1043.0
-      throughput: 958.7727708533077
+      inference_time: 1044.0
+      throughput: 957.8544061302682
       estimated_peak_memory_range:
-        min: 12288
-        max: 2222648
+        min: 28672
+        max: 2002104
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 84
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 84
-      job_id: j2p046reg
+      job_id: jnp1yvlnp
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1075.0
+      throughput: 930.2325581395348
+      estimated_peak_memory_range:
+        min: 20480
+        max: 26621784
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 143
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 143
+      job_id: jz5707wng
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1293.0
+      throughput: 773.3952049497293
+      estimated_peak_memory_range:
+        min: 12288
+        max: 46074600
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j0pxndj85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:44:36.230603Z'
+    timestamp: '2024-04-16T20:17:32.443133Z'
+  - torchscript_onnx_tflite:
+      inference_time: 650.0
+      throughput: 1538.4615384615386
+      estimated_peak_memory_range:
+        min: 16384
+        max: 45786064
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 84
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 84
+      job_id: jvgdez965
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 1085.0
-      throughput: 921.6589861751152
+      inference_time: 693.0
+      throughput: 1443.001443001443
       estimated_peak_memory_range:
-        min: 28672
-        max: 26694664
+        min: 0
+        max: 53494384
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 143
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 143
-      job_id: jogkv8yop
+      job_id: jqp4k9o2g
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 685.0
-      throughput: 1459.85401459854
+    torchscript_onnx_ort:
+      inference_time: 852.0
+      throughput: 1173.7089201877934
       estimated_peak_memory_range:
-        min: 12288
-        max: 45701264
+        min: 618496
+        max: 24414912
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 84
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 84
-      job_id: j1p82178p
+        total_layers: 1
+      job_id: jo5mqd27p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:47:18.152147Z'
-    torchscript_onnx_qnn:
-      inference_time: 694.0
-      throughput: 1440.922190201729
+    timestamp: '2024-04-16T20:17:32.443243Z'
+  - torchscript_onnx_ort:
+      inference_time: 41981.0
+      throughput: 23.820299659369716
       estimated_peak_memory_range:
-        min: 618496
-        max: 54284752
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 0
+        max: 44006304
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 143
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 143
-      job_id: jn5q0v2mp
+        layers_on_cpu: 84
+        total_layers: 84
+      job_id: jegnl7yj5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.443281Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.443286Z'
```

## qai_hub_models/models/googlenet_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.googlenet_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.googlenet_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/googlenet_quantized/model.py

```diff
@@ -16,32 +16,36 @@
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.googlenet.model import GoogLeNet
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
-from qai_hub_models.utils.quantization_aimet import tie_aimet_observer_groups
+from qai_hub_models.utils.quantization_aimet import (
+    constrain_quantized_inputs_to_image_range,
+    tie_aimet_observer_groups,
+)
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 2
+MODEL_ASSET_VERSION = 4
 DEFAULT_ENCODINGS = "googlenet_quantized_encodings.json"
 
 
 class GoogLeNetQuantizable(AIMETQuantizableMixin, GoogLeNet):
     """GoogleNet with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        GoogLeNet.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        GoogLeNet.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -65,14 +69,15 @@
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
         cls._tie_pre_concat_quantizers(sim)
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/googlenet_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: GoogLeNetQuantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 290.0
-      throughput: 3448.2758620689656
+      inference_time: 297.0
+      throughput: 3367.003367003367
       estimated_peak_memory_range:
         min: 12288
-        max: 1574472
+        max: 1529584
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 85
+        layers_on_npu: 84
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 85
-      job_id: j1gl4lkl5
+        total_layers: 84
+      job_id: jopr8nqk5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 346.0
+      throughput: 2890.173410404624
+      estimated_peak_memory_range:
+        min: 16384
+        max: 139797592
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 86
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 86
+      job_id: jogk79mvp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 756.0
+      throughput: 1322.7513227513227
+      estimated_peak_memory_range:
+        min: 12288
+        max: 22997816
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1gl61r2g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:10:55.550466Z'
+    timestamp: '2024-04-16T20:17:32.468801Z'
+  - torchscript_onnx_tflite:
+      inference_time: 229.0
+      throughput: 4366.812227074236
+      estimated_peak_memory_range:
+        min: 12288
+        max: 32807600
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 84
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 84
+      job_id: jqpyr7w05
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 337.0
-      throughput: 2967.359050445104
+      inference_time: 242.0
+      throughput: 4132.231404958678
       estimated_peak_memory_range:
-        min: 73728
-        max: 4963272
+        min: 163840
+        max: 41416608
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 86
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 86
-      job_id: jwgoz8vdp
+      job_id: jn5qemoe5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 208.0
-      throughput: 4807.692307692308
+    torchscript_onnx_ort:
+      inference_time: 547.0
+      throughput: 1828.1535648994516
       estimated_peak_memory_range:
-        min: 12288
-        max: 33584240
+        min: 3473408
+        max: 30390976
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 85
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 85
-      job_id: j1p3n6mz5
+        total_layers: 1
+      job_id: jw56edlng
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:12:28.573393Z'
-    torchscript_onnx_qnn:
-      inference_time: 248.0
-      throughput: 4032.2580645161293
+    timestamp: '2024-04-16T20:17:32.468895Z'
+  - torchscript_onnx_ort:
+      inference_time: 10247.0
+      throughput: 97.58953840148337
       estimated_peak_memory_range:
-        min: 163840
-        max: 44949040
-      primary_compute_unit: NPU
-      precision: int8
+        min: 2646016
+        max: 50596416
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 86
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 86
-      job_id: j1pvq7wmg
+        layers_on_cpu: 95
+        total_layers: 95
+      job_id: j1p3vw2mg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.468936Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.468942Z'
```

## qai_hub_models/models/hrnet_pose/app.py

```diff
@@ -29,29 +29,41 @@
         batch_heatmaps, np.ndarray
     ), "batch_heatmaps should be numpy.ndarray"
     assert batch_heatmaps.ndim == 4, "batch_images should be 4-ndim"
 
     batch_size = batch_heatmaps.shape[0]
     num_joints = batch_heatmaps.shape[1]
     width = batch_heatmaps.shape[3]
+
+    # shape [batch, num joints, image h * w]
     heatmaps_reshaped = batch_heatmaps.reshape((batch_size, num_joints, -1))
+
+    # index of max pixel per joint
     idx = np.argmax(heatmaps_reshaped, 2)
+
+    # value of max pixel per joint
     maxvals = np.amax(heatmaps_reshaped, 2)
 
+    # Reshape to prep for tiling
     maxvals = maxvals.reshape((batch_size, num_joints, 1))
     idx = idx.reshape((batch_size, num_joints, 1))
 
+    # Tile indices to make room for (x, y)
     preds = np.tile(idx, (1, 1, 2)).astype(np.float32)
 
+    # Convert index [..., 0] to x
     preds[:, :, 0] = (preds[:, :, 0]) % width
+    # Convert [..., 1] to y
     preds[:, :, 1] = np.floor((preds[:, :, 1]) / width)
 
+    # Tile mask back to (x, y) plane to ignore negatives
     pred_mask = np.tile(np.greater(maxvals, 0.0), (1, 1, 2))
     pred_mask = pred_mask.astype(np.float32)
 
+    # apply mask
     preds *= pred_mask
     return preds, maxvals
 
 
 class HRNetPoseApp:
     """
     This class consists of light-weight "app code" that is required to perform end to end inference with LiteHRNet.
@@ -106,47 +118,77 @@
                 keypoints: np.ndarray, shape [B, N, 2]
                     Numpy array of keypoints within the images Each keypoint is an (x, y) pair of coordinates within the image.
 
             Otherwise, returns:
                 predicted_images: List[PIL.Image]
                     Images with keypoints drawn.
         """
-        # Preprocess image to get data required for post processing
+        # Convert from PIL / torch/ etc. to NHWC, RGB numpy frames, which is the required input type.
         NHWC_int_numpy_frames, _ = app_to_net_image_inputs(pixel_values_or_image)
+
+        # MMPose does a lot of heavy lifting here. The preprocessor does the following:
+        # * runs a detetor model to find people in each frame
+        # * for each bounding box...
+        # *     crop to the bounding box. resize bounding box to fit model input size using scaling factor
+        # *     Save bounding box coordinates and box scaling factor for use later
         inputs = self.inferencer.preprocess(NHWC_int_numpy_frames, batch_size=1)
+
+        # We only get the first (highest probability) box and ignore the others.
+        # Other implementations may choose to run pose estimation on all boxes
+        # if they want to support multiple people in the same frame.
         proc_inputs, _ = list(inputs)[0]
         proc_inputs_ = proc_inputs["inputs"][0]
 
+        # RGB -> BGR
         x = proc_inputs_[[2, 1, 0], ...]
+        # Convert to expected model input distrubtion
         x = (x - self.pre_processor.mean) / self.pre_processor.std
+        # Add batch dimension
         x = torch.unsqueeze(x, 0)
 
         # run inference
         heatmaps = self.model(x)
         heatmaps = heatmaps.detach().numpy()
 
         # create predictions from heatmap
         pred_kps, scores = get_max_preds(heatmaps)
 
-        # get the bounding box center from the preprocessing
-        # In older versions of the MM modules the center is directly a member
-        # of gt_instances and does not need to be computed.
+        # Coordinates are relative to the cropped bbox, not the original image.
+        # We need to grab the box center and scale to transform the coordinates
+        # back to the original image.
         bbox = proc_inputs["data_samples"][0].gt_instances.bboxes[0]
         center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
-
         scale = proc_inputs["data_samples"][0].gt_instances.bbox_scales[0]
 
-        # perform refinement
+        # Refine keypoints.
+        # Move 1px towards the "second maximum".
+        #
+        # A key insight here is because this is a heatmap, the second maximum should be adjacent to the maximum.
+        # It's accounting for if the "real" pixel is in-between the first and second maxima in a heatmap "hot spot",
+        # considering the heatmap is lower resolution than the input image to the model (this is the cropped bbox image,
+        # not the entire image provided by the user).
+        #
+        # There could theoretically be a second maximum somewhere completely different in the frame.
+        # That said, moving your keypoint in that direction would not assist the keypoint prediction,
+        # since the "second maximum" refers to a different prediction area entirely.
         keypoints = refine_keypoints(pred_kps, np.squeeze(heatmaps))
+
+        # Multiply by the downscaling factor of model output. In other words, the predicted heatmap is
+        # 1/16 the size of the network input image (or 1/4 in each dimension). Therefore, for this model,
+        # the scaling factor is 4x. Multiplying by 4 will place the predicted keypoints in the coordinate
+        # space of the cropped input network image.
         scale_factor = np.array([4.0, 4.0])
         keypoints = keypoints * scale_factor
+
+        # The keypoints predicted by the network are relative to the cropped image for each bounding box, not
+        # the original image. Use the predicted bounding box center and scale to map the predicted coordinates
+        # back to the original input image provided by the user.
         input_size = proc_inputs["data_samples"][0].metainfo["input_size"]
         keypoints = keypoints / input_size * scale + center - 0.5 * scale
         keypoints = np.round(keypoints).astype(np.int32)
-
         if raw_output:
             return keypoints
 
         predicted_images = []
         for i, img in enumerate(NHWC_int_numpy_frames):
             draw_points(img, keypoints[i], color=(255, 0, 0), size=2)
             predicted_images.append(fromarray(img))
```

## qai_hub_models/models/hrnet_pose/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.hrnet_pose import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.hrnet_pose.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/hrnet_pose/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: HRNetPose
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2297.0
-      throughput: 435.35045711798
+      inference_time: 2289.0
+      throughput: 436.871996505024
       estimated_peak_memory_range:
         min: 16384
-        max: 2784976
+        max: 2655344
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 514
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 514
-      job_id: j7gjdql8g
+      job_id: jwgok4q1p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2297.0
+      throughput: 435.35045711798
+      estimated_peak_memory_range:
+        min: 12288
+        max: 59340792
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 745
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 745
+      job_id: j7gjzw415
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3007.0
+      throughput: 332.5573661456601
+      estimated_peak_memory_range:
+        min: 0
+        max: 148641888
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jygzo4k45
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:57.614569Z'
+    timestamp: '2024-04-16T20:17:32.492469Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1753.0
+      throughput: 570.4506560182544
+      estimated_peak_memory_range:
+        min: 225280
+        max: 107290736
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 514
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 514
+      job_id: j1pv09xz5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 2295.0
-      throughput: 435.7298474945534
+      inference_time: 1719.0
+      throughput: 581.7335660267597
       estimated_peak_memory_range:
-        min: 12288
-        max: 58975320
+        min: 606208
+        max: 177224704
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 745
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 745
-      job_id: jygz2n76g
+      job_id: jlpeel38p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1723.0
-      throughput: 580.3830528148578
+    torchscript_onnx_ort:
+      inference_time: 2250.0
+      throughput: 444.44444444444446
       estimated_peak_memory_range:
-        min: 16384
-        max: 106291456
+        min: 12288
+        max: 81136704
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 514
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 514
-      job_id: jlpeoyv0g
+        total_layers: 1
+      job_id: jz5w21n45
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:43.560020Z'
-    torchscript_onnx_qnn:
-      inference_time: 1715.0
-      throughput: 583.0903790087464
+    timestamp: '2024-04-16T20:17:32.492853Z'
+  - torchscript_onnx_ort:
+      inference_time: 158917.0
+      throughput: 6.292592988792892
       estimated_peak_memory_range:
-        min: 606208
-        max: 177690672
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 16871424
+        max: 185399920
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 745
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 745
-      job_id: jz5ww49j5
+        layers_on_cpu: 379
+        total_layers: 379
+      job_id: jmg9jxem5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.492969Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.492975Z'
```

## qai_hub_models/models/huggingface_wavlm_base_plus/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.huggingface_wavlm_base_plus import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.huggingface_wavlm_base_plus.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/huggingface_wavlm_base_plus/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: HuggingFace-WavLM-Base-Plus
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 911873.0
-      throughput: 1.0966439405487387
+      inference_time: 884463.0
+      throughput: 1.1306295458374178
       estimated_peak_memory_range:
-        min: 149282816
-        max: 153276888
+        min: 149233664
+        max: 152668384
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 848
-        total_layers: 848
-      job_id: jz57yq4q5
+        layers_on_cpu: 811
+        total_layers: 811
+      job_id: jo5mqdy7p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 613080.0
+      throughput: 1.631108501337509
+      estimated_peak_memory_range:
+        min: 16220160
+        max: 44091568
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 484
+        total_layers: 484
+      job_id: jopr8njk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-03-26T15:30:16.725161Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.541978Z'
+  - torchscript_onnx_tflite:
+      inference_time: 789013.0
+      throughput: 1.2674062404548467
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 148623360
+        max: 174462192
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 712941.0
-      throughput: 1.4026406112146728
+        layers_on_cpu: 811
+        total_layers: 811
+      job_id: jegnl78j5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 513891.0
+      throughput: 1.9459379518224682
       estimated_peak_memory_range:
-        min: 147787776
-        max: 179693888
+        min: 995328
+        max: 204911264
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 848
-        total_layers: 848
-      job_id: joprvzlvg
+        layers_on_cpu: 484
+        total_layers: 484
+      job_id: jep20vn6g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-03-26T15:30:16.725174Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.542329Z'
+  - torchscript_onnx_ort:
+      inference_time: 825393.0
+      throughput: 1.211544076579278
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 72355840
+        max: 279092176
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 484
+        total_layers: 484
+      job_id: jqpyr7005
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.542466Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.542471Z'
```

## qai_hub_models/models/inception_v3/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.inception_v3 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.inception_v3.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/inception_v3/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Inception-v3
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1428.0
-      throughput: 700.2801120448179
+      inference_time: 1337.0
+      throughput: 747.9431563201197
       estimated_peak_memory_range:
-        min: 28672
-        max: 2409000
+        min: 20480
+        max: 2064624
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 131
+        layers_on_npu: 129
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 131
-      job_id: jqp4n3xlg
+        total_layers: 129
+      job_id: j2p03600p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1396.0
+      throughput: 716.3323782234957
+      estimated_peak_memory_range:
+        min: 16384
+        max: 150190256
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 219
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 219
+      job_id: jogk78xvp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1728.0
+      throughput: 578.7037037037037
+      estimated_peak_memory_range:
+        min: 57344
+        max: 214567960
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1gl6lm2g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:46.144805Z'
+    timestamp: '2024-04-16T20:17:32.563810Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1019.0
+      throughput: 981.3542688910696
+      estimated_peak_memory_range:
+        min: 12288
+        max: 51945968
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 129
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 129
+      job_id: j1p801yqg
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 1458.0
-      throughput: 685.8710562414266
+      inference_time: 1044.0
+      throughput: 957.8544061302682
       estimated_peak_memory_range:
-        min: 622592
-        max: 149278208
+        min: 618496
+        max: 62186832
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 219
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 219
-      job_id: jo5me8wqp
+      job_id: jn5qevqe5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1047.0
-      throughput: 955.1098376313277
+    torchscript_onnx_ort:
+      inference_time: 1343.0
+      throughput: 744.6016381236038
       estimated_peak_memory_range:
-        min: 12288
-        max: 51670896
+        min: 618496
+        max: 25688304
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 131
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 131
-      job_id: j0px9x79p
+        total_layers: 1
+      job_id: jw56ew4ng
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:30.685618Z'
-    torchscript_onnx_qnn:
-      inference_time: 1083.0
-      throughput: 923.3610341643582
+    timestamp: '2024-04-16T20:17:32.563949Z'
+  - torchscript_onnx_ort:
+      inference_time: 73090.0
+      throughput: 13.681762210972773
       estimated_peak_memory_range:
-        min: 618496
-        max: 66991296
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 1110016
+        max: 60531168
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 219
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 219
-      job_id: jegn0k9m5
+        layers_on_cpu: 123
+        total_layers: 123
+      job_id: j1p3v60mg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.563990Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.563995Z'
```

## qai_hub_models/models/inception_v3_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.inception_v3_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.inception_v3_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/inception_v3_quantized/model.py

```diff
@@ -16,18 +16,21 @@
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.inception_v3.model import InceptionNetV3
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
-from qai_hub_models.utils.quantization_aimet import tie_aimet_observer_groups
+from qai_hub_models.utils.quantization_aimet import (
+    constrain_quantized_inputs_to_image_range,
+    tie_aimet_observer_groups,
+)
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 4
+MODEL_ASSET_VERSION = 6
 DEFAULT_ENCODINGS = "inception_v3_quantized_encodings.json"
 
 
 class InceptionNetV3Quantizable(
     AIMETQuantizableMixin,
     InceptionNetV3,
 ):
@@ -36,15 +39,16 @@
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        InceptionNetV3.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        InceptionNetV3.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -68,14 +72,15 @@
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
         cls._tie_pre_concat_quantizers(sim)
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/inception_v3_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Inception-v3-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 633.0
-      throughput: 1579.778830963665
+      inference_time: 623.0
+      throughput: 1605.1364365971108
       estimated_peak_memory_range:
-        min: 12288
-        max: 1553272
+        min: 40960
+        max: 1585824
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 144
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 144
-      job_id: jopr6w4ep
+      job_id: jwgok861p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1098.0
+      throughput: 910.7468123861566
+      estimated_peak_memory_range:
+        min: 53248
+        max: 53526464
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j7gjzqn15
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:19:51.517901Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:32.586344Z'
   - torchscript_onnx_tflite:
-      inference_time: 461.0
-      throughput: 2169.1973969631235
+      inference_time: 492.0
+      throughput: 2032.520325203252
       estimated_peak_memory_range:
         min: 12288
-        max: 64115632
+        max: 64321136
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 144
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 144
-      job_id: jep2xe7mg
+      job_id: j1pv07kz5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 880.0
+      throughput: 1136.3636363636363
+      estimated_peak_memory_range:
+        min: 618496
+        max: 36779824
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jlpeeym8p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:51.517914Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.586427Z'
+  - torchscript_onnx_ort:
+      inference_time: 26460.0
+      throughput: 37.79289493575208
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 17575936
+        max: 85502320
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 138
+        total_layers: 138
+      job_id: jygzond45
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.586468Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.586474Z'
```

## qai_hub_models/models/lama_dilated/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.lama_dilated import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.lama_dilated.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/lama_dilated/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: LaMa-Dilated
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 87826.0
-      throughput: 11.386149887277115
+      inference_time: 87925.0
+      throughput: 11.373329542223486
       estimated_peak_memory_range:
-        min: 3280896
-        max: 139026816
+        min: 0
+        max: 3269648
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 346
+        layers_on_npu: 347
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 346
-      job_id: jqpyzm44g
+        total_layers: 347
+      job_id: jz5w24645
       job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 81938.0
+      throughput: 12.204349630208206
+      estimated_peak_memory_range:
+        min: 1654784
+        max: 33961664
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 332
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 332
+      job_id: jnp1y6znp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jz5w246z5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:34.825319Z'
-    torchscript_onnx_qnn:
-      inference_time: 82023.0
-      throughput: 12.191702327395975
+    timestamp: '2024-04-16T20:17:32.607133Z'
+  - torchscript_onnx_tflite:
+      inference_time: 60997.0
+      throughput: 16.39424889748676
       estimated_peak_memory_range:
-        min: 667648
-        max: 36691936
+        min: 2707456
+        max: 271146544
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 332
+        layers_on_npu: 347
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 332
-      job_id: jogkv8lop
+        total_layers: 347
+      job_id: jmg9jdnm5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 61367.0
-      throughput: 16.295403066794858
+    torchscript_onnx_qnn:
+      inference_time: 57249.0
+      throughput: 17.4675540184108
       estimated_peak_memory_range:
-        min: 36864
-        max: 268387328
+        min: 4161536
+        max: 189298048
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 346
+        layers_on_npu: 332
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 346
-      job_id: j1p82138p
+        total_layers: 332
+      job_id: jvgde2165
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jmg9jdnq5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:17.633943Z'
-    torchscript_onnx_qnn:
-      inference_time: 57731.0
-      throughput: 17.321716235644626
+    timestamp: '2024-04-16T20:17:32.607354Z'
+  - torchscript_onnx_ort:
+      inference_time: 4472091.0
+      throughput: 0.2236090455225531
       estimated_peak_memory_range:
-        min: 155123712
-        max: 340846160
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 91983872
+        max: 195795248
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 332
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 332
-      job_id: jn5q0v7mp
+        layers_on_cpu: 220
+        total_layers: 220
+      job_id: jnp1y6zkp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.607436Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.607442Z'
```

## qai_hub_models/models/litehrnet/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.litehrnet import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.litehrnet.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/litehrnet/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: LiteHRNet
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 15544.0
-      throughput: 64.33350488934637
+      inference_time: 15561.0
+      throughput: 64.263222157959
       estimated_peak_memory_range:
-        min: 6557696
-        max: 21204936
+        min: 6553600
+        max: 13181120
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 1226
         layers_on_gpu: 0
         layers_on_cpu: 10
         total_layers: 1236
-      job_id: j1gl4l0l5
+      job_id: jvgde21k5
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:47:29.705067Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jqp4k3rqg
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:32.630164Z'
   - torchscript_onnx_tflite:
-      inference_time: 10368.0
-      throughput: 96.45061728395062
+      inference_time: 10344.0
+      throughput: 96.67440061871616
       estimated_peak_memory_range:
         min: 20480
-        max: 72953920
+        max: 73273328
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 1226
         layers_on_gpu: 0
         layers_on_cpu: 10
         total_layers: 1236
-      job_id: jw562w37g
+      job_id: jz5709rqg
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:47:29.705081Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: j0pxnxoj5
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:32.630465Z'
+  - torchscript_onnx_ort:
+      inference_time: 37860.0
+      throughput: 26.413100898045432
+      estimated_peak_memory_range:
+        min: 10416128
+        max: 398877440
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 939
+        total_layers: 939
+      job_id: jo5mq8xyp
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.630724Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.630734Z'
```

## qai_hub_models/models/mediapipe_face/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mediapipe_face import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mediapipe_face.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mediapipe_face/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,292 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MediaPipeFaceDetector
   performance_metrics:
   - torchscript_onnx_tflite:
       inference_time: 785.0
       throughput: 1273.8853503184714
       estimated_peak_memory_range:
         min: 12288
-        max: 1644744
+        max: 1533536
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 112
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 112
-      job_id: j1p3n64z5
+      job_id: jegnlk6v5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 839.0
+      throughput: 1191.8951132300358
+      estimated_peak_memory_range:
+        min: 815104
+        max: 6910200
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 148
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 148
+      job_id: j2p036z2p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 996.0
+      throughput: 1004.0160642570281
+      estimated_peak_memory_range:
+        min: 806912
+        max: 6602536
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1gl6lveg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:54:57.036020Z'
+    timestamp: '2024-04-16T20:17:32.651181Z'
+  - torchscript_onnx_tflite:
+      inference_time: 544.0
+      throughput: 1838.235294117647
+      estimated_peak_memory_range:
+        min: 12288
+        max: 28679584
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 112
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 112
+      job_id: jep20ekxg
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 836.0
-      throughput: 1196.1722488038276
+      inference_time: 595.0
+      throughput: 1680.672268907563
       estimated_peak_memory_range:
-        min: 811008
-        max: 7017760
+        min: 802816
+        max: 47837376
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 148
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 148
-      job_id: jlpeoyr0g
+      job_id: jogk78eyp
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 546.0
-      throughput: 1831.5018315018315
+    torchscript_onnx_ort:
+      inference_time: 706.0
+      throughput: 1416.4305949008499
       estimated_peak_memory_range:
-        min: 16384
-        max: 29604672
+        min: 12288
+        max: 20347024
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 112
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 112
-      job_id: j1pvq71mg
+        total_layers: 1
+      job_id: j1p3v6jxg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:57:38.738298Z'
-    torchscript_onnx_qnn:
-      inference_time: 594.0
-      throughput: 1683.5016835016836
+    timestamp: '2024-04-16T20:17:32.651255Z'
+  - torchscript_onnx_ort:
+      inference_time: 17041.0
+      throughput: 58.68200222991609
       estimated_peak_memory_range:
-        min: 12288
-        max: 43350624
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 315392
+        max: 42258624
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 148
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 148
-      job_id: jz5ww4dj5
+        layers_on_cpu: 84
+        total_layers: 84
+      job_id: j1pv07675
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.651281Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.651287Z'
 - name: MediaPipeFaceLandmarkDetector
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 309.0
-      throughput: 3236.2459546925566
+      inference_time: 315.0
+      throughput: 3174.6031746031745
       estimated_peak_memory_range:
-        min: 12288
-        max: 1598880
+        min: 24576
+        max: 1781952
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 101
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 101
-      job_id: jwgoz81dp
+      job_id: jopr8wvv5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 390.0
+      throughput: 2564.102564102564
+      estimated_peak_memory_range:
+        min: 458752
+        max: 94680040
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 107
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 107
+      job_id: j1p801qzg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 494.0
+      throughput: 2024.2914979757086
+      estimated_peak_memory_range:
+        min: 12288
+        max: 7623304
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jw56ewyvg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:04:19.041124Z'
+    timestamp: '2024-04-16T20:17:32.651349Z'
+  - torchscript_onnx_tflite:
+      inference_time: 230.0
+      throughput: 4347.826086956522
+      estimated_peak_memory_range:
+        min: 12288
+        max: 25090016
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 101
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 101
+      job_id: jqpyrm1r5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 394.0
-      throughput: 2538.0710659898477
+      inference_time: 285.0
+      throughput: 3508.7719298245615
       estimated_peak_memory_range:
-        min: 471040
-        max: 59853120
+        min: 12288
+        max: 33592960
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 107
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 107
-      job_id: jygz2nx6g
+      job_id: jn5qev675
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 253.0
-      throughput: 3952.5691699604745
+    torchscript_onnx_ort:
+      inference_time: 408.0
+      throughput: 2450.9803921568628
       estimated_peak_memory_range:
         min: 12288
-        max: 25742560
+        max: 15898592
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 101
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 101
-      job_id: j7gjdq08g
+        total_layers: 1
+      job_id: jwgok824p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:06:04.371420Z'
-    torchscript_onnx_qnn:
-      inference_time: 284.0
-      throughput: 3521.1267605633802
+    timestamp: '2024-04-16T20:17:32.651411Z'
+  - torchscript_onnx_ort:
+      inference_time: 4387.0
+      throughput: 227.94620469569182
       estimated_peak_memory_range:
-        min: 12288
-        max: 37168176
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 0
+        max: 40117968
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 107
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 107
-      job_id: jmg90d3vg
+        layers_on_cpu: 80
+        total_layers: 80
+      job_id: j7gjzqv75
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.651435Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.651440Z'
```

## qai_hub_models/models/mediapipe_hand/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mediapipe_hand import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mediapipe_hand.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mediapipe_hand/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,292 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MediaPipeHandDetector
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 963.0
-      throughput: 1038.4215991692627
+      inference_time: 953.0
+      throughput: 1049.3179433368311
       estimated_peak_memory_range:
-        min: 24576
-        max: 3475384
+        min: 12288
+        max: 7786576
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 152
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 152
-      job_id: jnp126dlg
+      job_id: jlpeeyd7p
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:50.064065Z'
     torchscript_onnx_qnn:
-      inference_time: 1013.0
-      throughput: 987.1668311944719
+      inference_time: 1019.0
+      throughput: 981.3542688910696
       estimated_peak_memory_range:
         min: 806912
-        max: 21114408
+        max: 8813592
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 197
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 197
-      job_id: j0px9xe9p
+      job_id: jnp1y64kp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1219.0
+      throughput: 820.3445447087777
+      estimated_peak_memory_range:
+        min: 12288
+        max: 19518840
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j0pxnxkj5
       job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:32.692034Z'
   - torchscript_onnx_tflite:
       inference_time: 679.0
       throughput: 1472.7540500736377
       estimated_peak_memory_range:
-        min: 16384
-        max: 52478672
+        min: 12288
+        max: 52020064
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 152
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 152
-      job_id: jz5729vrp
+      job_id: jz5w24ez5
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:31.887081Z'
     torchscript_onnx_qnn:
       inference_time: 722.0
       throughput: 1385.0415512465374
       estimated_peak_memory_range:
         min: 802816
-        max: 55474400
+        max: 57062560
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 197
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 197
-      job_id: jegn0krm5
+      job_id: jz5709yqg
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 838.0
+      throughput: 1193.3174224343675
+      estimated_peak_memory_range:
+        min: 565248
+        max: 29618560
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jegnlk0v5
+      job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:32.692119Z'
+  - torchscript_onnx_ort:
+      inference_time: 41236.0
+      throughput: 24.25065476767873
+      estimated_peak_memory_range:
+        min: 348160
+        max: 56481568
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 116
+        total_layers: 116
+      job_id: jep20exxg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.692149Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.692154Z'
 - name: MediaPipeHandLandmarkDetector
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1204.0
-      throughput: 830.5647840531561
+      inference_time: 1259.0
+      throughput: 794.2811755361398
       estimated_peak_memory_range:
-        min: 20480
-        max: 2109720
+        min: 24576
+        max: 1977616
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 159
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 159
-      job_id: jvgdn2rl5
+      job_id: jygzon3z5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1293.0
+      throughput: 773.3952049497293
+      estimated_peak_memory_range:
+        min: 638976
+        max: 10247184
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 210
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 210
+      job_id: jvgde2xk5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 54823.0
+      throughput: 18.240519489995076
+      estimated_peak_memory_range:
+        min: 217088
+        max: 18000624
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jo5mq8nyp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:36.652846Z'
+    timestamp: '2024-04-16T20:17:32.692237Z'
+  - torchscript_onnx_tflite:
+      inference_time: 901.0
+      throughput: 1109.8779134295228
+      estimated_peak_memory_range:
+        min: 12288
+        max: 56691584
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 159
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 159
+      job_id: jmg9jdlq5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 1286.0
-      throughput: 777.6049766718507
+      inference_time: 963.0
+      throughput: 1038.4215991692627
       estimated_peak_memory_range:
-        min: 16384
-        max: 10322344
+        min: 802816
+        max: 62409504
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 210
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 210
-      job_id: jo5me8vqp
+      job_id: jqp4k3lqg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 892.0
-      throughput: 1121.0762331838564
+    torchscript_onnx_ort:
+      inference_time: 41069.0
+      throughput: 24.34926586963403
       estimated_peak_memory_range:
-        min: 12288
-        max: 56429024
+        min: 868352
+        max: 30450496
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 159
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 159
-      job_id: jqp4n3jlg
+        total_layers: 1
+      job_id: jopr8w6v5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:18.255922Z'
-    torchscript_onnx_qnn:
-      inference_time: 967.0
-      throughput: 1034.126163391934
+    timestamp: '2024-04-16T20:17:32.692320Z'
+  - torchscript_onnx_ort:
+      inference_time: 38223.0
+      throughput: 26.162258326138712
       estimated_peak_memory_range:
-        min: 802816
-        max: 63039088
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 425984
+        max: 56359008
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 210
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 210
-      job_id: jopr6w1ep
+        layers_on_cpu: 116
+        total_layers: 116
+      job_id: jqpyrmzr5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.692348Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.692352Z'
```

## qai_hub_models/models/mediapipe_pose/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mediapipe_pose import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mediapipe_pose.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mediapipe_pose/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,292 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MediaPipePoseDetector
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 832.0
-      throughput: 1201.923076923077
+      inference_time: 835.0
+      throughput: 1197.6047904191616
       estimated_peak_memory_range:
-        min: 12288
-        max: 4854072
+        min: 16384
+        max: 1889240
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 107
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 107
-      job_id: jep2xe3mg
+      job_id: j2p03642p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 884.0
+      throughput: 1131.2217194570135
+      estimated_peak_memory_range:
+        min: 69632
+        max: 15459024
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 140
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 140
+      job_id: j1gl6l4eg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1006.0
+      throughput: 994.0357852882704
+      estimated_peak_memory_range:
+        min: 16384
+        max: 9676016
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1pv07q75
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:08:14.918160Z'
+    timestamp: '2024-04-16T20:17:32.732493Z'
+  - torchscript_onnx_tflite:
+      inference_time: 612.0
+      throughput: 1633.986928104575
+      estimated_peak_memory_range:
+        min: 16384
+        max: 40580928
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 107
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 107
+      job_id: jogk78vyp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 888.0
-      throughput: 1126.126126126126
+      inference_time: 636.0
+      throughput: 1572.3270440251572
       estimated_peak_memory_range:
-        min: 12288
-        max: 15880848
+        min: 208896
+        max: 44032080
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 140
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 140
-      job_id: jogkv8rop
+      job_id: j1p3v6nxg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 595.0
-      throughput: 1680.672268907563
+    torchscript_onnx_ort:
+      inference_time: 732.0
+      throughput: 1366.120218579235
       estimated_peak_memory_range:
-        min: 61440
-        max: 40000256
+        min: 208896
+        max: 21601008
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 107
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 107
-      job_id: j2p046eeg
+        total_layers: 1
+      job_id: jlpeeyo7p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:09:48.929940Z'
-    torchscript_onnx_qnn:
-      inference_time: 635.0
-      throughput: 1574.8031496062993
+    timestamp: '2024-04-16T20:17:32.732591Z'
+  - torchscript_onnx_ort:
+      inference_time: 42472.0
+      throughput: 23.544923714447165
       estimated_peak_memory_range:
         min: 0
-        max: 42314640
-      primary_compute_unit: NPU
-      precision: fp16
+        max: 42875888
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 140
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 140
-      job_id: j1gl4lel5
+        layers_on_cpu: 81
+        total_layers: 81
+      job_id: jz5w24wz5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.732621Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.732626Z'
 - name: MediaPipePoseLandmarkDetector
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1234.0
-      throughput: 810.3727714748784
+      inference_time: 1206.0
+      throughput: 829.1873963515754
       estimated_peak_memory_range:
-        min: 24576
-        max: 2060312
+        min: 16384
+        max: 2448848
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 230
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 230
-      job_id: jqpyzmv4g
+      job_id: j1p8012zg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1297.0
+      throughput: 771.0100231303007
+      estimated_peak_memory_range:
+        min: 12288
+        max: 15533680
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 306
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 306
+      job_id: jw56ew2vg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 106535.0
+      throughput: 9.386586567794621
+      estimated_peak_memory_range:
+        min: 102400
+        max: 26214168
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j7gjzqd75
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:14:29.934608Z'
-    torchscript_onnx_qnn:
-      inference_time: 1299.0
-      throughput: 769.8229407236336
+    timestamp: '2024-04-16T20:17:32.732805Z'
+  - torchscript_onnx_tflite:
+      inference_time: 880.0
+      throughput: 1136.3636363636363
       estimated_peak_memory_range:
         min: 16384
-        max: 16124312
+        max: 87924496
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 230
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 230
+      job_id: jn5qev075
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 964.0
+      throughput: 1037.344398340249
+      estimated_peak_memory_range:
+        min: 802816
+        max: 83648384
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 306
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 306
-      job_id: jn5q0v9mp
+      job_id: jwgok8z4p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 897.0
-      throughput: 1114.8272017837235
+    torchscript_onnx_ort:
+      inference_time: 82694.0
+      throughput: 12.092775775751566
       estimated_peak_memory_range:
-        min: 16384
-        max: 87742400
+        min: 819200
+        max: 35448288
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 230
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 230
-      job_id: j1p821w8p
+        total_layers: 1
+      job_id: jygzon2z5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:16:04.740529Z'
-    torchscript_onnx_qnn:
-      inference_time: 944.0
-      throughput: 1059.322033898305
+    timestamp: '2024-04-16T20:17:32.732969Z'
+  - torchscript_onnx_ort:
+      inference_time: 28143.0
+      throughput: 35.532814554240844
       estimated_peak_memory_range:
-        min: 815104
-        max: 87180432
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 0
+        max: 78807408
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 306
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 306
-      job_id: jw562wq7g
+        layers_on_cpu: 172
+        total_layers: 172
+      job_id: jmg9jd0q5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.733019Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.733023Z'
```

## qai_hub_models/models/mediapipe_selfie/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mediapipe_selfie import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mediapipe_selfie.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mediapipe_selfie/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MediaPipe-Selfie-Segmentation
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 811.0
-      throughput: 1233.0456226880394
+      inference_time: 792.0
+      throughput: 1262.6262626262626
       estimated_peak_memory_range:
         min: 12288
-        max: 1889216
+        max: 4536656
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 118
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 118
-      job_id: j1p3n6qz5
+      job_id: jnp1y62kp
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 773.0
+      throughput: 1293.6610608020699
+      estimated_peak_memory_range:
+        min: 32768
+        max: 18516080
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 138
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 138
+      job_id: jz57092qg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 164651.0
+      throughput: 6.073452332509368
+      estimated_peak_memory_range:
+        min: 1437696
+        max: 5932024
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j0pxnx9j5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:20.583232Z'
+    timestamp: '2024-04-16T20:17:32.778315Z'
+  - torchscript_onnx_tflite:
+      inference_time: 536.0
+      throughput: 1865.6716417910447
+      estimated_peak_memory_range:
+        min: 12288
+        max: 23055696
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 118
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 118
+      job_id: jvgde2nk5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 774.0
-      throughput: 1291.9896640826873
+      inference_time: 525.0
+      throughput: 1904.7619047619048
       estimated_peak_memory_range:
-        min: 802816
-        max: 90946416
+        min: 176128
+        max: 41755712
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 138
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 138
-      job_id: j1pvq7zmg
+      job_id: jqp4k3nqg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 554.0
-      throughput: 1805.0541516245487
+    torchscript_onnx_ort:
+      inference_time: 121169.0
+      throughput: 8.252935981975588
       estimated_peak_memory_range:
         min: 12288
-        max: 22551568
+        max: 18735968
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 118
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 118
-      job_id: jwgoz8edp
+        total_layers: 1
+      job_id: jo5mq8eyp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:48.415603Z'
-    torchscript_onnx_qnn:
-      inference_time: 529.0
-      throughput: 1890.359168241966
+    timestamp: '2024-04-16T20:17:32.778430Z'
+  - torchscript_onnx_ort:
+      inference_time: 8168.0
+      throughput: 122.42899118511264
       estimated_peak_memory_range:
-        min: 176128
-        max: 41833568
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 225280
+        max: 49546208
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 138
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 138
-      job_id: j7gjdqk8g
+        layers_on_cpu: 110
+        total_layers: 110
+      job_id: jegnlklv5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.778470Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.778476Z'
```

## qai_hub_models/models/mnasnet05/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mnasnet05 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mnasnet05.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mnasnet05/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MNASNet05
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 370.0
-      throughput: 2702.7027027027025
+      inference_time: 800.0
+      throughput: 1250.0
       estimated_peak_memory_range:
-        min: 20480
-        max: 2386016
+        min: 16384
+        max: 1867832
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 69
+        layers_on_npu: 71
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 69
-      job_id: jlpeoy40g
+        total_layers: 71
+      job_id: jopr8w8v5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 848.0
+      throughput: 1179.245283018868
+      estimated_peak_memory_range:
+        min: 630784
+        max: 4926760
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 103
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 103
+      job_id: jqpyrmrr5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 990.0
+      throughput: 1010.10101010101
+      estimated_peak_memory_range:
+        min: 12288
+        max: 21275160
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p8010zg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:21.394093Z'
-    torchscript_onnx_qnn:
-      inference_time: 362.0
-      throughput: 2762.4309392265195
+    timestamp: '2024-04-16T20:17:32.802104Z'
+  - torchscript_onnx_tflite:
+      inference_time: 530.0
+      throughput: 1886.7924528301887
       estimated_peak_memory_range:
         min: 12288
-        max: 120863224
+        max: 45612800
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 101
+        layers_on_npu: 71
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 101
-      job_id: jz5ww4mj5
+        total_layers: 71
+      job_id: jep20e0xg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 277.0
-      throughput: 3610.1083032490974
+    torchscript_onnx_qnn:
+      inference_time: 565.0
+      throughput: 1769.9115044247787
+      estimated_peak_memory_range:
+        min: 0
+        max: 41195552
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 103
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 103
+      job_id: j2p03632p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 641.0
+      throughput: 1560.0624024960998
       estimated_peak_memory_range:
         min: 24576
-        max: 44606688
+        max: 21468016
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 69
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 69
-      job_id: jygz2nv6g
+        total_layers: 1
+      job_id: jogk787yp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:47.948402Z'
-    torchscript_onnx_qnn:
-      inference_time: 258.0
-      throughput: 3875.968992248062
+    timestamp: '2024-04-16T20:17:32.802197Z'
+  - torchscript_onnx_ort:
+      inference_time: 12908.0
+      throughput: 77.47133560582584
       estimated_peak_memory_range:
-        min: 618496
-        max: 37367488
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 0
+        max: 31498400
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 101
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 101
-      job_id: jmg90d9vg
+        layers_on_cpu: 56
+        total_layers: 56
+      job_id: jn5qeve75
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.802219Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.802226Z'
```

## qai_hub_models/models/mobilenet_v2/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mobilenet_v2 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mobilenet_v2.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mobilenet_v2/model.py

```diff
@@ -18,20 +18,14 @@
 # from https://github.com/quic/aimet-model-zoo/blob/d09d2b0404d10f71a7640a87e9d5e5257b028802/aimet_zoo_torch/mobilenetv2/model/model_cards/mobilenetv2_w8a8.json
 MOBILENETV2_CFG = "mobilenetv2_w8a8.json"
 MOBILENETV2_SOURCE_REPOSITORY = "https://github.com/tonylins/pytorch-mobilenet-v2"
 MOBILENETV2_SOURCE_REPO_COMMIT = "99f213657e97de463c11c9e0eaca3bda598e8b3f"
 
 
 class MobileNetV2(ImagenetClassifier):
-    def __init__(
-        self,
-        mobilenet_v2_model: torch.nn.Module,
-    ) -> None:
-        super().__init__(mobilenet_v2_model)
-
     @classmethod
     def from_pretrained(cls, weights: str = MOBILENETV2_WEIGHTS) -> MobileNetV2:
         model = _load_mobilenet_v2_source_model()
         checkpoint_path = CachedWebModelAsset.from_asset_store(
             MODEL_ID, MODEL_ASSET_VERSION, weights
         ).fetch()
         checkpoint = torch.load(checkpoint_path, map_location=torch.device("cpu"))
```

## qai_hub_models/models/mobilenet_v2/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MobileNet-v2
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 549.0
-      throughput: 1821.4936247723133
+      inference_time: 974.0
+      throughput: 1026.694045174538
+      estimated_peak_memory_range:
+        min: 20480
+        max: 1954912
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 72
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 72
+      job_id: j1gl6l6eg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1281.0
+      throughput: 780.64012490242
+      estimated_peak_memory_range:
+        min: 622592
+        max: 7823048
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 105
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 105
+      job_id: j1p3v6vxg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1110.0
+      throughput: 900.9009009009009
       estimated_peak_memory_range:
         min: 12288
-        max: 1985288
+        max: 31867536
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 70
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 70
-      job_id: jnp126qlg
+        total_layers: 1
+      job_id: j1pv07075
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:43:39.892190Z'
+    timestamp: '2024-04-16T20:17:32.825870Z'
+  - torchscript_onnx_tflite:
+      inference_time: 651.0
+      throughput: 1536.0983102918588
+      estimated_peak_memory_range:
+        min: 16384
+        max: 56986240
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 72
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 72
+      job_id: jw56ewevg
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 805.0
-      throughput: 1242.2360248447205
+      inference_time: 836.0
+      throughput: 1196.1722488038276
       estimated_peak_memory_range:
-        min: 12288
-        max: 197702240
+        min: 618496
+        max: 42487872
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 103
+        layers_on_npu: 105
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 103
-      job_id: jz57296rp
+        total_layers: 105
+      job_id: jwgok8k4p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 394.0
-      throughput: 2538.0710659898477
+    torchscript_onnx_ort:
+      inference_time: 750.0
+      throughput: 1333.3333333333333
       estimated_peak_memory_range:
         min: 12288
-        max: 56118336
+        max: 22319216
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 70
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 70
-      job_id: jvgdn27l5
+        total_layers: 1
+      job_id: j7gjzqz75
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:19.700460Z'
-    torchscript_onnx_qnn:
-      inference_time: 535.0
-      throughput: 1869.1588785046729
+    timestamp: '2024-04-16T20:17:32.825968Z'
+  - torchscript_onnx_ort:
+      inference_time: 19487.0
+      throughput: 51.31626212346693
       estimated_peak_memory_range:
-        min: 618496
-        max: 36988752
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 2371584
+        max: 33778432
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 103
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 103
-      job_id: jqp4n38lg
+        layers_on_cpu: 57
+        total_layers: 57
+      job_id: jlpeeye7p
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.825993Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.826002Z'
```

## qai_hub_models/models/mobilenet_v2_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mobilenet_v2_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mobilenet_v2_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mobilenet_v2_quantized/model.py

```diff
@@ -13,38 +13,39 @@
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
-from qai_hub_models.models.mobilenet_v2.model import (
-    MobileNetV2,
-    _load_mobilenet_v2_source_model,
-)
+from qai_hub_models.models.mobilenet_v2.model import MobileNetV2
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
-from qai_hub_models.utils.quantization_aimet import convert_all_depthwise_to_per_tensor
+from qai_hub_models.utils.quantization_aimet import (
+    constrain_quantized_inputs_to_image_range,
+    convert_all_depthwise_to_per_tensor,
+)
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 3
+MODEL_ASSET_VERSION = 5
 
 # Weights downloaded from https://github.com/quic/aimet-model-zoo/releases/download/phase_2_january_artifacts/torch_mobilenetv2_w8a8_state_dict.pth
 QUANTIZED_WEIGHTS = "torch_mobilenetv2_w8a8_state_dict.pth"
 DEFAULT_ENCODINGS = "mobilenet_v2_quantized_encodings.json"
 
 
 class MobileNetV2Quantizable(AIMETQuantizableMixin, MobileNetV2):
     """MobileNetV2 with post train quantization support."""
 
     def __init__(
         self,
         quant_sim_model: QuantizationSimModel,
     ) -> None:
-        MobileNetV2.__init__(self, quant_sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        MobileNetV2.__init__(self, quant_sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             quant_sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -55,43 +56,32 @@
         Parameters:
           aimet_encodings:
             if "DEFAULT": Loads the model with aimet encodings calibrated on imagenette.
             elif None: Doesn't load any encodings. Used when computing encodings.
             else: Interprets as a filepath and loads the encodings stored there.
         """
         # Load Model
-        model = _load_mobilenet_v2_source_model()
+        model = MobileNetV2.from_pretrained()
         input_shape = cls.get_input_spec()["image_tensor"][0]
         # Following
         # https://github.com/quic/aimet-model-zoo/blob/develop/aimet_zoo_torch/mobilenetv2/model/model_definition.py#L64
         model = prepare_model(model)
         equalize_model(model, input_shape)
 
-        # Download weights and quantization parameters
-        weights = CachedWebModelAsset.from_asset_store(
-            MODEL_ID, MODEL_ASSET_VERSION, QUANTIZED_WEIGHTS
-        ).fetch()
         aimet_config = get_default_aimet_config()
-
-        # Load the QAT/PTQ tuned model weights
-        checkpoint = torch.load(weights, map_location=torch.device("cpu"))
-        state_dict = {
-            k.replace("classifier.1", "classifier"): v
-            for k, v in checkpoint["state_dict"].items()
-        }
-        model.load_state_dict(state_dict)
         sim = QuantizationSimModel(
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=aimet_config,
             dummy_input=torch.rand(input_shape),
         )
         convert_all_depthwise_to_per_tensor(sim.model)
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/mobilenet_v2_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MobileNet-v2-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 234.0
-      throughput: 4273.504273504273
+      inference_time: 302.0
+      throughput: 3311.2582781456954
+      estimated_peak_memory_range:
+        min: 16384
+        max: 1568424
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 72
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 72
+      job_id: jygzonoz5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 666.0
+      throughput: 1501.5015015015015
       estimated_peak_memory_range:
         min: 12288
-        max: 1572504
+        max: 75287400
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 70
+        layers_on_npu: 71
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 70
-      job_id: j0px9xm9p
+        total_layers: 71
+      job_id: jmg9jdjq5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 897.0
+      throughput: 1114.8272017837235
+      estimated_peak_memory_range:
+        min: 12288
+        max: 146664848
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jvgde2ek5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:56.088303Z'
+    timestamp: '2024-04-16T20:17:32.849738Z'
+  - torchscript_onnx_tflite:
+      inference_time: 233.0
+      throughput: 4291.845493562232
+      estimated_peak_memory_range:
+        min: 12288
+        max: 37162256
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 72
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 72
+      job_id: jz5w242z5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 349.0
-      throughput: 2865.3295128939826
+      inference_time: 480.0
+      throughput: 2083.3333333333335
       estimated_peak_memory_range:
-        min: 167936
-        max: 46798608
+        min: 159744
+        max: 36918192
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 68
+        layers_on_npu: 71
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 68
-      job_id: jegn0kxm5
+        total_layers: 71
+      job_id: jnp1y6ykp
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 196.0
-      throughput: 5102.040816326531
+    torchscript_onnx_ort:
+      inference_time: 644.0
+      throughput: 1552.7950310559006
       estimated_peak_memory_range:
-        min: 12288
-        max: 36730112
+        min: 0
+        max: 18572416
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 70
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 70
-      job_id: jo5me84qp
+        total_layers: 1
+      job_id: jz57090qg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:03:12.952170Z'
-    torchscript_onnx_qnn:
-      inference_time: 245.0
-      throughput: 4081.6326530612246
+    timestamp: '2024-04-16T20:17:32.849816Z'
+  - torchscript_onnx_ort:
+      inference_time: 6507.0
+      throughput: 153.68065160596282
       estimated_peak_memory_range:
-        min: 163840
-        max: 32368720
-      primary_compute_unit: NPU
-      precision: int8
+        min: 335872
+        max: 43247408
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 68
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 68
-      job_id: jopr6w9ep
+        layers_on_cpu: 84
+        total_layers: 84
+      job_id: jqp4k3kqg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.849852Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.849857Z'
```

## qai_hub_models/models/mobilenet_v3_large/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mobilenet_v3_large import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mobilenet_v3_large.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mobilenet_v3_large/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MobileNet-v3-Large
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 600.0
-      throughput: 1666.6666666666667
+      inference_time: 1022.0
+      throughput: 978.4735812133073
       estimated_peak_memory_range:
-        min: 12288
-        max: 1649368
+        min: 16384
+        max: 1643944
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 134
+        layers_on_npu: 136
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 134
-      job_id: jep2xejmg
+        total_layers: 136
+      job_id: j0pxnxnj5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3790.0
+      throughput: 263.85224274406335
+      estimated_peak_memory_range:
+        min: 0
+        max: 28283024
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 9
+        layers_on_gpu: 0
+        layers_on_cpu: 8
+        total_layers: 17
+      job_id: jegnlkmv5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:02:57.989143Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.872299Z'
+  - torchscript_onnx_tflite:
+      inference_time: 691.0
+      throughput: 1447.178002894356
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 16384
+        max: 61060464
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 136
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 424.0
-      throughput: 2358.490566037736
+        total_layers: 136
+      job_id: jo5mq8qyp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2766.0
+      throughput: 361.53289949385396
       estimated_peak_memory_range:
-        min: 16384
-        max: 60523168
+        min: 12288
+        max: 25734304
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 134
+        layers_on_npu: 9
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 134
-      job_id: jqpyzmn4g
+        layers_on_cpu: 8
+        total_layers: 17
+      job_id: jopr8w2v5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:57.989157Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.872367Z'
+  - torchscript_onnx_ort:
+      inference_time: 19040.0
+      throughput: 52.52100840336134
       estimated_peak_memory_range:
         min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        max: 57628960
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 126
+        total_layers: 126
+      job_id: jep20e9xg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.872408Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.872414Z'
```

## qai_hub_models/models/mobilenet_v3_large_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mobilenet_v3_large_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mobilenet_v3_large_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mobilenet_v3_large_quantized/model.py

```diff
@@ -4,43 +4,45 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.mobilenet_v3_large.model import MobileNetV3Large
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 1
+MODEL_ASSET_VERSION = 2
 DEFAULT_ENCODINGS = "mobilenet_v3_large_quantized_encodings.json"
 
 
 class MobileNetV3LargeQuantizable(AIMETQuantizableMixin, MobileNetV3Large):
     """MobileNetV3Large with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        MobileNetV3Large.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        MobileNetV3Large.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -63,14 +65,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/mobilenet_v3_large_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MobileNet-v3-Large-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2909.0
-      throughput: 343.7607425232039
+      inference_time: 585.0
+      throughput: 1709.4017094017095
       estimated_peak_memory_range:
-        min: 1351680
-        max: 5759640
+        min: 12288
+        max: 1681920
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 134
+        layers_on_npu: 136
         layers_on_gpu: 0
-        layers_on_cpu: 15
-        total_layers: 149
-      job_id: j2p046keg
+        layers_on_cpu: 0
+        total_layers: 136
+      job_id: jqpyrmjr5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 6430.0
+      throughput: 155.52099533437013
+      estimated_peak_memory_range:
+        min: 15818752
+        max: 29085400
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 9
+        layers_on_gpu: 0
+        layers_on_cpu: 8
+        total_layers: 17
+      job_id: j1p801mzg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:35:49.786504Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.893025Z'
+  - torchscript_onnx_tflite:
+      inference_time: 413.0
+      throughput: 2421.3075060532688
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 12288
+        max: 46829184
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 136
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 2580.0
-      throughput: 387.5968992248062
+        total_layers: 136
+      job_id: j2p03622p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 4730.0
+      throughput: 211.41649048625794
       estimated_peak_memory_range:
-        min: 12288
-        max: 45919040
+        min: 21893120
+        max: 53274160
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 134
+        layers_on_npu: 9
         layers_on_gpu: 0
-        layers_on_cpu: 15
-        total_layers: 149
-      job_id: j1p82188p
+        layers_on_cpu: 8
+        total_layers: 17
+      job_id: jogk78qyp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:35:49.786517Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.893099Z'
+  - torchscript_onnx_ort:
+      inference_time: 10400.0
+      throughput: 96.15384615384616
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 11681792
+        max: 108762160
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 218
+        total_layers: 218
+      job_id: jn5qevr75
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.893166Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.893172Z'
```

## qai_hub_models/models/mobilenet_v3_small/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.mobilenet_v3_small import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.mobilenet_v3_small.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/mobilenet_v3_small/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: MobileNet-v3-Small
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 421.0
-      throughput: 2375.296912114014
+      inference_time: 840.0
+      throughput: 1190.4761904761904
       estimated_peak_memory_range:
-        min: 36864
-        max: 8536712
+        min: 12288
+        max: 1842512
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 122
+        layers_on_npu: 124
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 122
-      job_id: jogkv8dop
+        total_layers: 124
+      job_id: j1gl6l2eg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3404.0
+      throughput: 293.7720329024677
+      estimated_peak_memory_range:
+        min: 16384
+        max: 13250040
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 10
+        layers_on_gpu: 0
+        layers_on_cpu: 9
+        total_layers: 19
+      job_id: j1p3v61xg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:24:45.951383Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.913835Z'
+  - torchscript_onnx_tflite:
+      inference_time: 547.0
+      throughput: 1828.1535648994516
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 12288
+        max: 40731056
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 124
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 312.0
-      throughput: 3205.128205128205
+        total_layers: 124
+      job_id: jw56ewzvg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3006.0
+      throughput: 332.667997338656
       estimated_peak_memory_range:
         min: 12288
-        max: 40933232
+        max: 27095152
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 122
+        layers_on_npu: 10
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 122
-      job_id: jn5q0vwmp
+        layers_on_cpu: 9
+        total_layers: 19
+      job_id: jwgok8n4p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:24:45.951396Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:32.913910Z'
+  - torchscript_onnx_ort:
+      inference_time: 8623.0
+      throughput: 115.96892032935173
       estimated_peak_memory_range:
         min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        max: 53013952
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 114
+        total_layers: 114
+      job_id: j1pv07r75
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.913950Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.913955Z'
```

## qai_hub_models/models/openai_clip/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.openai_clip import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.openai_clip.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/openai_clip/demo.py

```diff
@@ -41,30 +41,34 @@
     add_output_dir_arg(parser)
     args = parser.parse_args([] if is_test else None)
 
     # Load model
     clip_model = Clip.from_pretrained()
     app = ClipApp(clip_model=clip_model)
 
-    image_names = args.image_names.split(",")
-    text = app.process_text(args.text)
-    images = []
+    # Determine device
+    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+
+    # Preprocess text
+    text = app.process_text(args.text).to(device)
 
     # Iterate through images and text provided by user
+    images = []
+    image_names = args.image_names.split(",")
     for filename in image_names:
         # Make sure the file is an image
         if os.path.splitext(filename)[1].lower() in [".jpg", ".jpeg", ".png"]:
             if not args.image_dir:
                 image = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, filename
                 )
             else:
                 image = os.path.join(args.image_dir, filename)
             # Preprocess image and text pair
-            image = app.process_image(load_image(image))
+            image = app.process_image(load_image(image)).to(device)
             images.append(image)
 
         else:
             print(f"Skipping file {filename}")
 
     images = torch.stack(images).squeeze(1)
```

## qai_hub_models/models/openai_clip/export.py

```diff
@@ -215,15 +215,18 @@
         for component_name in components
     }
 
 
 def main():
     warnings.filterwarnings("ignore")
     parser = export_parser(
-        model_cls=Model, components=ALL_COMPONENTS, supports_ort=False
+        model_cls=Model,
+        components=ALL_COMPONENTS,
+        supports_qnn=False,
+        supports_ort=False,
     )
     args = parser.parse_args()
     export_model(**vars(args))
 
 
 if __name__ == "__main__":
     main()
```

## qai_hub_models/models/openai_clip/model.py

```diff
@@ -26,16 +26,17 @@
         OPENAI_CLIP_SOURCE_REPOSITORY,
         OPENAI_CLIP_SOURCE_REPO_COMMIT,
         MODEL_ID,
         MODEL_ASSET_VERSION,
     ):
         import clip
 
+        device = "cuda" if torch.cuda.is_available() else "cpu"
         tokenizer_func = clip.tokenize
-        net, preprocess = clip.load(PRETRAINED_WEIGHTS)
+        net, preprocess = clip.load(PRETRAINED_WEIGHTS, device=device)
         return net, preprocess, tokenizer_func
 
 
 class Clip(CollectionModel):
     def __init__(
         self,
         text_encoder: torch.nn.Module,
```

## qai_hub_models/models/openai_clip/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,232 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: CLIPTextEncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 15437.0
-      throughput: 64.77942605428515
+      inference_time: 15395.0
+      throughput: 64.95615459564793
       estimated_peak_memory_range:
-        min: 16384
-        max: 3773072
+        min: 32768
+        max: 2875584
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 574
         layers_on_gpu: 0
         layers_on_cpu: 2
         total_layers: 576
-      job_id: j1gl4l7l5
+      job_id: j7gjzq275
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 33201.0
+      throughput: 30.119574711605072
+      estimated_peak_memory_range:
+        min: 40960
+        max: 328459688
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 1
+        total_layers: 2
+      job_id: jmg9jdyq5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:38:20.337723Z'
-    torchscript_onnx_qnn:
-      inference_time: 8102.0
-      throughput: 123.42631449024933
+    timestamp: '2024-04-16T20:17:32.934211Z'
+  - torchscript_onnx_tflite:
+      inference_time: 11237.0
+      throughput: 88.99172376968941
       estimated_peak_memory_range:
-        min: 32768
-        max: 20779640
+        min: 16384
+        max: 219358080
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 377
+        layers_on_npu: 574
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 377
-      job_id: j1pvq74mg
+        layers_on_cpu: 2
+        total_layers: 576
+      job_id: jygzonjz5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 11180.0
-      throughput: 89.44543828264759
+    torchscript_onnx_ort:
+      inference_time: 23967.0
+      throughput: 41.7240372178412
       estimated_peak_memory_range:
-        min: 16384
-        max: 221118656
+        min: 36864
+        max: 216279616
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 574
+        layers_on_npu: 1
         layers_on_gpu: 0
-        layers_on_cpu: 2
-        total_layers: 576
-      job_id: j1p3n68z5
+        layers_on_cpu: 1
+        total_layers: 2
+      job_id: jvgde2qk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:03.797053Z'
-    torchscript_onnx_qnn:
-      inference_time: 5698.0
-      throughput: 175.5001755001755
-      estimated_peak_memory_range:
-        min: 12288
-        max: 143619840
-      primary_compute_unit: NPU
-      precision: fp16
-      layer_info:
-        layers_on_npu: 377
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 377
-      job_id: jlpeoy20g
+    timestamp: '2024-04-16T20:17:32.934371Z'
+  - torchscript_onnx_ort:
+      inference_time: 55778.0
+      throughput: 17.92821542543655
+      estimated_peak_memory_range:
+        min: 761856
+        max: 125360048
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 290
+        total_layers: 290
+      job_id: jmg9jdyv5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.934453Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.934458Z'
 - name: CLIPImageEncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 126791.0
-      throughput: 7.886995133724002
+      inference_time: 126657.0
+      throughput: 7.895339381163299
       estimated_peak_memory_range:
         min: 163840
-        max: 4397144
+        max: 3470824
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 576
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 576
-      job_id: jw562wv7g
+      job_id: jlpeeyw7p
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jnp1y6wkp
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:49:16.432598Z'
-    torchscript_onnx_qnn:
-      inference_time: 50465.0
-      throughput: 19.815713861091847
+    timestamp: '2024-04-16T20:17:32.934627Z'
+  - torchscript_onnx_tflite:
+      inference_time: 96976.0
+      throughput: 10.31182973106748
       estimated_peak_memory_range:
-        min: 57344
-        max: 62046320
+        min: 229376
+        max: 865695568
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 371
+        layers_on_npu: 576
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 371
-      job_id: j7gjdq18g
+        total_layers: 576
+      job_id: jz5w243z5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 96475.0
-      throughput: 10.365379632029024
+    torchscript_onnx_ort:
+      inference_time: 128177.0
+      throughput: 7.801711695546003
       estimated_peak_memory_range:
-        min: 266240
-        max: 867371232
+        min: 774144
+        max: 1720363664
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 576
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 576
-      job_id: jwgoz8mdp
+        total_layers: 1
+      job_id: jz5w243j5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:00.458152Z'
-    torchscript_onnx_qnn:
-      inference_time: 38292.0
-      throughput: 26.115115428810196
-      estimated_peak_memory_range:
-        min: 643072
-        max: 228425888
-      primary_compute_unit: NPU
-      precision: fp16
-      layer_info:
-        layers_on_npu: 371
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 371
-      job_id: jygz2nw6g
+    timestamp: '2024-04-16T20:17:32.934785Z'
+  - torchscript_onnx_ort:
+      inference_time: 365962.0
+      throughput: 2.732524141850793
+      estimated_peak_memory_range:
+        min: 954368
+        max: 125503856
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 280
+        total_layers: 280
+      job_id: jnp1y6wlp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.934858Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.934863Z'
```

## qai_hub_models/models/openpose/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.openpose import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.openpose.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/openpose/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: OpenPose
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 11734.0
-      throughput: 85.22243054371911
+      inference_time: 11751.0
+      throughput: 85.09914049868097
       estimated_peak_memory_range:
-        min: 237568
-        max: 2523304
+        min: 225280
+        max: 2603680
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 103
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 103
-      job_id: jw562wm6g
+      job_id: j0pxnxy95
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 11827.0
+      throughput: 84.5522955948254
+      estimated_peak_memory_range:
+        min: 651264
+        max: 242798248
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 186
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 186
+      job_id: jegnlk3m5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 12055.0
+      throughput: 82.9531314807134
+      estimated_peak_memory_range:
+        min: 589824
+        max: 430729112
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jep20elmg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:49:44.284847Z'
+    timestamp: '2024-04-16T20:17:32.970561Z'
+  - torchscript_onnx_tflite:
+      inference_time: 8779.0
+      throughput: 113.90818999886092
+      estimated_peak_memory_range:
+        min: 196608
+        max: 34017488
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 103
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 103
+      job_id: jo5mq83qp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 11894.0
-      throughput: 84.07600470825626
+      inference_time: 8774.0
+      throughput: 113.97310234784591
       estimated_peak_memory_range:
-        min: 618496
-        max: 231521112
+        min: 638976
+        max: 51579776
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 186
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 186
-      job_id: jwgoz8wqp
+      job_id: jopr8wee5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 8768.0
-      throughput: 114.05109489051095
+    torchscript_onnx_ort:
+      inference_time: 9248.0
+      throughput: 108.13148788927336
       estimated_peak_memory_range:
-        min: 217088
-        max: 33805040
+        min: 622592
+        max: 22342656
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 103
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 103
-      job_id: j1p3n6735
+        total_layers: 1
+      job_id: jqpyrm645
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:25.633149Z'
-    torchscript_onnx_qnn:
-      inference_time: 8773.0
-      throughput: 113.98609369656901
+    timestamp: '2024-04-16T20:17:32.970679Z'
+  - torchscript_onnx_ort:
+      inference_time: 948410.0
+      throughput: 1.0543963053953458
       estimated_peak_memory_range:
-        min: 618496
-        max: 53251968
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 28573696
+        max: 81966016
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 186
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 186
-      job_id: j1pvq7nkg
+        layers_on_cpu: 103
+        total_layers: 103
+      job_id: j2p036lep
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.970720Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.970725Z'
```

## qai_hub_models/models/quicksrnetlarge/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetlarge import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetlarge.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetlarge/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: QuickSRNetLarge
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2479.0
-      throughput: 403.3884630899556
+      inference_time: 2492.0
+      throughput: 401.2841091492777
       estimated_peak_memory_range:
         min: 16384
-        max: 2082976
+        max: 8350520
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 28
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 31
-      job_id: jz5ww4xj5
+      job_id: j1p801z8g
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2101.0
+      throughput: 475.9638267491671
+      estimated_peak_memory_range:
+        min: 225280
+        max: 5584760
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 31
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 31
+      job_id: jn5qev3m5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2738.0
+      throughput: 365.23009495982467
+      estimated_peak_memory_range:
+        min: 12288
+        max: 5692928
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jw56ewn7g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:38:35.151948Z'
+    timestamp: '2024-04-16T20:17:32.994123Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1917.0
+      throughput: 521.6484089723526
+      estimated_peak_memory_range:
+        min: 16384
+        max: 28332832
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 28
+        layers_on_gpu: 0
+        layers_on_cpu: 3
+        total_layers: 31
+      job_id: jogk783op
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 2103.0
-      throughput: 475.51117451260103
+      inference_time: 1500.0
+      throughput: 666.6666666666666
       estimated_peak_memory_range:
-        min: 212992
-        max: 70526200
+        min: 208896
+        max: 17648384
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 31
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 31
-      job_id: jnp1263lg
+      job_id: j1gl6l3lg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1724.0
-      throughput: 580.046403712297
+    torchscript_onnx_ort:
+      inference_time: 1897.0
+      throughput: 527.1481286241434
       estimated_peak_memory_range:
-        min: 16384
-        max: 28078224
+        min: 212992
+        max: 19230192
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 28
+        layers_on_npu: 1
         layers_on_gpu: 0
-        layers_on_cpu: 3
-        total_layers: 31
-      job_id: jmg90d8vg
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p3v6ezg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:14.086310Z'
-    torchscript_onnx_qnn:
-      inference_time: 1489.0
-      throughput: 671.591672263264
+    timestamp: '2024-04-16T20:17:32.994193Z'
+  - torchscript_onnx_ort:
+      inference_time: 139583.0
+      throughput: 7.164196213005882
       estimated_peak_memory_range:
-        min: 204800
-        max: 18038672
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 577536
+        max: 14778160
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 31
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 31
-      job_id: jvgdn20l5
+        layers_on_cpu: 15
+        total_layers: 15
+      job_id: jwgok83dp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:32.994212Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:32.994218Z'
```

## qai_hub_models/models/quicksrnetlarge_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetlarge_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetlarge_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetlarge_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,78 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: QuickSRNetLarge-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1505.0
-      throughput: 664.4518272425249
+      inference_time: 1512.0
+      throughput: 661.3756613756614
       estimated_peak_memory_range:
         min: 20480
-        max: 1674904
+        max: 1404424
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 28
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 31
-      job_id: jz5ww4865
+      job_id: j1pv07vm5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:46:59.414680Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.020831Z'
   - torchscript_onnx_tflite:
-      inference_time: 1194.0
-      throughput: 837.5209380234506
+      inference_time: 1167.0
+      throughput: 856.898029134533
       estimated_peak_memory_range:
         min: 12288
-        max: 25612592
+        max: 25644128
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 28
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 31
-      job_id: jmg90dklg
+      job_id: j7gjzqe85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:59.414694Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.020859Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.020865Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.020870Z'
```

## qai_hub_models/models/quicksrnetmedium/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetmedium import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetmedium.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetmedium/perf.yaml

```diff
@@ -1,109 +1,175 @@
+aggregated:
+  supported_oses:
+  - Android
+  supported_devices:
+  - Google Pixel 3
+  - Google Pixel 3a
+  - Google Pixel 3a XL
+  - Google Pixel 4
+  - Google Pixel 4a
+  - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
+  - Samsung Galaxy S21
+  - Samsung Galaxy S21 Ultra
+  - Samsung Galaxy S21+
+  - Samsung Galaxy S22 5G
+  - Samsung Galaxy S22 Ultra 5G
+  - Samsung Galaxy S22+ 5G
+  - Samsung Galaxy S23
+  - Samsung Galaxy S23 Ultra
+  - Samsung Galaxy S23+
+  - Samsung Galaxy S24
+  - Samsung Galaxy S24 Ultra
+  - Samsung Galaxy S24+
+  - Samsung Galaxy Tab S8
+  - Xiaomi 12
+  - Xiaomi 12 Pro
+  supported_chipsets:
+  - Qcs6490
+  - Qcs8550
+  - Snapdragon 8 Gen 1
+  - Snapdragon 8 Gen 2
+  - Snapdragon 8 Gen 3
+  - Snapdragon 888
 models:
 - name: QuickSRNetMedium
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1386.0
-      throughput: 721.5007215007215
+      inference_time: 1385.0
+      throughput: 722.0216606498195
       estimated_peak_memory_range:
-        min: 24576
-        max: 8284584
+        min: 16384
+        max: 1507064
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: jnp12672g
+      job_id: jlpeeyk0p
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:43:54.390470Z'
     torchscript_onnx_qnn:
       inference_time: 998.0
       throughput: 1002.0040080160321
       estimated_peak_memory_range:
-        min: 212992
-        max: 7518912
+        min: 221184
+        max: 7358048
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 17
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 17
-      job_id: jz5729klp
+      job_id: jz5w24qj5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1500.0
+      throughput: 666.6666666666666
+      estimated_peak_memory_range:
+        min: 212992
+        max: 8597144
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jnp1y6elp
       job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:33.040879Z'
   - torchscript_onnx_tflite:
-      inference_time: 899.0
-      throughput: 1112.3470522803113
+      inference_time: 871.0
+      throughput: 1148.105625717566
       estimated_peak_memory_range:
         min: 16384
-        max: 19609168
+        max: 19182544
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: jvgdn28e5
+      job_id: jygzonr65
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:31.914821Z'
     torchscript_onnx_qnn:
-      inference_time: 651.0
-      throughput: 1536.0983102918588
+      inference_time: 641.0
+      throughput: 1560.0624024960998
       estimated_peak_memory_range:
         min: 208896
-        max: 15417120
+        max: 14603312
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 17
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 17
-      job_id: jqp4n3mvg
+      job_id: jmg9jdwv5
       job_status: Passed
-aggregated:
-  supported_oses:
-  - Android
-  supported_devices:
-  - Google Pixel 3
-  - Google Pixel 3a
-  - Google Pixel 3a XL
-  - Google Pixel 4
-  - Google Pixel 4a
-  - Google Pixel 5a 5G
-  - Samsung Galaxy S21
-  - Samsung Galaxy S21 Ultra
-  - Samsung Galaxy S21+
-  - Samsung Galaxy S22 5G
-  - Samsung Galaxy S22 Ultra 5G
-  - Samsung Galaxy S22+ 5G
-  - Samsung Galaxy S23
-  - Samsung Galaxy S23 Ultra
-  - Samsung Galaxy S23+
-  - Samsung Galaxy S24
-  - Samsung Galaxy S24 Ultra
-  - Samsung Galaxy S24+
-  - Samsung Galaxy Tab S8
-  - Xiaomi 12
-  - Xiaomi 12 Pro
-  supported_chipsets:
-  - Snapdragon 8 Gen 1
-  - Snapdragon 8 Gen 2
-  - Snapdragon 8 Gen 3
-  - Snapdragon 888
+    torchscript_onnx_ort:
+      inference_time: 1118.0
+      throughput: 894.4543828264758
+      estimated_peak_memory_range:
+        min: 217088
+        max: 15048656
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jvgde2ol5
+      job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:33.040928Z'
+  - torchscript_onnx_ort:
+      inference_time: 20332.0
+      throughput: 49.18355301987015
+      estimated_peak_memory_range:
+        min: 335872
+        max: 12174960
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 8
+        total_layers: 8
+      job_id: jz5709drg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.040945Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.040950Z'
```

## qai_hub_models/models/quicksrnetmedium_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetmedium_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetmedium_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetmedium_quantized/perf.yaml

```diff
@@ -1,109 +1,100 @@
+aggregated:
+  supported_oses:
+  - Android
+  supported_devices:
+  - Google Pixel 3
+  - Google Pixel 3a
+  - Google Pixel 3a XL
+  - Google Pixel 4
+  - Google Pixel 4a
+  - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
+  - Samsung Galaxy S21
+  - Samsung Galaxy S21 Ultra
+  - Samsung Galaxy S21+
+  - Samsung Galaxy S22 5G
+  - Samsung Galaxy S22 Ultra 5G
+  - Samsung Galaxy S22+ 5G
+  - Samsung Galaxy S23
+  - Samsung Galaxy S23 Ultra
+  - Samsung Galaxy S23+
+  - Samsung Galaxy S24
+  - Samsung Galaxy S24 Ultra
+  - Samsung Galaxy S24+
+  - Samsung Galaxy Tab S8
+  - Xiaomi 12
+  - Xiaomi 12 Pro
+  supported_chipsets:
+  - Qcs6490
+  - Qcs8550
+  - Snapdragon 8 Gen 1
+  - Snapdragon 8 Gen 2
+  - Snapdragon 8 Gen 3
+  - Snapdragon 888
 models:
 - name: QuickSRNetMedium-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1054.0
-      throughput: 948.7666034155598
+      inference_time: 1046.0
+      throughput: 956.0229445506692
       estimated_peak_memory_range:
-        min: 12288
-        max: 1550760
+        min: 1339392
+        max: 2781424
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: j0px9x31p
+      job_id: jqp4k3wlg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:22:27.279987Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.064857Z'
   - torchscript_onnx_tflite:
-      inference_time: 854.0
-      throughput: 1170.96018735363
+      inference_time: 871.0
+      throughput: 1148.105625717566
       estimated_peak_memory_range:
-        min: 12288
-        max: 19670544
+        min: 16384
+        max: 19479952
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: jo5me8owp
+      job_id: j0pxnx195
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:22:27.280002Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-aggregated:
-  supported_oses:
-  - Android
-  supported_devices:
-  - Google Pixel 3
-  - Google Pixel 3a
-  - Google Pixel 3a XL
-  - Google Pixel 4
-  - Google Pixel 4a
-  - Google Pixel 5a 5G
-  - Samsung Galaxy S21
-  - Samsung Galaxy S21 Ultra
-  - Samsung Galaxy S21+
-  - Samsung Galaxy S22 5G
-  - Samsung Galaxy S22 Ultra 5G
-  - Samsung Galaxy S22+ 5G
-  - Samsung Galaxy S23
-  - Samsung Galaxy S23 Ultra
-  - Samsung Galaxy S23+
-  - Samsung Galaxy S24
-  - Samsung Galaxy S24 Ultra
-  - Samsung Galaxy S24+
-  - Samsung Galaxy Tab S8
-  - Xiaomi 12
-  - Xiaomi 12 Pro
-  supported_chipsets:
-  - Snapdragon 8 Gen 1
-  - Snapdragon 8 Gen 2
-  - Snapdragon 8 Gen 3
-  - Snapdragon 888
+    timestamp: '2024-04-16T20:17:33.064887Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.064893Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.064899Z'
```

## qai_hub_models/models/quicksrnetsmall/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetsmall import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetsmall.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetsmall/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: QuickSRNetSmall
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1324.0
-      throughput: 755.2870090634441
+      inference_time: 1316.0
+      throughput: 759.8784194528876
       estimated_peak_memory_range:
-        min: 16384
-        max: 15227496
+        min: 24576
+        max: 8392968
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 8
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 11
-      job_id: jegn0kor5
+      job_id: jo5mq8zqp
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:38:53.058069Z'
     torchscript_onnx_qnn:
       inference_time: 1010.0
       throughput: 990.0990099009902
       estimated_peak_memory_range:
-        min: 225280
-        max: 8292184
+        min: 217088
+        max: 51877032
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 11
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 11
-      job_id: jep2xe44g
+      job_id: jopr8wye5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1411.0
+      throughput: 708.7172218284904
+      estimated_peak_memory_range:
+        min: 217088
+        max: 8686544
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jqpyrmd45
       job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:33.083745Z'
   - torchscript_onnx_tflite:
-      inference_time: 939.0
-      throughput: 1064.9627263045793
+      inference_time: 914.0
+      throughput: 1094.0919037199126
       estimated_peak_memory_range:
         min: 16384
-        max: 18004576
+        max: 18347856
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 8
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 11
-      job_id: jopr6wo9p
+      job_id: jegnlkem5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 617.0
+      throughput: 1620.7455429497568
+      estimated_peak_memory_range:
+        min: 208896
+        max: 14414800
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 11
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 11
+      job_id: jep20emmg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1011.0
+      throughput: 989.1196834817013
+      estimated_peak_memory_range:
+        min: 0
+        max: 12267184
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j2p036rep
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:32.292172Z'
-    torchscript_onnx_qnn:
-      inference_time: 621.0
-      throughput: 1610.3059581320451
+    timestamp: '2024-04-16T20:17:33.083791Z'
+  - torchscript_onnx_ort:
+      inference_time: 11762.0
+      throughput: 85.01955449753443
       estimated_peak_memory_range:
-        min: 229376
-        max: 14179680
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 253952
+        max: 10698672
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 11
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 11
-      job_id: jqpyzmq7g
+        layers_on_cpu: 5
+        total_layers: 5
+      job_id: j1p80178g
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.083807Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.083813Z'
```

## qai_hub_models/models/quicksrnetsmall_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.quicksrnetsmall_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.quicksrnetsmall_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/quicksrnetsmall_quantized/perf.yaml

```diff
@@ -1,109 +1,100 @@
+aggregated:
+  supported_oses:
+  - Android
+  supported_devices:
+  - Google Pixel 3
+  - Google Pixel 3a
+  - Google Pixel 3a XL
+  - Google Pixel 4
+  - Google Pixel 4a
+  - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
+  - Samsung Galaxy S21
+  - Samsung Galaxy S21 Ultra
+  - Samsung Galaxy S21+
+  - Samsung Galaxy S22 5G
+  - Samsung Galaxy S22 Ultra 5G
+  - Samsung Galaxy S22+ 5G
+  - Samsung Galaxy S23
+  - Samsung Galaxy S23 Ultra
+  - Samsung Galaxy S23+
+  - Samsung Galaxy S24
+  - Samsung Galaxy S24 Ultra
+  - Samsung Galaxy S24+
+  - Samsung Galaxy Tab S8
+  - Xiaomi 12
+  - Xiaomi 12 Pro
+  supported_chipsets:
+  - Qcs6490
+  - Qcs8550
+  - Snapdragon 8 Gen 1
+  - Snapdragon 8 Gen 2
+  - Snapdragon 8 Gen 3
+  - Snapdragon 888
 models:
 - name: QuickSRNetSmall-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 992.0
-      throughput: 1008.0645161290323
+      inference_time: 987.0
+      throughput: 1013.1712259371834
       estimated_peak_memory_range:
         min: 20480
-        max: 3845112
+        max: 1821960
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 8
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 11
-      job_id: j2p046d6g
+      job_id: jogk78yop
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:30:25.941729Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.108943Z'
   - torchscript_onnx_tflite:
-      inference_time: 806.0
-      throughput: 1240.6947890818858
+      inference_time: 1612.0
+      throughput: 620.3473945409429
       estimated_peak_memory_range:
-        min: 12288
-        max: 18429184
+        min: 16384
+        max: 18121488
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 8
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 11
-      job_id: j1p8216xp
+      job_id: jn5qev2m5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:25.941742Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-aggregated:
-  supported_oses:
-  - Android
-  supported_devices:
-  - Google Pixel 3
-  - Google Pixel 3a
-  - Google Pixel 3a XL
-  - Google Pixel 4
-  - Google Pixel 4a
-  - Google Pixel 5a 5G
-  - Samsung Galaxy S21
-  - Samsung Galaxy S21 Ultra
-  - Samsung Galaxy S21+
-  - Samsung Galaxy S22 5G
-  - Samsung Galaxy S22 Ultra 5G
-  - Samsung Galaxy S22+ 5G
-  - Samsung Galaxy S23
-  - Samsung Galaxy S23 Ultra
-  - Samsung Galaxy S23+
-  - Samsung Galaxy S24
-  - Samsung Galaxy S24 Ultra
-  - Samsung Galaxy S24+
-  - Samsung Galaxy Tab S8
-  - Xiaomi 12
-  - Xiaomi 12 Pro
-  supported_chipsets:
-  - Snapdragon 8 Gen 1
-  - Snapdragon 8 Gen 2
-  - Snapdragon 8 Gen 3
-  - Snapdragon 888
+    timestamp: '2024-04-16T20:17:33.108969Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.108975Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.108980Z'
```

## qai_hub_models/models/real_esrgan_general_x4v3/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.real_esrgan_general_x4v3 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.real_esrgan_general_x4v3.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/real_esrgan_general_x4v3/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Real-ESRGAN-General-x4v3
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 7135.0
-      throughput: 140.1541695865452
+      inference_time: 7205.0
+      throughput: 138.79250520471894
       estimated_peak_memory_range:
-        min: 15785984
-        max: 26631064
+        min: 15941632
+        max: 27205736
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 69
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 72
-      job_id: jn5q0vz4p
+      job_id: j1gl6lklg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 7008.0
+      throughput: 142.69406392694063
+      estimated_peak_memory_range:
+        min: 45056
+        max: 45937496
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 72
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 72
+      job_id: j1p3v6mzg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 7130.0
+      throughput: 140.25245441795232
+      estimated_peak_memory_range:
+        min: 8429568
+        max: 23590888
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1pv07wm5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:40:09.101637Z'
+    timestamp: '2024-04-16T20:17:33.136582Z'
+  - torchscript_onnx_tflite:
+      inference_time: 5369.0
+      throughput: 186.25442354255912
+      estimated_peak_memory_range:
+        min: 20480
+        max: 55365360
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 69
+        layers_on_gpu: 0
+        layers_on_cpu: 3
+        total_layers: 72
+      job_id: jw56ew17g
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 7001.0
-      throughput: 142.836737608913
+      inference_time: 4934.0
+      throughput: 202.67531414673692
       estimated_peak_memory_range:
-        min: 57344
-        max: 12072040
+        min: 12288
+        max: 31445424
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 72
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 72
-      job_id: jw562wr0g
+      job_id: jwgok8vdp
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 5501.0
-      throughput: 181.78512997636793
+    torchscript_onnx_ort:
+      inference_time: 5279.0
+      throughput: 189.42981625307823
       estimated_peak_memory_range:
-        min: 20480
-        max: 55158288
+        min: 8392704
+        max: 47488976
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 69
+        layers_on_npu: 1
         layers_on_gpu: 0
-        layers_on_cpu: 3
-        total_layers: 72
-      job_id: j1gl4lo85
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j7gjzql85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:42:50.185115Z'
-    torchscript_onnx_qnn:
-      inference_time: 4936.0
-      throughput: 202.5931928687196
+    timestamp: '2024-04-16T20:17:33.136676Z'
+  - torchscript_onnx_ort:
+      inference_time: 398793.0
+      throughput: 2.507566582161673
       estimated_peak_memory_range:
-        min: 12288
-        max: 31063632
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 626688
+        max: 35598960
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 72
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 72
-      job_id: j1p3n6xl5
+        layers_on_cpu: 70
+        total_layers: 70
+      job_id: jlpeeyv0p
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.136705Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.136710Z'
```

## qai_hub_models/models/real_esrgan_x4plus/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.real_esrgan_x4plus import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.real_esrgan_x4plus.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/real_esrgan_x4plus/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Real-ESRGAN-x4plus
   performance_metrics:
-  - torchscript_onnx_tflite:
-      inference_time: 'null'
-      throughput: 'null'
+  - torchscript_onnx_qnn:
+      inference_time: 65726.0
+      throughput: 15.214679122417309
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 102400
+        max: 107703704
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 1031
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        total_layers: 1031
+      job_id: jygzon765
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 69431.0
+      throughput: 14.402788379830335
+      estimated_peak_memory_range:
+        min: 6467584
+        max: 119585224
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jd4v5
+      job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:05:08.717805Z'
-    torchscript_onnx_qnn:
-      inference_time: 66817.0
-      throughput: 14.966251103761019
+    timestamp: '2024-04-16T20:17:33.162732Z'
+  - torchscript_onnx_qnn:
+      inference_time: 50526.0
+      throughput: 19.79179036535645
       estimated_peak_memory_range:
-        min: 139264
-        max: 108335072
+        min: 53248
+        max: 259398784
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 1031
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 1031
-      job_id: j1pvq7ejg
+      job_id: jz5w249j5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 'null'
-      throughput: 'null'
+    torchscript_onnx_ort:
+      inference_time: 50628.0
+      throughput: 19.751915935845776
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 7217152
+        max: 193898256
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        total_layers: 1
+      job_id: jvgde2vl5
+      job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:06:57.492677Z'
-    torchscript_onnx_qnn:
-      inference_time: 51292.0
-      throughput: 19.49621773375965
+    timestamp: '2024-04-16T20:17:33.163018Z'
+  - torchscript_onnx_ort:
+      inference_time: 7662961.0
+      throughput: 0.13049785846489367
       estimated_peak_memory_range:
-        min: 73728
-        max: 258670240
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 194519040
+        max: 419255440
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 1031
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 1031
-      job_id: jygz2n8kg
+        layers_on_cpu: 677
+        total_layers: 677
+      job_id: jz5709jrg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.163186Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.163195Z'
```

## qai_hub_models/models/regnet/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.regnet import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.regnet.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/regnet/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: RegNet
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1895.0
-      throughput: 527.7044854881267
+      inference_time: 2314.0
+      throughput: 432.152117545376
       estimated_peak_memory_range:
-        min: 180224
-        max: 45308848
+        min: 16384
+        max: 2190392
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 112
+        layers_on_npu: 114
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 112
-      job_id: jmg90dxlg
+        total_layers: 114
+      job_id: jqp4k3xlg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2128.0
+      throughput: 469.9248120300752
+      estimated_peak_memory_range:
+        min: 20480
+        max: 15932376
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 188
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 188
+      job_id: jo5mq8wqp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2423.0
+      throughput: 412.71151465125877
+      estimated_peak_memory_range:
+        min: 12288
+        max: 87079712
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jopr8w4e5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:33:39.883573Z'
+    timestamp: '2024-04-16T20:17:33.184487Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1616.0
+      throughput: 618.8118811881188
+      estimated_peak_memory_range:
+        min: 12288
+        max: 134209840
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 114
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 114
+      job_id: j0pxnx795
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 1662.0
-      throughput: 601.6847172081829
+      inference_time: 1506.0
+      throughput: 664.0106241699867
       estimated_peak_memory_range:
-        min: 622592
-        max: 60403520
+        min: 618496
+        max: 77239488
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 186
+        layers_on_npu: 188
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 186
-      job_id: jvgdn2ze5
+        total_layers: 188
+      job_id: jegnlk9m5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1348.0
-      throughput: 741.839762611276
+    torchscript_onnx_ort:
+      inference_time: 1699.0
+      throughput: 588.5815185403178
       estimated_peak_memory_range:
-        min: 12288
-        max: 134684864
+        min: 618496
+        max: 36167024
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 112
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 112
-      job_id: jnp126v2g
+        total_layers: 1
+      job_id: jep20e7mg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:36:21.856849Z'
-    torchscript_onnx_qnn:
-      inference_time: 1192.0
-      throughput: 838.9261744966443
+    timestamp: '2024-04-16T20:17:33.184605Z'
+  - torchscript_onnx_ort:
+      inference_time: 76051.0
+      throughput: 13.149071018132569
       estimated_peak_memory_range:
-        min: 618496
-        max: 71874880
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 10616832
+        max: 56250448
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 186
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 186
-      job_id: j0px9xd1p
+        layers_on_cpu: 85
+        total_layers: 85
+      job_id: jqpyrm445
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.184644Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.184650Z'
```

## qai_hub_models/models/resnet101/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnet101 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnet101.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnet101/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNet101
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2981.0
-      throughput: 335.4579000335458
+      inference_time: 3390.0
+      throughput: 294.9852507374631
       estimated_peak_memory_range:
-        min: 20480
-        max: 2256968
+        min: 28672
+        max: 1775440
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 145
+        layers_on_npu: 147
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 145
-      job_id: j2p046v6g
+        total_layers: 147
+      job_id: j7gjzq085
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 3448.0
+      throughput: 290.0232018561485
+      estimated_peak_memory_range:
+        min: 638976
+        max: 216598456
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 245
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 245
+      job_id: jygzonx65
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3747.0
+      throughput: 266.88017080330934
+      estimated_peak_memory_range:
+        min: 618496
+        max: 366172984
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jd3v5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:33:00.839758Z'
+    timestamp: '2024-04-16T20:17:33.231297Z'
+  - torchscript_onnx_tflite:
+      inference_time: 2446.0
+      throughput: 408.8307440719542
+      estimated_peak_memory_range:
+        min: 212992
+        max: 104476752
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 147
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 147
+      job_id: jlpeeyr0p
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 2909.0
-      throughput: 343.7607425232039
+      inference_time: 2469.0
+      throughput: 405.0222762251924
       estimated_peak_memory_range:
-        min: 626688
-        max: 228487056
+        min: 434176
+        max: 81113840
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 243
+        layers_on_npu: 245
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 243
-      job_id: jogkv892p
+        total_layers: 245
+      job_id: jz5w24dj5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 2205.0
-      throughput: 453.51473922902494
+    torchscript_onnx_ort:
+      inference_time: 2676.0
+      throughput: 373.69207772795215
       estimated_peak_memory_range:
-        min: 12288
-        max: 105917360
+        min: 618496
+        max: 44227744
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 145
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 145
-      job_id: j1p8214xp
+        total_layers: 1
+      job_id: jnp1y6dlp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:35:41.997410Z'
-    torchscript_onnx_qnn:
-      inference_time: 2129.0
-      throughput: 469.7040864255519
+    timestamp: '2024-04-16T20:17:33.231479Z'
+  - torchscript_onnx_ort:
+      inference_time: 176170.0
+      throughput: 5.6763353578929445
       estimated_peak_memory_range:
-        min: 618496
-        max: 73551600
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 6721536
+        max: 58771664
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 243
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 243
-      job_id: jn5q0vm4p
+        layers_on_cpu: 110
+        total_layers: 110
+      job_id: jvgde2rl5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.231519Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.231525Z'
```

## qai_hub_models/models/resnet101_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnet101_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnet101_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnet101_quantized/model.py

```diff
@@ -4,14 +4,15 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import (
     equalize_bn_folded_model,
@@ -21,15 +22,15 @@
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.resnet101.model import ResNet101
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 4
+MODEL_ASSET_VERSION = 5
 DEFAULT_ENCODINGS = "resnet101_quantized_encodings.json"
 
 
 class ResNet101Quantizable(
     AIMETQuantizableMixin,
     ResNet101,
 ):
@@ -38,15 +39,16 @@
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        ResNet101.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        ResNet101.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -71,14 +73,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/resnet101_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNet101Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1103.0
-      throughput: 906.6183136899365
+      inference_time: 1171.0
+      throughput: 853.9709649871904
       estimated_peak_memory_range:
-        min: 40960
-        max: 1823040
+        min: 28672
+        max: 1746016
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 148
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 148
+      job_id: jz5709vrg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1394.0
+      throughput: 717.3601147776184
+      estimated_peak_memory_range:
+        min: 12288
+        max: 186309248
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 146
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 146
-      job_id: j1gl4l185
+      job_id: jopr8w1e5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1804.0
+      throughput: 554.3237250554324
+      estimated_peak_memory_range:
+        min: 12288
+        max: 70503128
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jogk78rop
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:59:57.701225Z'
-    torchscript_onnx_qnn:
-      inference_time: 1097.0
-      throughput: 911.5770282588878
+    timestamp: '2024-04-16T20:17:33.272224Z'
+  - torchscript_onnx_tflite:
+      inference_time: 922.0
+      throughput: 1084.5986984815618
       estimated_peak_memory_range:
-        min: 20480
-        max: 197523472
+        min: 16384
+        max: 92718400
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 143
+        layers_on_npu: 148
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 143
-      job_id: jwgoz84xp
+        total_layers: 148
+      job_id: jo5mq8vqp
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 863.0
-      throughput: 1158.7485515643104
+    torchscript_onnx_qnn:
+      inference_time: 1061.0
+      throughput: 942.5070688030161
       estimated_peak_memory_range:
-        min: 20480
-        max: 92174016
+        min: 167936
+        max: 59048544
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 146
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 146
-      job_id: jw562wd0g
+      job_id: jep20e3mg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1380.0
+      throughput: 724.6376811594203
+      estimated_peak_memory_range:
+        min: 618496
+        max: 46374032
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jn5qev9m5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:25.700326Z'
-    torchscript_onnx_qnn:
-      inference_time: 817.0
-      throughput: 1223.9902080783354
+    timestamp: '2024-04-16T20:17:33.272344Z'
+  - torchscript_onnx_ort:
+      inference_time: 53190.0
+      throughput: 18.80052641473961
       estimated_peak_memory_range:
-        min: 167936
-        max: 53912720
-      primary_compute_unit: NPU
-      precision: int8
+        min: 12480512
+        max: 88971072
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 143
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 143
-      job_id: j1pvq79jg
+        layers_on_cpu: 156
+        total_layers: 156
+      job_id: j1gl6lelg
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.272399Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.272409Z'
```

## qai_hub_models/models/resnet18/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnet18 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnet18.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnet18/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNet18
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1038.0
-      throughput: 963.3911368015414
+      inference_time: 1398.0
+      throughput: 715.307582260372
+      estimated_peak_memory_range:
+        min: 24576
+        max: 2046480
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 38
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 38
+      job_id: jw56ewq7g
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1489.0
+      throughput: 671.591672263264
+      estimated_peak_memory_range:
+        min: 12288
+        max: 83625152
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 53
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 53
+      job_id: jwgok8edp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1543.0
+      throughput: 648.0881399870383
       estimated_peak_memory_range:
         min: 16384
-        max: 1682008
+        max: 82413040
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 36
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 36
-      job_id: j7gjdqwxg
+        total_layers: 1
+      job_id: j7gjzqk85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:32:51.123052Z'
+    timestamp: '2024-04-16T20:17:33.298377Z'
+  - torchscript_onnx_tflite:
+      inference_time: 987.0
+      throughput: 1013.1712259371834
+      estimated_peak_memory_range:
+        min: 12288
+        max: 24202432
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 38
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 38
+      job_id: j1p3v6qzg
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 985.0
-      throughput: 1015.2284263959391
+      inference_time: 1015.0
+      throughput: 985.2216748768473
       estimated_peak_memory_range:
-        min: 16384
-        max: 95517680
+        min: 0
+        max: 31898144
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 51
+        layers_on_npu: 53
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 51
-      job_id: jygz2n4kg
+        total_layers: 53
+      job_id: j1pv07zm5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 772.0
-      throughput: 1295.3367875647668
+    torchscript_onnx_ort:
+      inference_time: 1128.0
+      throughput: 886.5248226950355
       estimated_peak_memory_range:
-        min: 12288
-        max: 23648144
+        min: 618496
+        max: 19073216
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 36
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 36
-      job_id: jlpeoyl1g
+        total_layers: 1
+      job_id: jlpeey40p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:35:30.038080Z'
-    torchscript_onnx_qnn:
-      inference_time: 716.0
-      throughput: 1396.6480446927374
+    timestamp: '2024-04-16T20:17:33.298441Z'
+  - torchscript_onnx_ort:
+      inference_time: 50603.0
+      throughput: 19.76167420903899
       estimated_peak_memory_range:
-        min: 622592
-        max: 26671488
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 3657728
+        max: 22461600
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 51
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 51
-      job_id: jz5ww4465
+        layers_on_cpu: 26
+        total_layers: 26
+      job_id: jygzonv65
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.298460Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.298465Z'
```

## qai_hub_models/models/resnet18_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnet18_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnet18_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnet18_quantized/model.py

```diff
@@ -4,43 +4,45 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.resnet18.model import ResNet18
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 7
+MODEL_ASSET_VERSION = 8
 DEFAULT_ENCODINGS = "resnet18_quantized_encodings.json"
 
 
 class ResNet18Quantizable(AIMETQuantizableMixin, ResNet18):
     """ResNet with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         resnet18_model: QuantizationSimModel,
     ) -> None:
-        ResNet18.__init__(self, resnet18_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        ResNet18.__init__(self, resnet18_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             resnet18_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -63,14 +65,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/resnet18_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNet18Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 355.0
-      throughput: 2816.9014084507044
+      inference_time: 427.0
+      throughput: 2341.92037470726
       estimated_peak_memory_range:
-        min: 12288
-        max: 1475416
+        min: 24576
+        max: 14744816
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 39
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 39
+      job_id: jz5w24mj5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 633.0
+      throughput: 1579.778830963665
+      estimated_peak_memory_range:
+        min: 16384
+        max: 61110464
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 37
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 37
-      job_id: jmg90ddlg
+      job_id: jnp1y6qlp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 977.0
+      throughput: 1023.5414534288639
+      estimated_peak_memory_range:
+        min: 45056
+        max: 142126416
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jz5w24x65
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:39.960726Z'
-    torchscript_onnx_qnn:
-      inference_time: 368.0
-      throughput: 2717.391304347826
+    timestamp: '2024-04-16T20:17:33.321715Z'
+  - torchscript_onnx_tflite:
+      inference_time: 351.0
+      throughput: 2849.002849002849
       estimated_peak_memory_range:
-        min: 0
-        max: 206530616
+        min: 12288
+        max: 24268608
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 34
+        layers_on_npu: 39
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 34
-      job_id: jvgdn22e5
+        total_layers: 39
+      job_id: jmg9jd9v5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 294.0
-      throughput: 3401.360544217687
+    torchscript_onnx_qnn:
+      inference_time: 480.0
+      throughput: 2083.3333333333335
       estimated_peak_memory_range:
-        min: 12288
-        max: 23142320
+        min: 0
+        max: 26088768
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 37
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 37
-      job_id: jnp12662g
+      job_id: jvgde27l5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 750.0
+      throughput: 1333.3333333333333
+      estimated_peak_memory_range:
+        min: 0
+        max: 19250192
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jd8l5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:23.722899Z'
-    torchscript_onnx_qnn:
-      inference_time: 287.0
-      throughput: 3484.320557491289
+    timestamp: '2024-04-16T20:17:33.321775Z'
+  - torchscript_onnx_ort:
+      inference_time: 11826.0
+      throughput: 84.5594452900389
       estimated_peak_memory_range:
-        min: 12288
-        max: 22112096
-      primary_compute_unit: NPU
-      precision: int8
+        min: 1556480
+        max: 29105488
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 34
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 34
-      job_id: jz57299lp
+        layers_on_cpu: 47
+        total_layers: 47
+      job_id: jvgde20e5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.321799Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.321804Z'
```

## qai_hub_models/models/resnet50/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnet50 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnet50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnet50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNet50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1893.0
-      throughput: 528.2620179609086
+      inference_time: 2302.0
+      throughput: 434.4048653344918
       estimated_peak_memory_range:
-        min: 24576
-        max: 2236144
+        min: 20480
+        max: 2370264
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 79
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: jqp4n33vg
+        total_layers: 79
+      job_id: jqp4k38vg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2340.0
+      throughput: 427.35042735042737
+      estimated_peak_memory_range:
+        min: 20480
+        max: 185567384
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 126
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 126
+      job_id: jegnlkxr5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2587.0
+      throughput: 386.5481252415926
+      estimated_peak_memory_range:
+        min: 12288
+        max: 217558712
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jep20ej4g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:02.772259Z'
+    timestamp: '2024-04-16T20:17:33.345425Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1648.0
+      throughput: 606.7961165048544
+      estimated_peak_memory_range:
+        min: 16384
+        max: 69510112
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 79
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 79
+      job_id: jo5mq84wp
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 1782.0
-      throughput: 561.1672278338945
+      inference_time: 1630.0
+      throughput: 613.4969325153374
       estimated_peak_memory_range:
         min: 618496
-        max: 186769968
+        max: 51350896
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 126
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 124
-      job_id: jo5me88wp
+        total_layers: 126
+      job_id: jopr8w995
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1410.0
-      throughput: 709.2198581560284
+    torchscript_onnx_ort:
+      inference_time: 1868.0
+      throughput: 535.3319057815846
       estimated_peak_memory_range:
         min: 0
-        max: 68342016
+        max: 35536992
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: j0px9xx1p
+        total_layers: 1
+      job_id: jqpyrmn75
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:27.391913Z'
-    torchscript_onnx_qnn:
-      inference_time: 1303.0
-      throughput: 767.4597083653108
+    timestamp: '2024-04-16T20:17:33.345522Z'
+  - torchscript_onnx_ort:
+      inference_time: 87191.0
+      throughput: 11.469073642921861
       estimated_peak_memory_range:
-        min: 618496
-        max: 49585360
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 3137536
+        max: 34987136
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 124
-      job_id: jegn0kkr5
+        layers_on_cpu: 59
+        total_layers: 59
+      job_id: j2p036k6p
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.345551Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.345557Z'
```

## qai_hub_models/models/resnext101/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnext101 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnext101.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnext101/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNeXt101
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 6465.0
-      throughput: 154.67904098994586
+      inference_time: 6665.0
+      throughput: 150.03750937734435
       estimated_peak_memory_range:
-        min: 32768
-        max: 2912504
+        min: 53248
+        max: 3235600
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 145
+        layers_on_npu: 147
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 145
-      job_id: j1pvq77jg
+        total_layers: 147
+      job_id: jogk78o2p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 6665.0
+      throughput: 150.03750937734435
+      estimated_peak_memory_range:
+        min: 94208
+        max: 34973960
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 245
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 245
+      job_id: j1gl6lo8g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 7040.0
+      throughput: 142.04545454545453
+      estimated_peak_memory_range:
+        min: 0
+        max: 454692632
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p3v6xlg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:51:13.215900Z'
+    timestamp: '2024-04-16T20:17:33.501047Z'
+  - torchscript_onnx_tflite:
+      inference_time: 4816.0
+      throughput: 207.64119601328903
+      estimated_peak_memory_range:
+        min: 20480
+        max: 366481792
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 147
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 147
+      job_id: jn5qevz45
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 6084.0
-      throughput: 164.3655489809336
+      inference_time: 4797.0
+      throughput: 208.46362309776944
       estimated_peak_memory_range:
-        min: 16384
-        max: 36270640
+        min: 618496
+        max: 131176640
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 243
+        layers_on_npu: 245
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 243
-      job_id: jlpeoyy1g
+        total_layers: 245
+      job_id: jw56ewr0g
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 4520.0
-      throughput: 221.23893805309734
+    torchscript_onnx_ort:
+      inference_time: 5231.0
+      throughput: 191.16803670426305
       estimated_peak_memory_range:
-        min: 20480
-        max: 364641136
+        min: 618496
+        max: 100656704
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 145
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 145
-      job_id: j7gjdqqxg
+        total_layers: 1
+      job_id: jwgok8oxp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:53:55.219027Z'
-    torchscript_onnx_qnn:
-      inference_time: 4424.0
-      throughput: 226.03978300180833
+    timestamp: '2024-04-16T20:17:33.501140Z'
+  - torchscript_onnx_ort:
+      inference_time: 330933.0
+      throughput: 3.0217596915387706
       estimated_peak_memory_range:
-        min: 618496
-        max: 130132064
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 14622720
+        max: 74979712
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 243
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 243
-      job_id: jygz2nnkg
+        layers_on_cpu: 110
+        total_layers: 110
+      job_id: j1pv07ej5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.501174Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.501179Z'
```

## qai_hub_models/models/resnext101_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnext101_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnext101_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnext101_quantized/model.py

```diff
@@ -4,43 +4,45 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.resnext101.model import ResNeXt101
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 4
+MODEL_ASSET_VERSION = 5
 DEFAULT_ENCODINGS = "resnext101_quantized_encodings.json"
 
 
 class ResNeXt101Quantizable(AIMETQuantizableMixin, ResNeXt101):
     """ResNeXt101 with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        ResNeXt101.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        ResNeXt101.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -63,14 +65,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/resnext101_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNeXt101Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2844.0
-      throughput: 351.6174402250352
+      inference_time: 2913.0
+      throughput: 343.2887058015791
       estimated_peak_memory_range:
-        min: 0
-        max: 2204768
+        min: 24576
+        max: 1706912
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 146
+        layers_on_npu: 148
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 146
-      job_id: jz5ww4765
+        total_layers: 148
+      job_id: j7gjzqox5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 3921.0
+      throughput: 255.03698036215252
+      estimated_peak_memory_range:
+        min: 12288
+        max: 136560960
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jygzon8k5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:41:28.974979Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.523763Z'
+  - torchscript_onnx_tflite:
+      inference_time: 2167.0
+      throughput: 461.4674665436087
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 12288
+        max: 262604528
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 148
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 2070.0
-      throughput: 483.09178743961354
+        total_layers: 148
+      job_id: jlpeey81p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2990.0
+      throughput: 334.44816053511704
       estimated_peak_memory_range:
-        min: 12288
-        max: 261887168
+        min: 618496
+        max: 95251808
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 146
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 146
-      job_id: jmg90dmlg
+        total_layers: 1
+      job_id: jz5w24165
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:28.974992Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.523816Z'
+  - torchscript_onnx_ort:
+      inference_time: 88885.0
+      throughput: 11.250492209034146
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 8159232
+        max: 88001424
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 156
+        total_layers: 156
+      job_id: jmg9jdxl5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.523856Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.523862Z'
```

## qai_hub_models/models/resnext50/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnext50 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnext50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnext50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNeXt50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2186.0
-      throughput: 457.45654162854527
+      inference_time: 2502.0
+      throughput: 399.68025579536373
       estimated_peak_memory_range:
-        min: 20480
-        max: 2564264
+        min: 16384
+        max: 2039136
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 79
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: jnp126j2g
+        total_layers: 79
+      job_id: jnp1y6v2p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2619.0
+      throughput: 381.82512409316536
+      estimated_peak_memory_range:
+        min: 12288
+        max: 67332096
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 126
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 126
+      job_id: jz57097lg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2938.0
+      throughput: 340.3675970047652
+      estimated_peak_memory_range:
+        min: 90112
+        max: 153500352
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j0pxnxd15
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:40.598047Z'
+    timestamp: '2024-04-16T20:17:33.545672Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1788.0
+      throughput: 559.2841163310962
+      estimated_peak_memory_range:
+        min: 16384
+        max: 164107600
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 79
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 79
+      job_id: jvgde2ze5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 2074.0
-      throughput: 482.1600771456123
+      inference_time: 1857.0
+      throughput: 538.5029617662897
       estimated_peak_memory_range:
-        min: 622592
-        max: 68996704
+        min: 0
+        max: 60102256
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 126
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 124
-      job_id: jz57294lp
+        total_layers: 126
+      job_id: jqp4k39vg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1561.0
-      throughput: 640.6149903907751
+    torchscript_onnx_ort:
+      inference_time: 2158.0
+      throughput: 463.3920296570899
       estimated_peak_memory_range:
-        min: 12288
-        max: 164341728
+        min: 618496
+        max: 42526736
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: jvgdn23e5
+        total_layers: 1
+      job_id: jo5mq8dwp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:03:00.522367Z'
-    torchscript_onnx_qnn:
-      inference_time: 1518.0
-      throughput: 658.7615283267457
+    timestamp: '2024-04-16T20:17:33.545745Z'
+  - torchscript_onnx_ort:
+      inference_time: 86849.0
+      throughput: 11.514237354488825
       estimated_peak_memory_range:
-        min: 618496
-        max: 60133216
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 11636736
+        max: 43512800
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 124
-      job_id: jqp4n31vg
+        layers_on_cpu: 59
+        total_layers: 59
+      job_id: jegnlk7r5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.545770Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.545776Z'
```

## qai_hub_models/models/resnext50_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.resnext50_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.resnext50_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/resnext50_quantized/model.py

```diff
@@ -4,43 +4,45 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.resnext50.model import ResNeXt50
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 1
+MODEL_ASSET_VERSION = 2
 DEFAULT_ENCODINGS = "resnext50_quantized_encodings.json"
 
 
 class ResNeXt50Quantizable(AIMETQuantizableMixin, ResNeXt50):
     """ResNeXt50 with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        ResNeXt50.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        ResNeXt50.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -63,14 +65,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/resnext50_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: ResNeXt50Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 879.0
-      throughput: 1137.6564277588168
+      inference_time: 949.0
+      throughput: 1053.740779768177
+      estimated_peak_memory_range:
+        min: 40960
+        max: 32336880
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 80
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 80
+      job_id: jopr8wn95
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1749.0
+      throughput: 571.7552887364208
       estimated_peak_memory_range:
         min: 12288
-        max: 1573712
+        max: 65405552
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 78
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 78
-      job_id: j0px9x41p
+        total_layers: 1
+      job_id: jqpyrm775
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:13:52.082055Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.568493Z'
+  - torchscript_onnx_tflite:
+      inference_time: 724.0
+      throughput: 1381.2154696132598
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 12288
+        max: 99522896
+      primary_compute_unit: NPU
+      precision: int8
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 80
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 683.0
-      throughput: 1464.1288433382138
+        total_layers: 80
+      job_id: jep20ev4g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1274.0
+      throughput: 784.9293563579278
       estimated_peak_memory_range:
-        min: 12288
-        max: 98876096
+        min: 0
+        max: 42945536
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 78
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 78
-      job_id: jo5me8mwp
+        total_layers: 1
+      job_id: j2p036v6p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:13:52.082068Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.568546Z'
+  - torchscript_onnx_ort:
+      inference_time: 31790.0
+      throughput: 31.456432840515884
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 8765440
+        max: 56053712
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 88
+        total_layers: 88
+      job_id: j1p8014xg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.568576Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.568582Z'
```

## qai_hub_models/models/sam/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.sam import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,14 +16,16 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.sam.Model.from_pretrained",
         return_value=Model.from_pretrained(
             model_type="vit_b",
         ),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/sam/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SAMDecoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 57777.0
-      throughput: 17.30792529899441
+      inference_time: 47957.0
+      throughput: 20.852013261880433
       estimated_peak_memory_range:
-        min: 5091328
-        max: 14286200
+        min: 4009984
+        max: 23686696
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 364
-        layers_on_gpu: 1
+        layers_on_npu: 340
+        layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 365
-      job_id: jegn0knr5
+        total_layers: 340
+      job_id: jogk7892p
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1089085.0
+      throughput: 0.9182019768888563
+      estimated_peak_memory_range:
+        min: 15695872
+        max: 53847464
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 2
+        layers_on_gpu: 0
+        layers_on_cpu: 1
+        total_layers: 3
+      job_id: j1gl6l18g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:41:53.968079Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.589529Z'
+  - torchscript_onnx_tflite:
+      inference_time: 33609.0
+      throughput: 29.75393495789818
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 61440
+        max: 246507888
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 340
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 39989.0
-      throughput: 25.006876891145065
+        total_layers: 340
+      job_id: jn5qevm45
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 809800.0
+      throughput: 1.2348728081007656
       estimated_peak_memory_range:
-        min: 16384
-        max: 209265456
+        min: 19857408
+        max: 115862864
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 364
-        layers_on_gpu: 1
-        layers_on_cpu: 0
-        total_layers: 365
-      job_id: jopr6w09p
+        layers_on_npu: 2
+        layers_on_gpu: 0
+        layers_on_cpu: 1
+        total_layers: 3
+      job_id: jw56ewd0g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:53.968093Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:33.589602Z'
+  - torchscript_onnx_ort:
+      inference_time: 75754.0
+      throughput: 13.200623069408875
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 62357504
+        max: 174265200
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 284
+        total_layers: 284
+      job_id: j1p3v6wlg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.589653Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.589658Z'
```

## qai_hub_models/models/sesr_m5/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.sesr_m5 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.sesr_m5.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/sesr_m5/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SESR-M5
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2254.0
-      throughput: 443.6557231588287
+      inference_time: 2236.0
+      throughput: 447.2271914132379
       estimated_peak_memory_range:
         min: 24576
-        max: 8961568
+        max: 1639560
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 22
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 25
-      job_id: jep2xew4g
+      job_id: jwgok84xp
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2141.0
+      throughput: 467.07146193367583
+      estimated_peak_memory_range:
+        min: 217088
+        max: 66412728
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 31
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 31
+      job_id: j7gjzqwx5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2959.0
+      throughput: 337.95201081446436
+      estimated_peak_memory_range:
+        min: 28672
+        max: 6879728
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jygzon4k5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:43:53.479475Z'
+    timestamp: '2024-04-16T20:17:33.610579Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1608.0
+      throughput: 621.8905472636816
+      estimated_peak_memory_range:
+        min: 16384
+        max: 24474768
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 22
+        layers_on_gpu: 0
+        layers_on_cpu: 3
+        total_layers: 25
+      job_id: j1pv079j5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 2137.0
-      throughput: 467.94571829667757
+      inference_time: 1452.0
+      throughput: 688.7052341597796
       estimated_peak_memory_range:
-        min: 24576
-        max: 6179792
+        min: 208896
+        max: 24978944
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 31
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 31
-      job_id: j2p046j6g
+      job_id: jlpeeyl1p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1589.0
-      throughput: 629.3266205160478
+    torchscript_onnx_ort:
+      inference_time: 2024.0
+      throughput: 494.0711462450593
       estimated_peak_memory_range:
-        min: 16384
-        max: 24462352
+        min: 208896
+        max: 16041184
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 22
+        layers_on_npu: 1
         layers_on_gpu: 0
-        layers_on_cpu: 3
-        total_layers: 25
-      job_id: jqpyzmx7g
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jz5w24465
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:31.476167Z'
-    torchscript_onnx_qnn:
-      inference_time: 1456.0
-      throughput: 686.8131868131868
+    timestamp: '2024-04-16T20:17:33.610631Z'
+  - torchscript_onnx_ort:
+      inference_time: 116893.0
+      throughput: 8.554832196966457
       estimated_peak_memory_range:
-        min: 212992
-        max: 22416672
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 31080448
+        max: 45827008
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 31
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 31
-      job_id: j1p821xxp
+        layers_on_cpu: 17
+        total_layers: 17
+      job_id: jmg9jddl5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.610651Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.610657Z'
```

## qai_hub_models/models/sesr_m5_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.sesr_m5_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.sesr_m5_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/sesr_m5_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,78 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SESR-M5-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1357.0
-      throughput: 736.9196757553427
+      inference_time: 1356.0
+      throughput: 737.4631268436578
       estimated_peak_memory_range:
-        min: 12288
-        max: 3744312
+        min: 24576
+        max: 1678184
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 11
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 14
-      job_id: jogkv842p
+      job_id: jnp1y662p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:13:49.881073Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.648019Z'
   - torchscript_onnx_tflite:
-      inference_time: 1112.0
-      throughput: 899.2805755395683
+      inference_time: 1067.0
+      throughput: 937.207122774133
       estimated_peak_memory_range:
         min: 12288
-        max: 22134720
+        max: 21689744
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 11
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 14
-      job_id: jn5q0vy4p
+      job_id: jvgde22e5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:13:49.881086Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:33.648046Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.648052Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.648057Z'
```

## qai_hub_models/models/shufflenet_v2/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.shufflenet_v2 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.shufflenet_v2.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/shufflenet_v2/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Shufflenet-v2
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 917.0
-      throughput: 1090.5125408942204
+      inference_time: 1290.0
+      throughput: 775.1937984496124
+      estimated_peak_memory_range:
+        min: 16384
+        max: 6876504
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 204
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 204
+      job_id: jz57099lg
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 797.0
+      throughput: 1254.7051442910915
+      estimated_peak_memory_range:
+        min: 622592
+        max: 68665608
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 158
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 158
+      job_id: j0pxnxx15
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1264.0
+      throughput: 791.1392405063291
       estimated_peak_memory_range:
         min: 12288
-        max: 6661376
+        max: 11265544
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 202
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 202
-      job_id: j1gl4lx85
+        total_layers: 1
+      job_id: jegnlkkr5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:55:19.973155Z'
+    timestamp: '2024-04-16T20:17:33.741217Z'
+  - torchscript_onnx_tflite:
+      inference_time: 855.0
+      throughput: 1169.5906432748538
+      estimated_peak_memory_range:
+        min: 16384
+        max: 33284208
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 204
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 204
+      job_id: jqp4k33vg
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 310.0
-      throughput: 3225.8064516129034
+      inference_time: 528.0
+      throughput: 1893.939393939394
       estimated_peak_memory_range:
-        min: 12288
-        max: 87860112
+        min: 618496
+        max: 53183776
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 156
+        layers_on_npu: 158
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 156
-      job_id: j1p3n69l5
+        total_layers: 158
+      job_id: jo5mq88wp
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 583.0
-      throughput: 1715.2658662092624
+    torchscript_onnx_ort:
+      inference_time: 836.0
+      throughput: 1196.1722488038276
       estimated_peak_memory_range:
         min: 12288
-        max: 33769008
+        max: 17464352
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 202
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 202
-      job_id: jw562w70g
+        total_layers: 1
+      job_id: jopr8ww95
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:58:01.979025Z'
-    torchscript_onnx_qnn:
-      inference_time: 223.0
-      throughput: 4484.304932735426
+    timestamp: '2024-04-16T20:17:33.741324Z'
+  - torchscript_onnx_ort:
+      inference_time: 3481.0
+      throughput: 287.2737719046251
       estimated_peak_memory_range:
-        min: 12288
-        max: 48783840
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 282624
+        max: 62466080
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 156
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 156
-      job_id: jwgoz8rxp
+        layers_on_cpu: 138
+        total_layers: 138
+      job_id: jep20ee4g
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.741367Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.741372Z'
```

## qai_hub_models/models/shufflenet_v2_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.shufflenet_v2_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.shufflenet_v2_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/shufflenet_v2_quantized/model.py

```diff
@@ -4,14 +4,15 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import (
     equalize_bn_folded_model,
@@ -25,15 +26,15 @@
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 from qai_hub_models.utils.quantization_aimet import (
     convert_all_depthwise_to_per_tensor,
     tie_aimet_observer_groups,
 )
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 2
+MODEL_ASSET_VERSION = 3
 DEFAULT_ENCODINGS = "shufflenet_v2_quantized_encodings.json"
 
 
 class ShufflenetV2Quantizable(
     AIMETQuantizableMixin,
     ShufflenetV2,
 ):
@@ -42,15 +43,16 @@
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        ShufflenetV2.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        ShufflenetV2.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -77,14 +79,15 @@
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=dummy_input,
         )
         convert_all_depthwise_to_per_tensor(sim.model)
         cls._tie_pre_concat_quantizers(sim)
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/shufflenet_v2_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,108 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Shufflenet-v2Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 557.0
-      throughput: 1795.3321364452424
+      inference_time: 644.0
+      throughput: 1552.7950310559006
       estimated_peak_memory_range:
         min: 12288
-        max: 1902352
+        max: 1838712
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 203
+        layers_on_npu: 205
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 203
-      job_id: j1pvq7djg
+        total_layers: 205
+      job_id: jqpyrmm75
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 592.0
+      throughput: 1689.1891891891892
+      estimated_peak_memory_range:
+        min: 172032
+        max: 9372520
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 122
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 122
+      job_id: j1p8011xg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:43.037345Z'
-    torchscript_onnx_qnn:
-      inference_time: 274.0
-      throughput: 3649.6350364963505
+    timestamp: '2024-04-16T20:17:33.790579Z'
+  - torchscript_onnx_tflite:
+      inference_time: 464.0
+      throughput: 2155.1724137931033
       estimated_peak_memory_range:
         min: 12288
-        max: 69529408
+        max: 22792592
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 119
+        layers_on_npu: 205
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 119
-      job_id: jlpeoyz1g
+        total_layers: 205
+      job_id: j2p03666p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 404.0
-      throughput: 2475.2475247524753
+    torchscript_onnx_qnn:
+      inference_time: 424.0
+      throughput: 2358.490566037736
       estimated_peak_memory_range:
-        min: 12288
-        max: 22095680
+        min: 163840
+        max: 45354944
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 203
+        layers_on_npu: 122
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 203
-      job_id: j7gjdq7xg
+        total_layers: 122
+      job_id: jogk7882p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:24.193795Z'
-    torchscript_onnx_qnn:
-      inference_time: 194.0
-      throughput: 5154.639175257732
-      estimated_peak_memory_range:
-        min: 163840
-        max: 40609808
-      primary_compute_unit: NPU
-      precision: int8
-      layer_info:
-        layers_on_npu: 119
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 119
-      job_id: jygz2nmkg
-      job_status: Passed
+    timestamp: '2024-04-16T20:17:33.790668Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.790674Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.790679Z'
```

## qai_hub_models/models/sinet/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.sinet import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.sinet.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/sinet/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SINet
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1813.0
-      throughput: 551.5719801434087
+      inference_time: 1826.0
+      throughput: 547.645125958379
       estimated_peak_memory_range:
-        min: 28672
-        max: 2078752
+        min: 12288
+        max: 2609144
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 240
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 240
-      job_id: jz5ww4l65
+      job_id: jn5qevv45
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 1184.0
+      throughput: 844.5945945945946
+      estimated_peak_memory_range:
+        min: 618496
+        max: 4714320
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 186
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 186
+      job_id: jw56eww0g
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jwgok88xp
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:44.533757Z'
-    torchscript_onnx_qnn:
-      inference_time: 1195.0
-      throughput: 836.8200836820083
+    timestamp: '2024-04-16T20:17:33.859879Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1171.0
+      throughput: 853.9709649871904
       estimated_peak_memory_range:
-        min: 622592
-        max: 58073808
+        min: 12288
+        max: 25301888
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 186
+        layers_on_npu: 240
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 186
-      job_id: jnp126n2g
+        total_layers: 240
+      job_id: j1gl6ll8g
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1197.0
-      throughput: 835.421888053467
+    torchscript_onnx_qnn:
+      inference_time: 799.0
+      throughput: 1251.5644555694619
       estimated_peak_memory_range:
         min: 12288
-        max: 25406400
+        max: 64850320
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 240
+        layers_on_npu: 186
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 240
-      job_id: jmg90dzlg
+        total_layers: 186
+      job_id: j1p3v66lg
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: j1pv077j5
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:24.421326Z'
-    torchscript_onnx_qnn:
-      inference_time: 798.0
-      throughput: 1253.1328320802006
+    timestamp: '2024-04-16T20:17:33.859978Z'
+  - torchscript_onnx_ort:
+      inference_time: 10435.0
+      throughput: 95.83133684714902
       estimated_peak_memory_range:
-        min: 0
-        max: 67803232
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 319488
+        max: 87361408
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 186
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 186
-      job_id: jvgdn2de5
+        layers_on_cpu: 200
+        total_layers: 200
+      job_id: j7gjzqqx5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.860021Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.860031Z'
```

## qai_hub_models/models/squeezenet1_1/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.squeezenet1_1 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.squeezenet1_1.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/squeezenet1_1/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SqueezeNet-1_1
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 223.0
-      throughput: 4484.304932735426
+      inference_time: 672.0
+      throughput: 1488.095238095238
       estimated_peak_memory_range:
-        min: 24576
-        max: 1673088
+        min: 12288
+        max: 1740976
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 41
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 41
+      job_id: jlpeeyy1p
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 711.0
+      throughput: 1406.4697609001407
+      estimated_peak_memory_range:
+        min: 638976
+        max: 12256680
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 39
+        layers_on_npu: 70
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 39
-      job_id: jz5ww4l35
+        total_layers: 70
+      job_id: jz5w24765
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 861.0
+      throughput: 1161.4401858304298
+      estimated_peak_memory_range:
+        min: 12288
+        max: 10395112
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jnp1y6j2p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:16:32.269958Z'
+    timestamp: '2024-04-16T20:17:33.903003Z'
+  - torchscript_onnx_tflite:
+      inference_time: 453.0
+      throughput: 2207.5055187637968
+      estimated_peak_memory_range:
+        min: 12288
+        max: 22540768
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 41
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 41
+      job_id: jygzonnk5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 274.0
-      throughput: 3649.6350364963505
+      inference_time: 490.0
+      throughput: 2040.8163265306123
       estimated_peak_memory_range:
-        min: 16384
-        max: 8208760
+        min: 618496
+        max: 28785760
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 68
+        layers_on_npu: 70
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 68
-      job_id: jnp126n8g
+        total_layers: 70
+      job_id: jmg9jdml5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 182.0
-      throughput: 5494.505494505494
+    torchscript_onnx_ort:
+      inference_time: 618.0
+      throughput: 1618.1229773462783
       estimated_peak_memory_range:
-        min: 12288
-        max: 21808400
+        min: 618496
+        max: 20314848
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 39
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 39
-      job_id: jmg90dzwg
+        total_layers: 1
+      job_id: jvgde23e5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:11.667370Z'
-    torchscript_onnx_qnn:
-      inference_time: 199.0
-      throughput: 5025.125628140703
+    timestamp: '2024-04-16T20:17:33.903066Z'
+  - torchscript_onnx_ort:
+      inference_time: 9264.0
+      throughput: 107.94473229706391
       estimated_peak_memory_range:
-        min: 618496
-        max: 28004672
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 311296
+        max: 24698816
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 68
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 68
-      job_id: jvgdn2dr5
+        layers_on_cpu: 41
+        total_layers: 41
+      job_id: jz5w24735
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.903088Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.903093Z'
```

## qai_hub_models/models/squeezenet1_1_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.squeezenet1_1_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.squeezenet1_1_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/squeezenet1_1_quantized/model.py

```diff
@@ -4,43 +4,45 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import equalize_model
 from aimet_torch.model_preparer import prepare_model
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.squeezenet1_1.model import SqueezeNet
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 2
+MODEL_ASSET_VERSION = 3
 DEFAULT_ENCODINGS = "squeezenet1_1_quantized_encodings.json"
 
 
 class SqueezeNetQuantizable(AIMETQuantizableMixin, SqueezeNet):
     """SqueezeNet with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        SqueezeNet.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        SqueezeNet.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -63,14 +65,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=torch.rand(input_shape),
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/squeezenet1_1_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: SqueezeNet-1_1Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 150.0
-      throughput: 6666.666666666667
+      inference_time: 218.0
+      throughput: 4587.155963302752
+      estimated_peak_memory_range:
+        min: 24576
+        max: 1453208
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 41
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 41
+      job_id: jmg9jdmw5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 466.0
+      throughput: 2145.922746781116
       estimated_peak_memory_range:
         min: 12288
-        max: 1450328
+        max: 10115704
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 39
+        layers_on_npu: 45
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 39
-      job_id: jz5729evp
+        total_layers: 45
+      job_id: jvgde23r5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 811.0
+      throughput: 1233.0456226880394
+      estimated_peak_memory_range:
+        min: 618496
+        max: 5355192
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jqp4k318g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:15.491720Z'
-    torchscript_onnx_qnn:
-      inference_time: 179.0
-      throughput: 5586.592178770949
+    timestamp: '2024-04-16T20:17:33.926625Z'
+  - torchscript_onnx_tflite:
+      inference_time: 178.0
+      throughput: 5617.9775280898875
       estimated_peak_memory_range:
         min: 12288
-        max: 73066960
+        max: 21783424
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 42
+        layers_on_npu: 41
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 42
-      job_id: j0px9xl3p
+        total_layers: 41
+      job_id: jnp1y6j8p
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 130.0
-      throughput: 7692.307692307692
+    torchscript_onnx_qnn:
+      inference_time: 343.0
+      throughput: 2915.451895043732
+      estimated_peak_memory_range:
+        min: 167936
+        max: 23042032
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 45
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 45
+      job_id: jz57094vg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 632.0
+      throughput: 1582.2784810126582
       estimated_peak_memory_range:
         min: 12288
-        max: 21769728
+        max: 16606592
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 39
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 39
-      job_id: jqp4n3y8g
+        total_layers: 1
+      job_id: j0pxnx435
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:02:39.628312Z'
-    torchscript_onnx_qnn:
-      inference_time: 155.0
-      throughput: 6451.612903225807
+    timestamp: '2024-04-16T20:17:33.926679Z'
+  - torchscript_onnx_ort:
+      inference_time: 3597.0
+      throughput: 278.00945232137894
       estimated_peak_memory_range:
-        min: 184320
-        max: 20075776
-      primary_compute_unit: NPU
-      precision: int8
+        min: 0
+        max: 28318256
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 42
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 42
-      job_id: jo5me80dp
+        layers_on_cpu: 51
+        total_layers: 51
+      job_id: jo5mq8mdp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.926703Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.926709Z'
```

## qai_hub_models/models/stylegan2/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.stylegan2 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.stylegan2.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/stylegan2/info.yaml

```diff
@@ -5,15 +5,14 @@
 headline: Generate realistic, randomized images of real classes.
 domain: Computer Vision
 description: StyleGAN2 is a machine learning model that generates realistic images
   from random input state vectors.
 use_case: Image Generation
 tags:
   - real-time
-  - generative-ai
 research_paper: http://arxiv.org/abs/1912.04958
 research_paper_title: Analyzing and Improving the Image Quality of StyleGAN
 license: https://github.com/NVlabs/stylegan3/blob/main/LICENSE.txt
 deploy_license: https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/Qualcomm+AI+Hub+Proprietary+License.pdf
 source_repo: https://github.com/NVlabs/stylegan3
 technical_details:
   Model checkpoint: StyleGAN2 (afhqcat dataset)
```

## qai_hub_models/models/stylegan2/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: StyleGAN2
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1245465.0
-      throughput: 0.8029129682488066
+      inference_time: 1317970.0
+      throughput: 0.7587426117438182
       estimated_peak_memory_range:
-        min: 1583226880
-        max: 1586523400
+        min: 1448136704
+        max: 2566842336
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 89
-        layers_on_cpu: 478
-        total_layers: 567
-      job_id: jegn0kzk5
+        layers_on_gpu: 78
+        layers_on_cpu: 402
+        total_layers: 480
+      job_id: jegnlknk5
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:46:54.066866Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jep20ewrg
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:33.993139Z'
   - torchscript_onnx_tflite:
-      inference_time: 1030564.0
-      throughput: 0.970342453258604
+      inference_time: 1012977.0
+      throughput: 0.9871892451654875
       estimated_peak_memory_range:
-        min: 897953792
-        max: 928847488
+        min: 954945536
+        max: 980253632
       primary_compute_unit: CPU
       precision: fp32
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 89
-        layers_on_cpu: 478
-        total_layers: 567
-      job_id: jopr6wl0p
+        layers_on_gpu: 78
+        layers_on_cpu: 402
+        total_layers: 480
+      job_id: jopr8w005
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: jqpyrmx85
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:54.066880Z'
-    torchscript_onnx_qnn:
+    timestamp: '2024-04-16T20:17:33.993259Z'
+  - torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: j2p036j9p
+      job_status: Failed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:33.993275Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:33.993281Z'
```

## qai_hub_models/models/swin_base/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.swin_base import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.swin_base.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/swin_base/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Swin-Base
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 66984.0
-      throughput: 14.928938253911381
+      inference_time: 61028.0
+      throughput: 16.38592121649079
+      estimated_peak_memory_range:
+        min: 106496
+        max: 3418200
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1568
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1568
+      job_id: j1p801xkg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 72900.0
+      throughput: 13.717421124828531
       estimated_peak_memory_range:
         min: 118784
-        max: 4254288
+        max: 421108168
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 1614
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 1614
-      job_id: jep2xerrg
+        total_layers: 1
+      job_id: jn5qevyn5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:14:19.208239Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.015592Z'
+  - torchscript_onnx_tflite:
+      inference_time: 39474.0
+      throughput: 25.333130668287986
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 73728
+        max: 512044160
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 1568
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 43260.0
-      throughput: 23.11604253351826
+        total_layers: 1568
+      job_id: jogk784wp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 51726.0
+      throughput: 19.332637358388432
       estimated_peak_memory_range:
-        min: 90112
-        max: 512533392
+        min: 651264
+        max: 268896832
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 1614
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 1614
-      job_id: jqpyzmo8g
+        total_layers: 1
+      job_id: j1gl6lxjg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:14:19.208253Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.015822Z'
+  - torchscript_onnx_ort:
+      inference_time: 316019.0
+      throughput: 3.1643666994706012
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 50855936
+        max: 473442224
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 1054
+        total_layers: 1054
+      job_id: jw56ew76g
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.015972Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.015979Z'
```

## qai_hub_models/models/swin_base/test.py

```diff
@@ -7,24 +7,25 @@
 
 from qai_hub_models.models._shared.imagenet_classifier.test_utils import (  # noqa: F401
     imagenet_sample_torch,
     run_imagenet_classifier_test,
 )
 from qai_hub_models.models.swin_base.demo import main as demo_main
 from qai_hub_models.models.swin_base.model import MODEL_ID, SwinBase
+from qai_hub_models.utils.image_processing import normalize_image_torchvision
 
 
 def test_numerical(imagenet_sample_torch):
     # Ensure that the optimized SwinBase matches the original one numerically
     x = imagenet_sample_torch
     model_opt = SwinBase.from_pretrained().eval()
     model_orig = tv_models.swin_b(weights="IMAGENET1K_V1").eval()
     np.testing.assert_allclose(
         model_opt(x).detach().numpy(),
-        model_orig(x).detach().numpy(),
+        model_orig(normalize_image_torchvision(x)).detach().numpy(),
         atol=1e-5,
         rtol=1e-3,
     )
 
 
 def test_task():
     run_imagenet_classifier_test(
```

## qai_hub_models/models/swin_small/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.swin_small import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.swin_small.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/swin_small/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Swin-Small
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 50305.0
-      throughput: 19.87873968790379
+      inference_time: 46059.0
+      throughput: 21.711283353959054
       estimated_peak_memory_range:
-        min: 114688
-        max: 3114440
+        min: 28672
+        max: 8907776
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 1609
+        layers_on_npu: 1563
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 1609
-      job_id: j2p046m9g
+        total_layers: 1563
+      job_id: j1p3v693g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 61104.0
+      throughput: 16.365540717465304
+      estimated_peak_memory_range:
+        min: 12288
+        max: 250842792
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1pv07lk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:59:03.699659Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.038305Z'
+  - torchscript_onnx_tflite:
+      inference_time: 29579.0
+      throughput: 33.80776902532202
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 45056
+        max: 479603376
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 1563
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 32975.0
-      throughput: 30.32600454890068
+        total_layers: 1563
+      job_id: jwgok8rqp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 43618.0
+      throughput: 22.926314824155167
       estimated_peak_memory_range:
-        min: 45056
-        max: 479723312
+        min: 696320
+        max: 646499600
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 1609
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 1609
-      job_id: j1p821ekp
+        total_layers: 1
+      job_id: j7gjzqrv5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:59:03.699672Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.038593Z'
+  - torchscript_onnx_ort:
+      inference_time: 191054.0
+      throughput: 5.234122290033184
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 38006784
+        max: 457314976
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 1050
+        total_layers: 1050
+      job_id: jlpeey7op
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.038775Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.038781Z'
```

## qai_hub_models/models/swin_small/test.py

```diff
@@ -7,24 +7,25 @@
 
 from qai_hub_models.models._shared.imagenet_classifier.test_utils import (  # noqa: F401
     imagenet_sample_torch,
     run_imagenet_classifier_test,
 )
 from qai_hub_models.models.swin_small.demo import main as demo_main
 from qai_hub_models.models.swin_small.model import MODEL_ID, SwinSmall
+from qai_hub_models.utils.image_processing import normalize_image_torchvision
 
 
 def test_numerical(imagenet_sample_torch):
     # Ensure that the optimized SwinSmall matches the original one numerically
     x = imagenet_sample_torch
     model_opt = SwinSmall.from_pretrained().eval()
     model_orig = tv_models.swin_s(weights="IMAGENET1K_V1").eval()
     np.testing.assert_allclose(
         model_opt(x).detach().numpy(),
-        model_orig(x).detach().numpy(),
+        model_orig(normalize_image_torchvision(x)).detach().numpy(),
         atol=1e-5,
         rtol=1e-3,
     )
 
 
 def test_task():
     run_imagenet_classifier_test(
```

## qai_hub_models/models/swin_tiny/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.swin_tiny import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.swin_tiny.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/swin_tiny/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Swin-Tiny
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 31126.0
-      throughput: 32.12748184797275
+      inference_time: 28481.0
+      throughput: 35.11112671605632
       estimated_peak_memory_range:
-        min: 53248
-        max: 3289744
+        min: 217088
+        max: 74292680
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 859
+        layers_on_npu: 837
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 859
-      job_id: jogkv82wp
+        total_layers: 837
+      job_id: jygzonlo5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 27887.0
+      throughput: 35.85900240255316
+      estimated_peak_memory_range:
+        min: 16384
+        max: 164109776
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jmg9jdzw5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:46:54.220773Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.060657Z'
+  - torchscript_onnx_tflite:
+      inference_time: 18310.0
+      throughput: 54.614964500273075
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 40960
+        max: 293649808
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 837
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 20461.0
-      throughput: 48.87346659498558
+        total_layers: 837
+      job_id: jz5w24l35
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 19785.0
+      throughput: 50.543340914834474
       estimated_peak_memory_range:
-        min: 45056
-        max: 293868864
+        min: 634880
+        max: 162638432
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 859
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 859
-      job_id: jn5q0vlnp
+        total_layers: 1
+      job_id: jnp1y6n8p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:46:54.220786Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.060798Z'
+  - torchscript_onnx_ort:
+      inference_time: 103881.0
+      throughput: 9.626399437818273
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 40472576
+        max: 272448208
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 564
+        total_layers: 564
+      job_id: jvgde2dr5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.060892Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.060899Z'
```

## qai_hub_models/models/swin_tiny/test.py

```diff
@@ -8,24 +8,25 @@
 from qai_hub_models.models._shared.imagenet_classifier.test_utils import (  # noqa: F401
     imagenet_sample_torch,
     run_imagenet_classifier_test,
     run_imagenet_classifier_trace_test,
 )
 from qai_hub_models.models.swin_tiny.demo import main as demo_main
 from qai_hub_models.models.swin_tiny.model import MODEL_ID, SwinTiny
+from qai_hub_models.utils.image_processing import normalize_image_torchvision
 
 
 def test_numerical(imagenet_sample_torch):
     # Ensure that the optimized SwinTiny matches the original one numerically
     x = imagenet_sample_torch
     model_opt = SwinTiny.from_pretrained().eval()
     model_orig = tv_models.swin_t(weights="IMAGENET1K_V1").eval()
     np.testing.assert_allclose(
         model_opt(x).detach().numpy(),
-        model_orig(x).detach().numpy(),
+        model_orig(normalize_image_torchvision(x)).detach().numpy(),
         atol=1e-5,
         rtol=1e-3,
     )
 
 
 def test_task():
     run_imagenet_classifier_test(
```

## qai_hub_models/models/trocr/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.trocr import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.trocr.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/trocr/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,232 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: TrOCREncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 243112.0
-      throughput: 4.1133304814241995
+      inference_time: 216492.0
+      throughput: 4.619108327328492
       estimated_peak_memory_range:
-        min: 7290880
-        max: 10682856
+        min: 7274496
+        max: 10306224
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 628
+        layers_on_npu: 592
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 628
-      job_id: j1gl4lyj5
+        total_layers: 592
+      job_id: jz5709evg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 189041.0
+      throughput: 5.289857755724949
+      estimated_peak_memory_range:
+        min: 69632
+        max: 125141888
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jegnlkzk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:25:12.572315Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.085150Z'
+  - torchscript_onnx_tflite:
+      inference_time: 162590.0
+      throughput: 6.1504397564425854
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 5963776
+        max: 327025904
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 592
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 182195.0
-      throughput: 5.488624825050084
+        total_layers: 592
+      job_id: j0pxnxl35
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 143879.0
+      throughput: 6.95028461415495
       estimated_peak_memory_range:
-        min: 6701056
-        max: 331600272
+        min: 14708736
+        max: 90842000
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 628
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 628
-      job_id: j1p3n6z35
+        total_layers: 1
+      job_id: jep20errg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:25:12.572329Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.085260Z'
+  - torchscript_onnx_ort:
+      inference_time: 329378.0
+      throughput: 3.036025478325814
       estimated_peak_memory_range:
         min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        max: 157362896
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 365
+        total_layers: 365
+      job_id: j2p036m9p
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.085323Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.085329Z'
 - name: TrOCRDecoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2781.0
-      throughput: 359.5828838547285
+      inference_time: 2684.0
+      throughput: 372.5782414307005
       estimated_peak_memory_range:
-        min: 28672
-        max: 2706376
+        min: 16384
+        max: 2557552
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 394
+        layers_on_npu: 370
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 394
-      job_id: jw562w86g
+        total_layers: 370
+      job_id: jqp4k3y8g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2944.0
+      throughput: 339.67391304347825
+      estimated_peak_memory_range:
+        min: 28672
+        max: 392358928
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 1
+        total_layers: 2
+      job_id: jopr8wl05
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:30:38.723405Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.085406Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1948.0
+      throughput: 513.347022587269
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 12288
+        max: 192910976
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 370
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 1988.0
-      throughput: 503.01810865191146
+        total_layers: 370
+      job_id: jo5mq80dp
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2482.0
+      throughput: 402.90088638195004
       estimated_peak_memory_range:
-        min: 12288
-        max: 194199920
+        min: 0
+        max: 36159696
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 394
+        layers_on_npu: 1
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 394
-      job_id: jwgoz8lqp
+        layers_on_cpu: 1
+        total_layers: 2
+      job_id: jqpyrmo85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:38.723420Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+    timestamp: '2024-04-16T20:17:34.085483Z'
+  - torchscript_onnx_ort:
+      inference_time: 7508.0
+      throughput: 133.19126265316996
+      estimated_peak_memory_range:
+        min: 7491584
+        max: 135510624
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 300
+        total_layers: 300
+      job_id: j1p801ekg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.085537Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.085542Z'
```

## qai_hub_models/models/unet_segmentation/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.unet_segmentation import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.unet_segmentation.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/unet_segmentation/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Unet-Segmentation
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 159721.0
-      throughput: 6.260917474846764
+      inference_time: 155616.0
+      throughput: 6.4260744396463085
       estimated_peak_memory_range:
-        min: 6688768
-        max: 230831992
+        min: 6692864
+        max: 229373376
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 31
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 31
-      job_id: j1pvq72kg
+      job_id: jogk782wp
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 150609.0
+      throughput: 6.63970944631463
+      estimated_peak_memory_range:
+        min: 9854976
+        max: 34064640
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 51
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 51
+      job_id: j1gl6lyjg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 150132.0
+      throughput: 6.6608051581275145
+      estimated_peak_memory_range:
+        min: 13246464
+        max: 147066768
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1p3v6z3g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T16:00:44.075564Z'
+    timestamp: '2024-04-16T20:17:34.126218Z'
+  - torchscript_onnx_tflite:
+      inference_time: 112866.0
+      throughput: 8.860064146864424
+      estimated_peak_memory_range:
+        min: 5500928
+        max: 359682512
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 31
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 31
+      job_id: jn5qevln5
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 143885.0
-      throughput: 6.949994787503909
+      inference_time: 111273.0
+      throughput: 8.98690607784458
       estimated_peak_memory_range:
-        min: 9871360
-        max: 36840448
+        min: 9814016
+        max: 110733232
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 51
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 51
-      job_id: jlpeoy6og
+      job_id: jw56ew86g
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 113226.0
-      throughput: 8.831893734654585
+    torchscript_onnx_ort:
+      inference_time: 110582.0
+      throughput: 9.043063066321825
       estimated_peak_memory_range:
-        min: 4681728
-        max: 361817664
+        min: 16162816
+        max: 113694432
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 31
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 31
-      job_id: j7gjdq3vg
+        total_layers: 1
+      job_id: jwgok8lqp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T16:03:02.410135Z'
-    torchscript_onnx_qnn:
-      inference_time: 110489.0
-      throughput: 9.050674727800958
+    timestamp: '2024-04-16T20:17:34.126274Z'
+  - torchscript_onnx_ort:
+      inference_time: 11877125.0
+      throughput: 0.08419545975983245
       estimated_peak_memory_range:
-        min: 9871360
-        max: 113176352
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 1166123008
+        max: 1184789632
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 51
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 51
-      job_id: jygz2nzog
+        layers_on_cpu: 31
+        total_layers: 31
+      job_id: j1pv072k5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.126295Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.126300Z'
```

## qai_hub_models/models/vit/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.vit import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.vit.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/vit/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: VIT
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 135551.0
-      throughput: 7.3772971058863455
+      inference_time: 119744.0
+      throughput: 8.351149118118654
       estimated_peak_memory_range:
-        min: 167936
-        max: 4072768
+        min: 196608
+        max: 3447072
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 557
+        layers_on_npu: 535
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 557
-      job_id: jz5ww4y35
+        total_layers: 535
+      job_id: j7gjzq3v5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 128755.0
+      throughput: 7.766688672284571
+      estimated_peak_memory_range:
+        min: 36864
+        max: 430908512
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jygzonzo5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:59:30.586343Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.149872Z'
+  - torchscript_onnx_tflite:
+      inference_time: 89024.0
+      throughput: 11.23292595255212
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 151552
+        max: 407939792
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 535
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 100385.0
-      throughput: 9.96164765652239
+        total_layers: 535
+      job_id: jlpeey6op
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 98667.0
+      throughput: 10.135100894929408
       estimated_peak_memory_range:
-        min: 172032
-        max: 414376288
+        min: 663552
+        max: 874006192
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 557
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 557
-      job_id: jmg90dowg
+        total_layers: 1
+      job_id: jz5w24y35
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:59:30.586357Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.149997Z'
+  - torchscript_onnx_ort:
+      inference_time: 370419.0
+      throughput: 2.6996455365410523
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 7974912
+        max: 138230016
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 285
+        total_layers: 285
+      job_id: jmg9jdow5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.150063Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.150070Z'
```

## qai_hub_models/models/whisper_base_en/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.whisper_base_en import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.whisper_base_en.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/whisper_base_en/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,232 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: WhisperEncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 154210.0
-      throughput: 6.484663770183516
+      inference_time: 154415.0
+      throughput: 6.476054787423502
       estimated_peak_memory_range:
-        min: 11546624
-        max: 113388704
+        min: 36925440
+        max: 139242008
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 315
+        layers_on_gpu: 303
         layers_on_cpu: 0
-        total_layers: 315
-      job_id: jnp126o8g
+        total_layers: 303
+      job_id: jnp1y6o8p
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:35:51.877964Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: j0pxnx035
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:34.173016Z'
   - torchscript_onnx_tflite:
-      inference_time: 124136.0
-      throughput: 8.055680866146806
+      inference_time: 118628.0
+      throughput: 8.42971305256769
       estimated_peak_memory_range:
-        min: 35241984
-        max: 63999568
+        min: 36814848
+        max: 61467824
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 315
+        layers_on_gpu: 303
         layers_on_cpu: 0
-        total_layers: 315
-      job_id: jz5729ovp
+        total_layers: 303
+      job_id: jz5709ovg
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:35:51.877979Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jegnlk1k5
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:34.173102Z'
+  - torchscript_onnx_ort:
+      inference_time: 5372639.0
+      throughput: 0.186128269552449
+      estimated_peak_memory_range:
+        min: 165142528
+        max: 204558448
+      primary_compute_unit: GPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 7
+        layers_on_cpu: 6
+        total_layers: 13
+      job_id: jep20eorg
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.173121Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.173126Z'
 - name: WhisperDecoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 14069.0
-      throughput: 71.0782571611344
+      inference_time: 13793.0
+      throughput: 72.50054375407815
       estimated_peak_memory_range:
-        min: 5812224
-        max: 8998208
+        min: 5775360
+        max: 8469096
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 459
+        layers_on_npu: 447
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 461
-      job_id: jvgdn26r5
+        total_layers: 449
+      job_id: jvgde26r5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 17653.0
+      throughput: 56.64759530957911
+      estimated_peak_memory_range:
+        min: 11657216
+        max: 330606792
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 3
+      job_id: jo5mq89dp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:41:26.044149Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.173228Z'
   - torchscript_onnx_tflite:
-      inference_time: 10562.0
-      throughput: 94.6790380609733
+      inference_time: 10194.0
+      throughput: 98.09691975671964
       estimated_peak_memory_range:
-        min: 4571136
-        max: 110220208
+        min: 3768320
+        max: 98615936
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 459
+        layers_on_npu: 447
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 449
+      job_id: jqp4k3e8g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 14072.0
+      throughput: 71.0631040363843
+      estimated_peak_memory_range:
+        min: 52715520
+        max: 167779568
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 461
-      job_id: jqp4n3e8g
+        total_layers: 3
+      job_id: jopr8wx05
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:26.044164Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.173327Z'
+  - torchscript_onnx_ort:
+      inference_time: 38739.0
+      throughput: 25.813779395441287
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 43307008
+        max: 164573664
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 294
+        total_layers: 294
+      job_id: jqpyrm885
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.173391Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.173396Z'
```

## qai_hub_models/models/whisper_small_en/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.whisper_small_en import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.whisper_small_en.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/whisper_small_en/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,232 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: WhisperEncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 598326.0
-      throughput: 1.6713296764640013
+      inference_time: 600006.0
+      throughput: 1.666650000166665
       estimated_peak_memory_range:
-        min: 95817728
-        max: 535321856
+        min: 79036416
+        max: 532898328
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 609
+        layers_on_gpu: 585
         layers_on_cpu: 0
-        total_layers: 609
-      job_id: j0px9x03p
+        total_layers: 585
+      job_id: j2p036o9p
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:36:02.927472Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: j1gl6lwjg
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:34.211429Z'
   - torchscript_onnx_tflite:
-      inference_time: 469347.0
-      throughput: 2.1306197759866365
+      inference_time: 465622.0
+      throughput: 2.1476648440151025
       estimated_peak_memory_range:
-        min: 28250112
-        max: 60097088
+        min: 110800896
+        max: 143440272
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 609
+        layers_on_gpu: 585
         layers_on_cpu: 0
-        total_layers: 609
-      job_id: jegn0k1k5
+        total_layers: 585
+      job_id: jogk786wp
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 'null'
+      throughput: 'null'
+      estimated_peak_memory_range:
+        min: 0
+        max: 0
+      primary_compute_unit: 'null'
+      precision: 'null'
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 0
+      job_id: j1p3v6o3g
+      job_status: Failed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:36:02.927486Z'
-    torchscript_onnx_qnn:
+    timestamp: '2024-04-16T20:17:34.211536Z'
+  - torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: j1pv07mk5
+      job_status: Failed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.211553Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.211558Z'
 - name: WhisperDecoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 46381.0
-      throughput: 21.560552812574116
+      inference_time: 45614.0
+      throughput: 21.92309378699522
       estimated_peak_memory_range:
-        min: 16228352
-        max: 19790512
+        min: 16830464
+        max: 20007784
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 903
+        layers_on_npu: 879
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 905
-      job_id: jo5me89dp
+        total_layers: 881
+      job_id: j1p801jkg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 75579.0
+      throughput: 13.231188557668135
+      estimated_peak_memory_range:
+        min: 40751104
+        max: 289480944
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 3
+      job_id: jw56ewo6g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:41:42.406080Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.211699Z'
   - torchscript_onnx_tflite:
-      inference_time: 34412.0
-      throughput: 29.059630361501803
+      inference_time: 34559.0
+      throughput: 28.936022454353424
       estimated_peak_memory_range:
-        min: 20180992
-        max: 1716349552
+        min: 15560704
+        max: 1589538480
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 903
+        layers_on_npu: 879
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 881
+      job_id: jn5qev4n5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 60639.0
+      throughput: 16.49103712132456
+      estimated_peak_memory_range:
+        min: 160247808
+        max: 557923088
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 905
-      job_id: jopr6wx0p
+        total_layers: 3
+      job_id: jwgok8dqp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:42.406095Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.211846Z'
+  - torchscript_onnx_ort:
+      inference_time: 97060.0
+      throughput: 10.302905419328251
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 136572928
+        max: 369089808
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 582
+        total_layers: 582
+      job_id: j7gjzqyv5
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.211956Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.211964Z'
```

## qai_hub_models/models/whisper_tiny_en/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.whisper_tiny_en import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.whisper_tiny_en.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/whisper_tiny_en/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,168 +23,232 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: WhisperEncoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 69083.0
-      throughput: 14.475341256170115
+      inference_time: 67351.0
+      throughput: 14.847589493845675
       estimated_peak_memory_range:
-        min: 2011136
-        max: 68110808
+        min: 16117760
+        max: 104999648
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 217
+        layers_on_gpu: 209
         layers_on_cpu: 0
-        total_layers: 217
-      job_id: jep2xeorg
+        total_layers: 209
+      job_id: jlpeeyxop
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:14:01.654956Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jnp1y618p
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:34.249472Z'
   - torchscript_onnx_tflite:
-      inference_time: 53036.0
-      throughput: 18.855117278829475
+      inference_time: 52682.0
+      throughput: 18.981815420826848
       estimated_peak_memory_range:
         min: 0
-        max: 25669392
+        max: 28255008
       primary_compute_unit: GPU
       precision: fp16
       layer_info:
         layers_on_npu: 0
-        layers_on_gpu: 217
+        layers_on_gpu: 209
         layers_on_cpu: 0
-        total_layers: 217
-      job_id: j2p046o9g
+        total_layers: 209
+      job_id: jz5w24z35
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:14:01.654971Z'
-    torchscript_onnx_qnn:
+    torchscript_onnx_ort:
       inference_time: 'null'
       throughput: 'null'
       estimated_peak_memory_range:
         min: 0
         max: 0
       primary_compute_unit: 'null'
       precision: 'null'
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 0
-      job_id: ''
-      job_status: Skipped
+      job_id: jz5709nvg
+      job_status: Failed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:34.249530Z'
+  - torchscript_onnx_ort:
+      inference_time: 2208077.0
+      throughput: 0.4528827572589181
+      estimated_peak_memory_range:
+        min: 123895808
+        max: 156042800
+      primary_compute_unit: GPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 5
+        layers_on_cpu: 4
+        total_layers: 9
+      job_id: j0pxnxr35
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.249548Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.249553Z'
 - name: WhisperDecoder
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 7365.0
-      throughput: 135.77732518669382
+      inference_time: 7115.0
+      throughput: 140.54813773717498
       estimated_peak_memory_range:
-        min: 3002368
-        max: 5408984
+        min: 2977792
+        max: 5417544
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 311
+        layers_on_npu: 303
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 313
-      job_id: jqpyzm88g
+        total_layers: 305
+      job_id: jygzonyo5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 8714.0
+      throughput: 114.75786091347257
+      estimated_peak_memory_range:
+        min: 6172672
+        max: 212702328
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 3
+      job_id: jvgde24r5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:19:28.253886Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.249619Z'
   - torchscript_onnx_tflite:
-      inference_time: 5492.0
-      throughput: 182.0830298616169
+      inference_time: 5479.0
+      throughput: 182.5150574922431
       estimated_peak_memory_range:
-        min: 20480
-        max: 233538800
+        min: 2871296
+        max: 232253952
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 311
+        layers_on_npu: 303
+        layers_on_gpu: 0
+        layers_on_cpu: 2
+        total_layers: 305
+      job_id: jmg9jd2w5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 6141.0
+      throughput: 162.83992835043153
+      estimated_peak_memory_range:
+        min: 24158208
+        max: 103238656
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 2
-        total_layers: 313
-      job_id: j1p821jkp
+        total_layers: 3
+      job_id: jqp4k348g
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:19:28.253901Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.249684Z'
+  - torchscript_onnx_ort:
+      inference_time: 18647.0
+      throughput: 53.62792942564488
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 22511616
+        max: 106667856
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 198
+        total_layers: 198
+      job_id: jo5mq8kdp
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.249724Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.249729Z'
```

## qai_hub_models/models/wideresnet50/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.wideresnet50 import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.wideresnet50.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/wideresnet50/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: WideResNet50
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 4786.0
-      throughput: 208.94274968658587
+      inference_time: 4900.0
+      throughput: 204.08163265306123
       estimated_peak_memory_range:
-        min: 28672
-        max: 170961592
+        min: 49152
+        max: 2616288
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 79
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: jogkv86wp
+        total_layers: 79
+      job_id: jegnlkqk5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 5767.0
+      throughput: 173.40038148083926
+      estimated_peak_memory_range:
+        min: 618496
+        max: 261398592
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 126
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 126
+      job_id: jep20edrg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 5427.0
+      throughput: 184.26386585590566
+      estimated_peak_memory_range:
+        min: 36864
+        max: 457326944
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j2p03699p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:27:33.204984Z'
+    timestamp: '2024-04-16T20:17:34.287009Z'
+  - torchscript_onnx_tflite:
+      inference_time: 3655.0
+      throughput: 273.59781121751024
+      estimated_peak_memory_range:
+        min: 16384
+        max: 97733152
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 79
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 79
+      job_id: jopr8wd05
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 4614.0
-      throughput: 216.7316861725184
+      inference_time: 4245.0
+      throughput: 235.57126030624264
       estimated_peak_memory_range:
-        min: 643072
-        max: 314223792
+        min: 618496
+        max: 53403616
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 126
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 124
-      job_id: j1gl4lwj5
+        total_layers: 126
+      job_id: jqpyrm285
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 3605.0
-      throughput: 277.39251040221916
+    torchscript_onnx_ort:
+      inference_time: 4122.0
+      throughput: 242.600679281902
       estimated_peak_memory_range:
-        min: 20480
-        max: 96019088
+        min: 618496
+        max: 39529440
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 77
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 77
-      job_id: jn5q0v4np
+        total_layers: 1
+      job_id: j1p801rkg
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:30:15.130717Z'
-    torchscript_onnx_qnn:
-      inference_time: 3410.0
-      throughput: 293.2551319648094
+    timestamp: '2024-04-16T20:17:34.287087Z'
+  - torchscript_onnx_ort:
+      inference_time: 244281.0
+      throughput: 4.093646251652809
       estimated_peak_memory_range:
-        min: 618496
-        max: 53769616
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 4247552
+        max: 41412368
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 124
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 124
-      job_id: jw562wo6g
+        layers_on_cpu: 59
+        total_layers: 59
+      job_id: jogk780wp
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.287114Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.287120Z'
```

## qai_hub_models/models/wideresnet50_quantized/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.wideresnet50_quantized import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.wideresnet50_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/wideresnet50_quantized/model.py

```diff
@@ -4,14 +4,15 @@
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 # isort: off
 # This verifies aimet is installed, and this must be included first.
 from qai_hub_models.utils.quantization_aimet import (
     AIMETQuantizableMixin,
+    constrain_quantized_inputs_to_image_range,
 )
 
 # isort: on
 
 import torch
 from aimet_torch.cross_layer_equalization import (
     equalize_bn_folded_model,
@@ -21,29 +22,30 @@
 from aimet_torch.quantsim import QuantizationSimModel, load_encodings_to_sim
 
 from qai_hub_models.models.wideresnet50.model import WideResNet50
 from qai_hub_models.utils.aimet.config_loader import get_default_aimet_config
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset
 
 MODEL_ID = __name__.split(".")[-2]
-MODEL_ASSET_VERSION = 2
+MODEL_ASSET_VERSION = 3
 DEFAULT_ENCODINGS = "wideresnet50_quantized_encodings.json"
 
 
 class WideResNet50Quantizable(AIMETQuantizableMixin, WideResNet50):
     """WideResNet50 with post train quantization support.
 
     Supports only 8 bit weights and activations, and only loads pre-quantized checkpoints.
     Support for quantizing using your own weights & data will come at a later date."""
 
     def __init__(
         self,
         sim_model: QuantizationSimModel,
     ) -> None:
-        WideResNet50.__init__(self, sim_model.model)
+        # Input is already normalized by sim_model. Disable it in the wrapper model.
+        WideResNet50.__init__(self, sim_model.model, normalize_input=False)
         AIMETQuantizableMixin.__init__(
             self,
             sim_model,
         )
 
     @classmethod
     def from_pretrained(
@@ -68,14 +70,15 @@
             model,
             quant_scheme="tf_enhanced",
             default_param_bw=8,
             default_output_bw=8,
             config_file=get_default_aimet_config(),
             dummy_input=dummy_input,
         )
+        constrain_quantized_inputs_to_image_range(sim)
 
         if aimet_encodings:
             if aimet_encodings == "DEFAULT":
                 aimet_encodings = CachedWebModelAsset.from_asset_store(
                     MODEL_ID, MODEL_ASSET_VERSION, DEFAULT_ENCODINGS
                 ).fetch()
             load_encodings_to_sim(sim, aimet_encodings)
```

## qai_hub_models/models/wideresnet50_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: WideResNet50-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1771.0
-      throughput: 564.652738565782
+      inference_time: 1807.0
+      throughput: 553.4034311012729
       estimated_peak_memory_range:
-        min: 12288
-        max: 2057600
+        min: 49152
+        max: 2181928
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 80
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 80
+      job_id: jn5qev1n5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 2119.0
+      throughput: 471.92071731949034
+      estimated_peak_memory_range:
+        min: 0
+        max: 480120320
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 78
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 78
-      job_id: jwgoz8dqp
+      job_id: jw56ewm6g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 2464.0
+      throughput: 405.84415584415586
+      estimated_peak_memory_range:
+        min: 24576
+        max: 187692992
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jwgok8wqp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:50:01.927438Z'
-    torchscript_onnx_qnn:
-      inference_time: 1722.0
-      throughput: 580.7200929152149
+    timestamp: '2024-04-16T20:17:34.311033Z'
+  - torchscript_onnx_tflite:
+      inference_time: 1351.0
+      throughput: 740.1924500370096
       estimated_peak_memory_range:
-        min: 16384
-        max: 480044216
+        min: 12288
+        max: 55206416
       primary_compute_unit: NPU
       precision: int8
       layer_info:
-        layers_on_npu: 75
+        layers_on_npu: 80
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 75
-      job_id: j7gjdqyvg
+        total_layers: 80
+      job_id: j1gl6l8jg
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 1346.0
-      throughput: 742.9420505200594
+    torchscript_onnx_qnn:
+      inference_time: 1589.0
+      throughput: 629.3266205160478
       estimated_peak_memory_range:
-        min: 12288
-        max: 55534992
+        min: 167936
+        max: 45857248
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 78
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 78
-      job_id: j1pvq7mkg
+      job_id: j1p3v673g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1858.0
+      throughput: 538.2131324004306
+      estimated_peak_memory_range:
+        min: 0
+        max: 28645856
+      primary_compute_unit: NPU
+      precision: int8
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: j1pv07nk5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:43.890803Z'
-    torchscript_onnx_qnn:
-      inference_time: 1290.0
-      throughput: 775.1937984496124
+    timestamp: '2024-04-16T20:17:34.311102Z'
+  - torchscript_onnx_ort:
+      inference_time: 75852.0
+      throughput: 13.183568000843747
       estimated_peak_memory_range:
-        min: 167936
-        max: 41464352
-      primary_compute_unit: NPU
-      precision: int8
+        min: 4431872
+        max: 54054544
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 75
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 75
-      job_id: jlpeoyxog
+        layers_on_cpu: 88
+        total_layers: 88
+      job_id: j7gjzq8v5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.311130Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.311135Z'
```

## qai_hub_models/models/xlsr/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.xlsr import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.xlsr.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/xlsr/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: XLSR
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 2520.0
-      throughput: 396.8253968253968
+      inference_time: 2596.0
+      throughput: 385.2080123266564
       estimated_peak_memory_range:
-        min: 28672
-        max: 1367248
+        min: 12288
+        max: 1829544
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 13
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 16
-      job_id: jygz2nyog
+      job_id: jlpeeynop
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S23
-      os: '13'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:55:01.326907Z'
     torchscript_onnx_qnn:
       inference_time: 971.0
       throughput: 1029.8661174047375
       estimated_peak_memory_range:
         min: 217088
-        max: 67726144
+        max: 11994560
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 21
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 21
-      job_id: jmg90d2wg
+      job_id: jz5w24r35
       job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1502.0
+      throughput: 665.7789613848203
+      estimated_peak_memory_range:
+        min: 212992
+        max: 8613544
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jnp1y6m8p
+      job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S23
+      os: '13'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 2
+    timestamp: '2024-04-16T20:17:34.334232Z'
   - torchscript_onnx_tflite:
-      inference_time: 1798.0
-      throughput: 556.1735261401557
+      inference_time: 1833.0
+      throughput: 545.5537370430987
       estimated_peak_memory_range:
         min: 16384
-        max: 19705360
+        max: 19549104
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 13
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 16
-      job_id: jz5ww4z35
+      job_id: jygzon0o5
       job_status: Passed
-    reference_device_info:
-      name: Samsung Galaxy S24
-      os: '14'
-      form_factor: Phone
-      os_name: Android
-      manufacturer: Samsung
-      chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:57:38.953477Z'
     torchscript_onnx_qnn:
-      inference_time: 628.0
-      throughput: 1592.3566878980891
+      inference_time: 632.0
+      throughput: 1582.2784810126582
       estimated_peak_memory_range:
         min: 208896
-        max: 18068960
+        max: 17756816
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 21
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 21
-      job_id: jnp12618g
+      job_id: jmg9jdqw5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 1006.0
+      throughput: 994.0357852882704
+      estimated_peak_memory_range:
+        min: 344064
+        max: 16233520
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jvgde2mr5
+      job_status: Passed
+    reference_device_info:
+      name: Samsung Galaxy S24
+      os: '14'
+      form_factor: Phone
+      os_name: Android
+      manufacturer: Samsung
+      chipset: Snapdragon 8 Gen 3
+    timestamp: '2024-04-16T20:17:34.334283Z'
+  - torchscript_onnx_ort:
+      inference_time: 14457.0
+      throughput: 69.17064397869544
+      estimated_peak_memory_range:
+        min: 348160
+        max: 14558736
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 0
+        layers_on_gpu: 0
+        layers_on_cpu: 14
+        total_layers: 14
+      job_id: jz5w24rm5
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.334301Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.334307Z'
```

## qai_hub_models/models/xlsr_quantized/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.xlsr_quantized import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.xlsr_quantized.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/xlsr_quantized/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,78 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: XLSR-Quantized
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 1152.0
-      throughput: 868.0555555555555
+      inference_time: 1128.0
+      throughput: 886.5248226950355
       estimated_peak_memory_range:
-        min: 77824
-        max: 1569664
+        min: 12288
+        max: 1590504
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: jvgdn24r5
+      job_id: jmg9jdq85
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:52:42.432436Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.357060Z'
   - torchscript_onnx_tflite:
-      inference_time: 927.0
-      throughput: 1078.7486515641856
+      inference_time: 1209.0
+      throughput: 827.129859387924
       estimated_peak_memory_range:
-        min: 16384
-        max: 20315072
+        min: 53248
+        max: 20193472
       primary_compute_unit: NPU
       precision: int8
       layer_info:
         layers_on_npu: 14
         layers_on_gpu: 0
         layers_on_cpu: 3
         total_layers: 17
-      job_id: jz5729nvp
+      job_id: jnp1y6m7p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:52:42.432450Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.357086Z'
+  - reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.357093Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.357098Z'
```

## qai_hub_models/models/yolov6/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.yolov6 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.yolov6.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/yolov6/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,153 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Yolo-v6
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 7224.0
-      throughput: 138.42746400885935
+      inference_time: 7953.0
+      throughput: 125.7387149503332
       estimated_peak_memory_range:
-        min: 53248
-        max: 8291064
+        min: 2138112
+        max: 5576840
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 182
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 182
-      job_id: jqp4n348g
+      job_id: jvgde2mz5
+      job_status: Passed
+    torchscript_onnx_qnn:
+      inference_time: 6885.0
+      throughput: 145.24328249818447
+      estimated_peak_memory_range:
+        min: 4939776
+        max: 18625080
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 229
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 229
+      job_id: jqp4k321g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 6690.0
+      throughput: 149.47683109118086
+      estimated_peak_memory_range:
+        min: 5345280
+        max: 37259592
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jo5mq8l9p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:38:46.956110Z'
+    timestamp: '2024-04-16T20:17:34.376242Z'
+  - torchscript_onnx_tflite:
+      inference_time: 5649.0
+      throughput: 177.02248185519562
+      estimated_peak_memory_range:
+        min: 16384
+        max: 82704608
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 182
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 182
+      job_id: jz570989g
+      job_status: Passed
     torchscript_onnx_qnn:
-      inference_time: 6898.0
-      throughput: 144.96955639315743
+      inference_time: 4867.0
+      throughput: 205.4653790836244
       estimated_peak_memory_range:
-        min: 5578752
-        max: 19291464
+        min: 4931584
+        max: 98473200
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 229
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 229
-      job_id: jo5me8kdp
+      job_id: j0pxnxzl5
       job_status: Passed
-  - torchscript_onnx_tflite:
-      inference_time: 5152.0
-      throughput: 194.09937888198758
+    torchscript_onnx_ort:
+      inference_time: 4842.0
+      throughput: 206.52622883106156
       estimated_peak_memory_range:
-        min: 36864
-        max: 82013648
+        min: 4931584
+        max: 66299664
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 182
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 182
-      job_id: j0px9xr3p
+        total_layers: 1
+      job_id: jegnlkwq5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:41:29.144196Z'
-    torchscript_onnx_qnn:
-      inference_time: 4871.0
-      throughput: 205.29665366454526
+    timestamp: '2024-04-16T20:17:34.376351Z'
+  - torchscript_onnx_ort:
+      inference_time: 126965.0
+      throughput: 7.876186350569054
       estimated_peak_memory_range:
-        min: 4947968
-        max: 93426784
-      primary_compute_unit: NPU
-      precision: fp16
+        min: 0
+        max: 67148048
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
-        layers_on_npu: 229
+        layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 229
-      job_id: jegn0kqk5
+        layers_on_cpu: 149
+        total_layers: 149
+      job_id: jopr8w775
       job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.376390Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.376396Z'
```

## qai_hub_models/models/yolov7/app.py

```diff
@@ -1,16 +1,19 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
+from typing import Tuple
+
 import torch
 
 from qai_hub_models.models._shared.yolo.app import YoloObjectDetectionApp
+from qai_hub_models.models._shared.yolo.utils import detect_postprocess
 from qai_hub_models.models.yolov7.model import YoloV7
 
 
 class YoloV7DetectionApp(YoloObjectDetectionApp):
     def check_image_size(self, pixel_values: torch.Tensor) -> None:
         """
         Verify image size is valid model input.
@@ -20,7 +23,27 @@
         if (
             pixel_values.shape[2] % YoloV7.STRIDE_MULTIPLE != 0
             or pixel_values.shape[3] % YoloV7.STRIDE_MULTIPLE != 0
         ):
             raise ValueError(
                 f"Pixel values must have spatial dimensions (H & W) that are multiples of {YoloV7.STRIDE_MULTIPLE}."
             )
+
+    def pre_nms_postprocess(
+        self, *predictions: torch.Tensor
+    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
+        """
+        Process the output of the YOLO detector for input to NMS.
+
+        Parameters:
+            detector_output: torch.Tensor
+                The output of Yolo detection model. Tensor shape varies by model implementation.
+
+        Returns:
+            boxes: torch.Tensor
+                Bounding box locations. Shape is [batch, num preds, 4] where 4 == (x1, y1, x2, y2)
+            scores: torch.Tensor
+                class scores multiplied by confidence: Shape is [batch, num_preds]
+            class_idx: torch.Tensor
+                Shape is [batch, num_preds] where the last dim is the index of the most probable class of the prediction.
+        """
+        return detect_postprocess(torch.cat(predictions, -1))
```

## qai_hub_models/models/yolov7/conftest.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.yolov7 import Model
 from qai_hub_models.utils.testing import skip_clone_repo_check
 
@@ -15,12 +16,14 @@
 @pytest.fixture(autouse=True)
 @skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.yolov7.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/yolov7/model.py

```diff
@@ -1,24 +1,26 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 from importlib import reload
-from typing import Any, List, Mapping, Optional
+from typing import Any, List, Mapping, Optional, Tuple
 
 import torch
 
+from qai_hub_models.evaluators.base_evaluators import BaseEvaluator
+from qai_hub_models.evaluators.detection_evaluator import DetectionEvaluator
 from qai_hub_models.models._shared.yolo.utils import (
-    detect_postprocess,
+    detect_postprocess_split_input,
     yolo_sample_inputs,
 )
 from qai_hub_models.models.common import SampleInputsType
-from qai_hub_models.utils.asset_loaders import SourceAsRoot
+from qai_hub_models.utils.asset_loaders import SourceAsRoot, find_replace_in_repo
 from qai_hub_models.utils.base_model import BaseModel
 from qai_hub_models.utils.input_spec import InputSpec
 
 YOLOV7_SOURCE_REPOSITORY = "https://github.com/WongKinYiu/yolov7"
 YOLOV7_SOURCE_REPO_COMMIT = "84932d70fb9e2932d0a70e4a1f02a1d6dd1dd6ca"
 MODEL_ID = __name__.split(".")[-2]
 DEFAULT_WEIGHTS = "yolov7-tiny.pt"
@@ -29,82 +31,111 @@
     """Exportable YoloV7 bounding box detector, end-to-end."""
 
     def __init__(
         self,
         yolov7_feature_extractor: torch.nn.Module,
         yolov7_detector: torch.nn.Module,
         include_postprocessing: bool = True,
+        split_output: bool = False,
     ) -> None:
         super().__init__()
         self.yolov7_feature_extractor = yolov7_feature_extractor
         self.yolov7_detector = yolov7_detector
         self.include_postprocessing = include_postprocessing
+        self.split_output = split_output
 
     # All image input spatial dimensions should be a multiple of this stride.
     STRIDE_MULTIPLE = 32
 
+    def get_evaluator(self) -> BaseEvaluator:
+        return DetectionEvaluator(640, 640)
+
     @classmethod
     def from_pretrained(
         cls,
         weights_name: Optional[str] = DEFAULT_WEIGHTS,
         include_postprocessing: bool = True,
+        split_output: bool = False,
     ):
         """Load YoloV7 from a weightfile created by the source YoloV7 repository."""
         # Load PyTorch model from disk
         yolov7_model = _load_yolov7_source_model_from_weights(weights_name)
 
         yolov7_model.profile = False
 
         # When traced = True, the model will skip the "Detect" step,
         # which allows us to override it with an exportable version.
         yolov7_model.traced = True
 
         # Generate replacement detector that can be traced
         detector_head_state_dict = yolov7_model.model[-1].state_dict()
         detector_head_state_dict["stride"] = yolov7_model.model[-1].stride
-        detector_head_state_dict["f"] = yolov7_model.model[
-            -1
-        ].f  # Previous (input) node indices in sequential model
-        detector_head_state_dict["i"] = yolov7_model.model[
-            -1
-        ].i  # Index in sequential model
+
+        h, w = cls.get_input_spec()["image"][0][2:]
+        detector_head_state_dict["h"] = h
+        detector_head_state_dict["w"] = w
         yolov7_detect = _YoloV7Detector.from_yolov7_state_dict(detector_head_state_dict)
 
-        return cls(yolov7_model, yolov7_detect, include_postprocessing)
+        return cls(
+            yolov7_model,
+            yolov7_detect,
+            include_postprocessing,
+            split_output,
+        )
 
-    def forward(self, image: torch.Tensor):
+    def forward(self, image):
         """
         Run YoloV7 on `image`, and produce a predicted set of bounding boxes and associated class probabilities.
 
         Parameters:
             image: Pixel values pre-processed for encoder consumption.
                    Range: float[0, 1]
                    3-channel Color Space: BGR
 
         Returns:
             If self.include_postprocessing:
-                boxes: Shape [batch, num preds, 4] where 4 == (center_x, center_y, w, h)
-                classes: class scores multiplied by confidence: Shape [batch, num_preds, # of classes (typically 80)]
+                boxes: torch.Tensor
+                    Bounding box locations.  Shape [batch, num preds, 4] where 4 == (center_x, center_y, w, h)
+                scores: torch.Tensor
+                    class scores multiplied by confidence: Shape is [batch, num_preds]
+                class_idx: torch.tensor
+                    Shape is [batch, num_preds] where the last dim is the index of the most probable class of the prediction.
+
+            else if self.split_output:
+                output_xy: torch.Tensor
+                    Shape is [batch, num_preds, 2]
+                        where, 2 is [x_center, y_center] (box_coordinates)
+
+                output_wh: torch.Tensor
+                    Shape is [batch, num_preds, 2]
+                        where, 2 is [width, height] (box_size)
+
+                output_scores: torch.Tensor
+                    Shape is [batch, num_preds, j]
+                        where j is [confidence (1 element) , # of classes elements]
 
-            Otherwise:
+
+            else:
                 detector_output: torch.Tensor
                     Shape is [batch, num_preds, k]
                         where, k = # of classes + 5
                         k is structured as follows [box_coordinates (4) , conf (1) , # of classes]
                         and box_coordinates are [x_center, y_center, w, h]
         """
         feature_extraction_output = (
             *self.yolov7_feature_extractor(image),
         )  # Convert output list to Tuple, for exportability
-        prediction = self.yolov7_detector(feature_extraction_output)
-        return (
-            detect_postprocess(prediction)
-            if self.include_postprocessing
-            else prediction
-        )
+        detector_output = self.yolov7_detector(feature_extraction_output)
+
+        if not self.include_postprocessing:
+            if self.split_output:
+                return detector_output
+            return torch.cat(detector_output, -1)
+
+        return detect_postprocess_split_input(*detector_output)
 
     @staticmethod
     def get_input_spec(
         batch_size: int = 1,
         num_channels: int = 3,
         height: int = 640,
         width: int = 640,
@@ -124,29 +155,27 @@
 
 class _YoloV7Detector(torch.nn.Module):  # YoloV7 Detection
     """Converts features extracted by YoloV7 to predicted bounding boxes & associated class predictions."""
 
     def __init__(
         self,
         stride: torch.Tensor,
-        f,
-        i,
         num_anchors: int,
         num_layers: int,
         m_in_channels: List[int],
         m_out_channel,
+        input_shape: Tuple[int, int],
     ):
         super(_YoloV7Detector, self).__init__()
-        self.f = f
-        self.i = i
         self.stride = stride
         self.na = num_anchors
         self.no = m_out_channel // self.na  # number of outputs per anchor
         self.nc = self.no - 5  # number of classes
         self.nl = num_layers
+        self.h, self.w = input_shape
         for i in range(0, self.nl):
             self.register_buffer(
                 f"anchor_grid_{i}", torch.zeros(1, self.na, 1, 1, 2)
             )  # nl * [ tensor(shape(1,na,1,1,2)) ]
         self.m = torch.nn.ModuleList(
             torch.nn.Conv2d(m_in_channel, m_out_channel, 1)
             for m_in_channel in m_in_channels
@@ -176,75 +205,96 @@
         for i in range(0, nl):
             weight = f"m.{i}.weight"
             for x in [weight, f"m.{i}.bias"]:
                 new_state_dict[x] = state_dict[x]
             m_in_channels.append(new_state_dict[weight].shape[1])
             m_out_channel = new_state_dict[weight].shape[0]
 
+        input_shape = state_dict["h"], state_dict["w"]
+
         out = _YoloV7Detector(
             state_dict["stride"],
-            state_dict["f"],
-            state_dict["i"],
             na,
             nl,
             m_in_channels,
             m_out_channel,
+            input_shape,
         )
         out.load_state_dict(new_state_dict, strict)
         return out
 
     def make_grid_points(self, x, i):
         x = x.sigmoid()
-        bs, _, ny, nx = x.shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
-        x = x.view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
+        # bs, _, ny, nx = x.shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
+        stride = int(self.stride[i])
+        nx, ny = self.h // stride, self.w // stride
+        x = x.reshape(-1, self.na, self.no, nx, ny).permute(0, 1, 3, 4, 2).contiguous()
         grid = self._make_grid(nx, ny)
         y = x
-        xy = (y[..., 0:2] * 2.0 - 0.5 + grid) * self.stride[i]
-        wh = (y[..., 2:4] * 2) ** 2 * self.__getattr__(f"anchor_grid_{i}")
 
-        cat = torch.cat((xy, wh, y[..., 4:]), -1)
-        return cat.view(bs, -1, self.no)
+        # Fp16 NPU only supports tensor math up to rank 4
+        # xy computation suffers from accuracy loss when moved to NPU
+        # Only convert wh to rank 4
+        xy = (y[..., 0:2] * 2.0 - 0.5 + grid) * stride
+        xy = xy.reshape(-1, self.na * nx * ny, 2)
+
+        wh = y[..., 2:4].reshape(-1, self.na, nx * ny, 2)
+        wh = (wh * 2) ** 2 * self.__getattr__(f"anchor_grid_{i}").squeeze(2)
+        wh = wh.reshape(-1, self.na * nx * ny, 2)
+
+        scores = y[..., 4:].reshape(-1, self.na * nx * ny, self.no - 4)
+        return xy, wh, scores
 
-    def forward(self, all_x: tuple[torch.Tensor, ...]):
+    def forward(self, all_x: Tuple[torch.Tensor, ...]):
         """
         From the outputs of the feature extraction layers of YoloV7, predict bounding boxes,
         classes, and confidence.
 
         Parameters:
-            all_x: tuple[torch.Tensor]
+            all_x: Tuple[torch.Tensor]
                 Outputs of the feature extraction layers of YoloV7. Typically 3 5D tensors.
 
         Returns:
             pred: [batch_size, # of predictions, 5 + # of classes]
                 Where the rightmost dim contains [center_x, center_y, w, h, confidence score, n per-class scores]
         """
-        z = []  # inference output
+        # inference output
+        all_xy = []
+        all_wh = []
+        all_scores = []
         for i in range(self.nl):
             x = all_x[i]
             x = self.m[i](x)  # conv
-            points = self.make_grid_points(x, i)
-            z.append(points)
+            xy, wh, scores = self.make_grid_points(x, i)
+            all_xy.append(xy)
+            all_wh.append(wh)
+            all_scores.append(scores)
 
-        return torch.cat(z, 1)
+        return torch.cat(all_xy, 1), torch.cat(all_wh, 1), torch.cat(all_scores, 1)
 
     @staticmethod
-    def _make_grid(nx=20, ny=20):
+    def _make_grid(nx: int, ny: int):
         yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)], indexing="ij")
         return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()
 
 
 def _load_yolov7_source_model_from_weights(weights_name: str) -> torch.nn.Module:
     # Load YoloV7 model from the source repository using the given weights.
     # Returns <source repository>.models.yolo.Model
     with SourceAsRoot(
         YOLOV7_SOURCE_REPOSITORY,
         YOLOV7_SOURCE_REPO_COMMIT,
         MODEL_ID,
         MODEL_ASSET_VERSION,
-    ):
+    ) as repo_path:
+        # We don't touch these flags, and having conditionals in `forward`
+        # dependent on inputs to the function makes torch fx Graph creation unhappy.
+        find_replace_in_repo(repo_path, "models/yolo.py", "if augment:", "if False:")
+        find_replace_in_repo(repo_path, "models/yolo.py", "if profile:", "if False:")
+
         # Our qai_hub_models/models package may already be loaded and cached
         # as "models" (reproduce by running python -m models.yolov7.demo from
         # models qai_hub_models folder). To make sure it loads the external
         # "models" package, explicitly reload first.
         import models
 
         reload(models)
```

## qai_hub_models/models/yolov7/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: Yolo-v7
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 25218.0
-      throughput: 39.65421524308034
+      inference_time: 20875.0
+      throughput: 47.90419161676647
       estimated_peak_memory_range:
-        min: 9555968
-        max: 43269368
+        min: 9580544
+        max: 45193728
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 286
+        layers_on_npu: 292
         layers_on_gpu: 0
         layers_on_cpu: 21
-        total_layers: 307
-      job_id: jopr6wd0p
+        total_layers: 313
+      job_id: jep20ezqg
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 22899.0
+      throughput: 43.670029258919605
+      estimated_peak_memory_range:
+        min: 9625600
+        max: 55617832
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 2
+        layers_on_gpu: 0
+        layers_on_cpu: 21
+        total_layers: 23
+      job_id: j2p036xnp
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:35:57.654637Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
-      estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
-      layer_info:
-        layers_on_npu: 0
-        layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+    timestamp: '2024-04-16T20:17:34.400111Z'
   - torchscript_onnx_tflite:
-      inference_time: 19396.0
-      throughput: 51.557022066405445
+      inference_time: 16244.0
+      throughput: 61.56119182467373
       estimated_peak_memory_range:
-        min: 12288
-        max: 131497776
+        min: 40960
+        max: 202538080
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 286
+        layers_on_npu: 292
         layers_on_gpu: 0
         layers_on_cpu: 21
-        total_layers: 307
-      job_id: jep2xedrg
+        total_layers: 313
+      job_id: jqpyrmyl5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 18014.0
+      throughput: 55.51237926057511
+      estimated_peak_memory_range:
+        min: 17952768
+        max: 200617376
+      primary_compute_unit: CPU
+      precision: fp32
+      layer_info:
+        layers_on_npu: 2
+        layers_on_gpu: 0
+        layers_on_cpu: 21
+        total_layers: 23
+      job_id: j1p801kog
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:35:57.654650Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.400202Z'
+  - torchscript_onnx_ort:
+      inference_time: 157265.0
+      throughput: 6.358693924267955
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 33193984
+        max: 124688816
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 212
+        total_layers: 212
+      job_id: jogk78knp
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.400247Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.400256Z'
```

## qai_hub_models/models/yolov7/requirements.txt

```diff
@@ -1,3 +1,4 @@
 matplotlib==3.7.4
+object-detection-metrics==0.4.post1
 scipy==1.8.1
 seaborn==0.11.0
```

## qai_hub_models/models/yolov7/test.py

```diff
@@ -22,15 +22,15 @@
 OUTPUT_IMAGE_ADDRESS = CachedWebModelAsset.from_asset_store(
     MODEL_ID, MODEL_ASSET_VERSION, "yolov7_demo_640_output.png"
 )
 WEIGHTS = "yolov7-tiny.pt"
 
 
 @skip_clone_repo_check
-def test_task():
+def test_numerical():
     """Verify that raw (numeric) outputs of both (QAIHM and non-qaihm) networks are the same."""
     processed_sample_image = preprocess_PIL_image(load_image(IMAGE_ADDRESS))
     source_model = _load_yolov7_source_model_from_weights(WEIGHTS)
     qaihm_model = YoloV7.from_pretrained(WEIGHTS)
 
     with torch.no_grad():
         # original model output
@@ -42,15 +42,15 @@
         # Qualcomm AI Hub Model output
         qaihm_out_postprocessed = qaihm_model(processed_sample_image)
         for i in range(0, len(source_out_postprocessed)):
             assert np.allclose(source_out_postprocessed[i], qaihm_out_postprocessed[i])
 
 
 @skip_clone_repo_check
-def test_yolov7_app():
+def test_task():
     image = load_image(IMAGE_ADDRESS)
     output_image = load_image(OUTPUT_IMAGE_ADDRESS).convert("RGB")
     app = YoloV7DetectionApp(YoloV7.from_pretrained(WEIGHTS))
     assert np.allclose(app.predict_boxes_from_image(image)[0], np.asarray(output_image))
 
 
 @skip_clone_repo_check
```

## qai_hub_models/models/yolov8_det/conftest.py

```diff
@@ -1,24 +1,29 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.yolov8_det import Model
+from qai_hub_models.utils.testing import skip_clone_repo_check
 
 
 @pytest.fixture(autouse=True)
+@skip_clone_repo_check
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.yolov8_det.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/yolov8_det/info.yaml

```diff
@@ -5,16 +5,16 @@
 headline: Real-time object detection optimized for mobile and edge by Ultralytics.
 domain: Computer Vision
 use_case: Object Detection
 description: Ultralytics YOLOv8 is a machine learning model that predicts bounding boxes and classes
   of objects in an image.
 tags:
   - real-time
-research_paper: https://arxiv.org/abs/2305.09972
-research_paper_title: Real-Time Flying Object Detection with YOLOv8
+research_paper: https://docs.ultralytics.com/tasks/detect/
+research_paper_title: "Ultralytics YOLOv8 Docs: Object Detection"
 license: https://github.com/ultralytics/ultralytics/blob/main/LICENSE
 deploy_license: https://github.com/ultralytics/ultralytics/blob/main/LICENSE
 source_repo:
   https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models/yolo/detect
 technical_details:
   Model checkpoint: YOLOv8-N
   Input resolution: 640x640
```

## qai_hub_models/models/yolov8_det/model.py

```diff
@@ -2,53 +2,116 @@
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
 import torch
 import torch.nn as nn
-from ultralytics import YOLO as ultralytics_YOLO
 
+from qai_hub_models.evaluators.base_evaluators import BaseEvaluator
+from qai_hub_models.evaluators.detection_evaluator import DetectionEvaluator
 from qai_hub_models.models._shared.yolo.utils import (
-    get_most_likely_score,
+    box_transform_xywh2xyxy_split_input,
     transform_box_layout_xywh2xyxy,
 )
+from qai_hub_models.utils.asset_loaders import (
+    SourceAsRoot,
+    find_replace_in_repo,
+    wipe_sys_modules,
+)
 from qai_hub_models.utils.base_model import BaseModel
 from qai_hub_models.utils.input_spec import InputSpec
 
 MODEL_ASSET_VERSION = 1
 MODEL_ID = __name__.split(".")[-2]
+SOURCE_REPO = "https://github.com/ultralytics/ultralytics"
+SOURCE_REPO_COMMIT = "3208eb72ef277b0b825306a84df6c460a8406647"
 
 SUPPORTED_WEIGHTS = [
     "yolov8n.pt",
     "yolov8s.pt",
     "yolov8m.pt",
     "yolov8l.pt",
     "yolov8x.pt",
 ]
 DEFAULT_WEIGHTS = "yolov8n.pt"
 
 
 class YoloV8Detector(BaseModel):
     """Exportable YoloV8 bounding box detector, end-to-end."""
 
-    def __init__(self, model: nn.Module, include_postprocessing: bool = True) -> None:
+    def __init__(
+        self,
+        model: nn.Module,
+        include_postprocessing: bool = True,
+        split_output: bool = False,
+        use_quantized_postprocessing: bool = False,
+    ) -> None:
         super().__init__()
         self.model = model
         self.include_postprocessing = include_postprocessing
+        self.split_output = split_output
+        self.use_quantized_postprocessing = use_quantized_postprocessing
 
     @classmethod
     def from_pretrained(
-        cls, ckpt_name: str = DEFAULT_WEIGHTS, include_postprocessing: bool = True
+        cls,
+        ckpt_name: str = DEFAULT_WEIGHTS,
+        include_postprocessing: bool = True,
+        split_output: bool = False,
+        use_quantized_postprocessing: bool = False,
     ):
-        model = ultralytics_YOLO(ckpt_name).model
-        model.eval()
-        return cls(model, include_postprocessing)
+        with SourceAsRoot(
+            SOURCE_REPO,
+            SOURCE_REPO_COMMIT,
+            MODEL_ID,
+            MODEL_ASSET_VERSION,
+        ) as repo_path:
+            # Functionally equivalent re-writes that make it torch.fx.Graph compatible
+            find_replace_in_repo(
+                repo_path,
+                "ultralytics/nn/modules/block.py",
+                "softmax(1)",
+                "softmax(dim=1)",
+            )
+            find_replace_in_repo(
+                repo_path,
+                "ultralytics/nn/modules/block.py",
+                "y = list(self.cv1(x).chunk(2, 1))",
+                "y = self.cv1(x).chunk(2, 1)\n        y = [y[0], y[1]]",
+            )
+            find_replace_in_repo(
+                repo_path,
+                "ultralytics/nn/modules/head.py",
+                "self.dynamic or self.shape != shape",
+                "False",
+            )
+            # Boxes and scores have different scales, so return separately
+            find_replace_in_repo(
+                repo_path,
+                "ultralytics/nn/modules/head.py",
+                "y = torch.cat((dbox, cls.sigmoid()), 1)",
+                "return (dbox, cls.sigmoid())",
+            )
+
+            import ultralytics
+
+            wipe_sys_modules(ultralytics)
+            from ultralytics import YOLO as ultralytics_YOLO
+
+            model = ultralytics_YOLO(ckpt_name).model
+            model.eval()
+            return cls(
+                model,
+                include_postprocessing,
+                split_output,
+                use_quantized_postprocessing,
+            )
 
-    def forward(self, image: torch.Tensor):
+    def forward(self, image):
         """
         Run YoloV8 on `image`, and produce a predicted set of bounding boxes and associated class probabilities.
 
         Parameters:
             image: Pixel values pre-processed for encoder consumption.
                     Range: float[0, 1]
                     3-channel Color Space: RGB
@@ -57,28 +120,34 @@
             If self.include_postprocessing:
                 boxes: torch.Tensor
                     Bounding box locations. Shape is [batch, num preds, 4] where 4 == (x1, y1, x2, y2)
                 scores: torch.Tensor
                     class scores multiplied by confidence: Shape is [batch, num_preds]
                 class_idx: torch.tensor
                     Shape is [batch, num_preds] where the last dim is the index of the most probable class of the prediction.
-
-            Otherwise:
+            Elif self.split_output:
+                boxes: torch.Tensor
+                    Bounding box predictions in xywh format. Shape [batch, 4, num_preds].
+                scores: torch.Tensor
+                    Full score distribution over all classes for each box.
+                    Shape [batch, num_classes, num_preds].
+            Else:
                 predictions: torch.Tensor
-                    Shape is [batch, k, num_preds]
-                        Where, k = # of classes + 4
-                        The array dimension k is structured as follows:
-                            [box coordintes, # of classes]
-                        where box coordinates are [x_center, y_center, w, h]
+                Same as previous case but with boxes and scores concatenated into a single tensor.
+                Shape [batch, 4 + num_classes, num_preds]
         """
-        predictions, *_ = self.model(image)
+        boxes, scores = self.model(image)
         if not self.include_postprocessing:
-            return predictions
-
-        boxes, scores, classes = yolov8_detect_postprocess(predictions)
+            if self.split_output:
+                return boxes, scores
+            return torch.cat([boxes, scores], dim=1)
+
+        boxes, scores, classes = yolov8_detect_postprocess(
+            boxes, scores, self.use_quantized_postprocessing
+        )
         return boxes, scores, classes
 
     @staticmethod
     def get_input_spec(
         batch_size: int = 1,
         num_channels: int = 3,
         height: int = 640,
@@ -86,42 +155,56 @@
     ) -> InputSpec:
         """
         Returns the input specification (name -> (shape, type). This can be
         used to submit profiling job on Qualcomm AI Hub.
         """
         return {"image": ((batch_size, num_channels, height, width), "float32")}
 
+    def get_evaluator(self) -> BaseEvaluator:
+        return DetectionEvaluator(640, 640)
+
 
-def yolov8_detect_postprocess(detector_output: torch.Tensor):
+def yolov8_detect_postprocess(
+    boxes: torch.Tensor,
+    scores: torch.Tensor,
+    use_quantized_postprocessing: bool = False,
+):
     """
     Post processing to break YoloV8 detector output into multiple, consumable tensors (eg. for NMS).
         such as bounding boxes, scores and classes.
 
     Parameters:
         detector_output: torch.Tensor
             The output of Yolo Detection model
             Shape is [batch, k, num_preds]
                 Where, k = # of classes + 4
                 The array dimension k is structured as follows:
                     [box coordintes, # of classes]
                 where box coordinates are [x_center, y_center, w, h]
+        use_quantized_postprocessing: bool
+            If post-processing a non-quantized model, need to split the bounding box
+            processing into multiple smaller tensors due to NPU limitations.
+            If quantized, the entire processing can be done in a single operation.
 
     Returns:
         boxes: torch.Tensor
             Bounding box locations. Shape is [batch, num preds, 4] where 4 == (x1, y1, x2, y2)
         scores: torch.Tensor
             class scores multiplied by confidence: Shape is [batch, num_preds]
         class_idx: torch.tensor
             Shape is [batch, num_preds] where the last dim is the index of the most probable class of the prediction.
     """
     # Break output into parts
-    detector_output = torch.permute(detector_output, [0, 2, 1])
-    boxes = detector_output[:, :, :4]
-    scores = detector_output[:, :, 4:]
+    boxes = torch.permute(boxes, [0, 2, 1])
+    scores = torch.permute(scores, [0, 2, 1])
 
     # Convert boxes to (x1, y1, x2, y2)
-    boxes = transform_box_layout_xywh2xyxy(boxes)
+    # Doing transform in fp16 requires special logic to keep on NPU
+    if use_quantized_postprocessing:
+        boxes = box_transform_xywh2xyxy_split_input(boxes[..., 0:2], boxes[..., 2:4])
+    else:
+        boxes = transform_box_layout_xywh2xyxy(boxes)
 
     # Get class ID of most likely score.
-    scores, class_idx = get_most_likely_score(scores)
+    scores, class_idx = torch.max(scores, -1, keepdim=False)
 
     return boxes, scores, class_idx
```

## qai_hub_models/models/yolov8_det/requirements.txt

```diff
@@ -1,3 +1,4 @@
+object-detection-metrics==0.4.post1
 seaborn==0.11.0
 thop==0.1.1.post2209072238
 ultralytics==8.0.193
```

## qai_hub_models/models/yolov8_det/test.py

```diff
@@ -13,40 +13,45 @@
     MODEL_ASSET_VERSION,
     MODEL_ID,
     YoloV8Detector,
     yolov8_detect_postprocess,
 )
 from qai_hub_models.utils.asset_loaders import CachedWebModelAsset, load_image
 from qai_hub_models.utils.image_processing import preprocess_PIL_image
+from qai_hub_models.utils.testing import skip_clone_repo_check
 
 OUTPUT_IMAGE_ADDRESS = CachedWebModelAsset.from_asset_store(
     MODEL_ID, MODEL_ASSET_VERSION, "test_images/output_image.png"
 )
 WEIGHTS = "yolov8n.pt"
 
 
-def test_task():
+@skip_clone_repo_check
+def test_numerical():
     """Verify that raw (numeric) outputs of both (QAIHM and non-qaihm) networks are the same."""
     processed_sample_image = preprocess_PIL_image(load_image(IMAGE_ADDRESS))
     source_model = ultralytics_YOLO(WEIGHTS).model
     qaihm_model = YoloV8Detector.from_pretrained(WEIGHTS)
 
     with torch.no_grad():
         # original model output
         source_detect_out, *_ = source_model(processed_sample_image)
-        source_out_postprocessed = yolov8_detect_postprocess(source_detect_out)
+        boxes, scores = torch.split(source_detect_out, [4, 80], 1)
+        source_out_postprocessed = yolov8_detect_postprocess(boxes, scores)
 
         # Qualcomm AI Hub Model output
         qaihm_out_postprocessed = qaihm_model(processed_sample_image)
         for i in range(0, len(source_out_postprocessed)):
             assert np.allclose(source_out_postprocessed[i], qaihm_out_postprocessed[i])
 
 
-def test_yolov8_det_app():
+@skip_clone_repo_check
+def test_task():
     image = load_image(IMAGE_ADDRESS)
     output_image = load_image(OUTPUT_IMAGE_ADDRESS)
     app = YoloV8DetectionApp(YoloV8Detector.from_pretrained(WEIGHTS))
     assert np.allclose(app.predict_boxes_from_image(image)[0], np.asarray(output_image))
 
 
+@skip_clone_repo_check
 def test_demo():
     demo_main(is_test=True)
```

## qai_hub_models/models/yolov8_seg/conftest.py

```diff
@@ -1,24 +1,27 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 # THIS FILE WAS AUTO-GENERATED. DO NOT EDIT MANUALLY.
 
+import inspect
 from unittest.mock import patch
 
 import pytest
 
 from qai_hub_models.models.yolov8_seg import Model
 
 
 @pytest.fixture(autouse=True)
 def mock_from_pretrained():
     """
     Model.from_pretrained() can be slow. Invoke it once and cache it so all invocations
     across all tests return the cached instance of the model.
     """
+    sig = inspect.signature(Model.from_pretrained)
     mock = patch(
         "qai_hub_models.models.yolov8_seg.Model.from_pretrained",
         return_value=Model.from_pretrained(),
     )
-    mock.start()
+    mock_obj = mock.start()
+    mock_obj.__signature__ = sig
```

## qai_hub_models/models/yolov8_seg/info.yaml

```diff
@@ -5,16 +5,16 @@
 headline: Real-time object segmentation optimized for mobile and edge by Ultralytics.
 domain: Computer Vision
 use_case: Semantic Segmentation
 description: Ultralytics YOLOv8 is a machine learning model that predicts bounding boxes, segmentation
   masks and classes of objects in an image.
 tags:
   - real-time
-research_paper: https://arxiv.org/abs/2305.09972
-research_paper_title: Real-Time Flying Object Detection with YOLOv8
+research_paper: https://docs.ultralytics.com/tasks/segment/
+research_paper_title: "Ultralytics YOLOv8 Docs: Instance Segmentation"
 license: https://github.com/ultralytics/ultralytics/blob/main/LICENSE
 deploy_license: https://github.com/ultralytics/ultralytics/blob/main/LICENSE
 source_repo:
   https://github.com/ultralytics/ultralytics/tree/main/ultralytics/models/yolo/segment
 technical_details:
   Model checkpoint: YOLOv8N-Seg
   Input resolution: 640x640
```

## qai_hub_models/models/yolov8_seg/perf.yaml

```diff
@@ -4,14 +4,17 @@
   supported_devices:
   - Google Pixel 3
   - Google Pixel 3a
   - Google Pixel 3a XL
   - Google Pixel 4
   - Google Pixel 4a
   - Google Pixel 5a 5G
+  - QCS6490 (Proxy)
+  - QCS8550 (Proxy)
+  - RB3 Gen 2 (Proxy)
   - Samsung Galaxy S21
   - Samsung Galaxy S21 Ultra
   - Samsung Galaxy S21+
   - Samsung Galaxy S22 5G
   - Samsung Galaxy S22 Ultra 5G
   - Samsung Galaxy S22+ 5G
   - Samsung Galaxy S23
@@ -20,90 +23,123 @@
   - Samsung Galaxy S24
   - Samsung Galaxy S24 Ultra
   - Samsung Galaxy S24+
   - Samsung Galaxy Tab S8
   - Xiaomi 12
   - Xiaomi 12 Pro
   supported_chipsets:
+  - Qcs6490
+  - Qcs8550
   - Snapdragon 8 Gen 1
   - Snapdragon 8 Gen 2
   - Snapdragon 8 Gen 3
   - Snapdragon 888
 models:
 - name: YOLOv8-Segmentation
   performance_metrics:
   - torchscript_onnx_tflite:
-      inference_time: 7056.0
-      throughput: 141.7233560090703
+      inference_time: 7033.0
+      throughput: 142.18683349921798
       estimated_peak_memory_range:
-        min: 4612096
-        max: 14526392
+        min: 4595712
+        max: 6959144
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
         layers_on_npu: 337
         layers_on_gpu: 0
         layers_on_cpu: 0
         total_layers: 337
-      job_id: jn5q0v1np
+      job_id: jqp4k361g
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 8072.0
+      throughput: 123.8850346878097
+      estimated_peak_memory_range:
+        min: 15532032
+        max: 36380192
+      primary_compute_unit: NPU
+      precision: fp16
+      layer_info:
+        layers_on_npu: 1
+        layers_on_gpu: 0
+        layers_on_cpu: 0
+        total_layers: 1
+      job_id: jo5mq819p
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S23
       os: '13'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 2
-    timestamp: '2024-04-02T15:25:01.845719Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.459189Z'
+  - torchscript_onnx_tflite:
+      inference_time: 5210.0
+      throughput: 191.93857965451056
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 40960
+        max: 98992992
+      primary_compute_unit: NPU
+      precision: fp16
       layer_info:
-        layers_on_npu: 0
+        layers_on_npu: 337
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
-  - torchscript_onnx_tflite:
-      inference_time: 5151.0
-      throughput: 194.1370607649
+        total_layers: 337
+      job_id: j0pxnx8l5
+      job_status: Passed
+    torchscript_onnx_ort:
+      inference_time: 5653.0
+      throughput: 176.89722271360338
       estimated_peak_memory_range:
-        min: 16384
-        max: 98489488
+        min: 17702912
+        max: 83989088
       primary_compute_unit: NPU
       precision: fp16
       layer_info:
-        layers_on_npu: 337
+        layers_on_npu: 1
         layers_on_gpu: 0
         layers_on_cpu: 0
-        total_layers: 337
-      job_id: j1gl4l8j5
+        total_layers: 1
+      job_id: jegnlkdq5
       job_status: Passed
     reference_device_info:
       name: Samsung Galaxy S24
       os: '14'
       form_factor: Phone
       os_name: Android
       manufacturer: Samsung
       chipset: Snapdragon 8 Gen 3
-    timestamp: '2024-04-02T15:25:01.845733Z'
-    torchscript_onnx_qnn:
-      inference_time: 'null'
-      throughput: 'null'
+    timestamp: '2024-04-16T20:17:34.459265Z'
+  - torchscript_onnx_ort:
+      inference_time: 163872.0
+      throughput: 6.10232376488967
       estimated_peak_memory_range:
-        min: 0
-        max: 0
-      primary_compute_unit: 'null'
-      precision: 'null'
+        min: 49770496
+        max: 153912944
+      primary_compute_unit: CPU
+      precision: fp32
       layer_info:
         layers_on_npu: 0
         layers_on_gpu: 0
-        layers_on_cpu: 0
-        total_layers: 0
-      job_id: ''
-      job_status: Skipped
+        layers_on_cpu: 242
+        total_layers: 242
+      job_id: jopr8wm75
+      job_status: Passed
+    reference_device_info:
+      name: RB3 Gen 2 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs6490
+    timestamp: '2024-04-16T20:17:34.459312Z'
+  - reference_device_info:
+      name: QCS8550 (Proxy)
+      os: '12'
+      form_factor: Iot
+      os_name: Android
+      manufacturer: ''
+      chipset: Qcs8550
+    timestamp: '2024-04-16T20:17:34.459318Z'
```

## qai_hub_models/test/test_utils/test_perf_summary.py

```diff
@@ -2,15 +2,15 @@
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 import os
 
 import ruamel.yaml
 
-from qai_hub_models.utils.perf_summary import PerformanceSummary
+from qai_hub_models.utils.scorecard.perf_summary import PerformanceSummary
 
 CHIPSET = "GEN2"
 OS = "13"
 MODEL_ID = "dummy"
 
 
 def get_basic_speedup_report(
```

## qai_hub_models/utils/asset_loaders.py

```diff
@@ -14,14 +14,15 @@
 import tempfile
 import threading
 import time
 from contextlib import contextmanager
 from enum import Enum
 from functools import partial
 from pathlib import Path
+from types import ModuleType
 from typing import Any, Callable, Dict, List, Optional, Union
 from zipfile import ZipFile
 
 import gdown
 import numpy as np
 import requests
 import torch
@@ -140,14 +141,27 @@
             raise ValueError(
                 f"Unable to load {model_name} without its required repository."
             )
 
     return local_path
 
 
+def wipe_sys_modules(module: ModuleType) -> None:
+    """
+    Wipe all modules from sys.modules whose names start with the given module name.
+
+    An alternative to `importlib.reload`, which only reloads the top-level module
+        but may still reference the old package for submodules.
+    """
+    module_name = module.__name__
+    dep_modules = [name for name in sys.modules.keys() if name.startswith(module_name)]
+    for submodule_name in dep_modules:
+        sys.modules.pop(submodule_name)
+
+
 def _load_file(
     file: PathType,
     loader_func: Callable[[str], Any],
     dst_folder_path: tempfile.TemporaryDirectory | str | None = None,
 ) -> Any:
     if isinstance(file, (str, Path)):
         file = str(file)
```

## qai_hub_models/utils/bounding_box_processing.py

```diff
@@ -259,7 +259,24 @@
     """
     xlen = vec_end[..., 0] - vec_start[..., 0]
     ylen = vec_end[..., 1] - vec_start[..., 1]
     vec_len = torch.sqrt(torch.float_power(xlen, 2) + torch.float_power(ylen, 2))
 
     xc += offset * (xlen / vec_len)
     yc += offset * (ylen / vec_len)
+
+
+def get_iou(boxA: np.ndarray, boxB: np.ndarray) -> float:
+    """
+    Given two tensors of shape (4,) in xyxy format,
+    compute the iou between the two boxes.
+    """
+    xA = max(boxA[0], boxB[0])
+    yA = max(boxA[1], boxB[1])
+    xB = min(boxA[2], boxB[2])
+    yB = min(boxA[3], boxB[3])
+
+    inter_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)
+    boxA_area = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
+    boxB_area = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)
+
+    return inter_area / float(boxA_area + boxB_area - inter_area)
```

## qai_hub_models/utils/image_processing.py

```diff
@@ -1,13 +1,14 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
 from __future__ import annotations
 
+import functools
 from typing import Callable, List, Tuple
 
 import cv2
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from PIL.Image import Image
@@ -102,26 +103,42 @@
     Convert a Torch tensor (dtype float32) with range [0, 1] and shape CHW into PIL image CHW
     """
     out = torch.clip(data, min=0.0, max=1.0)
     np_out = (out.permute(1, 2, 0).detach().numpy() * 255).astype(np.uint8)
     return ImageFromArray(np_out)
 
 
-def normalize_image_transform() -> Callable:
+def normalize_image_torchvision(
+    image_tensor: torch.Tensor, image_tensor_has_batch=True
+) -> torch.Tensor:
+    """
+    Normalizes according to standard torchvision constants.
+
+    Due to issues with FX Graph tracing in AIMET, image_tensor_has_batch is a constant passed in,
+    rather than determining the image rank using len(image_tensor.shape).
+
+    There are many PyTorch models that expect input images normalized with
+    these specific constants, so this utility can be re-used across many models.
+    """
+    shape = [-1, 1, 1]
+    if image_tensor_has_batch:
+        shape.insert(0, 1)
+    mean = torch.Tensor([0.485, 0.456, 0.406]).reshape(*shape)
+    std = torch.Tensor([[0.229, 0.224, 0.225]]).reshape(*shape)
+    return (image_tensor - mean) / std
+
+
+def normalize_image_transform() -> Callable[[torch.Tensor], torch.Tensor]:
     """
     Returns a torchvision transform that returns a torch tensor normalized according to some constants.
 
     There are many PyTorch models that expect input images normalized with
     these specific constants, so this utility can be re-used across many models.
     """
-    return transforms.Compose(
-        [
-            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
-        ]
-    )
+    return functools.partial(normalize_image_torchvision, image_tensor_has_batch=False)
 
 
 def pad_to_square(frame: np.ndarray) -> np.ndarray:
     """
     Pad an image or video frame to square dimensions with whitespace.
     Assumes the input shape is of format (H, W, C).
     """
```

## qai_hub_models/utils/printing.py

```diff
@@ -30,14 +30,17 @@
     inference_data = [
         np.concatenate(outputs, axis=0) for outputs in inference_result.values()
     ]
     output_names = list(inference_result.keys())
     df_eval = generate_comparison_metrics(
         torch_out, inference_data, names=output_names, metrics=metrics
     )
+    for output_idx in outputs_to_skip or []:
+        if output_idx < len(output_names):
+            df_eval = df_eval.drop(output_names[output_idx])
 
     def custom_float_format(x):
         if isinstance(x, float):
             return f"{x:.4g}"
         return x
 
     formatted_df = df_eval.applymap(custom_float_format)
```

## qai_hub_models/utils/quantization_aimet.py

```diff
@@ -7,14 +7,16 @@
 """
 from __future__ import annotations
 
 import logging
 import os
 
 try:
+    from aimet_common.connected_graph.operation import Op as AimetOp
+    from aimet_common.connected_graph.product import Product as AimetProduct
     from aimet_common.utils import AimetLogger  # type: ignore
     from aimet_torch import onnx_utils
     from aimet_torch.qc_quantize_op import QcQuantizeWrapper
     from aimet_torch.quantsim import QuantizationSimModel
     from aimet_torch.tensor_quantizer import StaticGridPerTensorQuantizer
 
     # Suppress aimet info logs within zoo
@@ -27,51 +29,127 @@
         "Install AIMET via the instructions here: "
         "https://quic.github.io/aimet-pages/releases/latest/install/index.html"
     )
 
 import shutil
 import tempfile
 from pathlib import Path
-from typing import Any, List
+from typing import Any, Dict, List, Optional, Tuple
 from zipfile import ZipFile
 
+import aimet_torch.elementwise_ops as aimet_ops
 import torch
+import torch.nn.modules as nn
 from qai_hub.client import DatasetEntries
 
 from qai_hub_models.evaluators.base_evaluators import _DataLoader, _for_each_batch
 from qai_hub_models.models._shared.common import apply_module_function_recursively
 from qai_hub_models.models.common import SourceModelFormat, TargetRuntime
 from qai_hub_models.models.protocols import (
     PretrainedHubModelProtocol,
     QuantizableModelProtocol,
 )
 from qai_hub_models.utils.input_spec import InputSpec, make_torch_inputs
 
 
-def tie_aimet_observer_groups(groups: List[List[Any]]):
+def _should_tie_observers(op: torch.nn.Module) -> bool:
     """
-    This defines groups of ops that all should use the same output
-    quantizer observer. The input groups is a list of lists, where the
-    inner lists contain op references that should all use the same output
-    quantizer. Each op should have an `output_quantizers` member.
+    Determine whether the input and output observers of this op should be tied.
+    """
+    if not hasattr(op, "_module_to_wrap"):
+        return False
+    wrapped_op = op._module_to_wrap
+    op_types_to_tie = [nn.MaxPool2d, nn.AvgPool2d, nn.Upsample, aimet_ops.Concat]
+    for op_type in op_types_to_tie:
+        if isinstance(wrapped_op, op_type):
+            return True
+    return False
+
+
+def _get_observer_module_name(modules: Dict[str, Any], name: str) -> Optional[str]:
+    module = modules.get(name)
+    if isinstance(module, QcQuantizeWrapper):
+        return name
+    elif isinstance(module, aimet_ops.CustomSiLU):
+        return name + ".mul"
+    return None
+
+
+def _tie_quantizer_deps(
+    quantizer_deps: Dict[str, List[str]], modules: Dict[str, torch.nn.Module]
+) -> None:
+    """
+    Given a dependency graph of nodes, tie output quantizers of nodes that share an edge.
+    All edges should be bidirectional.
+    """
+    seen = set([])
+    for input_module_name in quantizer_deps.keys():
+        if input_module_name in seen:
+            continue
+        seen.add(input_module_name)
+        stack = [input_module_name]
+        module = modules[input_module_name]
+        assert isinstance(module, QcQuantizeWrapper)
+        quantizer = module.output_quantizers[0]
+        while len(stack) > 0:
+            curr_node = stack.pop()
+            for edge in quantizer_deps[curr_node]:
+                if edge in seen:
+                    continue
+                seen.add(edge)
+                stack.append(edge)
+                edge_module = modules[edge]
+                assert isinstance(edge_module, QcQuantizeWrapper)
+                edge_module.output_quantizers[0] = quantizer
 
-    Example:
 
-        groups = [
-            [
-                sim.model.net.maxpool2,
-                sim.model.net.Mixed_5b.module_avg_pool2d,
-            ],
-        ]
-        _tie_aimet_observer_groups(groups)
+def tie_observers(quant_sim: QuantizationSimModel) -> None:
     """
-    for group in groups:
-        output_quantizer = group[0].output_quantizers[0]
-        for op in group[1:]:
-            op.output_quantizers[0] = output_quantizer
+    For certain ops, the input and output observers need to be the same.
+
+    For example, in a concat op, all the inputs need to have the same scale.
+    Otherwise, there will need to be an additional explicit quantize which is lossy.
+
+    Other ops like MaxPool and AvgPool are constraints in tflite.
+
+    This assumes all modules have exactly one output.
+    All modules (i.e. instances of `StaticGridQuantWrapper`) have both an
+        `output_quantizers` and `input_quantizers` field.
+    We only update output_quantizers since empircally that's all that seems to matter.
+    """
+    fx_graph = quant_sim.model
+    nodes = [node for node in fx_graph.graph.nodes]
+    modules = dict(fx_graph.named_modules())
+
+    # quant_sim.model is a torch fx graph. This graph stores nodes and modules.
+    # nodes store the graph structure (which ops input into other ops).
+    # modules store the op objects themselves.
+    # Create a dependency graph of modules that need to share output quantizers.
+    quantizer_deps: Dict[str, List[str]] = {}
+    for node in nodes:
+        module = modules.get(node.target)
+        if module is None or not _should_tie_observers(module):
+            continue
+        if node.target not in quantizer_deps:
+            quantizer_deps[node.target] = []
+        for input_node in node.all_input_nodes:
+            # If the node is something like a reshape with no observers,
+            # Keep going up the tree until you find something with an observer.
+            # If one of these nodes has multiple inputs, this may behave incorrectly.
+            while (
+                observer_module_name := _get_observer_module_name(
+                    modules, input_node.target
+                )
+            ) is None:
+                input_node = input_node.all_input_nodes[0]
+            if observer_module_name not in quantizer_deps:
+                quantizer_deps[observer_module_name] = []
+            quantizer_deps[observer_module_name].append(node.target)
+            quantizer_deps[node.target].append(observer_module_name)
+    _tie_quantizer_deps(quantizer_deps, modules)
 
 
 def convert_all_depthwise_to_per_tensor(module):
     """
     This recursively iterates a PyTorch module (that has been prepared by
     AIMET for quantization) and replaces the weight quantizers with a
     per-tensor for all depthwise convolutions. All parameters (bitwidth,
@@ -94,14 +172,57 @@
                 )
 
     apply_module_function_recursively(
         module, torch.nn.Conv2d, convert_depthwise_to_per_tensor
     )
 
 
+def constrain_quantized_inputs_to_range(
+    qsim: QuantizationSimModel, range: Tuple[float, float]
+):
+    """
+    For all model inputs, set the quantizer to have the provided input range.
+    """
+
+    # Map: <nn.Module, List of Quantized Inputs>
+    module_to_inputs_idx: Dict[torch.nn.Module, List[int]] = {}
+    op: AimetOp
+    for op in qsim.connected_graph.get_all_ops().values():
+        if op.get_module():
+            module = op.get_module()
+            idx: int
+            input_product: AimetProduct
+            for idx, input_product in enumerate(op.get_input_products()):
+                if input_product.is_model_input:
+                    if module in module_to_inputs_idx:
+                        module_to_inputs_idx[module].append(idx)
+                    else:
+                        module_to_inputs_idx[module] = [idx]
+
+    for _, quant_wrapper in qsim.quant_wrappers():
+        if indices := module_to_inputs_idx.get(quant_wrapper._module_to_wrap):
+            for index in indices:
+                if index < len(quant_wrapper.input_quantizers):
+                    quant_wrapper.input_quantizers[
+                        index
+                    ].encoding_min_max_fixed_vals = range
+
+
+def constrain_quantized_inputs_to_image_range(qsim: QuantizationSimModel):
+    """
+    For all model inputs, set the quantizer to have a range of (0, 1).
+
+    The range translates to the full image range for int8/uint8/int16/uint16.
+
+    This is typically useful for use in pipelines where the input is already int8/uint8 and
+    we know the quantization range beforehand (eg. a RGB camera feed).
+    """
+    return constrain_quantized_inputs_to_range(qsim, (0.0, 1.0))
+
+
 class AIMETQuantizableMixin(PretrainedHubModelProtocol, QuantizableModelProtocol):
     """
     Mixin that allows a model to be quantized & exported to disk using AIMET.
 
     Inheritor must implement HubModel for this mixin to function.
     """
 
@@ -301,7 +422,33 @@
         )
         return compile_options + " --quantize_full_type int8 --quantize_io"
 
     def preferred_hub_source_model_format(
         self, target_runtime: TargetRuntime
     ) -> SourceModelFormat:
         return SourceModelFormat.ONNX
+
+
+def tie_aimet_observer_groups(groups: List[List[Any]]):
+    """
+    Unless you're doing something very customized, you likely want to use
+    the `tie_observers` method instead.
+
+    This defines groups of ops that all should use the same output
+    quantizer observer. The input groups is a list of lists, where the
+    inner lists contain op references that should all use the same output
+    quantizer. Each op should have an `output_quantizers` member.
+
+    Example:
+
+        groups = [
+            [
+                sim.model.net.maxpool2,
+                sim.model.net.Mixed_5b.module_avg_pool2d,
+            ],
+        ]
+        _tie_aimet_observer_groups(groups)
+    """
+    for group in groups:
+        output_quantizer = group[0].output_quantizers[0]
+        for op in group[1:]:
+            op.output_quantizers[0] = output_quantizer
```

## qai_hub_models/utils/aimet/default_config.json

### Pretty-printed

 * *Similarity: 0.9722222222222222%*

 * *Differences: {"'op_type'": "{'Sigmoid': OrderedDict([('encoding_constraints', OrderedDict([('min', 0.0), "*

 * *              "('max', 0.99609375)]))]), 'Softmax': OrderedDict([('encoding_constraints', "*

 * *              "OrderedDict([('min', 0.0), ('max', 0.99609375)]))])}"}*

```diff
@@ -21,14 +21,26 @@
         },
         "Mean": {
             "is_output_quantized": "False"
         },
         "Pad": {
             "is_output_quantized": "True"
         },
+        "Sigmoid": {
+            "encoding_constraints": {
+                "max": 0.99609375,
+                "min": 0.0
+            }
+        },
+        "Softmax": {
+            "encoding_constraints": {
+                "max": 0.99609375,
+                "min": 0.0
+            }
+        },
         "Squeeze": {
             "is_output_quantized": "True"
         }
     },
     "params": {
         "bias": {
             "is_quantized": "False"
```

## Comparing `qai_hub_models/utils/model_card.py` & `qai_hub_models/utils/scorecard/model_card.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,20 +1,67 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
+from __future__ import annotations
+
 import datetime
+import functools
+import multiprocessing
+import pprint
 from dataclasses import dataclass
-from enum import Enum
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Dict, List, Set, Tuple, Union
 
 import qai_hub as hub
 
+from qai_hub_models.models.common import TargetRuntime
+from qai_hub_models.utils.config_loaders import MODEL_IDS
+from qai_hub_models.utils.scorecard.common import (
+    REFERENCE_DEVICE_PER_SUPPORTED_CHIPSETS,
+)
+from qai_hub_models.utils.scorecard.job_summary import (
+    CompileJobSummary,
+    ProfileJobSummary,
+)
+
+
+def supported_chipsets(chips: List[str]) -> List[str]:
+    """Return all the supported chipsets given the chipset it works on."""
+
+    # Don't assign "chips" directly to supported_chips.
+    # The lists will share the same pointer, and hence the for
+    # loop below will break.
+    supported_chips = set(chips)
+
+    for chip in chips:
+        if chip == "qualcomm-snapdragon-8gen3":
+            supported_chips.update(
+                [
+                    "qualcomm-snapdragon-8gen2",
+                    "qualcomm-snapdragon-8gen1",
+                    "qualcomm-snapdragon-888",
+                ]
+            )
+        if chip == "qualcomm-snapdragon-8gen2":
+            supported_chips.update(
+                [
+                    "qualcomm-snapdragon-8gen3",
+                    "qualcomm-snapdragon-8gen1",
+                    "qualcomm-snapdragon-888",
+                ]
+            )
+        if chip == "qualcomm-snapdragon-855":
+            supported_chips.update(
+                ["qualcomm-snapdragon-845", "qualcomm-snapdragon-865"]
+            )
+
+    return sorted(list(supported_chips))
 
-def chipset_marketting_name(chipset) -> str:
+
+def chipset_marketing_name(chipset) -> str:
     """Sanitize chip name to match marketting."""
     chip = [word.capitalize() for word in chipset.split("-")]
     details_to_remove = []
     for i in range(len(chip)):
         if chip[i] == "8gen3":
             chip[i] = "8 Gen 3"
         if chip[i] == "8gen2":
@@ -28,325 +75,304 @@
             details_to_remove.append(chip[i])
 
     for detail in details_to_remove:
         chip.remove(detail)
     return " ".join(chip)
 
 
-class MODEL_CARD_RUNTIMES(Enum):
-    """Runtime to be stored in model card."""
-
-    TORCHSCRIPT_ONNX_TFLITE = 100
-    TORCHSCRIPT_ONNX_QNN = 101
-
-    @staticmethod
-    def from_string(string: str) -> "MODEL_CARD_RUNTIMES":
-        return MODEL_CARD_RUNTIMES["TORCHSCRIPT_ONNX_" + string.upper()]
+def supported_chipsets_santized(chips) -> List[str]:
+    """Santize the chip name passed via hub."""
+    chips = [chip for chip in chips if chip != ""]
+    return sorted(
+        list(set([chipset_marketing_name(chip) for chip in supported_chipsets(chips)]))
+    )
+
+
+# Caching this information is helpful because it requires pulling data from hub.
+# Pulling data from hub is slow.
+__CHIP_SUPPORTED_DEVICES_CACHE: Dict[str, List[str]] = {}
+
+
+def supported_devices(chips) -> List[str]:
+    """Return all the supported devices given the chipset being used."""
+    supported_devices = set(
+        [
+            "Google Pixel 3",
+            "Google Pixel 3a",
+            "Google Pixel 4",
+            "Google Pixel 3a XL",
+            "Google Pixel 4a",
+            "Google Pixel 5a 5G",
+        ]
+    )
+
+    for chip in supported_chipsets(chips):
+        supported_devices_for_chip = __CHIP_SUPPORTED_DEVICES_CACHE.get(chip, list())
+        if not supported_devices_for_chip:
+            supported_devices_for_chip = [
+                device.name for device in hub.get_devices(attributes=f"chipset:{chip}")
+            ]
+            __CHIP_SUPPORTED_DEVICES_CACHE[chip] = supported_devices_for_chip
+        supported_devices.update(supported_devices_for_chip)
 
+    return sorted(list(supported_devices))
 
-@dataclass
-class ModelRun:
-    model_id: str
-    profile_job_id: str
-    runtime: MODEL_CARD_RUNTIMES
-    device_type: str
-
-    def chipset(self) -> Optional[str]:
-        """Chipset the job was run on."""
-        if self.profile_job is not None:
-            hub_device = self.profile_job.device
-            for attr in hub_device.attributes:
-                if attr.startswith("chipset:qualcomm"):
-                    return attr.split(":")[1]
-        return ""
-
-    @property
-    def profile_job(self):
-        """Get the hub.ProfileJob object."""
-        if len(self.profile_job_id) > 0:
-            job = hub.get_job(self.profile_job_id)
-            job.wait()
-            return job
-        return None
-
-    def job_status(self) -> str:
-        """Get the job status of the profile job."""
-        if self.profile_job is not None:
-            if self.profile_job.get_status().success:
-                return "Passed"
-            elif self.profile_job.get_status().failure:
-                return "Failed"
-        return "Skipped"
-
-    @property
-    def quantized(self) -> str:
-        """Quantized models are marked so precision can be correctly recorded."""
-        return (
-            "Yes"
-            if self.model_id.endswith("Quantized")
-            or self.model_id.endswith("Quantizable")
-            else "No"
-        )
 
-    @property
-    def profile_results(self):
-        """Profile results from profile job."""
-        if self.job_status() == "Passed":
-            return self.profile_job.download_profile()
-        return None
-
-    def get_inference_time(self) -> Union[float, str]:
-        """Get the inference time from the profile job."""
-        if self.profile_results is not None:
-            return float(
-                self.profile_results["execution_summary"]["estimated_inference_time"]
-            )
-        return "null"
+def supported_oses() -> List[str]:
+    """Return all the supported operating systems."""
+    return ["Android"]
 
-    def get_throughput(self) -> Union[float, str]:
-        """Get the throughput from the profile job."""
-        if not isinstance(self.get_inference_time(), str):
-            return 1000000 / self.get_inference_time()  # type: ignore
-        return "null"
-
-    def get_layer_info(self, unit: str) -> int:
-        """Count layers per compute unit."""
-        if self.profile_results is not None:
-            count: int = 0
-            count = sum(
-                1
-                for detail in self.profile_results["execution_detail"]
-                if detail["compute_unit"] == unit
-            )
-            return count
-        return 0
 
-    def npu(self) -> Any:
-        """Get number of layers running on NPU."""
-        return self.get_layer_info("NPU") if self.profile_results is not None else 0
-
-    def gpu(self) -> Any:
-        """Get number of layers running on GPU."""
-        return self.get_layer_info("GPU") if self.profile_results is not None else 0
-
-    def cpu(self) -> Any:
-        """Get number of layers running on CPU."""
-        return self.get_layer_info("CPU") if self.profile_results is not None else 0
-
-    def total(self) -> Any:
-        """Get the total number of layers."""
-        return self.npu() + self.gpu() + self.cpu()
-
-    def primary_compute_unit(self) -> str:
-        """Get the primary compute unit."""
-        layers_npu = self.npu()
-        layers_gpu = self.gpu()
-        layers_cpu = self.cpu()
-
-        if layers_npu == 0 and layers_gpu == 0 and layers_cpu == 0:
-            return "null"
-        compute_unit_for_most_layers = max(layers_cpu, layers_gpu, layers_npu)
-        if compute_unit_for_most_layers == layers_npu:
-            return "NPU"
-        elif compute_unit_for_most_layers == layers_gpu:
-            return "GPU"
-        return "CPU"
-
-    def get_peak_memory_range(self) -> Dict[str, int]:
-        """Get the estimated peak memory range."""
-        if self.profile_results is not None:
-            low, high = self.profile_results["execution_summary"][
-                "inference_memory_peak_range"
-            ]
-            return dict(min=low, max=high)
-        return dict(min=0, max=0)
+# Caching this information is helpful because it requires pulling data from hub.
+# Pulling data from hub is slow.
+__REFERENCE_DEVICE_INFO_PER_CHIPSET = {}
 
-    def precision(self) -> str:
-        """Get the precision of the model based on the run."""
-        if self.profile_results is not None:
-            compute_unit = self.primary_compute_unit()
-            if compute_unit == "CPU":
-                return "fp32"
-            if self.quantized == "Yes":
-                return "int8"
-            return "fp16"
-        return "null"
-
-    def performance_metrics(self) -> Dict[str, Any]:
-        return dict(
-            inference_time=self.get_inference_time(),
-            throughput=self.get_throughput(),
-            estimated_peak_memory_range=self.get_peak_memory_range(),
-            primary_compute_unit=self.primary_compute_unit(),
-            precision=self.precision(),
-            layer_info=dict(
-                layers_on_npu=self.npu(),
-                layers_on_gpu=self.gpu(),
-                layers_on_cpu=self.cpu(),
-                total_layers=self.total(),
-            ),
-            job_id=self.profile_job_id,
-            job_status=self.job_status(),
-        )
 
-    def reference_device_info(self) -> Dict[str, str]:
-        """Return a reference ID."""
-        REF_DEVICE_MAP = {
-            "s23": ("qualcomm-snapdragon-8gen2", "Samsung Galaxy S23"),
-            "s24": ("qualcomm-snapdragon-8gen3", "Samsung Galaxy S24"),
-        }
-        chipset = REF_DEVICE_MAP[self.device_type][0]
-        hub_device = hub.get_devices(REF_DEVICE_MAP[self.device_type][1])[0]
+def get_reference_device_info(chipset: str) -> Dict[str, str]:
+    if chipset not in __REFERENCE_DEVICE_INFO_PER_CHIPSET:
+        hub_device = REFERENCE_DEVICE_PER_SUPPORTED_CHIPSETS[chipset]
         device_name = hub_device.name
         os_version = hub_device.os
         os_name, form_factor, manufacturer = "", "", ""
         for attr in hub_device.attributes:
             if attr.startswith("vendor"):
                 manufacturer = attr.split(":")[-1]
             if attr.startswith("format"):
                 form_factor = attr.split(":")[-1]
             if attr.startswith("os"):
                 os_name = attr.split(":")[-1].capitalize()
-        chipset = chipset_marketting_name(chipset)
-        device_info = dict(
+        chipset = chipset_marketing_name(chipset)
+        __REFERENCE_DEVICE_INFO_PER_CHIPSET[chipset] = dict(
             name=device_name,
             os=os_version,
             form_factor=form_factor.capitalize(),
             os_name=os_name,
             manufacturer=manufacturer.capitalize(),
             chipset=chipset,
         )
-        return device_info
+    return __REFERENCE_DEVICE_INFO_PER_CHIPSET[chipset]
 
 
 @dataclass
-class ModelPerf:
-    model_runs: List[ModelRun]
+class ChipsetPerfSummary:
+    chipset_name: str
+    run_per_runtime: Dict[TargetRuntime, ProfileJobSummary]  # Map<Runtime, Summary>
 
-    def supported_chipsets(self, chips: List[str]) -> List[str]:
-        """Return all the supported chipsets given the chipset it works on."""
+    @staticmethod
+    def from_runs(chipset_name: str, runtime_runs: List[ProfileJobSummary]):
+        # Figure out unique devices in various baselines
+        run_per_runtime: Dict[TargetRuntime, ProfileJobSummary] = {}
+        for run in runtime_runs:
+            assert run.chipset == chipset_name  # Chipset should match
+            run_per_runtime[run.runtime] = run
+
+        return ChipsetPerfSummary(chipset_name, run_per_runtime)
+
+    def get_perf_card(self) -> Dict[str, str | Dict[str, str]]:
+        perf_card: Dict[str, str | Dict[str, str]] = {}
+        for runtime, run in self.run_per_runtime.items():
+            if not run.skipped:  # Skipped runs are not included
+                perf_card[runtime.long_name] = run.performance_metrics
+        perf_card["reference_device_info"] = get_reference_device_info(
+            self.chipset_name
+        )
+        perf_card["timestamp"] = datetime.datetime.utcnow().isoformat() + "Z"
+        return perf_card
 
-        # Don't assign "chips" directly to supported_chips.
-        # The lists will share the same pointer, and hence the for
-        # loop below will break.
-        supported_chips = []
-        supported_chips.extend(chips)
-
-        for chip in chips:
-            if chip == "qualcomm-snapdragon-8gen3":
-                supported_chips.extend(
-                    [
-                        "qualcomm-snapdragon-8gen2",
-                        "qualcomm-snapdragon-8gen1",
-                        "qualcomm-snapdragon-888",
-                    ]
-                )
-            if chip == "qualcomm-snapdragon-8gen2":
-                supported_chips.extend(
-                    [
-                        "qualcomm-snapdragon-8gen3",
-                        "qualcomm-snapdragon-8gen1",
-                        "qualcomm-snapdragon-888",
-                    ]
-                )
-            if chip == "qualcomm-snapdragon-855":
-                supported_chips.extend(
-                    ["qualcomm-snapdragon-845", "qualcomm-snapdragon-865"]
-                )
-        return supported_chips
-
-    def supported_chipsets_santized(self, chips) -> List[str]:
-        """Santize the chip name passed via hub."""
-        chips = [chip for chip in chips if chip != ""]
-        return sorted(
-            list(
-                set(
-                    [
-                        chipset_marketting_name(chip)
-                        for chip in self.supported_chipsets(chips)
-                    ]
-                )
-            )
+    def __repr__(self) -> str:
+        return pprint.pformat(self.get_perf_card())
+
+
+@dataclass
+class ModelPerfSummary:
+    model_id: str
+    runs_per_chipset: Dict[str, ChipsetPerfSummary]  # Map<Device Name, Summary>
+
+    @staticmethod
+    def from_runs(model_id: str, device_runs: List[ProfileJobSummary]):
+        # Figure out unique devices in various baselines
+        runs_per_chipset: Dict[str, List[ProfileJobSummary]] = {}
+        for run in device_runs:
+            assert run.model_id == model_id  # All should have the same model ID
+            list = runs_per_chipset.get(run.chipset or "", [])
+            runs_per_chipset[run.chipset] = list
+            list.append(run)
+
+        return ModelPerfSummary(
+            model_id,
+            {
+                chipset_name: ChipsetPerfSummary.from_runs(chipset_name, runs)
+                for chipset_name, runs in runs_per_chipset.items()
+            },
         )
 
-    def supported_devices(self, chips) -> List[str]:
-        """Return all the supported devicesgiven the chipset being used."""
-        supported_devices = []
-        for chip in self.supported_chipsets(chips):
-            supported_devices.extend(
-                [
-                    device.name
-                    for device in hub.get_devices(attributes=f"chipset:{chip}")
-                ]
-            )
-        supported_devices.extend(
-            [
-                "Google Pixel 3",
-                "Google Pixel 3a",
-                "Google Pixel 4",
-                "Google Pixel 3a XL",
-                "Google Pixel 4a",
-                "Google Pixel 5a 5G",
-            ]
+    def get_perf_card(self) -> List[Dict[str, Union[str, Dict[str, str]]]]:
+        perf_card = []
+        for summary in self.runs_per_chipset.values():
+            perf_card.append(summary.get_perf_card())
+        return perf_card
+
+    def __repr__(self):
+        return pprint.pformat(self.get_perf_card())
+
+
+@dataclass
+class PerfSummary:
+    runs_per_model: Dict[str, ModelPerfSummary]  # Map<Model ID, Summary>
+
+    @staticmethod
+    def from_model_ids(
+        job_ids: Dict[str, str], model_ids=MODEL_IDS
+    ) -> Dict[str, PerfSummary]:
+        """
+        Reads jobs for every `model_id` from the dictionary and creates summaries for each. `job_ids` format:
+        Either:
+            <model_id>|<runtime>|<device>|<model_component_id> : job_id
+            <model_id>|<runtime>|<device> : job_id
+
+        Returns models in this format:
+            model_id: List[Summary]
+        """
+        print("Generating Performance Summary for Models")
+        pool = multiprocessing.Pool(processes=15)
+        model_summaries = pool.map(
+            functools.partial(PerfSummary.from_model_id, job_ids=job_ids), model_ids
         )
-        return sorted(list(set(supported_devices)))
+        pool.close()
+        print("Finished\n")
+        return {k: v for k, v in model_summaries}
 
-    def supported_oses(self) -> List[str]:
-        """Return all the supported operating systems."""
-        return ["Android"]
-
-    def performance_metrics(self):
-        """Performance metrics as per model card."""
-        perf_card = dict()
+    @staticmethod
+    def from_model_id(
+        model_id: str, job_ids: Dict[str, str]
+    ) -> Tuple[str, PerfSummary]:
+        """
+        Reads jobs for every `model_id` from the dictionary and creates summaries for each. `job_ids` format:
+        Either:
+            <model_id>|<runtime>|<device>|<model_component_id> : job_id
+            <model_id>|<runtime>|<device> : job_id
+
+        Returns models in this format:
+            model_id: List[Summary]
+        """
+        print(f"    {model_id} ")
+        runs = ProfileJobSummary.from_model_id(model_id, job_ids)
+        return model_id, PerfSummary.from_runs(runs)
 
+    @staticmethod
+    def from_runs(model_runs: List[ProfileJobSummary]):
         # Figure out unique models in various baselines
-        unique_model_ids = []
-        chips = []
-        devices = []
-        for run in self.model_runs:
-            if run.model_id not in unique_model_ids:
-                unique_model_ids.append(run.model_id)
-            if run.chipset not in chips:
-                chips.append(run.chipset())
-            if run.device_type not in devices:
-                devices.append(run.device_type)
+        runs_per_model: Dict[str, List[ProfileJobSummary]] = {}
+        for run in model_runs:
+            list = runs_per_model.get(run.model_id, [])
+            list.append(run)
+            runs_per_model[run.model_id] = list
+
+        return PerfSummary(
+            {
+                model_id: ModelPerfSummary.from_runs(model_id, runs)
+                for model_id, runs in runs_per_model.items()
+            }
+        )
+
+    def get_chipsets(self) -> Set[str]:
+        chips: Set[str] = set()
+        for _, model_summary in self.runs_per_model.items():
+            chips.update(model_summary.runs_per_chipset.keys())
+        return chips
+
+    def get_perf_card(self) -> Dict[str, str | List[Any] | Dict[str, Any]]:
+        perf_card: Dict[str, str | List[Any] | Dict[str, Any]] = {}
 
+        chips = self.get_chipsets()
         perf_card["aggregated"] = dict(
-            supported_oses=self.supported_oses(),
-            supported_devices=self.supported_devices(chips),
-            supported_chipsets=self.supported_chipsets_santized(chips),
+            supported_oses=supported_oses(),
+            supported_devices=supported_devices(chips),
+            supported_chipsets=supported_chipsets_santized(chips),
         )
 
-        perf_per_model = []
+        models_list: List[Dict[str, Any]] = []
+        for model_id, summary in self.runs_per_model.items():
+            models_list.append(
+                {"name": model_id, "performance_metrics": summary.get_perf_card()}
+            )
+        perf_card["models"] = models_list
+        return perf_card
 
-        for mid in unique_model_ids:
-            # Calculate per data per runtime
-            perf_per_device = dict()
-            for run in self.model_runs:
-                if run.model_id == mid:
-                    for dev in devices:
-                        if run.device_type == dev:
-                            # perf_per_runtime = dict()
-                            if dev not in perf_per_device:
-                                perf_per_device[dev] = dict()
-                            runtime_name = run.runtime.name.lower()
-                            perf_per_device[dev][
-                                runtime_name
-                            ] = run.performance_metrics()
-                            # Per model, the device used and timestamp for model card
-                            if "reference_device_info" not in perf_per_device[dev]:
-                                perf_per_device[dev][
-                                    "reference_device_info"
-                                ] = run.reference_device_info()
-
-                            perf_per_device[dev]["timestamp"] = (
-                                datetime.datetime.utcnow().isoformat() + "Z"
-                            )
-
-                perf_model = dict(
-                    name=mid, performance_metrics=list(perf_per_device.values())
-                )
-            perf_per_model.append(perf_model)
+    def __repr__(self):
+        return pprint.pformat(self.get_perf_card())
 
-        # Perf card with multiple models
-        perf_card["models"] = perf_per_model
-        return perf_card
+
+@dataclass
+class ModelCompileSummary:
+    model_id: str
+    runs_per_runtime: Dict[
+        TargetRuntime, CompileJobSummary
+    ]  # Map<Device Name, Summary>
+
+    @staticmethod
+    def from_runs(model_id: str, runtime_runs: List[CompileJobSummary]):
+        run_per_runtime: Dict[TargetRuntime, CompileJobSummary] = {}
+        for run in runtime_runs:
+            assert run.model_id == model_id  # model id should match
+            run_per_runtime[run.runtime] = run
+        return ModelCompileSummary(model_id, run_per_runtime)
+
+
+@dataclass
+class CompileSummary:
+    runs_per_model: Dict[str, ModelCompileSummary]  # Map<Model ID, Summary>
+
+    @staticmethod
+    def from_model_ids(
+        job_ids: Dict[str, str], model_ids=MODEL_IDS
+    ) -> Dict[str, CompileSummary]:
+        """
+        Reads jobs for every `model_id` from the dictionary and creates summaries for each. `job_ids` format:
+        Either:
+            <model_id>|<runtime>|<device>|<model_component_id> : job_id
+            <model_id>|<runtime>|<device> : job_id
+
+        Returns models in this format:
+            model_id: List[Summary]
+        """
+        print("Generating Compilation Summary for Models")
+        pool = multiprocessing.Pool(processes=15)
+        model_summaries = pool.map(
+            functools.partial(CompileSummary.from_model_id, job_ids=job_ids), model_ids
+        )
+        pool.close()
+        print("Finished\n")
+        return {k: v for k, v in model_summaries}
+
+    @staticmethod
+    def from_model_id(
+        model_id: str, job_ids: Dict[str, str]
+    ) -> Tuple[str, CompileSummary]:
+        """
+        Reads jobs for every `model_id` from the dictionary and creates summaries for each. `job_ids` format:
+        Either:
+            <model_id>|<runtime>|<device>|<model_component_id> : job_id
+            <model_id>|<runtime>|<device> : job_id
+
+        Returns models in this format:
+            model_id: List[Summary]
+        """
+        print(f"    {model_id} ")
+        runs = CompileJobSummary.from_model_id(model_id, job_ids)
+        return model_id, CompileSummary.from_runs(runs)
+
+    @staticmethod
+    def from_runs(model_runs: List[CompileJobSummary]) -> "CompileSummary":
+        # Figure out unique models in various baselines
+        runs_per_model: Dict[str, List[CompileJobSummary]] = {}
+        for run in model_runs:
+            list = runs_per_model.get(run.model_id, [])
+            list.append(run)
+            runs_per_model[run.model_id] = list
+
+        return CompileSummary(
+            {
+                model_id: ModelCompileSummary.from_runs(model_id, runs)
+                for model_id, runs in runs_per_model.items()
+            }
+        )
```

## Comparing `qai_hub_models/utils/perf_summary.py` & `qai_hub_models/utils/scorecard/perf_summary.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 # ---------------------------------------------------------------------
 # Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
 # SPDX-License-Identifier: BSD-3-Clause
 # ---------------------------------------------------------------------
-import datetime
-import os
 from typing import Dict, List, Tuple
 
 from prettytable import PrettyTable
 
 RUNTIMES_TO_COMPARE = ["torchscript_onnx_qnn", "torchscript_onnx_tflite"]
 
 
@@ -27,21 +25,24 @@
         1. Inferences that started to fail or work (Speedup = "INF")
         2. Speedup difference >= 0.1 (check models closely from higher buckets)
         3. Missing devices (new runs missing data for certain devices)
         4. New models (models with new perf.yamls)
         5. Empty perf reports (models with no passing jobs)
     """
 
-    def __init__(self):
+    def __init__(self) -> None:
         # List of new reports being added
         self.new_perf_report: List[Tuple[str]] = []
 
         # Device present in previous run, but missing in new
         self.missing_devices: List = []
 
+        # Device + runtime present in previous run, but missing in new
+        self.missing_runtimes: List = []
+
         # Perf report with no passing job
         self.empty_perf_report: List[Tuple[str]] = []
 
         # Perf buckets to track
         self.perf_buckets = ["inf", 10, 5, 2, 1.5, 1.3, 1.2, 1.1, 1.05, 1.03]
 
         # Only track PerfSummary for Android
@@ -105,20 +106,24 @@
 
                 # Case 3: Chipset is missing in new data
                 if device not in new_perf_metrics:
                     self.missing_devices.append((model_id, device))
                     continue
 
                 for runtime_type in RUNTIMES_TO_COMPARE:
-                    prev_inference_time = prev_perf_metrics[device][runtime_type][
-                        "inference_time"
-                    ]
-                    new_inference_time = new_perf_metrics[device][runtime_type][
-                        "inference_time"
-                    ]
+                    prev_inference_time = prev_perf_metrics[device].get(
+                        runtime_type, {}
+                    )
+                    prev_inference_time = prev_inference_time.get(
+                        "inference_time", "null"
+                    )
+                    new_inference_time = new_perf_metrics[device].get(runtime_type, {})
+                    new_inference_time = new_inference_time.get(
+                        "inference_time", "null"
+                    )
                     if new_inference_time == prev_inference_time:
                         continue
 
                     if new_inference_time == "null" or prev_inference_time == "null":
                         # Case 1: Model either failed to infer or had a successful run
                         summary_entry = (
                             model_id,
@@ -145,15 +150,15 @@
                     )
                     is_progression = progression_speedup >= 1
                     speedup = (
                         progression_speedup if is_progression else regression_speedup
                     )
 
                     for bucket in self.perf_buckets[1:]:
-                        if bucket <= speedup:
+                        if bucket <= speedup:  # type: ignore
                             summary = (
                                 model_id,
                                 runtime_type,
                                 self._format_speedup(speedup),
                                 self._format_speedup(new_inference_time),
                                 self._format_speedup(prev_inference_time),
                                 device_info["chipset"],
@@ -194,26 +199,18 @@
             if len(val) > 0:
                 return True
         for _, val in self.regressions.items():
             if len(val) > 0:
                 return True
         return False
 
-    def print_summary(self):
+    def dump_summary(self, summary_file_path: str):
         """
-        Prints Perf change summary captured so far.
+        Dumps Perf change summary captured so far to the provided path.
         """
-
-        file_unique_name = datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
-        test_results_path = os.path.join("build", "test-results")
-        os.makedirs(test_results_path, exist_ok=True)
-        summary_file_path = os.path.join(
-            test_results_path, f"perf-summary-{file_unique_name}.txt"
-        )
-
         with open(summary_file_path, "w") as sf:
             sf.write("================= Perf Change Summary =================")
             if self._has_perf_changes():
                 sf.write("\n\n----------------- Regressions -----------------\n")
                 # Dumps Point 1 and 2 from Summary of Interest
                 # 1. Inferences that started to fail (Speedup = "INF")
                 # 2. Slower than previous run
```

## Comparing `qai_hub_models-0.4.1.dist-info/LICENSE` & `qai_hub_models-0.5.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `qai_hub_models-0.4.1.dist-info/METADATA` & `qai_hub_models-0.5.0.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: qai-hub-models
-Version: 0.4.1
+Version: 0.5.0
 Summary: Models optimized for export to run on device.
 Home-page: https://github.com/quic/ai-hub-models
 Author: Qualcomm Technologies, Inc.
 License: BSD-3
 Platform: UNKNOWN
 Requires-Python: >=3.8, <3.11
 Description-Content-Type: text/markdown
@@ -29,15 +29,15 @@
 Requires-Dist: scipy ==1.8.1
 Requires-Dist: tabulate ==0.9.0
 Requires-Dist: torch ==1.13.1
 Requires-Dist: torchvision ==0.14.1
 Requires-Dist: typing-extensions ==4.5.0
 Requires-Dist: tqdm ==4.66.2
 Requires-Dist: urllib3 ==1.26.18
-Requires-Dist: qai-hub >=0.9.0
+Requires-Dist: qai-hub >=0.10.0
 Provides-Extra: controlnet-quantized
 Requires-Dist: transformers ==4.27.4 ; extra == 'controlnet-quantized'
 Requires-Dist: diffusers[torch] ==0.21.4 ; extra == 'controlnet-quantized'
 Provides-Extra: controlnet_quantized
 Requires-Dist: transformers ==4.27.4 ; extra == 'controlnet_quantized'
 Requires-Dist: diffusers[torch] ==0.21.4 ; extra == 'controlnet_quantized'
 Provides-Extra: detr-resnet101
@@ -242,28 +242,51 @@
 Requires-Dist: openai-whisper ==20230314 ; extra == 'whisper_small_en'
 Requires-Dist: scipy ==1.8.1 ; extra == 'whisper_small_en'
 Provides-Extra: whisper_tiny_en
 Requires-Dist: openai-whisper ==20230314 ; extra == 'whisper_tiny_en'
 Requires-Dist: scipy ; extra == 'whisper_tiny_en'
 Provides-Extra: yolov7
 Requires-Dist: matplotlib ==3.7.4 ; extra == 'yolov7'
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov7'
 Requires-Dist: scipy ==1.8.1 ; extra == 'yolov7'
 Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov7'
+Provides-Extra: yolov7-quantized
+Requires-Dist: matplotlib ==3.7.4 ; extra == 'yolov7-quantized'
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov7-quantized'
+Requires-Dist: scipy ==1.8.1 ; extra == 'yolov7-quantized'
+Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov7-quantized'
+Provides-Extra: yolov7_quantized
+Requires-Dist: matplotlib ==3.7.4 ; extra == 'yolov7_quantized'
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov7_quantized'
+Requires-Dist: scipy ==1.8.1 ; extra == 'yolov7_quantized'
+Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov7_quantized'
 Provides-Extra: yolov8-det
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov8-det'
 Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8-det'
 Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8-det'
 Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8-det'
+Provides-Extra: yolov8-det-quantized
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov8-det-quantized'
+Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8-det-quantized'
+Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8-det-quantized'
+Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8-det-quantized'
 Provides-Extra: yolov8-seg
 Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8-seg'
 Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8-seg'
 Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8-seg'
 Provides-Extra: yolov8_det
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov8_det'
 Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8_det'
 Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8_det'
 Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8_det'
+Provides-Extra: yolov8_det_quantized
+Requires-Dist: object-detection-metrics ==0.4.post1 ; extra == 'yolov8_det_quantized'
+Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8_det_quantized'
+Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8_det_quantized'
+Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8_det_quantized'
 Provides-Extra: yolov8_seg
 Requires-Dist: seaborn ==0.11.0 ; extra == 'yolov8_seg'
 Requires-Dist: thop ==0.1.1.post2209072238 ; extra == 'yolov8_seg'
 Requires-Dist: ultralytics ==8.0.193 ; extra == 'yolov8_seg'
 
 [![Qualcomm AI Hub Models](https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/quic-logo.jpg)](https://aihub.qualcomm.com)
 
@@ -607,16 +630,18 @@
 | [DETR-ResNet101](https://aihub.qualcomm.com/models/detr_resnet101) | [qai_hub_models.models.detr_resnet101](qai_hub_models/models/detr_resnet101/README.md) |  |  | 
 | [DETR-ResNet101-DC5](https://aihub.qualcomm.com/models/detr_resnet101_dc5) | [qai_hub_models.models.detr_resnet101_dc5](qai_hub_models/models/detr_resnet101_dc5/README.md) |  |  | 
 | [DETR-ResNet50](https://aihub.qualcomm.com/models/detr_resnet50) | [qai_hub_models.models.detr_resnet50](qai_hub_models/models/detr_resnet50/README.md) |  |  | 
 | [DETR-ResNet50-DC5](https://aihub.qualcomm.com/models/detr_resnet50_dc5) | [qai_hub_models.models.detr_resnet50_dc5](qai_hub_models/models/detr_resnet50_dc5/README.md) |  |  | 
 | [MediaPipe-Face-Detection](https://aihub.qualcomm.com/models/mediapipe_face) | [qai_hub_models.models.mediapipe_face](qai_hub_models/models/mediapipe_face/README.md) |  |  | 
 | [MediaPipe-Hand-Detection](https://aihub.qualcomm.com/models/mediapipe_hand) | [qai_hub_models.models.mediapipe_hand](qai_hub_models/models/mediapipe_hand/README.md) |  |  | 
 | [YOLOv8-Detection](https://aihub.qualcomm.com/models/yolov8_det) | [qai_hub_models.models.yolov8_det](qai_hub_models/models/yolov8_det/README.md) |  |  | 
+| [YOLOv8-Detection-Quantized](https://aihub.qualcomm.com/models/yolov8_det_quantized) | [qai_hub_models.models.yolov8_det_quantized](qai_hub_models/models/yolov8_det_quantized/README.md) |  |  | 
 | [Yolo-v6](https://aihub.qualcomm.com/models/yolov6) | [qai_hub_models.models.yolov6](qai_hub_models/models/yolov6/README.md) |  |  | 
 | [Yolo-v7](https://aihub.qualcomm.com/models/yolov7) | [qai_hub_models.models.yolov7](qai_hub_models/models/yolov7/README.md) |  |  | 
+| [Yolo-v7-Quantized](https://aihub.qualcomm.com/models/yolov7_quantized) | [qai_hub_models.models.yolov7_quantized](qai_hub_models/models/yolov7_quantized/README.md) |  |  | 
 | | | | |
 | **Pose Estimation**
 | [HRNetPose](https://aihub.qualcomm.com/models/hrnet_pose) | [qai_hub_models.models.hrnet_pose](qai_hub_models/models/hrnet_pose/README.md) |  |  | 
 | [LiteHRNet](https://aihub.qualcomm.com/models/litehrnet) | [qai_hub_models.models.litehrnet](qai_hub_models/models/litehrnet/README.md) |  |  | 
 | [MediaPipe-Pose-Estimation](https://aihub.qualcomm.com/models/mediapipe_pose) | [qai_hub_models.models.mediapipe_pose](qai_hub_models/models/mediapipe_pose/README.md) |  |  | 
 | [OpenPose](https://aihub.qualcomm.com/models/openpose) | [qai_hub_models.models.openpose](qai_hub_models/models/openpose/README.md) |  |  | 
 
@@ -635,16 +660,16 @@
 | [Facebook-Denoiser](https://aihub.qualcomm.com/models/facebook_denoiser) | [qai_hub_models.models.facebook_denoiser](qai_hub_models/models/facebook_denoiser/README.md) |  |  | 
 
 ### Multimodal
 
 | Model | README | Torch App | Device Export | CLI Demo
 | -- | -- | -- | -- | --
 | | | | |
-| [OpenAI-Clip](https://aihub.qualcomm.com/models/openai_clip) | [qai_hub_models.models.openai_clip](qai_hub_models/models/openai_clip/README.md) |  |  | 
 | [TrOCR](https://aihub.qualcomm.com/models/trocr) | [qai_hub_models.models.trocr](qai_hub_models/models/trocr/README.md) |  |  | 
+| [OpenAI-Clip](https://aihub.qualcomm.com/models/openai_clip) | [qai_hub_models.models.openai_clip](qai_hub_models/models/openai_clip/README.md) |  |  | 
 
 ### Generative Ai
 
 | Model | README | Torch App | Device Export | CLI Demo
 | -- | -- | -- | -- | --
 | | | | |
 | **Image Generation**
```

## Comparing `qai_hub_models-0.4.1.dist-info/RECORD` & `qai_hub_models-0.5.0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,59 +1,59 @@
 qai_hub_models/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
-qai_hub_models/_version.py,sha256=cA83SEu5KF1vaKslxBJXqHJmN_NpCmBqkhyTWtwK1xQ,281
+qai_hub_models/_version.py,sha256=f9kkIsFtA1v7fOa_sakYAhr5DF4PqxO6HGLGtVMNeLo,281
 qai_hub_models/asset_bases.yaml,sha256=53T7xh4bysMolqjwBOIxm4tm23szHhVQPgOKo7JzCvo,620
 qai_hub_models/conftest.py,sha256=STs4po9vrxUPOpDmX0XbVCVSIHtsbKou_Y11coTBAbU,734
-qai_hub_models/global_requirements.txt,sha256=vJFzTNzkE3URaOOQTaqyY_iSHjc-pMYdAa5f-GYg8jM,877
+qai_hub_models/global_requirements.txt,sha256=y7Pp0d7YLb--E7J-8DQAPOG2Irq3K8oSPJqU0VhwR4M,913
 qai_hub_models/requirements-dev.txt,sha256=z81nhpASF1QUiIvaj3ZEXr75ifaWkSstpB-Y-3jOJuo,395
-qai_hub_models/requirements.txt,sha256=m_Ltyf69NVmnBlAgWGLMetiz8hlbqAkZVVzvR6pE5Wc,426
+qai_hub_models/requirements.txt,sha256=qu_-OPNrU_0-iG2lejY1zNn-4t0WbTOxw--z6IH7WQk,427
 qai_hub_models/datasets/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/datasets/bsd300.py,sha256=ndX_-l3KFRQeOPxsq8AjyIwDb0ozGYQpP7N84lpQwtk,4757
-qai_hub_models/datasets/coco.py,sha256=bjyHJPG6RPI-wimfOkfuu_R3LADAP_ES2XuWBq90vbQ,4054
-qai_hub_models/datasets/common.py,sha256=g89TBv_5JY-lHl3oWeJriMgUAVdHeYDsd6UoycNWSmM,1546
+qai_hub_models/datasets/coco.py,sha256=p1tVNIqajR6P1B3b7yNpztiVq_uo3KKBOuDzlCg0WNw,4109
+qai_hub_models/datasets/common.py,sha256=_MxFQMrogLDazscDyxu3NNid4j3IWK9jTl5kefWfgNA,1614
 qai_hub_models/datasets/imagenette.py,sha256=Rdz6vw6tL7ysw-7DSHZoW8u6jCBPA6PLOIyYKSun0Ks,3203
 qai_hub_models/evaluators/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/evaluators/base_evaluators.py,sha256=vFG_4HpZkx3bHBluZq17GvP7iBCWkGphy07__pkvaww,6212
 qai_hub_models/evaluators/classification_evaluator.py,sha256=ccjbu9vcVTn8UBB0iUM_fRxvTlbarwfFWlXIR90gFAU,1326
-qai_hub_models/evaluators/detection_evaluator.py,sha256=QQJSry7nlD9TDJZ69kpNNeNNU2qC_0AZ9I48KNB6mrw,3355
+qai_hub_models/evaluators/detection_evaluator.py,sha256=qQl-1WApD95Os0tYTVLpMsVNNT7ViqS4nvcNW7rAViw,3699
 qai_hub_models/evaluators/image_evaluator.py,sha256=nPMHIeyo7WreD6LEa-eqdHdvIZQA1NbPhYoVrOQw3DY,2434
 qai_hub_models/evaluators/superres_evaluator.py,sha256=7NwBcPFJCjCbnmVpjB0cctRPNc2Am6PCL7z8vYzcDUY,2181
 qai_hub_models/models/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
-qai_hub_models/models/common.py,sha256=ynBwesML8zxw-ibpwPk2xHIY6On5zU1_L8zLpBeoLao,571
+qai_hub_models/models/common.py,sha256=Pgd1o517c7YvY8GWVX8ksH2Lu2lc7Ueagi4OKGYyN_E,666
 qai_hub_models/models/protocols.py,sha256=4CntVWA7YWOYsnIrj6VgEUDQFk4Hswhl3UJHZGQrB0U,7882
 qai_hub_models/models/_shared/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/common.py,sha256=LHJiXmHRCP2A6GynzbwoLabojxZZlZOXwMtu4FMZcbg,1655
 qai_hub_models/models/_shared/cityscapes_segmentation/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/cityscapes_segmentation/app.py,sha256=2n2tPq3bmKmAudJaQGoewvOZAX_RybjjLJnBmvfWKEM,4346
 qai_hub_models/models/_shared/cityscapes_segmentation/demo.py,sha256=Hzjw4Bo2hKUbPkHQTk3-extZweVbAaL7bd7LAHeVy5w,2904
 qai_hub_models/models/_shared/cityscapes_segmentation/evaluator.py,sha256=25G3q93XoJhT9-1sKh6p0cstO1vhAI13hOR91IucKmE,890
 qai_hub_models/models/_shared/cityscapes_segmentation/model.py,sha256=z-F-WrxlqJDdv2TNXwJW73pKgx-S0fSR2gQK0BqOoBU,2888
 qai_hub_models/models/_shared/cityscapes_segmentation/patches/move_datasets.diff,sha256=y_7LNVu_y66oJzmjUps6PFe-1XRj0J5cf68-DJNeBcU,8565
 qai_hub_models/models/_shared/deeplab/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/deeplab/app.py,sha256=mQ00GgK-pwllOy4hqhEnvv6fbWPht5tghBSfic59Pjs,2651
 qai_hub_models/models/_shared/deeplab/demo.py,sha256=T98PVkEdE3enflfwJT_gKo4W0GnJ2ovCxLgrKgxpWho,2252
 qai_hub_models/models/_shared/deeplab/evaluator.py,sha256=z_lorsF_6cW4G5bNBxG89HdWmeG53PyRk9fOuswxB0M,915
 qai_hub_models/models/_shared/detr/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
-qai_hub_models/models/_shared/detr/app.py,sha256=suRWTpo_wYl88krqhdq_JHA99Zh2TP6TFIlePthGPXg,4243
+qai_hub_models/models/_shared/detr/app.py,sha256=EKqvk7pHd8_JVhc0BbESwLyZiVu_7poSf1Qgad2pbSM,4604
 qai_hub_models/models/_shared/detr/coco_label_map.py,sha256=QOEkaqmyW6mS8gXLxfUHJfCyWtCQ1lNzzLEap8zlW1c,3565
-qai_hub_models/models/_shared/detr/demo.py,sha256=06s1enzCfZU3GVyl2PUlkb2QlnQmG26yK4mGPCvRzQs,1944
-qai_hub_models/models/_shared/detr/model.py,sha256=BPRRhWAjfaeEb61P49Gq0NSm5nYQskhSw6xnQtTmRcM,2152
+qai_hub_models/models/_shared/detr/demo.py,sha256=TytpiefnNUXvlwezD9QkAe5Xt5aRzswJu9SWca4AwR8,2091
+qai_hub_models/models/_shared/detr/model.py,sha256=G0nk4_EnJDLINqr1jrbdW54EzH4-QoEKhCRqFvVViYs,2050
 qai_hub_models/models/_shared/fastsam/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/fastsam/app.py,sha256=VcGV3iloO_1t3g694bkV02PIPXIbnBaAoL6emPK-eRA,4883
 qai_hub_models/models/_shared/fastsam/demo.py,sha256=m9HSdl3LenmUHRF8lh8Gux66CLF6CyoHjXzP9SsZ4Q0,2022
 qai_hub_models/models/_shared/fastsam/model.py,sha256=Vr1iTFJ-UU0jxpwD2LCQ_mU-5fPCpw0NnPsbpGoOYzc,1935
 qai_hub_models/models/_shared/ffnet/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/ffnet/model.py,sha256=7fO0THAtD3QTphtGxRxIZbqnRAa88niDBN8xyX2xVYM,4548
 qai_hub_models/models/_shared/ffnet/test_utils.py,sha256=y-8cmFjaP_mCZIeSs4if8gKYMv-DW9mXKS_hIB_engc,1569
 qai_hub_models/models/_shared/ffnet_quantized/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/ffnet_quantized/aimet_config.json,sha256=RwkXlIJFptwSaAqRENlmu1spoW2oyFlhv2X20GGvIWM,1165
-qai_hub_models/models/_shared/ffnet_quantized/model.py,sha256=ppaDEceU2tbqohLZG9rKAw1f4-neaL-PhfyO6XDRZj8,2372
+qai_hub_models/models/_shared/ffnet_quantized/model.py,sha256=kFSAROGzDLIuSFPum3ZJ7_YTGcqs_BUYhAKpTa2uIRo,2475
 qai_hub_models/models/_shared/imagenet_classifier/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
-qai_hub_models/models/_shared/imagenet_classifier/app.py,sha256=af3jgCf_zfqi4c49oP6Ssn44yOMyyfuH6gZtgte3PVw,2272
+qai_hub_models/models/_shared/imagenet_classifier/app.py,sha256=PnznFwwswxLZy-Kzr9tw82hyF633a2EuB84s2SQDZ7E,3041
 qai_hub_models/models/_shared/imagenet_classifier/demo.py,sha256=8o3ad2SJUbkVzg5jecHin4N2J_YxMNQsQ-ioImN3ufU,2432
-qai_hub_models/models/_shared/imagenet_classifier/model.py,sha256=MqTs01pdsUe7IpYIzIKwc7sEtBm2CXdR4qrbkmzqF5o,3404
+qai_hub_models/models/_shared/imagenet_classifier/model.py,sha256=pvW_t6Tqb9ZFUpeYWGzi0Vr3TVxkqeV0dluRiIaApb0,4661
 qai_hub_models/models/_shared/imagenet_classifier/test_utils.py,sha256=MnxFDMDKULF87n4p4N1eYrUJ854zECi-nPqPLqakFZA,3781
 qai_hub_models/models/_shared/mediapipe/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/mediapipe/app.py,sha256=Sj7U03ljI1MHXkigQvvhSOf7taPFrBrpKKiLa-KLBcc,30293
 qai_hub_models/models/_shared/mediapipe/utils.py,sha256=Q1J3HW3u_dIvnjmt9AzBDMqv9USjWuDeBzmG765YET0,4394
 qai_hub_models/models/_shared/quicksrnet/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/quicksrnet/common.py,sha256=TDl166uGYRvm6Y8XxGN0diS_yfNCrPbTAY0iNBGkta8,985
 qai_hub_models/models/_shared/repaint/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
@@ -72,832 +72,853 @@
 qai_hub_models/models/_shared/video_classifier/model.py,sha256=obQoYEt1AGWxrfm3tD12j1gmj6WlOGeBbATiXoEFTds,1969
 qai_hub_models/models/_shared/whisper/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/models/_shared/whisper/app.py,sha256=FG9-3wysMYdfh7tcH6miAO5xf3EayCqVbCzLsSP05XQ,10188
 qai_hub_models/models/_shared/whisper/demo.py,sha256=7zi12g3CskAHOndf2nZIl_QVFLYp0n-P3VtO-ylEECU,1302
 qai_hub_models/models/_shared/whisper/model.py,sha256=8NfDTyLWl2Hp2t8lqc2fbNos65RsnwHLWxVXcelUT_8,14119
 qai_hub_models/models/_shared/whisper/test_utils.py,sha256=MVNzlRySllNxozJt9_biaPIii2hLNJHNga7weTv1mdU,2848
 qai_hub_models/models/_shared/yolo/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
-qai_hub_models/models/_shared/yolo/app.py,sha256=T6yNzcH8Z5AY7Nml-TLLqz10lop1Idg09k0a22IXBp0,7069
-qai_hub_models/models/_shared/yolo/demo.py,sha256=ZtQmTD4vs424i5ZSuRmf80xvicWbbTJd_5JIGsHrzho,2475
-qai_hub_models/models/_shared/yolo/utils.py,sha256=ZjnOQ68V6pZMtm_6iDeQDctyf7nf1ljGiYLwAmRebj8,4190
+qai_hub_models/models/_shared/yolo/app.py,sha256=iuFEHq3aGXkI5yEAsuixRk2ntWAM8dVdNdun4fF7Mvs,7354
+qai_hub_models/models/_shared/yolo/demo.py,sha256=XBrIzWUujUBj6r4qPhra5mbUnZF5FZSs0MzWTIEeqz8,2432
+qai_hub_models/models/_shared/yolo/utils.py,sha256=4c_Psz-kVEhq-iczYlj5chV37RH77HLDdtkC9LJ2XL0,5643
 qai_hub_models/models/aotgan/__init__.py,sha256=BaaLR3zQEAxIdLMsE_bj1ifMQKJs6_HBVeTvC601C8Q,450
-qai_hub_models/models/aotgan/conftest.py,sha256=IK65Meta4wuUMjG-2FJtQOVtbFs6sxUEjpF-BkV5hVI,870
+qai_hub_models/models/aotgan/conftest.py,sha256=CTqtFJRsqW03tZp4iC66bRJMqG8aDFWW5fmICXvQfyw,980
 qai_hub_models/models/aotgan/demo.py,sha256=pNMiZ4xPMXki0cep2i7KrSCYpbkFjVA7AjWJK3WLROw,597
 qai_hub_models/models/aotgan/export.py,sha256=HRVUYynOlKuoGa5cSUBxu5ilBFfX00mzOhuljik0uXk,8156
 qai_hub_models/models/aotgan/info.yaml,sha256=n2LVDkDfhrNh60R-XxQiZexVaNz3DHlmtJ7yuJ3MJ5U,1023
 qai_hub_models/models/aotgan/model.py,sha256=mj9Zn0MkmSh1Frsw9ESCB-pL1LjJoE_EHhNVPhfbqyo,4838
-qai_hub_models/models/aotgan/perf.yaml,sha256=3wrjWMMZl0WBUnN00w3Rcbp1N1YoCFG8dsHexZBr4Xk,2768
+qai_hub_models/models/aotgan/perf.yaml,sha256=s8lGifIN-sjniudD8y98pvt6tbOaIlRO3xMmEek3N8o,4412
 qai_hub_models/models/aotgan/test.py,sha256=sPojPTH2xmn5YoLMpTt8rurhiF1BDS1PMgRhXK01Fio,2006
 qai_hub_models/models/aotgan/patches/layer_norm.diff,sha256=NbhINLgR1N0wfrI3x89m7JheBbxT2MTNkEm9dpedBeY,532
 qai_hub_models/models/baichuan_7b_quantized/info.yaml,sha256=f4r1NJYFIzd7MJNcrOIkfg07OKkIjWFDFbViUT2umWU,1983
 qai_hub_models/models/baichuan_7b_quantized/perf.yaml,sha256=An29D-fEHO6H1ihUWR43hePTiHDuEP2VxUfHhloCkkk,2036
 qai_hub_models/models/controlnet_quantized/__init__.py,sha256=aCoQX1Qz9SrPHhuSJr4vD7f9nJtkhCzAa9__HBvcg4g,559
 qai_hub_models/models/controlnet_quantized/app.py,sha256=5wCKVlYNyeZ_m1PfqCOQlIq80bToaYsTdxw2Fk4l05U,9705
 qai_hub_models/models/controlnet_quantized/demo.py,sha256=rPSPdSGbFMUJ9jdMj5nLEypRqsbmrMaitON-j6zgzds,6397
 qai_hub_models/models/controlnet_quantized/export.py,sha256=SfnuhRIGIfCTGSP6tUhhlQ3TRJYkPovKHNsI2rowUZ8,7622
 qai_hub_models/models/controlnet_quantized/info.yaml,sha256=ivhi6oY9IC0gGtw9REooBoV7aJQqUIvHw-g9YfE-qVw,1329
 qai_hub_models/models/controlnet_quantized/model.py,sha256=8BO-diXqlxH6wuNRs7VeYUlSxhDGWYCemAT_XgEzVt8,5426
 qai_hub_models/models/controlnet_quantized/perf.yaml,sha256=a0C641UKT6i75a3Tu0x_zsyVtB07oWBzsM3P2PSftAc,8427
 qai_hub_models/models/controlnet_quantized/requirements.txt,sha256=HWz6kAx8f-AYWf5IWvv-q1IOznXS94gXTQrtKGY4L70,46
 qai_hub_models/models/controlnet_quantized/test.py,sha256=ilelb6gq5P7_1RveAB09vfppdhzrVbWpHYiB-twI55w,1556
 qai_hub_models/models/convnext_tiny/__init__.py,sha256=HCfwohVDc0VtmT7yLoa43BTiBAEkKXtFE9-jfRy3XrM,475
-qai_hub_models/models/convnext_tiny/conftest.py,sha256=ZQRy7bLSIl_c8HcIH6pIdu6k-EqGJzgyL19za_byjKs,798
+qai_hub_models/models/convnext_tiny/conftest.py,sha256=TchLpc6aQTfmrRY5s315X9ne0k4BmKnQ35H-mWGiQj8,908
 qai_hub_models/models/convnext_tiny/demo.py,sha256=22oIp3py29Uzbsh0ob2ak4ic4ZdetMiqwgyo3I2fqEY,543
 qai_hub_models/models/convnext_tiny/export.py,sha256=f6daP73JHRI7gBvlspn_eE8Kd86aEWLRt3hwyXyX8dY,7915
 qai_hub_models/models/convnext_tiny/info.yaml,sha256=C017TbQv8k22-OVMYW8RnesPhOAtRXZVqKANe2fAP7s,1287
 qai_hub_models/models/convnext_tiny/model.py,sha256=TohaPxU5EWTTBKMEjZusg238O3MEaA9MNKH36v6SoFw,708
 qai_hub_models/models/convnext_tiny/perf.yaml,sha256=Fg5TvSc1qlKNVDJEGh8C2aABL4YgG955krRLgO5yg7M,2707
 qai_hub_models/models/convnext_tiny/test.py,sha256=cijDPmavZsw6N6okJvEeQFhiC8zoWymxjT1QvbPUNhg,857
 qai_hub_models/models/ddrnet23_slim/__init__.py,sha256=fz62JiNfyn7NSLR8F95JKyRtjB6CQFJSxx8Vt2YQwyc,398
 qai_hub_models/models/ddrnet23_slim/app.py,sha256=bUGwG2F79praX6iTM5vHKxUlVlPyrUVl4FzmX3U9uWk,3750
-qai_hub_models/models/ddrnet23_slim/conftest.py,sha256=MXoAWwG-hVmyZQjF9uyBpDhZyy3DT-qQhoKWDW2CBuE,884
+qai_hub_models/models/ddrnet23_slim/conftest.py,sha256=KXIS06bjhHzQ0EeR6yV6tiET_eej7rF3unREuL8r_1I,994
 qai_hub_models/models/ddrnet23_slim/demo.py,sha256=DtX3jP0RGrtig0qNjNSrhuhYErtopHTmsVcArT_HDrg,2128
 qai_hub_models/models/ddrnet23_slim/export.py,sha256=qCMq8B7iRlRZqM2GwkpiA9lkuEPVgXAWj47y19ru_8M,8193
 qai_hub_models/models/ddrnet23_slim/info.yaml,sha256=J8BrgX-ROS7IN6jqb1Co6mC7mJxBO3VFVlCGHQyqIfc,1334
 qai_hub_models/models/ddrnet23_slim/model.py,sha256=o19xSxPaoEKCcYRotMWrqZyqPHI3iwigwU7OLXUKQ4M,3831
-qai_hub_models/models/ddrnet23_slim/perf.yaml,sha256=omKtcMXy8E3WaaCRoLWIpXHf-zSeXYxI_QKBgKfqa9A,2707
+qai_hub_models/models/ddrnet23_slim/perf.yaml,sha256=Sjaqe4RcbwHFSTBe0z365aClcGsVO2lY0mVRohqOexw,3617
 qai_hub_models/models/ddrnet23_slim/test.py,sha256=Km5AirOt-YDL_qfBSKMuco1rFWR5-4MpK-o1GRBqPBY,1790
 qai_hub_models/models/deeplabv3_resnet50/__init__.py,sha256=RgC9JWAyPRQugvGjLMpeeWh68mvBeK7KxBnIvMtA_P8,451
-qai_hub_models/models/deeplabv3_resnet50/conftest.py,sha256=KlED3VIE0L0dNlTfwe0EsnYmiMY7AVO7DzcaNYxbuzM,894
+qai_hub_models/models/deeplabv3_resnet50/conftest.py,sha256=VRJr9ADQ7R9WB9DhDy3wP3qV8Mwc05W1eqYXUv7LTPc,1004
 qai_hub_models/models/deeplabv3_resnet50/demo.py,sha256=pxsw91eJcacHy5-N-4POOM_vv8er47uTUIpIGM91P1k,1026
 qai_hub_models/models/deeplabv3_resnet50/export.py,sha256=Wuwe7Zq8MSoDuoCaohLFIbiCGf1xMZiWRArCtK9I_T8,8068
 qai_hub_models/models/deeplabv3_resnet50/info.yaml,sha256=xJyhJArERFP4UdDYrFc1dc9NLLJqkeQTi4EM_vZFaxQ,1278
 qai_hub_models/models/deeplabv3_resnet50/model.py,sha256=NLurkhtOrORi268v1t9_IlBzSTk3Lyy3jdZ2wlDHJUU,2886
-qai_hub_models/models/deeplabv3_resnet50/perf.yaml,sha256=XM55xjcK8x-GfGvBflwdagojbiA3SBC4dy1s2JjanRk,2761
+qai_hub_models/models/deeplabv3_resnet50/perf.yaml,sha256=IZnHJ9cWuh6o2DUnpVRaTzPYWWzeu2wWv6Oh1raUBfs,4374
 qai_hub_models/models/deeplabv3_resnet50/test.py,sha256=yXJY6pGC_QkjLGavh40vSP4flUm33H83FhWUFXTLzxM,2086
 qai_hub_models/models/densenet121/__init__.py,sha256=TxCV8tdZZ-D4d15naxmzu-0l5CHW_N3BkJiIV5HRzbY,471
-qai_hub_models/models/densenet121/conftest.py,sha256=wMqLTSpvvQHq1ZODIMnA-MHgV22YRf4ECxnMY2qrYNU,794
+qai_hub_models/models/densenet121/conftest.py,sha256=qid7VQx1XssPdfKlC2AkbzoNmJQAYpN8InrCjxQitbw,904
 qai_hub_models/models/densenet121/demo.py,sha256=kmSL8S4QnCR2AUdz-josBJzF3ehyQ5fOgHcsbgaIN2g,533
 qai_hub_models/models/densenet121/export.py,sha256=FrgJZ5oUwDfnRGuRYiyeHRd9l44-mRLl81Yl2I9wXGg,7888
 qai_hub_models/models/densenet121/info.yaml,sha256=RRS9Pk3XMI-kwohy4GZbzLePqaFD_03Iky3W4adFvX8,1310
 qai_hub_models/models/densenet121/model.py,sha256=Lp5noeTPApNrJL6z_VmsZfEHDuKCZNl_WUY-Lr7xatM,698
-qai_hub_models/models/densenet121/perf.yaml,sha256=6quM5-K__jVxKOK7j_NemdsII8Dru8rGOTHeBwn5rcM,2758
+qai_hub_models/models/densenet121/perf.yaml,sha256=lkpxXYeB7qYtmaI_zlITQEViR9i9sPoO8o9ZzTJs95g,4399
 qai_hub_models/models/densenet121/test.py,sha256=iCxswqgBQ_GXA2vfr-ShiukFZS2Gj38OV9zY6Jm3Gvk,841
 qai_hub_models/models/detr_resnet101/__init__.py,sha256=X6U_xy5Tp6diGFQfn7Na0XebaI6Ojc0wFv6xSoh_sKY,483
-qai_hub_models/models/detr_resnet101/conftest.py,sha256=6vZWUem8K0tAcN6Q7pswikMT1iLBsFWiiUe5HyAk4zY,800
+qai_hub_models/models/detr_resnet101/conftest.py,sha256=Ug7EujulNyBsCJ7yesXxfa97ZC95Di_ej4vjjIrQAvI,910
 qai_hub_models/models/detr_resnet101/demo.py,sha256=9o_p8fmwrZycE5JQAsWCfskglZNfyrJOAVV49KJwChg,896
 qai_hub_models/models/detr_resnet101/export.py,sha256=20hH6wkFADuLHYxelRN7gcw6TBGJDcgQg_s3d3pSguk,7905
 qai_hub_models/models/detr_resnet101/info.yaml,sha256=YP4G-_ATugwYJnXGz9uJ0ghrH38exu_7SQfOq-2_OLE,1188
 qai_hub_models/models/detr_resnet101/model.py,sha256=f6SJr1m53RdUirPG1GOVeLDluBBxLIsOV-z2hSgF20E,661
-qai_hub_models/models/detr_resnet101/perf.yaml,sha256=yxurEsPzilPkhry0Ni8OHeTyx-cH5UluPWxYsrEH0P0,2711
+qai_hub_models/models/detr_resnet101/perf.yaml,sha256=kgkOhp2A-T8SbT1eOMg_Nk13XbygaRaiSrIg_KztBi8,3658
 qai_hub_models/models/detr_resnet101/requirements.txt,sha256=7JPG1_GVGtM8EzOggEHT_-_rO9H8b9NsMK5aLI1nImM,34
 qai_hub_models/models/detr_resnet101/test.py,sha256=gDbI8asjHE5ONZLujGFXIcO_h-EC0OtEkg1t4SATMd8,1316
 qai_hub_models/models/detr_resnet101_dc5/__init__.py,sha256=u76QZ7QpcYASS-4FZptRsGd5jROIardr7dRIEktZ0Ds,490
-qai_hub_models/models/detr_resnet101_dc5/conftest.py,sha256=FaglsXCmZLy9we4l2PhNZD_xm-1cRgyS1zWeKsNOAG8,808
+qai_hub_models/models/detr_resnet101_dc5/conftest.py,sha256=l4mWRDRbUasGSYnD18XlfKpEa4F9AYAXo54YBE821A8,918
 qai_hub_models/models/detr_resnet101_dc5/demo.py,sha256=ie0VdX_40vFCnnIWRCnjxH9SRsxlGpGIJpvoteK6rNI,906
 qai_hub_models/models/detr_resnet101_dc5/export.py,sha256=Vo7EJDf9pRoMNM72GSWzwUWtE9Ipb4ZCTYUOZQx2QCM,7921
 qai_hub_models/models/detr_resnet101_dc5/info.yaml,sha256=otqz2oAdErfBmbBgnQNQgRXlBMcw_nI-p_UTJr4nYsw,1215
 qai_hub_models/models/detr_resnet101_dc5/model.py,sha256=A4OU7F9N_JMElzRdKUH7VKkXmqlmvBxlZ71B6kN1Yyo,668
-qai_hub_models/models/detr_resnet101_dc5/perf.yaml,sha256=95axI9nj9kF8HUEd6hDfRn-tylN04_ahpskux1aLKhw,2719
+qai_hub_models/models/detr_resnet101_dc5/perf.yaml,sha256=w3Pp_vEpOebwA1ke6dxiXTCeWKVU8iLNYcO963SUNk4,3677
 qai_hub_models/models/detr_resnet101_dc5/requirements.txt,sha256=7JPG1_GVGtM8EzOggEHT_-_rO9H8b9NsMK5aLI1nImM,34
-qai_hub_models/models/detr_resnet101_dc5/test.py,sha256=E8USeF-ehryQQ7bnGoXsNmZ6ULJI9RHBhuGbHdj1fjc,1373
+qai_hub_models/models/detr_resnet101_dc5/test.py,sha256=nvO-ikZrOs6mMSkoDxxFwOSuwA64diJrxslDgMVpXpw,1373
 qai_hub_models/models/detr_resnet50/__init__.py,sha256=atV57qR8yJou6gYUi56f7UTiBsbDVyQAvbwgHFuXI0c,481
-qai_hub_models/models/detr_resnet50/conftest.py,sha256=grxSREEFJM0IFk6__LgoDUMr68UYV7QgmtEIHJkH7d8,798
+qai_hub_models/models/detr_resnet50/conftest.py,sha256=zteaOt1YwLJ987gBK43ECIDTbvediAo2Jwg8uSitZlo,908
 qai_hub_models/models/detr_resnet50/demo.py,sha256=X9w6CWF9U1rYaN3Xo1RIDLgxk4l-CP8Kdrbp-wYaWBQ,893
 qai_hub_models/models/detr_resnet50/export.py,sha256=UN230OEgT-Sv9r44fpLHPkcCqSaWCaLPKvmhI7zYbx0,7901
 qai_hub_models/models/detr_resnet50/info.yaml,sha256=Zgk7l86YchB6yOV1EHo072l0o8pOroZ79-VHvZbQhdQ,1185
 qai_hub_models/models/detr_resnet50/model.py,sha256=f7rWSFyK5_LybX4KkfnxZVlHpCCVk6hRfbx6CyEs7dg,659
-qai_hub_models/models/detr_resnet50/perf.yaml,sha256=C8B6yFqDh1IXqbZGnWye9CvNiieb16TWz5kA9G68ZCY,2713
+qai_hub_models/models/detr_resnet50/perf.yaml,sha256=WPguHdWhZPevfqo-G3mybOKOSg83zcMobG-mfKBlZRI,3662
 qai_hub_models/models/detr_resnet50/requirements.txt,sha256=7JPG1_GVGtM8EzOggEHT_-_rO9H8b9NsMK5aLI1nImM,34
 qai_hub_models/models/detr_resnet50/test.py,sha256=O0P_osmIHBpoaSgCSsyPgMrS0hEhyWYiQiGfhVZzdMg,1636
 qai_hub_models/models/detr_resnet50_dc5/__init__.py,sha256=EOUQu8Eybv_S6dv2MxT06c5fP8fb-zbNd-MGM6Yo4DI,488
-qai_hub_models/models/detr_resnet50_dc5/conftest.py,sha256=VAVUi3nrH__WGTuTMDKNQamDlhNAMIDSiqjg1UskgBE,806
+qai_hub_models/models/detr_resnet50_dc5/conftest.py,sha256=AUw92oGCmYP4yO7DR8rSvPDrEtnTiGvY9p2Kbpew_ec,916
 qai_hub_models/models/detr_resnet50_dc5/demo.py,sha256=BFw09UhIreglAFeM1lS9xnKYumTh4fnS3hgqp0io7Es,903
 qai_hub_models/models/detr_resnet50_dc5/export.py,sha256=sF6QZQLdns8vQTkEnrR1bd5pccZttziRrexO0NFi_Fc,7917
 qai_hub_models/models/detr_resnet50_dc5/info.yaml,sha256=QrFUKwhno5ciqd0fpkPTis2SvXi2Nmqg9DkZTk6PaUE,1212
 qai_hub_models/models/detr_resnet50_dc5/model.py,sha256=8bZ0js6wEEb64RPwCHfwJtt9OrgTyk2KaRaS_9QxIAo,666
-qai_hub_models/models/detr_resnet50_dc5/perf.yaml,sha256=5OlrDAYcoiJFRnoWnWcA-iOmDjs7bejFSxt7unSloRg,2718
+qai_hub_models/models/detr_resnet50_dc5/perf.yaml,sha256=AR3xhPXEgzRxTG1wgDGmWrXYg_Fb2DR_7xtyox2vsTg,3670
 qai_hub_models/models/detr_resnet50_dc5/requirements.txt,sha256=7JPG1_GVGtM8EzOggEHT_-_rO9H8b9NsMK5aLI1nImM,34
 qai_hub_models/models/detr_resnet50_dc5/test.py,sha256=xt60UK2gLEMyw460kHLE14y2zgzHhhaM3peD7PfIb7Y,1344
 qai_hub_models/models/efficientnet_b0/__init__.py,sha256=7iMYCbJmA6I13XjCyUEWsizqKWjp0PMumYfobTRAhww,477
-qai_hub_models/models/efficientnet_b0/conftest.py,sha256=Le4ZI0-1wlpx5DkBPRM6sOxtbCiAMkjeYZ7jp2Rf-OM,802
+qai_hub_models/models/efficientnet_b0/conftest.py,sha256=LuC5mnIPILSq12OphTHYrPSmz95Be00kMBWYKhZNvL4,912
 qai_hub_models/models/efficientnet_b0/demo.py,sha256=aZVZDgd4XTbaL3_3NKFMSHP15gKWYwe2qX6DEwJRPuM,549
 qai_hub_models/models/efficientnet_b0/export.py,sha256=VOsj4Jwn6jCYO2YamVKQ82c77IMFQ3hTtPwgVqr2dEY,7903
 qai_hub_models/models/efficientnet_b0/info.yaml,sha256=qHfAm4KiPtXcdb3GmVePXiZZmsOE07Gbzl8c7Hg268c,1361
 qai_hub_models/models/efficientnet_b0/model.py,sha256=3miNRC3gRr5pfkWrwYdLFmx7Wjw0eI1CIKEOHLlB7jQ,714
-qai_hub_models/models/efficientnet_b0/perf.yaml,sha256=o6uSWx1GV03STwYLRM6dNj1DIsOOdLGatIkZKivP-Yo,2756
+qai_hub_models/models/efficientnet_b0/perf.yaml,sha256=xM1-XIKcBxXPWN6zlx6MDkzmKpYOJAzpTuTqjppmGZE,4428
 qai_hub_models/models/efficientnet_b0/test.py,sha256=RyrRTanG4fCwWk8d_EaFn9j5GVqLdDcubsEzKBM16mI,867
 qai_hub_models/models/esrgan/__init__.py,sha256=BYOPJKlrdJCd_dkZlkI9_rvh_Ip3TtrD70sT4hk6mWM,463
-qai_hub_models/models/esrgan/conftest.py,sha256=3QzbcoCBUzujSCNlw_lO8KdbslI8iFVr25PRBjcM77k,870
+qai_hub_models/models/esrgan/conftest.py,sha256=I4EmCrb9_b9FAiH4tIM6V0jPq5dDgXcXT-xn-0uSaAA,980
 qai_hub_models/models/esrgan/demo.py,sha256=QL3qaDz7O56O938cS7fMOPl_bb1gvcfJhP8onfAcMf4,939
 qai_hub_models/models/esrgan/export.py,sha256=vjeek7I4d4RvbA0YcTW7FWmv_8A7o5FkAInYRoxdkqM,8002
 qai_hub_models/models/esrgan/info.yaml,sha256=uO-MC4Ex0o9haQh7iX2SBYKmtjEHkeko_xZmkGRAlPs,1117
 qai_hub_models/models/esrgan/model.py,sha256=zitbXArjzUEyP9_u5Z4ePgLFGYxG4DFKiWBRPdGy9Ow,3473
-qai_hub_models/models/esrgan/perf.yaml,sha256=3_FDeQlttQJXLalHojI6luKKMdvpsESfY_fmqaB2120,2772
+qai_hub_models/models/esrgan/perf.yaml,sha256=_ZWbpDlr5JtouZu9zR44a-FSpbsEEpoHG2pOKHfrBKc,4460
 qai_hub_models/models/esrgan/test.py,sha256=b4pQrPN0z66v__gKsgAcXqIfEViysY9yhstuOaiNXi0,1831
 qai_hub_models/models/facebook_denoiser/__init__.py,sha256=2p_IKIllP1Me0a2Ga3OfzoAWS-sarWBUoedNgVhknoY,418
 qai_hub_models/models/facebook_denoiser/app.py,sha256=FNIaoA5NYrjXxrOoL3kiDS7TI_MpuxKPldE3ru_tA_w,3207
-qai_hub_models/models/facebook_denoiser/conftest.py,sha256=Pd2tGIihU72bq0JCljUMBnGRgdNjP_i2Pos3wAGcxxA,892
+qai_hub_models/models/facebook_denoiser/conftest.py,sha256=p9w_wBB9s_W1GWPSOjsknAXZMvcnudvfhPawH2rAQKE,1002
 qai_hub_models/models/facebook_denoiser/demo.py,sha256=pwZ7sKCYgl2YcRWBD6L4WChECUCwu_OrUmMWcfoqQOc,3172
 qai_hub_models/models/facebook_denoiser/export.py,sha256=z2MgZsaxc7s-1Di66Bt8lqZcn1a3uehI3gQynrE0W0c,7670
 qai_hub_models/models/facebook_denoiser/info.yaml,sha256=uBJBGRUnVPzhU6dK-LACvms0FCVSzJh2qYiLtv3JoGo,1070
 qai_hub_models/models/facebook_denoiser/model.py,sha256=_mrUIQsgrhGH_5HH103yFgEfpe1GEgU_FZe1qfbVTQo,2414
-qai_hub_models/models/facebook_denoiser/perf.yaml,sha256=RsLoV8fwasIjupZTHpMKSqbbp-LDiaYplGiSUABqDSU,2724
+qai_hub_models/models/facebook_denoiser/perf.yaml,sha256=JOfzNRAKBZU-9883_BqYC5ULqA5CztbB4ck9Ou_EBD0,3685
 qai_hub_models/models/facebook_denoiser/requirements.txt,sha256=o34BIQCgYdBbS6Yp3eup9VorcrIfdNiUoGtrK3AoiPg,74
 qai_hub_models/models/facebook_denoiser/test.py,sha256=kmnG_zoQOVGd45TqH-pJcRTDrHq_Y0TYymSPg2r7PdY,2492
 qai_hub_models/models/fastsam_s/__init__.py,sha256=t-LgQ3KECa94clPW6e9afDjg0_iE3_AT5wwGh9u0ViE,440
-qai_hub_models/models/fastsam_s/conftest.py,sha256=q8KoGAe7ot0_LiqUvHpbGFrhqoAHTi2wtR0zeyjtOd0,790
+qai_hub_models/models/fastsam_s/conftest.py,sha256=QfIFtpPs19JINAPuwmHizLtL7sOtHYdCCa58ZpcLlT4,900
 qai_hub_models/models/fastsam_s/demo.py,sha256=Ja3h5Trq_ZHYvEpQLp6AVki87esrcrrymRv0RpNp35g,762
 qai_hub_models/models/fastsam_s/export.py,sha256=iGdi4Hd_-rAGxyRg35qXCrlt5fQJsfyUHWwSlCslszI,8264
 qai_hub_models/models/fastsam_s/info.yaml,sha256=BGCkK4ixZsZXeXRq_6IUUBn-cc3mV-1Zcq73p3TjTlQ,1301
 qai_hub_models/models/fastsam_s/model.py,sha256=-ynkCngyRJIeb85n8GIsAmAWmAt_fiRcZ85pz1c0nPw,683
-qai_hub_models/models/fastsam_s/perf.yaml,sha256=FephWJLI4JSxQr4Q8LbwsvdjyV6mVNslpYhNi9z6J1k,2706
+qai_hub_models/models/fastsam_s/perf.yaml,sha256=n0WrFKadm4B-Lvfi2x9074gFXDzCEnnt8MCXcYunVOc,3660
 qai_hub_models/models/fastsam_s/requirements.txt,sha256=bzLR7n9PMXzABwKJJUEb6gOX23t_wZuYJkbyRPJjjQI,64
 qai_hub_models/models/fastsam_s/test.py,sha256=KJD_DBh8sto_x8A9VmEN-z2AyLBhTZyykZzGTv1KsMA,1332
 qai_hub_models/models/fastsam_x/__init__.py,sha256=1jZ4uim6OseYmBo5ppIM32GcilG-cEFb0CDmJAFvSPU,440
-qai_hub_models/models/fastsam_x/conftest.py,sha256=K9_9093ZgnzjefZIq3__TMHCmZrFo5MEL-Lv2bnCfeU,790
+qai_hub_models/models/fastsam_x/conftest.py,sha256=1GKSwPv29EJhCNXvUqDgVMSaRp4YDi9fvU70S6YXlC4,900
 qai_hub_models/models/fastsam_x/demo.py,sha256=7jJK0ZIIhiMh_XS_HOUmpek_XcKaeZ0TxQudsXzUBRc,762
 qai_hub_models/models/fastsam_x/export.py,sha256=pTsoCwNEN92apRgozJMXx_8HQLE__ajM5G7jcxbUqxc,8264
 qai_hub_models/models/fastsam_x/info.yaml,sha256=Z3zYIUu7OAKfoOkoFd9j5jH-ZJII930iPflu_wFp12I,1300
 qai_hub_models/models/fastsam_x/model.py,sha256=15O2L72SANNVLxoWjNdugNV4hgUb0oZzdoxnNddQYM4,683
-qai_hub_models/models/fastsam_x/perf.yaml,sha256=95oY7992jWS028jkbPMu4m34f81xBWUDGEiEhJ9X-lw,2707
+qai_hub_models/models/fastsam_x/perf.yaml,sha256=7nu_SMQRgIpGnWQ5n8sHKLDxbsVVtZOx7AZfFnrXivg,3668
 qai_hub_models/models/fastsam_x/requirements.txt,sha256=bzLR7n9PMXzABwKJJUEb6gOX23t_wZuYJkbyRPJjjQI,64
 qai_hub_models/models/fastsam_x/test.py,sha256=QUaUSFuPrqESZSMF8R6c2zH2rGrvD7FdDXrcRjue8wk,1332
 qai_hub_models/models/fcn_resnet50/__init__.py,sha256=PIkLfZIDzf16OqQ6kptH6YVx_2MdAwWt3zLJJLtlbDc,410
 qai_hub_models/models/fcn_resnet50/app.py,sha256=U_aLzk8it6_-tC66l4Dz17-LgBJAfyIz9hPjKZGhO3M,2683
-qai_hub_models/models/fcn_resnet50/conftest.py,sha256=TUolB42DGCyLWqdBAC_qN7H8dw_GoRG9mzYIY_0-68A,882
+qai_hub_models/models/fcn_resnet50/conftest.py,sha256=3dkT3E68bjtnzu_gZ1ILdnAsvbVM4LKqZxYbFBJ9sZs,992
 qai_hub_models/models/fcn_resnet50/demo.py,sha256=aHhtDDnA4ESHE4JkkOs_7EJtsTKYAZxW8Btz9Wxhcbg,2315
 qai_hub_models/models/fcn_resnet50/export.py,sha256=ViyDzn-IyTEOXUE-yRTZ68RnTEysHlQtpyi1v29Cu3s,8169
 qai_hub_models/models/fcn_resnet50/info.yaml,sha256=ny0XW7G2TGqi6uH9OAY4Gh8qzgd-QXNPqe8hSnayDLk,1241
 qai_hub_models/models/fcn_resnet50/model.py,sha256=LFsVZFks3DkPqsp62A5d6-ABQdVrIKlvBD6Sx2wrHpg,1989
-qai_hub_models/models/fcn_resnet50/perf.yaml,sha256=YjdEWzPs55bm2QOnijOP032bg0-NpSfRrjDTgqSJoB0,2761
+qai_hub_models/models/fcn_resnet50/perf.yaml,sha256=d2NIPrdgB13uQ5CSDsFfI6ZztZUazgHzLoyVgjfrNW4,4442
 qai_hub_models/models/fcn_resnet50/test.py,sha256=mIM8NwhGPlSf9KBX1QIWek3rTLoYC_bBvqMbZ0mrK70,1637
 qai_hub_models/models/ffnet_122ns_lowres/__init__.py,sha256=UoCIQtMaEcM3Dg5PhPZzDxbNdV4d3k_Rw0im4Jak6pY,487
-qai_hub_models/models/ffnet_122ns_lowres/conftest.py,sha256=d0NN6tjqEfuemK5UdVyWorW9u7eZejDuTa8mxnf-9rQ,894
+qai_hub_models/models/ffnet_122ns_lowres/conftest.py,sha256=tIRDyHxzyBoeWqcwso1mmJ0bIfpSpDFsQgmt5z74JaM,1004
 qai_hub_models/models/ffnet_122ns_lowres/demo.py,sha256=t2c7R8wXMYU_1XHw0y7W08uSWZFlG0ExvHW6RCDdaXg,607
 qai_hub_models/models/ffnet_122ns_lowres/export.py,sha256=WrmfZzJEnwZF2aS4TTJKrioTcw0qjX5ZUH8cX5m-3hk,8050
 qai_hub_models/models/ffnet_122ns_lowres/info.yaml,sha256=V2mZJGqPO-kJJwTVNFzLJ_xmB661g--bhcRMwsGULE8,1322
 qai_hub_models/models/ffnet_122ns_lowres/model.py,sha256=Jxz7d6RB3rbuya27MvlQgDrjkovo-gejpCBhpQda8wc,648
-qai_hub_models/models/ffnet_122ns_lowres/perf.yaml,sha256=g5pZhAwwd7VXPT3feEu2iKhdftAklZZ0jVqAyPzJJTA,2771
+qai_hub_models/models/ffnet_122ns_lowres/perf.yaml,sha256=HM3BCmbR58A-VUom1govFY8oSlWGJc-BuxNE9C7-kWw,4455
 qai_hub_models/models/ffnet_122ns_lowres/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_122ns_lowres/test.py,sha256=izaltx2uBp4Sa9cxpa27oo8koqI9wMs4KykgoOYxxBc,804
 qai_hub_models/models/ffnet_40s/__init__.py,sha256=cur1hXK3ukU_DL_ujlWpJykMMaxCXzpfT6yqAoZX4w4,479
-qai_hub_models/models/ffnet_40s/conftest.py,sha256=c2iejDkhMaxEESVXvVgLReqMFBuOXWJ740ERdft0ue8,876
+qai_hub_models/models/ffnet_40s/conftest.py,sha256=lWSTh2N1EVBkAJSKfJIFfj0mYIT5Ul28GAHDyYqWqzw,986
 qai_hub_models/models/ffnet_40s/demo.py,sha256=e5examY5jBnCcFrA73SOXV4sdY0gkOF_YheXwgLQ7GA,582
 qai_hub_models/models/ffnet_40s/export.py,sha256=1iBaGDRuKjfRy7UaPaqENsDrHYp4ca6Ng69lIRKlVa8,8014
 qai_hub_models/models/ffnet_40s/info.yaml,sha256=DbHnioJHDD2KHUyYryhPGiss8VnBKHvKUaeM1C6QgzQ,1298
 qai_hub_models/models/ffnet_40s/model.py,sha256=vMqOf4XTdSWVlmM_72tBvjNtks874DkBM-aizeN5QEM,580
-qai_hub_models/models/ffnet_40s/perf.yaml,sha256=g2z8wJI2jgaql4B_onuEle6FHYmmpcnPwFXsQSrDjrg,2764
+qai_hub_models/models/ffnet_40s/perf.yaml,sha256=b45D_QRMIoavioJCgtSIdHXZV_ExbHpOMVZ1DZod-0k,4437
 qai_hub_models/models/ffnet_40s/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_40s/test.py,sha256=Z-7FI6ko8Dw9B54eKzGZKYjPqJRT9iUumz3VaMMyzoE,746
 qai_hub_models/models/ffnet_40s_quantized/__init__.py,sha256=D9fLMk2pWGuTgkIU7jGbxtkoiWLnA7pajSv441yVE7w,490
-qai_hub_models/models/ffnet_40s_quantized/conftest.py,sha256=s59UyGhgZiGeED7ze6TNuvvLeTmf6lZQZPUF_PMMk7c,896
+qai_hub_models/models/ffnet_40s_quantized/conftest.py,sha256=EVLBxZKszqVxHitcaZ0aGdA5rFfCuldQhbUdk6lEuQE,1006
 qai_hub_models/models/ffnet_40s_quantized/demo.py,sha256=a2SWiqFS6qv59AOAJgHvbBpRMMiFXGVI1v26YqxKZtU,627
 qai_hub_models/models/ffnet_40s_quantized/export.py,sha256=AlwF-TGMFAw4R0MeMDtQibHBs4X3boypf8jjA8zkIxk,8467
 qai_hub_models/models/ffnet_40s_quantized/info.yaml,sha256=ZRi81cKXx7ih9hPKERPXwN6hIrpI4k0Q3ci8KfXsRJQ,1347
 qai_hub_models/models/ffnet_40s_quantized/model.py,sha256=_QVWRQb90OhW_0UCzzjy4-Hgc4V9DKRPrkvzhynHL9M,1169
-qai_hub_models/models/ffnet_40s_quantized/perf.yaml,sha256=nKZPKrRwoMKZdGV0o--rhnAKNFLmAo0e3gve4-I3eWE,2710
+qai_hub_models/models/ffnet_40s_quantized/perf.yaml,sha256=7YMGTwnsglGH0wIb8nZRxEzRj9MU_j9EEwfwLNiAODg,3661
 qai_hub_models/models/ffnet_40s_quantized/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_40s_quantized/test.py,sha256=11tNLKpWi4Wz1D99W0NAW531ENyWDNYpfxi6sMfy-UI,840
 qai_hub_models/models/ffnet_54s/__init__.py,sha256=Zhyq437g7aiixQVmV1yF2iZSE_0L_2Hb53mZab_fH78,479
-qai_hub_models/models/ffnet_54s/conftest.py,sha256=vYiMvfplHIC9a50_go0KbKNrh3F3BsOlBiwSEudA-b8,876
+qai_hub_models/models/ffnet_54s/conftest.py,sha256=h2ZefRpesghCUl0sgvcR8mJZpFr1sah79pGhIiY-Jq8,986
 qai_hub_models/models/ffnet_54s/demo.py,sha256=6oplfV5nQdodhEYRApOupdZMZ6Jxk-yxUwJS-j1zYyo,582
 qai_hub_models/models/ffnet_54s/export.py,sha256=MMBp8EiSDSthJU9TBnTigX9-PBqlKAoyJ3y-0kHN4x0,8014
 qai_hub_models/models/ffnet_54s/info.yaml,sha256=ipbP8LhRKP6hky2-CdAHgusN0zu4RcJLNkSj8UziC7M,1275
 qai_hub_models/models/ffnet_54s/model.py,sha256=uOu3W3LoWHUB4cUcHQDIRcn7d2INjhVn7nju2WxG7sc,580
-qai_hub_models/models/ffnet_54s/perf.yaml,sha256=frlF8kzN8IgsgaJsylrMbOn9KKLsr7O7n4AIgcdLR_A,2772
+qai_hub_models/models/ffnet_54s/perf.yaml,sha256=IjSx2SoBjkFWNlTDZeaj_q1qkN-CLfs05qKGuFAQQpA,4454
 qai_hub_models/models/ffnet_54s/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_54s/test.py,sha256=wxVmLWpT7VdTph6c4ktD7yYNyCeB-ms2aYQyZnWNXII,746
 qai_hub_models/models/ffnet_54s_quantized/__init__.py,sha256=exZ2v9rO0y7x3f0-V2qTvVLoeOjbmqdSMpHDMI9-cfE,490
-qai_hub_models/models/ffnet_54s_quantized/conftest.py,sha256=NAKtYA6XR99RBySbXIVwO3GhUof0Ao0lwhoXD7L6ddw,896
+qai_hub_models/models/ffnet_54s_quantized/conftest.py,sha256=S3PaKk_SCZzvbKNsn7XJU4MBvNosfxVtyKEtTGEEpEY,1006
 qai_hub_models/models/ffnet_54s_quantized/demo.py,sha256=QGw6h_1O-Ecp_yQJgAWqOgaGHPRQ2SvIrSrNf-_RdSY,627
 qai_hub_models/models/ffnet_54s_quantized/export.py,sha256=p8XeqNQl751nPnFo0f3Sr76yz4nzLXVIeZ2PdQwlrMw,8467
 qai_hub_models/models/ffnet_54s_quantized/info.yaml,sha256=whLq0baglC4ajzuhqqU7qvBh7cJBiK8yn61hUBalMOg,1347
 qai_hub_models/models/ffnet_54s_quantized/model.py,sha256=itN2MVSiS5LEUk9CcQfKFNM5JeCNrGQRwjeukp_7k4U,1156
-qai_hub_models/models/ffnet_54s_quantized/perf.yaml,sha256=qsqlVn4vmmtOLWQotukFEqgUrl8VbdcasWI0xO1bwz0,2714
+qai_hub_models/models/ffnet_54s_quantized/perf.yaml,sha256=VDHDfdQVuhEf5dqXGbHMbZd05qX-NC1FUGsgOhLR_mc,3668
 qai_hub_models/models/ffnet_54s_quantized/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_54s_quantized/test.py,sha256=QLlA7Q-IcJJZFYgXrFRyw_RyhULYRZkCcyXEpSeG1_M,840
 qai_hub_models/models/ffnet_78s/__init__.py,sha256=EZpm0M4BbQeAEyxW-qlt-qCFp0idi3Kbyo3qkhmtoIc,479
-qai_hub_models/models/ffnet_78s/conftest.py,sha256=N2PE09r7n-g3UnioClwy_if8WTcGDOh75pzudvdUYk8,876
+qai_hub_models/models/ffnet_78s/conftest.py,sha256=YIp8y8gW0viYVUOAD3Hn0ZBGBAI7ANF5VQTKIjgdRb8,986
 qai_hub_models/models/ffnet_78s/demo.py,sha256=4b0QiRJKM-uCuJbmhV5MlO9k8k9Y8nYHs3khMb8-IGs,582
 qai_hub_models/models/ffnet_78s/export.py,sha256=rCr-Ys2h1WKF0EZ0XBjKFGp2sD7Yh2XzG2oiNf9FOVk,8014
 qai_hub_models/models/ffnet_78s/info.yaml,sha256=eTVW7aCWkN36QgKXhmSHmuKgJE907R_6ZaFBHLLzY_w,1279
 qai_hub_models/models/ffnet_78s/model.py,sha256=zxXU_ZSi81vLKD92yok1BS3vgLgLkS8p2sfGJKZT0Os,580
-qai_hub_models/models/ffnet_78s/perf.yaml,sha256=uud5Vk2LVn66tdrili4OMw9DRVOj0Bf4ylecLgfSyB4,2772
+qai_hub_models/models/ffnet_78s/perf.yaml,sha256=DesrAjR9nzRAV279u17IittGCfmUMLAq696hGbpKMjI,4450
 qai_hub_models/models/ffnet_78s/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_78s/test.py,sha256=rgdUjMRz67XdsnmHkyNH0ba3uvbXYyVfe5PfVnbekEs,746
 qai_hub_models/models/ffnet_78s_lowres/__init__.py,sha256=dGFCFlJOiHyZHYM-RC3aU-dT6dU1kGGAXxtoFtI1GPY,485
-qai_hub_models/models/ffnet_78s_lowres/conftest.py,sha256=LPhhGBo5gI8i6cwAFgwiw4ZAKB8KGBCzNoS-OqSOxtc,890
+qai_hub_models/models/ffnet_78s_lowres/conftest.py,sha256=ndvpiShsViE59iCFIxhwyxJuf7Q8b-L1xKz2Y67CYjM,1000
 qai_hub_models/models/ffnet_78s_lowres/demo.py,sha256=DW_YMV_N9oqo3jn2VLiN6QjKDy2n70Y6UzTxABv7XAM,601
 qai_hub_models/models/ffnet_78s_lowres/export.py,sha256=SXpYonaWEA8QsVvmum1bOlUKSjjJQJOtZcTbq9jqbV8,8042
 qai_hub_models/models/ffnet_78s_lowres/info.yaml,sha256=Mgrc9Bf84QxaywT0AIXKUx2zorycN8lQ2bCBl_VLN0g,1327
 qai_hub_models/models/ffnet_78s_lowres/model.py,sha256=ckAt5bunYsfv5pqH9jrwREUfZQJwaKtcgBCjOz-Vw3I,640
-qai_hub_models/models/ffnet_78s_lowres/perf.yaml,sha256=zBdBL48veCtBCAewLG0Tl_Avfg3qX2WRdS-ge8oavhY,2767
+qai_hub_models/models/ffnet_78s_lowres/perf.yaml,sha256=Ae4vtbFcRrNe-dTudIpjyQdwZ16AJPXJ6uc2kfeZZNQ,4446
 qai_hub_models/models/ffnet_78s_lowres/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_78s_lowres/test.py,sha256=XuLMLq71pxQcI6SDVEqtwyl86MaLtxa9mtlLDfBgSSk,794
 qai_hub_models/models/ffnet_78s_quantized/__init__.py,sha256=byB0kzkpkVxI7x6LjOGtge9X58UkVzOkp_VjfUdJrVw,490
-qai_hub_models/models/ffnet_78s_quantized/conftest.py,sha256=O63QPLP5mukarSVEwK1E8XEnaShCZ8oEBbtf22TMEtU,896
+qai_hub_models/models/ffnet_78s_quantized/conftest.py,sha256=NqWjPkw149TZigi4Ac5OkEHw5l7U_Q2yrQP26V31tTQ,1006
 qai_hub_models/models/ffnet_78s_quantized/demo.py,sha256=3mI25tVr9FGDR2y5_2PuYvKJ5vHCzE7Ogweps8oziAs,627
 qai_hub_models/models/ffnet_78s_quantized/export.py,sha256=NmxGcUmhUsgEX_zlNsHpXLoQln0FMNWKewd_VMt0jk8,8467
 qai_hub_models/models/ffnet_78s_quantized/info.yaml,sha256=WdgiQxWS3hXRs4A3xeP-Mis44omsqUNaQPhIHFYJ2r0,1347
 qai_hub_models/models/ffnet_78s_quantized/model.py,sha256=gilgE2OHPv4mCaKEr4AAcFyFzAdUGq92_RIvhbcqNTA,1156
-qai_hub_models/models/ffnet_78s_quantized/perf.yaml,sha256=Hi26J7cnCeCwhDIU9ygI7OIuKanzQ2y6fRht5LrOMec,2713
+qai_hub_models/models/ffnet_78s_quantized/perf.yaml,sha256=xjkWYipRMwl8WYylYq4_qiKEjx2TRaO4wDAdc4_aw1o,3666
 qai_hub_models/models/ffnet_78s_quantized/requirements.txt,sha256=cVS0KTDz2ekpU0ckkwEtt7cSABHx0HhXfXNS6RFHX5A,21
 qai_hub_models/models/ffnet_78s_quantized/test.py,sha256=f63BCpe22Yh5AtLy3HmZ6M37zu3G7kr18SmevBwh-VI,840
 qai_hub_models/models/googlenet/__init__.py,sha256=yMXfFedJcmupf20Fk8xXuArMIPqOdIvxB2S_AJ5j1Pk,472
-qai_hub_models/models/googlenet/conftest.py,sha256=nWQxu_g_VJBfcFCE9g_PDZQF5XBs4O3LAeEWaZHuiyM,790
+qai_hub_models/models/googlenet/conftest.py,sha256=UplfK65r7WZ8QtJVmulnfe65DHdtm4rqUOvQrm6xYOI,900
 qai_hub_models/models/googlenet/demo.py,sha256=Owxr4VAkRm-resJoBLK_1ZcAEnI2IwjHZ6Hgqs7zYXU,533
 qai_hub_models/models/googlenet/export.py,sha256=29CZslvFCuCXsnN17D1EKFzhx7m7-YLs0ngbmzxHNrg,7879
 qai_hub_models/models/googlenet/info.yaml,sha256=6Pb1-Auz6VGYb2FEYhCoKR6a7sJxkm-6eJ9KPoGz1_c,1295
 qai_hub_models/models/googlenet/model.py,sha256=7tVmhQtiQZeWGgeYTPVvwKr4ustB0tHoYafJyXZvVKQ,743
-qai_hub_models/models/googlenet/perf.yaml,sha256=L0sREXe1qw5fgfw1pZuGB7PlhAp8xyCUP8T_5ug6Urc,2748
+qai_hub_models/models/googlenet/perf.yaml,sha256=XvTbWus0mzD6oJ6N_jChuLhBXnOLZf5CJHo7eZYex8I,4409
 qai_hub_models/models/googlenet/test.py,sha256=gJcMSpz8KmfhCwa9E0d6iTnlOB40dHwsr8Qp9B4QdAQ,840
 qai_hub_models/models/googlenet_quantized/__init__.py,sha256=96ENoBCt6lWCfOBrvFQJIE9xh-sA3IDtfUXmdIWVhqg,573
-qai_hub_models/models/googlenet_quantized/conftest.py,sha256=Z_JTshE8NJGBJvtRIt4qQuQHigIRkrMrpriRwaYNNmo,810
+qai_hub_models/models/googlenet_quantized/conftest.py,sha256=_RiShp_5sPn93L1eJbupV6yu71OnAibnKfND2LD8Qos,920
 qai_hub_models/models/googlenet_quantized/demo.py,sha256=FT-qPTxt9WnT7-wPR0jitsw0LnhvkbHlRCfJE_jiB-Y,578
 qai_hub_models/models/googlenet_quantized/export.py,sha256=eF4ic913Mj9jzn3GdNGRhzDBNJ90r2OY7X9Hb1ANE4M,8359
 qai_hub_models/models/googlenet_quantized/info.yaml,sha256=VmjYexBXTnmukRqI8u0IEJYGZxMbKxze2l-Q3ROPyC0,1325
-qai_hub_models/models/googlenet_quantized/model.py,sha256=unZShibpfs5W2U714o6vbyn6IOiSB3PpqwnKuYm9s8U,4079
-qai_hub_models/models/googlenet_quantized/perf.yaml,sha256=_dUK8oHdn1xeOSGH3XmptRhSigLoSO-RUI6zpE5C-eA,2753
+qai_hub_models/models/googlenet_quantized/model.py,sha256=vGyWrxc-hmzDhR2HSVudaBPosPrPdodjZ6SqUUa7qIk,4298
+qai_hub_models/models/googlenet_quantized/perf.yaml,sha256=KPgmV0yHb3oCahOUXs77v5gtBpHLu_1nJ-0najh8g5k,4423
 qai_hub_models/models/googlenet_quantized/test.py,sha256=ox8Mz4egNJmOQzfD-gNNXu9k5zHs7ZHKn1rV3xlNNd0,885
 qai_hub_models/models/hrnet_pose/__init__.py,sha256=_r8rdSD0i5yJRlSct5_EQpCV-hEExVZYmI_mHV5VkWQ,430
-qai_hub_models/models/hrnet_pose/app.py,sha256=nLCTOgYN_t7fQZyreZq2B_C1EwiAPRDXVj6fjZVZ3-I,5644
-qai_hub_models/models/hrnet_pose/conftest.py,sha256=WQ3j8PYRttJ_1ke9rYx6TmV1f6II8HEauWjr-ze3Tnw,878
+qai_hub_models/models/hrnet_pose/app.py,sha256=kioFIQB9kvspm1dtEbaOBn9o0R1XBu7bORye6rhQP8c,8134
+qai_hub_models/models/hrnet_pose/conftest.py,sha256=okrEhLkU2Hnfm3idY3JDH2Ly2oSxHDppfHofxH3E4r4,988
 qai_hub_models/models/hrnet_pose/demo.py,sha256=-XbTGmCKHJXe-qoj3Abrm81VZr1FGiJQ-Za6FBVFBww,1739
 qai_hub_models/models/hrnet_pose/export.py,sha256=3e6QFsKCsF5Thvcywll162yPLnIWafsi0421bg5yGSI,8160
 qai_hub_models/models/hrnet_pose/info.yaml,sha256=QdjXu2cv2b6EpWTS92p4iSu8-D2YmcRv59Zdxae7-yA,1195
 qai_hub_models/models/hrnet_pose/model.py,sha256=b5b4NUBfnMaqre3KXue5reT01t4RAF9VHv8Jvh6ixBA,2801
-qai_hub_models/models/hrnet_pose/perf.yaml,sha256=p3FsFulgslYjbSf6JfkK3jgLIjtVSoKd2BoKObNlza0,2755
+qai_hub_models/models/hrnet_pose/perf.yaml,sha256=jqJVyiZ_zZjyfPej3PW9SglplPQxH10nqYvrlGDY7cg,4426
 qai_hub_models/models/hrnet_pose/requirements.txt,sha256=2U8K4vxuQ1x6tB35TVOiLW4UA0gN77o0ZvKJ5baKAgo,51
 qai_hub_models/models/hrnet_pose/test.py,sha256=LHAh3hxZfE1aeQt5Cwvv4SF3w6X3Dxz4tly_UxZpr84,1420
 qai_hub_models/models/huggingface_wavlm_base_plus/__init__.py,sha256=muVZdjzxn0rzXTLE50i1-birAkTSWucNt1VWyCoUwJ8,434
 qai_hub_models/models/huggingface_wavlm_base_plus/app.py,sha256=QlmoRNNkpzNGI-EzErNXsR8S-ygiC09QdAiS7ggnQs8,2133
-qai_hub_models/models/huggingface_wavlm_base_plus/conftest.py,sha256=JS4OCY4Vd8bhvxG0n7t_zCB405P5EAN6oEo3WmRkb84,912
+qai_hub_models/models/huggingface_wavlm_base_plus/conftest.py,sha256=ocbQcBdTUBTANkvZvPi8ENwUJLvjr5mrpd5-EjB77ys,1022
 qai_hub_models/models/huggingface_wavlm_base_plus/demo.py,sha256=NtjLWFe0oiJgcm10f5ws6a4SIx-7RNbRLL-Q3pB3csY,1517
 qai_hub_models/models/huggingface_wavlm_base_plus/export.py,sha256=W9Mc2PVm2RlSySza9709N54UQ91aKQgybR6UJWmQx8Q,7567
 qai_hub_models/models/huggingface_wavlm_base_plus/info.yaml,sha256=fJzxA3WwfNBQnWZq65pR90IGEHzlm5hxoJHvzEhVN1E,1248
 qai_hub_models/models/huggingface_wavlm_base_plus/model.py,sha256=BjWZCqVFXNJaINoT1San9dY2aZOAFbZjJ_WKQLV-CGg,7587
-qai_hub_models/models/huggingface_wavlm_base_plus/perf.yaml,sha256=viyUwY7Q2FjQQo9Mco1EImWq0T_GEEq6PptZN87VTgg,2735
+qai_hub_models/models/huggingface_wavlm_base_plus/perf.yaml,sha256=NFtS1iNP2pn-Jv1YZtN2ENKIPupl0VUB8LEZzyoO-6k,3698
 qai_hub_models/models/huggingface_wavlm_base_plus/requirements.txt,sha256=L9-RRcRpUwd13vGIthoV8IQaEALYng-Hd7RhR1hdpSE,72
 qai_hub_models/models/huggingface_wavlm_base_plus/test.py,sha256=irHDKl6YChuYRBq8zcNwe5p7CLd9ghY7yicSfHEtBZw,2560
 qai_hub_models/models/inception_v3/__init__.py,sha256=7VMcF8m79rmZ-UZk265C_tIMIHJev0qZFBz5cNzSd98,477
-qai_hub_models/models/inception_v3/conftest.py,sha256=8GqhXxOL1_zP9gPtyLGLVwMD4k-UKYnZIaSB0s1eJ20,796
+qai_hub_models/models/inception_v3/conftest.py,sha256=ZGh1bPXQZGdeJVZ8WT8jd1GD5BSWkUoc6cMtxrNLUbQ,906
 qai_hub_models/models/inception_v3/demo.py,sha256=f9m6H1zPOHEGK1fi4PLDUYPb8TYoa8a4MqbjRWZBX1o,546
 qai_hub_models/models/inception_v3/export.py,sha256=ISZkP0_TbAFsH7ZSQUmYgT8KVnnuy9-I-KB13sKxrq0,7891
 qai_hub_models/models/inception_v3/info.yaml,sha256=XoUgkOsDw_vFkVOOMARDWbBGFdcsRt2EcGqIqJZC_BU,1359
 qai_hub_models/models/inception_v3/model.py,sha256=PKOe7hJigPXwymvjHC8Q_mwVFj5LTp96cIPA6hoaDto,756
-qai_hub_models/models/inception_v3/perf.yaml,sha256=yOMAkic_cVwx1NwLq8r6QJK3sz7pEAIT9z5KkaW1-kk,2760
+qai_hub_models/models/inception_v3/perf.yaml,sha256=ECL2nbDbmwY9D3WRLc5RdRRnQfqP1jNGGhkW4OVLaB8,4432
 qai_hub_models/models/inception_v3/test.py,sha256=H4y4OTCinQAYkJvaceCOenfWzwjPqpWb2kk_hvSm2WM,861
 qai_hub_models/models/inception_v3_quantized/__init__.py,sha256=LYwSg6XsJc3GL5Bvm8AjHw5I2aCmG_kmpyQQRxxYlsM,584
-qai_hub_models/models/inception_v3_quantized/conftest.py,sha256=SpX7-f30GnW2LNcSLm9Ht8rxD5FYXO_j4uRoQZXZxCE,816
+qai_hub_models/models/inception_v3_quantized/conftest.py,sha256=EihlfDsg84Ir_sALoRHtMG_fr5DDc9SZ6a5z65RRhPA,926
 qai_hub_models/models/inception_v3_quantized/demo.py,sha256=HT8ebEriXX7NZpj9rdy6CKBWSdpM10pxniEvhwVFe10,591
 qai_hub_models/models/inception_v3_quantized/export.py,sha256=cD_bkS8q1V1BDMVCWVS5Vh3BLnYnT89aCW-CWxwzRKc,8392
 qai_hub_models/models/inception_v3_quantized/info.yaml,sha256=FsSC1SKNT3quSNQaELEGwfybCmlNi1L2xiRI2oV08CQ,1556
-qai_hub_models/models/inception_v3_quantized/model.py,sha256=-Ie1rVfoQw0-u1Q2JAJD4YIn0rC_qN_Z-5_XOBVemr8,7543
-qai_hub_models/models/inception_v3_quantized/perf.yaml,sha256=WEgUVNtrxyAPQ8BlyLd593uHZmKTt7wrIQXRzQBjl_g,2712
+qai_hub_models/models/inception_v3_quantized/model.py,sha256=3eASb8PKybBcQ67prsdQYAddsmwdsYDIiJmWGKOuoT0,7762
+qai_hub_models/models/inception_v3_quantized/perf.yaml,sha256=xitxNrgeKqnUmEUGRtAQWnq8EPA6OmP_IP53Xv59JRs,3656
 qai_hub_models/models/inception_v3_quantized/test.py,sha256=Xf0YrWDwy01ulM-o4IuAOQotc6hOU0Dn2IaV7h8SrA4,901
 qai_hub_models/models/lama_dilated/__init__.py,sha256=XfDJqXXsCsai11UnjLNnECFN6WquE9I55knTyDl-R7E,455
-qai_hub_models/models/lama_dilated/conftest.py,sha256=kak27g05SfrZ80BRbjmraYuFRvWTY0j5f5NYWHEXtq8,882
+qai_hub_models/models/lama_dilated/conftest.py,sha256=bmSz9TVTOdlUdepfKx2xni7IWweTBQ07M2oGwg5So5g,992
 qai_hub_models/models/lama_dilated/demo.py,sha256=J8E3pR2GQTpmpqFfqPiQOfKUcywmDMPAzyUqIj2wMZY,911
 qai_hub_models/models/lama_dilated/export.py,sha256=JxVF14yOa09nmTuXQIhLPj7CvLpyVSKmiCU2bNby7NI,8179
 qai_hub_models/models/lama_dilated/info.yaml,sha256=whgpaBOBqJnbIc6ErqRS4PTlaeBIkoJBEtrfscPeC9U,1082
 qai_hub_models/models/lama_dilated/model.py,sha256=uJp3NNmPQuzBXZ_gcgk1pK4DDkG7JmO_R-KlpbfpLy0,4977
-qai_hub_models/models/lama_dilated/perf.yaml,sha256=l_hQdS5uwAj8pq5l-mJIKfUS2D6g2TzhWt44IGTE96o,2776
+qai_hub_models/models/lama_dilated/perf.yaml,sha256=UZPQeiNTuGGNYH705cbJe6vLN0C0DwAuFtvE8HvBi7w,4407
 qai_hub_models/models/lama_dilated/requirements.txt,sha256=897JpKdjy0fMli83RtBp6iSBaWYRHXNDK0oMaO5aMBo,171
 qai_hub_models/models/lama_dilated/test.py,sha256=g1YxEMQjYA65848I8YM0lxylfy4f0LGSJ38pJXrPOYM,2074
 qai_hub_models/models/litehrnet/__init__.py,sha256=lboiEAPcBxZN_ao_VVtBVJl-B9EvrrwXcxK02PiZbLY,404
 qai_hub_models/models/litehrnet/app.py,sha256=FEwh94V2uJrp6bofDJTP_p53fR85Ir-nCiacakJ90BI,3986
-qai_hub_models/models/litehrnet/conftest.py,sha256=8Jdb0v9ZiVff-cdb2fLdh1pl8IbO43mvtBH6own4zFo,790
+qai_hub_models/models/litehrnet/conftest.py,sha256=1YOPJdOwkP8ABG_u8tUuTh38BpKMFagNrY9-_t5qpGA,900
 qai_hub_models/models/litehrnet/demo.py,sha256=N3NDwdOwfdjFANzufoZq2mBE0yk4vTZZFQCl_fgk9Ds,2072
 qai_hub_models/models/litehrnet/export.py,sha256=hDups2agm9CsHmE51yhKzWTP8xzzPb_D_ogEW5MnkYM,7638
 qai_hub_models/models/litehrnet/info.yaml,sha256=xfMHffAMgyP3Z0UT9aBd5_C5yF4QYifTOvXd4-yGEDs,1112
 qai_hub_models/models/litehrnet/model.py,sha256=XELmt0HE-7-ZHQ7VOZAJNdAWBqR2Cg-zK_0ifR4UxGc,3788
-qai_hub_models/models/litehrnet/perf.yaml,sha256=DrgFbQRbFzHLPM0aGORhzrawZ0uRXF4iVgTOxQDHBT0,2711
+qai_hub_models/models/litehrnet/perf.yaml,sha256=c91sbiVaenoxuRQUYQjXQGqcGUdRPd4_zbxZGvsNCVQ,3620
 qai_hub_models/models/litehrnet/requirements.txt,sha256=CFGaEErf8SbXCYCCjg58TvJZIExg-yQiluC2q78zZoY,39
 qai_hub_models/models/litehrnet/test.py,sha256=FStsyYV21iqYE_DTsLCDyFBISas7lTXpvHrP86Xxc3M,1714
 qai_hub_models/models/llama_v2_7b_chat_quantized/info.yaml,sha256=rB9tYtIqi_cMMnWDorvulawmTGH7ATbTbWGQm8mvU_Q,1993
 qai_hub_models/models/llama_v2_7b_chat_quantized/perf.yaml,sha256=vS9DRf4_wVb93PCBo07qhZyOK37y-mcsER-FMIs4agU,2037
 qai_hub_models/models/mediapipe_face/__init__.py,sha256=24U-bkhm4gXXnVLowI7uytJShrDYSq5KbKWGxkK-xxM,412
 qai_hub_models/models/mediapipe_face/app.py,sha256=eug0kpc1nRgnnhO94P242qu8x-P15nmK9YDCRVi_4Ug,2099
-qai_hub_models/models/mediapipe_face/conftest.py,sha256=u_PEZIw4pyNtWcc3PeVwpad-ADvY2KESeet2MR-lUmk,886
+qai_hub_models/models/mediapipe_face/conftest.py,sha256=ry4doRmYtz__yWJtbGWXiuWExUELQfB4bsCJo33IB4I,996
 qai_hub_models/models/mediapipe_face/demo.py,sha256=k43EC7_YMXA4Wk41JwLaCtUc_1HSQFEyZ5UY317fWG8,2862
 qai_hub_models/models/mediapipe_face/export.py,sha256=TkGCrVAO3QQkHARQUXUXlIwLSWFoRyaVKT-NhXnACEM,9755
 qai_hub_models/models/mediapipe_face/info.yaml,sha256=QX3h5VsxsrDt0X6b0QpMelIhilsHJr6MatZewTwF2N4,1469
 qai_hub_models/models/mediapipe_face/model.py,sha256=WurHj_hb5bf8eOyryuBUAKzOC_mZkRgeM7fPpvERoss,7669
-qai_hub_models/models/mediapipe_face/perf.yaml,sha256=idJKz9rGEgdF4bQj6PPbjcQq_ZNklEKBaXQ7EY3XDhI,4857
+qai_hub_models/models/mediapipe_face/perf.yaml,sha256=dVMvzpzGPSJXNJqc58kS6OObimMC2nlHFqNbDSUBuEg,8096
 qai_hub_models/models/mediapipe_face/test.py,sha256=eAgJ0ZjbMNL1bRBF6Ma-mVQ0hBMTQvbUEWO6PH8Gr4I,1441
 qai_hub_models/models/mediapipe_hand/__init__.py,sha256=XWXPWZ12S5pgPBmT3fwgql_JF_6Y_dY699q8nntteVQ,412
 qai_hub_models/models/mediapipe_hand/app.py,sha256=4-UayauaiZDVytVsclGrBnqvGjVQNf0PPCUwYVk-KLQ,9819
-qai_hub_models/models/mediapipe_hand/conftest.py,sha256=Y9jfcCYPUKVWKasFl8Djmq6HiiFVbWEgc42Bu2inG1c,886
+qai_hub_models/models/mediapipe_hand/conftest.py,sha256=3U8iT-R0-Esc0SZ5VhldxgBJVijB8jvkz-UklSDBuaI,996
 qai_hub_models/models/mediapipe_hand/demo.py,sha256=u8ej7boLAgN-0O--m_lXFTVXb-4WW3qU4WKR5sijEJo,2832
 qai_hub_models/models/mediapipe_hand/export.py,sha256=p3n9sw0U5MSClD3IDR-kqxk-411Oht1H03AS_kmkSoY,9755
 qai_hub_models/models/mediapipe_hand/info.yaml,sha256=oSKmBY6rTjq_Jj8ToPWD7eIu6cxkVpB1RGuQ23rb7WU,1374
 qai_hub_models/models/mediapipe_hand/model.py,sha256=Mjz_ttgFHlNUsWIKbcIGEU3j6TMiOLHZvmnF0eY1df4,6017
-qai_hub_models/models/mediapipe_hand/perf.yaml,sha256=RupXMBE1UNs_LIUzNykXj44YWqWo3q9Hb22P37wzjjA,4858
+qai_hub_models/models/mediapipe_hand/perf.yaml,sha256=NzNrlHtSw3wCEtm07qYiKehx8CDItBRmAaise9VnLhE,8118
 qai_hub_models/models/mediapipe_hand/test.py,sha256=y-8RhCNppYbhLY_znVZKYVNwElIaJPdSkXEfBoyfGcM,1442
 qai_hub_models/models/mediapipe_pose/__init__.py,sha256=PE4aVOSnDXWvU9YVcKjBKUyO8926RMaeRXyD1chVXpw,412
 qai_hub_models/models/mediapipe_pose/app.py,sha256=djV3gcRkcvw2qYHBXqOjxY_2DxNahekk4BZ4Iax6uW4,4430
-qai_hub_models/models/mediapipe_pose/conftest.py,sha256=MmspZZI_CgLve8c3ltOgk6VmHI1b6l1bnxQZJyKrKdU,886
+qai_hub_models/models/mediapipe_pose/conftest.py,sha256=IFu2JzH2c_3PyIFy4vfzRxw76NdrBoVbHM0y2OP4lg8,996
 qai_hub_models/models/mediapipe_pose/demo.py,sha256=hvy2P0bX0dZ9cU0NrxSN8MjJqfat2M4GHlXjKcvixO4,2889
 qai_hub_models/models/mediapipe_pose/export.py,sha256=1SkXwMYtcqYpP-2Dw5KNyR30vzZPAhgApm-xae3GZJ4,9756
 qai_hub_models/models/mediapipe_pose/info.yaml,sha256=D2BVSmo_qZbGJIbONvBpj2JJcJFGtQA78VBMyInXkIA,1387
 qai_hub_models/models/mediapipe_pose/model.py,sha256=oPrNq_v0zKYU0OL84GwAKt9yUsdAaMsH4lDNsPB0k1Y,5801
-qai_hub_models/models/mediapipe_pose/perf.yaml,sha256=2hdFOFy0yhyU6F2XbcOYVXFe1l_o4jSTw4ziqgJ-ePI,4849
+qai_hub_models/models/mediapipe_pose/perf.yaml,sha256=jPwkV3799gcekIB_4msqZe9kQwZSUfSmjrhWVZXaUnE,8103
 qai_hub_models/models/mediapipe_pose/test.py,sha256=rsTIYChYPqBL1lI9cl4y_QR6jCmRhb4FgAjcwhLSGA4,1443
 qai_hub_models/models/mediapipe_selfie/__init__.py,sha256=TrPNyvFmctjh5bMloBxJAIFZTgojNj16AOnPBH6T8R4,362
 qai_hub_models/models/mediapipe_selfie/app.py,sha256=nWD63c4A6_M0gwC8P9n0dTlzsXL45V9Ep8I6hy3Ytd8,1411
-qai_hub_models/models/mediapipe_selfie/conftest.py,sha256=0Xztp_WqSok3jXJ39g1tHVGJzGE_EGKsi3iXakYJgHk,804
+qai_hub_models/models/mediapipe_selfie/conftest.py,sha256=yQNsBhlD07U83dK1jFhIrNRophSpKrLBg0chdGqaskQ,914
 qai_hub_models/models/mediapipe_selfie/demo.py,sha256=DULze0M58GkHmBIpIEoB6So-EsgYoqHBC3CQspRSR4Y,2674
 qai_hub_models/models/mediapipe_selfie/export.py,sha256=VqUG4XMoRgNCeSzHPLvZS3HBPK_K5OkUgXZuzG_NJbM,8198
 qai_hub_models/models/mediapipe_selfie/info.yaml,sha256=gEUPVKMaB0_qlPbEo1zM8uQ3dqAPK6YKQWHUNNOFdMo,1455
 qai_hub_models/models/mediapipe_selfie/model.py,sha256=COQHgx4VM0auz9h_etmnh1l3nQGU2BzmhP4qoqdIR_M,12352
-qai_hub_models/models/mediapipe_selfie/perf.yaml,sha256=KKd3MVb1fm6P4_g0xF0p4yUPI8S7aSKTX55fYwMWGbU,2775
+qai_hub_models/models/mediapipe_selfie/perf.yaml,sha256=-nH9E6BfcLhKE9ixp51vn2vzgE7VkKEQjxHldWVv2sI,4449
 qai_hub_models/models/mediapipe_selfie/requirements.txt,sha256=jjmBqpB3WUtMLBjVgPXNNN5yslq_EXOWdM9WMOES_a4,15
 qai_hub_models/models/mediapipe_selfie/test.py,sha256=5VWzDmnNS9jz90tZhqTPIIFaBUeHQ8GYGJRnmpvIavs,1396
 qai_hub_models/models/mediapipe_selfie/utils.py,sha256=-Fh52J_5r4Ty0YZiKtwSnP4yi93K3kpBc3-Y9jPCEUk,2492
 qai_hub_models/models/mnasnet05/__init__.py,sha256=d3xeB69OYbrgNbOBMVMVsEqwClH2MMhlJqhfSUIx8UY,472
-qai_hub_models/models/mnasnet05/conftest.py,sha256=w12ZIoLSzul1FaGhnOb_kNo3zgkcXS5ucDGsP0_IQXA,790
+qai_hub_models/models/mnasnet05/conftest.py,sha256=GsM0RlGz2wmj_Dc0_NR6-IQYJZHWHQOX7OIIGL-EMKE,900
 qai_hub_models/models/mnasnet05/demo.py,sha256=Fgz0-kQofu_pf78mBfAA0kcenEwRIYtoLuaofrbcfYA,533
 qai_hub_models/models/mnasnet05/export.py,sha256=e7ZUgRTMEUpSn_dtHm64jFB1fSxaeBwf_ra-KBavDS4,7879
 qai_hub_models/models/mnasnet05/info.yaml,sha256=A7bKsnRyqJJ6Jnx8SMQmn6EBaOMvHwXW08xOCLdT60o,1333
 qai_hub_models/models/mnasnet05/model.py,sha256=kkgjfQ0BbYuE_ls2Yh1zHIqncG678OyyvGTJGJemIjo,699
-qai_hub_models/models/mnasnet05/perf.yaml,sha256=9JQf1NXHf8s9BoRn0MyDI_M9trz9E2DYPQMZm7OSze8,2751
+qai_hub_models/models/mnasnet05/perf.yaml,sha256=z2ayms16d2uJUMuvwzJ2WvCJxdt764AVxgeBTLiINXE,4393
 qai_hub_models/models/mnasnet05/test.py,sha256=Vcc7zhvyUHQXDj3mcFZetvZmV0y36askMPKqPZRJ1i8,882
 qai_hub_models/models/mobilenet_v2/__init__.py,sha256=EF3fi_jeNIAmKhFrVJdKaZjazdFlsYXrW1TZT3fDaxY,474
-qai_hub_models/models/mobilenet_v2/conftest.py,sha256=3ONStgL-YiNc4ijSBHHtG_01yKOZqQ0XWMbyw9-MmpE,882
+qai_hub_models/models/mobilenet_v2/conftest.py,sha256=9Ig_No-mHV_fvhQrUbqXkmiSUqTkX0u3LizNSIyWA-M,992
 qai_hub_models/models/mobilenet_v2/demo.py,sha256=GR2uHGNaKtqt-bIO7rjjgR2V0fdziHAQWwDZs7FvZV4,540
 qai_hub_models/models/mobilenet_v2/export.py,sha256=ItKh11DZbK3kP7ylpeAUeN3tP7YSbQSx5D3oU3GCY88,7891
 qai_hub_models/models/mobilenet_v2/info.yaml,sha256=irPP5qDlcSbPbjkqJSO4k_iA159GEVB1u4pIruYAlyc,1380
-qai_hub_models/models/mobilenet_v2/model.py,sha256=qJy2c5OH18ugzKvzoBU6gcTsxTZVToRvtjm-7NUSrzU,2595
-qai_hub_models/models/mobilenet_v2/perf.yaml,sha256=CICp6vJGCfnKLNR1NYUkJRxV-td-TFt8kUJZKqEgoMk,2755
+qai_hub_models/models/mobilenet_v2/model.py,sha256=Tn-8Pf3YJEf0dXEOgoO2XYWquN8AtKSCYOtE1XJaHNk,2457
+qai_hub_models/models/mobilenet_v2/perf.yaml,sha256=jIjqvXPXPDdUg_YoEe7KiYqtaioqe5WjWPkSfLsDGlw,4419
 qai_hub_models/models/mobilenet_v2/test.py,sha256=Kjj6s-5jkKoqRaV7GkE9zf7js34k37uBSluNMFM3V-4,1091
 qai_hub_models/models/mobilenet_v2_quantized/__init__.py,sha256=MQOqYDYL-abmQsTEsRl7dBpFWu0Vd2mAW64gj02npN4,485
-qai_hub_models/models/mobilenet_v2_quantized/conftest.py,sha256=v1HPC1n5jDeGJBd_KOOwUQpbZsuqKISivzFY8M5-_Lw,902
+qai_hub_models/models/mobilenet_v2_quantized/conftest.py,sha256=RJjrm508tof2lfHqqFOspR8XOXQCgcvNwdV_52z2fG0,1012
 qai_hub_models/models/mobilenet_v2_quantized/demo.py,sha256=oxbLdz1mYSbr0GA4W6nRtFvnAp9Muma8F3eTP2VEKNo,585
 qai_hub_models/models/mobilenet_v2_quantized/export.py,sha256=PVcqu3hLtl38h7BwBdKbYOnfn3d_qwiI_PXs0L8aBx0,8372
 qai_hub_models/models/mobilenet_v2_quantized/info.yaml,sha256=B8RS3tsewoOtaOVFYWCp6aVqKJ2VIiCK3GJHfz8ghPo,1362
-qai_hub_models/models/mobilenet_v2_quantized/model.py,sha256=d7kyCZ1rh6r05U2tQbPZbsJUAPNYh45bLAybNABZqx0,3760
-qai_hub_models/models/mobilenet_v2_quantized/perf.yaml,sha256=2W4IBOoI1ni4rOyyKQyQ_XhBFBmA03AyX3HaVmW8KGQ,2759
+qai_hub_models/models/mobilenet_v2_quantized/model.py,sha256=gye1E7azV4sqwZTh4113gmdytvv-SHf1sPOgSmFny88,3429
+qai_hub_models/models/mobilenet_v2_quantized/perf.yaml,sha256=U6IdxP8CdDwDRlSxIdsqMj27gnPXnzjsZyjq18Q8CUo,4423
 qai_hub_models/models/mobilenet_v2_quantized/test.py,sha256=h54ZCxWmJA87qmOXeFpYZl8_3wLUQgDAJgowNlk_QhM,1002
 qai_hub_models/models/mobilenet_v3_large/__init__.py,sha256=7a-2Ng3rVspm46Uf4wyI8WfezV5IVaKm-oCfdkM0JVQ,479
-qai_hub_models/models/mobilenet_v3_large/conftest.py,sha256=vs8V8AXuTGrSY5oN8mmGq66-W33k91znQW7n98DtPS4,808
+qai_hub_models/models/mobilenet_v3_large/conftest.py,sha256=7WUkyKyBfQAAP3zBreDoZREblvLdbRPRSD3r8sTvLS8,918
 qai_hub_models/models/mobilenet_v3_large/demo.py,sha256=4KxbUpanGuUgvVcRk-YTTf90uQlEsMaBhbpjmXYEPUI,556
 qai_hub_models/models/mobilenet_v3_large/export.py,sha256=D4pRUuMYudoy7jVLy3vrpf1RYkg8PuhnubHYp7K3pGQ,7935
 qai_hub_models/models/mobilenet_v3_large/info.yaml,sha256=CbC2G_Zw1YshI-danUA20dWHRyzP2ZFsqHnVZU1nBUc,1340
 qai_hub_models/models/mobilenet_v3_large/model.py,sha256=AjaEjXhIddKyIg6FSzzGloeZibD96zC7HORYX7MZOqw,721
-qai_hub_models/models/mobilenet_v3_large/perf.yaml,sha256=_6hftU0WB7MUv_F8kcQMTCJr2thpubO2uaiuVnmZNLA,2708
+qai_hub_models/models/mobilenet_v3_large/perf.yaml,sha256=Oq_QLXAlXczdRPxeQPSALsu62Z1xxrUuCDBvm8zhrcs,3644
 qai_hub_models/models/mobilenet_v3_large/test.py,sha256=BKu3TBqXd6EelITtwPlPq58e20I530caSxC4vahg_MA,879
 qai_hub_models/models/mobilenet_v3_large_quantized/__init__.py,sha256=HWjXMytQDRVZh4KUJTPN8z_oCl6vbY5dtI1lC6C79ZI,607
-qai_hub_models/models/mobilenet_v3_large_quantized/conftest.py,sha256=BaonirYxKPSK1Phk_wNWDySVN1vQ0TRr9pQxwuHHVyo,828
+qai_hub_models/models/mobilenet_v3_large_quantized/conftest.py,sha256=1IVT8o6gQfThxEvgdGOrW8W1mKk348WM5HyMcWvoDB4,938
 qai_hub_models/models/mobilenet_v3_large_quantized/demo.py,sha256=XKC0CItIVpPeV60QD8VR7zAKBasKdjjcLZGuutvTm3s,748
 qai_hub_models/models/mobilenet_v3_large_quantized/export.py,sha256=e2NPb_LGjV0kprYLmO8mB6JKMboeqPV452-eiBTJICs,8104
 qai_hub_models/models/mobilenet_v3_large_quantized/info.yaml,sha256=w72_OYX5316wOqxjPIrMG1CD4q9mqAsRbE1tnsS7IOM,1374
-qai_hub_models/models/mobilenet_v3_large_quantized/model.py,sha256=d2MYpej-SxLYOiiPGEFeIpDjgD3gCu4JCRLOvnCoQoA,2865
-qai_hub_models/models/mobilenet_v3_large_quantized/perf.yaml,sha256=Ur6RkOpr7s0BwOsdy9KxXWLQmJ7m9IM-rbN64NPcA_8,2723
+qai_hub_models/models/mobilenet_v3_large_quantized/model.py,sha256=4H8KV9f1ju-Wv77NqjmXTJaI2FXffV6sYLMDDgxi7rw,3075
+qai_hub_models/models/mobilenet_v3_large_quantized/perf.yaml,sha256=f9IjMlTA7j6tTsq8aiJddtcXXTe2lEsi2eJoCudYMTo,3673
 qai_hub_models/models/mobilenet_v3_large_quantized/test.py,sha256=ruAffWPJDAifH_miRT6hNoOnaNY7tJpSXZ42U8zM9Yc,917
 qai_hub_models/models/mobilenet_v3_small/__init__.py,sha256=RhAKXSevAm64F3DtEwC1whT3RiawVPUuZRpHxupCwvY,479
-qai_hub_models/models/mobilenet_v3_small/conftest.py,sha256=fhQMwfPcfBud54LFyb4eZHPpGtH7OuHBnK0Dg24zSPc,808
+qai_hub_models/models/mobilenet_v3_small/conftest.py,sha256=DTQPnX2ZJUOcENlj0fQVSFzB3sMIE1DYANKbJQtv24A,918
 qai_hub_models/models/mobilenet_v3_small/demo.py,sha256=f2RqGEK_t9UJ2MNkIYTPnAkeNhOk5ORtBgORks8pQzE,556
 qai_hub_models/models/mobilenet_v3_small/export.py,sha256=D2OinHQ0I3p10v50ZlUAgu0BjbBAGIlo72v_ukqLSy4,7935
 qai_hub_models/models/mobilenet_v3_small/info.yaml,sha256=1UbgDdCaGry4M8mc17lsEQHN0c7dzg1OYujzQncLDGw,1338
 qai_hub_models/models/mobilenet_v3_small/model.py,sha256=AMSPekj2w7Odv-HX_YUPs5AIFiDMDmbaq-77eRM2MtU,721
-qai_hub_models/models/mobilenet_v3_small/perf.yaml,sha256=oFl4QGmmIhnYt-YcAr9AnxZ3B1nWhg7pon4Yvj4WWEs,2707
+qai_hub_models/models/mobilenet_v3_small/perf.yaml,sha256=x5OtkJw9NRxNoqlnj5u57RcGfA-dHynSRgqWdVL2UEs,3648
 qai_hub_models/models/mobilenet_v3_small/test.py,sha256=PkDBlLPWfV8ktLcict2uFWM7pn2nl8B_NtKHKIp9njM,879
 qai_hub_models/models/openai_clip/__init__.py,sha256=zmmQCL2hQl0hA_RIPa0pQrKUYOXbMBQWmaYYlSy-XrU,394
 qai_hub_models/models/openai_clip/app.py,sha256=hgOce5Y7aS2Y_V-EltMyp6CkLRXQDL0PTqelz-pBf9Y,3958
-qai_hub_models/models/openai_clip/conftest.py,sha256=3IdZjXX1wp6q_eh5lLcgRLPP5pSJNPtAgJKxvWudlag,880
-qai_hub_models/models/openai_clip/demo.py,sha256=Ti23UndQtFbGYT5Bj6Ywya-mn1C55eh22DaRcyDgrr0,3262
-qai_hub_models/models/openai_clip/export.py,sha256=KBngL-Ae9--l8FAW0b3NBThAENGwiyug8yNVhownzkY,9666
+qai_hub_models/models/openai_clip/conftest.py,sha256=bev7VH9Y--iOeI7Tps4PHX2JWWR9Frz5O5EUljDm-KU,990
+qai_hub_models/models/openai_clip/demo.py,sha256=3zSDWd1n8MHfreShD06TLyTTivGTmydTLeiA1UUJy9Y,3404
+qai_hub_models/models/openai_clip/export.py,sha256=qoOJ0JWBCvcgTigEWnjK-icB555TK5YTMHhUC2Qzlzk,9711
 qai_hub_models/models/openai_clip/info.yaml,sha256=tZQO7SbgP6M2JFAeoGOzl6WnuLhG_lyfWbiCc9WtpMM,1494
-qai_hub_models/models/openai_clip/model.py,sha256=CWeBH63cKI7nuOOEoq6qs33Rv88O3HHcYS377K7BIGA,5295
-qai_hub_models/models/openai_clip/perf.yaml,sha256=hhYwjE0wZ-mKDrD48J8fA36BFVLktiMjeiv4tgveTVY,4855
+qai_hub_models/models/openai_clip/model.py,sha256=KSRCG8Z9_KE_PyGUoTpzMSH41s0xvXEEnbGrg3p0hLk,5374
+qai_hub_models/models/openai_clip/perf.yaml,sha256=2rHERgIgF94xREfgTdwrxdYwgXN6NEQZswpoXDkdN2w,6529
 qai_hub_models/models/openai_clip/requirements.txt,sha256=qCIDOVe-LijMtnGXDgJtHPUP8Yig6otJASVYYaxE4JQ,29
 qai_hub_models/models/openai_clip/test.py,sha256=PV-_Wn-pUdg4M0DbbemnPREGDskjQnv8yqm19L9M2L4,2118
 qai_hub_models/models/openpose/__init__.py,sha256=DJnYvOA5-007mXB0GUl1TnKyBSNqFsQYlpGCpixb9Jk,402
 qai_hub_models/models/openpose/app.py,sha256=MrS_HKYzz8-ylXJH9_x2jEJg1H0ZZDBaYaWDOmme-Uc,12008
-qai_hub_models/models/openpose/conftest.py,sha256=54hvRxRjOJDvpu1Py8cZ8f5lae6F1p_xznYNMdTM47s,874
+qai_hub_models/models/openpose/conftest.py,sha256=uswkPSIX2k0yHNaMLKqgk_HpeW9UZGI8w7bwOXwOPEg,984
 qai_hub_models/models/openpose/demo.py,sha256=rPuIuHf7S_ncKOIFWoit8rR1jFG4uvHrAZ_NviMthuI,2053
 qai_hub_models/models/openpose/export.py,sha256=MYIXfRyGnSKCvHExllyEk6kxQfSgNWsNK2ZoEOEJ-d8,8171
 qai_hub_models/models/openpose/info.yaml,sha256=zZAZK46yA0iB2H7zccZHf0cxuQjdMdO3osgi1K-hRZo,1246
 qai_hub_models/models/openpose/model.py,sha256=iWpglU2znltOYKlQ9w-1xBt9yrrySJW5YhNBAH6lMkw,5084
-qai_hub_models/models/openpose/perf.yaml,sha256=oxVDjd4LmIecYtif5SksgrXZSWSqcBmFtyj8DFI7-po,2762
+qai_hub_models/models/openpose/perf.yaml,sha256=fm9TK-qERIdJiyXK1WBy4oDiI1NmJhNQQiPz1_j162g,4438
 qai_hub_models/models/openpose/requirements.txt,sha256=0xg0sn4HQZDSpN03SNwngv61Ry0AXQZvwPHrXtSuR00,31
 qai_hub_models/models/openpose/test.py,sha256=JhSAWSbHck2xqktdTa_2RAaBdoJOL86g6jLigVNHrgU,1321
 qai_hub_models/models/quicksrnetlarge/__init__.py,sha256=n0s0M56rmewoor90_VOznUSWRXF8hBUbBkwMNjKg1xQ,472
-qai_hub_models/models/quicksrnetlarge/conftest.py,sha256=0xShh4VAQuyE1d3yA17kRiW5-nA0SE-zDdsh1E60KmA,888
+qai_hub_models/models/quicksrnetlarge/conftest.py,sha256=iWxFgo0BdeV06oH0bb6TXfxNRFKEzhd0rnVXdKxwtt8,998
 qai_hub_models/models/quicksrnetlarge/demo.py,sha256=IgRtHWqQVLGsuNXJTb9kwaWkiR9xuz36Qnhc9Z34jKA,972
 qai_hub_models/models/quicksrnetlarge/export.py,sha256=efeI70rfwFR4UM1E0ilNnlPm-j1efd7jRGhc5bLLl0U,8181
 qai_hub_models/models/quicksrnetlarge/info.yaml,sha256=jwBhAffyc2KTYL7kvsETHA6a9gvrc0XEZ2vEOgaRqdU,1248
 qai_hub_models/models/quicksrnetlarge/model.py,sha256=DZpev_PEQicNemo1YZgQ1PXNZG0QgRuvQ53H2DNdHWc,3170
-qai_hub_models/models/quicksrnetlarge/perf.yaml,sha256=XLe-qirKe4BGdDGzfcNtJ-XNgsVQGwD_9OKy3Bqcwbk,2753
+qai_hub_models/models/quicksrnetlarge/perf.yaml,sha256=IJ0zShR56DYddJfytvd8K9rO0325urx2vGj9imUzA1E,4422
 qai_hub_models/models/quicksrnetlarge/test.py,sha256=HICEbmnkI-D2g1MYjiUGkzMcl1Sg9NjC9JS7vttnveU,1422
 qai_hub_models/models/quicksrnetlarge_quantized/__init__.py,sha256=kpW-qloH72jOP0aPE4r_0ZBcV8MackQ1Ro4yiunY9sM,483
-qai_hub_models/models/quicksrnetlarge_quantized/conftest.py,sha256=CR2u4DhKWH3PQd_GPVAtUbxuKq0JFUKHU14KesdAh7Q,908
+qai_hub_models/models/quicksrnetlarge_quantized/conftest.py,sha256=1u1yRi5Zc2bXLUeu0YbqtA2gSs0-fAjxVI1_DoHQZHQ,1018
 qai_hub_models/models/quicksrnetlarge_quantized/demo.py,sha256=gScOAfsMlVs9d-GBMW8zHfPeP7CJiFawQldlU1CVuvQ,891
 qai_hub_models/models/quicksrnetlarge_quantized/export.py,sha256=2ROI_sG-o2-DwWp9TQTBvvgjYBb76bGLBtm2lWkWOPA,8634
 qai_hub_models/models/quicksrnetlarge_quantized/info.yaml,sha256=qcahBBa33N55My5C2mINys5t3l41qQOFE3h-nLFR-ec,1274
 qai_hub_models/models/quicksrnetlarge_quantized/model.py,sha256=XeQCDOktDx1m2s56AlOEGwcsfUCkvI6i_MNU5VWPErI,4587
-qai_hub_models/models/quicksrnetlarge_quantized/perf.yaml,sha256=VACElfR2h-xqbbuyj0OTUzbCVhIQpG5tNV9jFg2Grrw,2712
+qai_hub_models/models/quicksrnetlarge_quantized/perf.yaml,sha256=GXbB2BbYjKKb-3XrH6yItbrIILU-wfyNGM4Mtd4Ne1Y,2485
 qai_hub_models/models/quicksrnetlarge_quantized/test.py,sha256=C7ytsb9iOxrsxGz__BL5XrGU2xBqYUwM9A1XOa6--Zc,2921
 qai_hub_models/models/quicksrnetmedium/__init__.py,sha256=GTyPcoDHE8Hz702v_Bk__uhwi2N0E2KqyXxPQ5wpY54,473
-qai_hub_models/models/quicksrnetmedium/conftest.py,sha256=GjJLLKExU9wGw0UEhNLZEmFiKCraQrj-6dM_8ZLZMGA,890
+qai_hub_models/models/quicksrnetmedium/conftest.py,sha256=MdNMSQH_3HKfqfc7I5-GSX-g6W1FEcduPwsA9LlIFN0,1000
 qai_hub_models/models/quicksrnetmedium/demo.py,sha256=EPLslU6kBps_nPCOUFcfVYWE66rGNIRGx9zC8gAoOes,976
 qai_hub_models/models/quicksrnetmedium/export.py,sha256=VECraeXBVPG7If_YJHHqRmJsloUXKrbZ1Ay-ilVS51o,8185
 qai_hub_models/models/quicksrnetmedium/info.yaml,sha256=qF6K6GLHopGKnuT0H3OBAwFMssi5KAt-4LW2ijIHWd8,1242
 qai_hub_models/models/quicksrnetmedium/model.py,sha256=ChFo9Fr8BHeFB7b_l6FfiWwE85fFZMMlmh_AxTxoCE8,3177
-qai_hub_models/models/quicksrnetmedium/perf.yaml,sha256=0PY7It0Eb6XDqLz7W6fvNTtTJCiCE9-2nssoD_NRVeI,2754
+qai_hub_models/models/quicksrnetmedium/perf.yaml,sha256=-ceHyhIYMOGsnqb0UVIKD6o_73U2TR8PE4-rk3egNFs,4419
 qai_hub_models/models/quicksrnetmedium/test.py,sha256=7MmkvCPJul33giNuZK8iAyRN11ci7Zw4bOq8LcjW824,1428
 qai_hub_models/models/quicksrnetmedium_quantized/__init__.py,sha256=1S_5eD4OACNMsJuLjPa1A7qoFokADw1fpuU3MtBkx6M,484
-qai_hub_models/models/quicksrnetmedium_quantized/conftest.py,sha256=0u-gkYfukSbzAsx6h07nAqKVQurUcgYwaF5ZtTxSkx0,910
+qai_hub_models/models/quicksrnetmedium_quantized/conftest.py,sha256=LiJ2kOvsSB_BFQQ25Ly95FMt-g0mufGFrkfSFGzOeDI,1020
 qai_hub_models/models/quicksrnetmedium_quantized/demo.py,sha256=6AGfl5ee02A7ZnM08cIJDOG14YEpQ1gWhJvPqBNVHEE,900
 qai_hub_models/models/quicksrnetmedium_quantized/export.py,sha256=dNztMKK0HIntu1TQeLIZdtPyoBWZQYYo5N7vmw0A0LU,8638
 qai_hub_models/models/quicksrnetmedium_quantized/info.yaml,sha256=oas-ZZ1q7bu5_jE1tiAPIAvsbbCRii6V-9piQUVh1Tw,1282
 qai_hub_models/models/quicksrnetmedium_quantized/model.py,sha256=QtXYgZiBkUH4YXV1w-1jFmvDVYFLafAIlnxmcHYI19M,4597
-qai_hub_models/models/quicksrnetmedium_quantized/perf.yaml,sha256=-WAcxgCa0rkf77jcW13tR79UIa5THgNiKIxe82gJ7QA,2711
+qai_hub_models/models/quicksrnetmedium_quantized/perf.yaml,sha256=4rFMOZpQn67w-CmzO9vqRzSsTdnlLim4oz202L7JEIU,2488
 qai_hub_models/models/quicksrnetmedium_quantized/test.py,sha256=g10Mox6qmH2HVihYkCXfOeBEo6CVGDA5CEXsuMIG1Es,2912
 qai_hub_models/models/quicksrnetsmall/__init__.py,sha256=x3REqFLXfs8YWq2ld1olPTKLwdQ5aRavepT-WIj9f2Y,472
-qai_hub_models/models/quicksrnetsmall/conftest.py,sha256=2dyEX_G6scqXvl_fODjeb1m2lCBSv1ozbuoiHHQr4g0,888
+qai_hub_models/models/quicksrnetsmall/conftest.py,sha256=YMJStKlUSpTK_8ui_UTEcGyKfUhdfvrtDiVXzDIE4zs,998
 qai_hub_models/models/quicksrnetsmall/demo.py,sha256=y1Z_GTvbWhOaJ7iyVMqTYaUxxePBhUI0J0bguRaEUB4,972
 qai_hub_models/models/quicksrnetsmall/export.py,sha256=SXxv1GFYjXTv-Pr2jhM1ul-Kwdam4B6I8UuSe861ZX4,8181
 qai_hub_models/models/quicksrnetsmall/info.yaml,sha256=cPEJEcn1_ctwMF7nHQ9-AeUsPaq9mhjhfb4Gm77Vgp8,1238
 qai_hub_models/models/quicksrnetsmall/model.py,sha256=6cufAzO8C3wItx4iQpkXrexkV5W9nUsi8z9OUcIhogA,3170
-qai_hub_models/models/quicksrnetsmall/perf.yaml,sha256=m-boFXuXsXJnCxO4w8cMvX1evuosX0rUbk_b4mz7ORY,2752
+qai_hub_models/models/quicksrnetsmall/perf.yaml,sha256=8aFUfFjy9001OLHu1LucJFTNyULO0LU6MpDtoM1neIo,4413
 qai_hub_models/models/quicksrnetsmall/test.py,sha256=d3OvtLPqk_3uzP2cSQMa6G4MJu9kx27aXOLBaeCzdPc,1422
 qai_hub_models/models/quicksrnetsmall_quantized/__init__.py,sha256=DYwTcgaBjIFARfMJ64zY-VPAT1DWz0kdcMunIa0uNuM,483
-qai_hub_models/models/quicksrnetsmall_quantized/conftest.py,sha256=dWKCF1_BuVx0nuZzJRGYqGt5t3EQVaPyaR-Iy-W7kUo,908
+qai_hub_models/models/quicksrnetsmall_quantized/conftest.py,sha256=7_mIH306wEY00_0C8UembQHI5xWJzrtVm7IytauIq2E,1018
 qai_hub_models/models/quicksrnetsmall_quantized/demo.py,sha256=mYIQyNQniXfQEVkmli0ft40hNwiXkeXkjUJWhT08YvE,891
 qai_hub_models/models/quicksrnetsmall_quantized/export.py,sha256=3V954w9CEcbWVnnQhrIdmEJpKg83VCw9R0DIcCPj4ik,8634
 qai_hub_models/models/quicksrnetsmall_quantized/info.yaml,sha256=OiqbT9kVtT8AxmvJ0QTU3i-kZwOaoDj2bkc9F7iS4mk,1278
 qai_hub_models/models/quicksrnetsmall_quantized/model.py,sha256=GfLJVnZxxDgWFcGmhHJbEdX28SYgW_QoqlBCdbBZroc,4577
-qai_hub_models/models/quicksrnetsmall_quantized/perf.yaml,sha256=YExIsvT6n3gyBxP85JZwPvq-3g4QzA-pEFdHQVBxW14,2710
+qai_hub_models/models/quicksrnetsmall_quantized/perf.yaml,sha256=FX8_2CbArdyk6ffp6Q6y22axVM6QXslC5oaczPH_GpI,2484
 qai_hub_models/models/quicksrnetsmall_quantized/test.py,sha256=bQdBBfrTuY5mN24JOeq8QYVz95uoQkw3NxFG9cUuVn4,2859
 qai_hub_models/models/real_esrgan_general_x4v3/__init__.py,sha256=-eD72P0MMcOI5S_6ZbVDAtQ5MAsZFiAZ2-Rs5wkfGCc,481
-qai_hub_models/models/real_esrgan_general_x4v3/conftest.py,sha256=uS-z6GqWupfVmz7X3Vh4AENocYrAdxUJFLqMwnpylwo,906
+qai_hub_models/models/real_esrgan_general_x4v3/conftest.py,sha256=m9br30O2D9u9reTypWuBFzIA2xqeANk3siuNzQmFcpg,1016
 qai_hub_models/models/real_esrgan_general_x4v3/demo.py,sha256=mdJUw7jmSDTPXDVyGHAOMgI-RUQdcjhvdLqju0Zeskg,1280
 qai_hub_models/models/real_esrgan_general_x4v3/export.py,sha256=O2aDAesmqpbnb3WKVg9XOcrAVdyP1IE4z3WTRVHkBNU,8217
 qai_hub_models/models/real_esrgan_general_x4v3/info.yaml,sha256=pKlB9DD4Qw5WDJgKW9xuxvccY-48a3vXY14Cp5M7RQ4,1206
 qai_hub_models/models/real_esrgan_general_x4v3/model.py,sha256=X0osnTyA3iHcWX-TlmCu6LN3-FUeLlPalUP6oSTk-nw,5226
-qai_hub_models/models/real_esrgan_general_x4v3/perf.yaml,sha256=Rx6vfFmFT6j-Nkylpo4pVVtXQHqIq6NCy6P7qpcFYV0,2765
+qai_hub_models/models/real_esrgan_general_x4v3/perf.yaml,sha256=3LaXDJp2bFwGQsdemG1AUUf-7pENs-IS6gre6DBOWac,4443
 qai_hub_models/models/real_esrgan_general_x4v3/requirements.txt,sha256=eivyaYj7iqy9Z98WwPoKDVihhM_HDbjOBu49PUryfJI,44
 qai_hub_models/models/real_esrgan_general_x4v3/test.py,sha256=CfOp0wKNA7sXZihxigo9inRQH-AQLkdzeg_o5KMKZIg,1480
 qai_hub_models/models/real_esrgan_x4plus/__init__.py,sha256=9EdQhD9AYsj6uAL3JlTGCNhMZc-2MiyfpZDJEmjspMQ,475
-qai_hub_models/models/real_esrgan_x4plus/conftest.py,sha256=NJjKsQ2SS_ZBqQ-BjcybV_Oj5v5m9m9r1rQyu4hP_iI,894
+qai_hub_models/models/real_esrgan_x4plus/conftest.py,sha256=_RYIUePYZKehGxjei0LK5feLM4VHgE5zSBg8-UaHupg,1004
 qai_hub_models/models/real_esrgan_x4plus/demo.py,sha256=_X0Jc79lhoHqB01NfCidG-TFBMaDtez-4Ipc5DCCL8Y,1256
 qai_hub_models/models/real_esrgan_x4plus/export.py,sha256=JL-SphhOUikqPMy3_4OnAGZMxhbymSdNEeMbMZS_2zI,7654
 qai_hub_models/models/real_esrgan_x4plus/info.yaml,sha256=xP8_0t2kPCJmXXY0M1oTjK5mPYGNaWMpgmRZ9rXNfUk,1330
 qai_hub_models/models/real_esrgan_x4plus/model.py,sha256=aH0QcIXpz336Nw7ca7BUPzMtuVFRvaFNOlun9pFVhQc,4443
-qai_hub_models/models/real_esrgan_x4plus/perf.yaml,sha256=6QmwiVBJy-rEezhfsjuFkmNNc6v9SdvKM3AyY1ThwGI,2720
+qai_hub_models/models/real_esrgan_x4plus/perf.yaml,sha256=C_CXBnfPgh79_2-IaCqKKzCzQCYy8WRhkxkjjhHQB7w,3673
 qai_hub_models/models/real_esrgan_x4plus/requirements.txt,sha256=eivyaYj7iqy9Z98WwPoKDVihhM_HDbjOBu49PUryfJI,44
 qai_hub_models/models/real_esrgan_x4plus/test.py,sha256=amJIYWs1sw7ndZgviSvm9X4uZSUH8TAz9Sa_9lyCTUA,1440
 qai_hub_models/models/regnet/__init__.py,sha256=eVvJ3D2GfGdcBriF_ihwwMVGDFu5OtZSuPz61h-uKsM,469
-qai_hub_models/models/regnet/conftest.py,sha256=CGNvhqmuHNqdbfeICiVsB1l22BBVLbC76XOrichi38U,784
+qai_hub_models/models/regnet/conftest.py,sha256=-vgdZlzN3w_54HqHgY2-ZoFjgFbg2SVY2p5tjgHcpgc,894
 qai_hub_models/models/regnet/demo.py,sha256=QTBBLpnIfWQLVnJOzzj1-pW5QWbpl68HJQ55_rtMAZs,524
 qai_hub_models/models/regnet/export.py,sha256=lHifWnGm7fCfxHFKr9pdTfBh5b4uqfMu7CYEHZIwSv8,7867
 qai_hub_models/models/regnet/info.yaml,sha256=hdUbHswd8D4ya7xX4_YPl4ZOT1ItebCTvId0VEh-mBg,1291
 qai_hub_models/models/regnet/model.py,sha256=ZAd-Ymzr5ak1Fe3oMS5a2DFvwnOWEKYJZaEP2tu-fQo,635
-qai_hub_models/models/regnet/perf.yaml,sha256=bHTRBGRRfWZpeaWlsrVWn8kj4oTF7NAK1sMtX0ffYrM,2755
+qai_hub_models/models/regnet/perf.yaml,sha256=vW_0MKs0lH0SWE9riPNw6MckDrb-aCDXAHqh35pwo5o,4424
 qai_hub_models/models/regnet/test.py,sha256=zZ4cDdGDWjkZ15L8zTOn770-LYfeTyRPaR-J2OA-RnI,984
 qai_hub_models/models/resnet101/__init__.py,sha256=giKR_QG6BGLXFiSVr_sRAJ-h2b2Ea6L8rhZgxEoJ7jY,472
-qai_hub_models/models/resnet101/conftest.py,sha256=1lXOOKtNS6W5tzQE9g6o6HwgJy2Few3YDDialK5DIcs,790
+qai_hub_models/models/resnet101/conftest.py,sha256=VimFHSIxjCAi71NH3R9cpUbU_j-RbjdPoKAMmsqMPo4,900
 qai_hub_models/models/resnet101/demo.py,sha256=RYdwNDEnxQpmUsUPP4qvYiGYJar-1WfLBbO5cVMx6N8,533
 qai_hub_models/models/resnet101/export.py,sha256=OTX5fEdD8f3QTWQo-bTq44gE50m6MTNgyrzVGy6fgJ4,7879
 qai_hub_models/models/resnet101/info.yaml,sha256=fbGPKTdV8UBcjMHR0aVK6amiizctrlbiQFaDSLrotcw,1312
 qai_hub_models/models/resnet101/model.py,sha256=Pjnm6vSdazT6uhrfn0Hx7hLU-U2rF2KiTMa9jWlmm7o,609
-qai_hub_models/models/resnet101/perf.yaml,sha256=YgFJP-cwaJ_p44ZK0a-hWKkeo8LB3iYnzsTMuJzyFwg,2759
+qai_hub_models/models/resnet101/perf.yaml,sha256=HfiWuZSZ6QemWmHRweJohaIseB5xm56s10t9xNDcuLM,4436
 qai_hub_models/models/resnet101/test.py,sha256=Gr4R3pO8Be43sRBm3KEc5NaJ3fHofnMMWfKTJ3K9lW0,961
 qai_hub_models/models/resnet101_quantized/__init__.py,sha256=aJsoYEIOw9cKKPYWV-wtGWvN45BTKvqZVoN31Eag4TA,483
-qai_hub_models/models/resnet101_quantized/conftest.py,sha256=34kMT1G4RQditAjZqpMYFr1IUGb2Q5YaTN_R_lnp0xE,810
+qai_hub_models/models/resnet101_quantized/conftest.py,sha256=mefhOjTyfCv-IbnJ3BrNlNuTtcGzY1UsmcSmPB2iuSY,920
 qai_hub_models/models/resnet101_quantized/demo.py,sha256=to8ShYfeBVmzd0OkyV4SxeflUXeedhqmrc6dwbnanfQ,578
 qai_hub_models/models/resnet101_quantized/export.py,sha256=qQ-nXnNW9ZXmaiGhXVWeDC1xN4BXnLTxGWRMPl5hQEQ,8359
 qai_hub_models/models/resnet101_quantized/info.yaml,sha256=28u2ptmsdw9O6ZAljymiAaTOZxV6DDD-_eXsXYZx3X8,1346
-qai_hub_models/models/resnet101_quantized/model.py,sha256=U9hffK5qjcWj1Aos_aFqZSb6-QrXixseYJ-Tbyb5U88,3000
-qai_hub_models/models/resnet101_quantized/perf.yaml,sha256=9rGEVoG_6iu42pjlB5DQogrv2xa3lS_FRg7HMlJranI,2765
+qai_hub_models/models/resnet101_quantized/model.py,sha256=7QEdqZJ4vJ1w51aJK4O11WvuJZuXcyBkFXpx5Blmi_4,3210
+qai_hub_models/models/resnet101_quantized/perf.yaml,sha256=k2bOHxTaniI2Rc7BHhMzEJszgS27tI-mDnX_822FPyQ,4437
 qai_hub_models/models/resnet101_quantized/test.py,sha256=C-8zqBiwN-nCgJb1I9RYfMykLPSKJIWW_t_Pbh97mJM,921
 qai_hub_models/models/resnet18/__init__.py,sha256=YXCoY4ADkV9rxnJQmx6th3bEwYaxE4UF6ECJMkuN4gY,471
-qai_hub_models/models/resnet18/conftest.py,sha256=-3fDAN4NFDZgwXbj1sPv2WXvzxjdVqA6SxVk9Zm3IwA,788
+qai_hub_models/models/resnet18/conftest.py,sha256=TAcwnazTwiIPxByxU625YwIZjDiA8-I5GUd-p6NHSZE,898
 qai_hub_models/models/resnet18/demo.py,sha256=e_s-tuUKno5C8PmEh8AISsqywzoNtYUQVFJjyaJRLYU,530
 qai_hub_models/models/resnet18/export.py,sha256=f7YafLDSqMCLK6jyz7XZGK4viTQOzRgHc2aruSHkn1M,7875
 qai_hub_models/models/resnet18/info.yaml,sha256=EApwQW1yExiQzFT8qWYraKeeULj1aF-_j15imZQshuU,1310
 qai_hub_models/models/resnet18/model.py,sha256=gl5xAhxkR3kMkbQ5DQXSZ42eGFE0uLN2gNmrianZWEY,607
-qai_hub_models/models/resnet18/perf.yaml,sha256=kkHN34wN93TmzTwwkQ2Dc0gNGZ6zUsto-XInjmKPSJs,2746
+qai_hub_models/models/resnet18/perf.yaml,sha256=aPH4wF1_-PiidGxIbqm_Auqhhk12_o1-UTpUO3KJKnk,4408
 qai_hub_models/models/resnet18/test.py,sha256=raI736nKtyy7_kNAmWEci7wQYPqPQ_ajP0h7MTfpdW4,955
 qai_hub_models/models/resnet18_quantized/__init__.py,sha256=6MfeTP9-civpAklCTt8I8kwEj4qfK2bpGpBFzi7Gp9Q,482
-qai_hub_models/models/resnet18_quantized/conftest.py,sha256=RVLrz596M1cs_04LE1gWbVOJy0MednIti84ezpKn3Vk,808
+qai_hub_models/models/resnet18_quantized/conftest.py,sha256=ea1HuqnhttyIgGi7uDAJiEcgDDY8x5GKooAx9E_v6u8,918
 qai_hub_models/models/resnet18_quantized/demo.py,sha256=J0yoGrm2LP5iUCCMXqc-paqC0VJZPP_Zi2heqCd_FGk,562
 qai_hub_models/models/resnet18_quantized/export.py,sha256=HFkos23ACf2up_oSihWvWBBxNM2k1utUbHQxloMNgTc,8355
 qai_hub_models/models/resnet18_quantized/info.yaml,sha256=EF_rGgvR-mbYSxraghrHtbP_TYxrI6cLx4xG2PuRPmE,1343
-qai_hub_models/models/resnet18_quantized/model.py,sha256=Cebk0B23oJotISOWBJ7a3Bi-uGWO1WdgHUYIfUvB4Ic,2802
-qai_hub_models/models/resnet18_quantized/perf.yaml,sha256=vhJju8a_yV7J0bWQ9wsDEAjTngHO_i_zO858MrCYmxc,2748
+qai_hub_models/models/resnet18_quantized/model.py,sha256=ayCXNSVAyPBqDnxYyE-UNG77dsNGhXuS6nBH-yNP7uo,3012
+qai_hub_models/models/resnet18_quantized/perf.yaml,sha256=6M3yivo4QBRpqGcZmoyhn-6OQB3WAunbktoN4Ua2exU,4411
 qai_hub_models/models/resnet18_quantized/test.py,sha256=gB-2uNRrC-phYHX6dwCn6cVSAxpVq41FFX_UwPwb5qk,917
 qai_hub_models/models/resnet50/__init__.py,sha256=i6A3by1VSJeHInRvYv3jO-x3QRBzywCjnlKuG6ALGA8,471
-qai_hub_models/models/resnet50/conftest.py,sha256=EzB3z3xK2kvCYXYdRqKQEV0AWSEG0c4vW-zJ8buv4do,788
+qai_hub_models/models/resnet50/conftest.py,sha256=iPKAMySlPbpydU4N2jijq0pXJkaMkHyk_7-Lkf_5CDg,898
 qai_hub_models/models/resnet50/demo.py,sha256=Ad2nWpI-kmP5M1sGhFAqSZFZ1Mz0Lov4q0ilsJIsdBg,530
 qai_hub_models/models/resnet50/export.py,sha256=aVxIA-zx0o5awp4QrqHXr_E18in5XvJCFURibYKjDNY,7875
 qai_hub_models/models/resnet50/info.yaml,sha256=mF1FdZhk7GG8vBDs0sW6l0VWW9jBxyZAkyS6SdaAF7M,1303
 qai_hub_models/models/resnet50/model.py,sha256=3Uz5cop4u1xHyZuR9ss0Lg6cSxWyV_xuJcgFENbiHlY,607
-qai_hub_models/models/resnet50/perf.yaml,sha256=8RR8vxyKlJSPBWw3zNf0sXurU3d06KUB4YM5Tj6AxaY,2748
+qai_hub_models/models/resnet50/perf.yaml,sha256=elVeynu-xaYdqtMqauK-QkyBjEEfDBsyofyvx4ttjQg,4418
 qai_hub_models/models/resnet50/test.py,sha256=7iQrq9aU53jUwGBRxj6dRXH9SwvFqTwegbMMxTmO5Fc,955
 qai_hub_models/models/resnext101/__init__.py,sha256=KsXu0bXmQcD_vUB9tOkoYL8cPsCuexuQfSA_ZoSEtxc,473
-qai_hub_models/models/resnext101/conftest.py,sha256=E9F0Qsex8miTp64s6OZGnBLpxD4trmOmyr5CHyJ9U6w,792
+qai_hub_models/models/resnext101/conftest.py,sha256=BXLqYikBB_tiff9HrRGb3fxh-eNFPa-3tQTjSYoiJOk,902
 qai_hub_models/models/resnext101/demo.py,sha256=W_MBGy--3Gyo6IkASUus4IeC2OJo6w7_vh8AN--pHj4,536
 qai_hub_models/models/resnext101/export.py,sha256=l_qAa4fRfY4FM9B-7Zdid8YA4Dy4lYYZJUt-uAy945U,7883
 qai_hub_models/models/resnext101/info.yaml,sha256=QQQ7IKSLieegTlThhnySi_BdYTnXcrBzSt-FNmAfspo,1324
 qai_hub_models/models/resnext101/model.py,sha256=dD8WyCTD397PbDRLg_EoNX-hcQekN2P7S8OrzHRz7SU,617
-qai_hub_models/models/resnext101/perf.yaml,sha256=EG1f7dDH62A8N-hU3Wq9mN9Trt2cc9HRlYVzsHosid8,2761
+qai_hub_models/models/resnext101/perf.yaml,sha256=yttbnVtzcAI_7IieLVt-Dru33eQO6Hz4U3OD2DEPP4A,4436
 qai_hub_models/models/resnext101/test.py,sha256=Gf470ZYn46oHSNisYxPiShq74rXykhqvriYbnNRnwoY,897
 qai_hub_models/models/resnext101_quantized/__init__.py,sha256=Sr23eMhxryEjt6hRjftWbdgS9YcDk1b4OshOi7irTY8,484
-qai_hub_models/models/resnext101_quantized/conftest.py,sha256=Kx6udb0VXDCbX-ie12uvyIOJySDxQWJ_cd-MM6fRtRs,812
+qai_hub_models/models/resnext101_quantized/conftest.py,sha256=Rx15T1AFt5AsA-bJpv8roVtFGJ8b32phEzVV9NKFH_0,922
 qai_hub_models/models/resnext101_quantized/demo.py,sha256=Po6sLvHLkvqNm9tZ-vAeM-A-t_FLKaE18gTnJh6oSuo,581
 qai_hub_models/models/resnext101_quantized/export.py,sha256=1CxhCRqEJ1pWuBoTLhwLui8GH-_HMkyGQbLUH6x8cZg,8383
 qai_hub_models/models/resnext101_quantized/info.yaml,sha256=Zlrngu5Y1UGGPhy_4bgpaE86oIzeB5NIeiAslZh8cto,1365
-qai_hub_models/models/resnext101_quantized/model.py,sha256=waex64mrxFUzyTJdYJYm7bT38hcsLijEKmpWitEPBVA,2807
-qai_hub_models/models/resnext101_quantized/perf.yaml,sha256=fD0B4IN9pVXs0VaJaijqpxOHM7LOzi0uuVt3Ot85CLY,2708
+qai_hub_models/models/resnext101_quantized/model.py,sha256=BQAwwRR0Z2ix9UGwm2DtMZYUohwaSXrQyZ8Da298LYg,3017
+qai_hub_models/models/resnext101_quantized/perf.yaml,sha256=DBVxBbb7aw2aHJpNIo_N5tdFQh8v1n-37m0YyBfca3Y,3658
 qai_hub_models/models/resnext101_quantized/test.py,sha256=jw2RahxL2zJq95ittlG6mBH1HKfCe-5MLpuL6f_9NOw,925
 qai_hub_models/models/resnext50/__init__.py,sha256=mvGLhLT1_Hj0eQ5sERqw2qBaaHTc8q9nGaoIMc_zVwE,472
-qai_hub_models/models/resnext50/conftest.py,sha256=HK9Rp1ysi2SAbpbS8kYNj3cWP-R8EFauBpmxy1ME99s,790
+qai_hub_models/models/resnext50/conftest.py,sha256=0sAqTtCuUs2CUoo9HvOj8bjynDaA_fEmmf0BtVaD4CI,900
 qai_hub_models/models/resnext50/demo.py,sha256=layKRO8OVlf7zDRarcUKuBwziX6mh0TahnxW_B4hOR8,533
 qai_hub_models/models/resnext50/export.py,sha256=mPGxM0Rl9-ULtL3LSWUEMi1RhjfymRmFRwYlCAdAup0,7879
 qai_hub_models/models/resnext50/info.yaml,sha256=x36YHWLVNgYYWVx4Y9GrJYKmwbgCmIXcUrVuX5Mv_XI,1322
 qai_hub_models/models/resnext50/model.py,sha256=g_2NntA_nWKxlgNZJiLaSpk-VcUO4S4EBtK1fLqvFH0,704
-qai_hub_models/models/resnext50/perf.yaml,sha256=nzFbtWWSo0lp5rB_dP4M4e-iyzv_Z0zg_J--Xdkjrwg,2754
+qai_hub_models/models/resnext50/perf.yaml,sha256=bH8XaVF6wYrTB1RJcZUqAhkio6VCSjAt2VwmsN9Xedg,4421
 qai_hub_models/models/resnext50/test.py,sha256=mO0iDd4c_7F_QjcOypdCsexc47QbdJpKFKFU5Mbwipk,840
 qai_hub_models/models/resnext50_quantized/__init__.py,sha256=4Oqop6yfnVXt2Zh9RoVJLqXYnXkriZIMSa90EcFh08Q,483
-qai_hub_models/models/resnext50_quantized/conftest.py,sha256=cvkXDQnHQg1kMCYpn6zMXPzLx059_FebLIEg6GztxzA,810
+qai_hub_models/models/resnext50_quantized/conftest.py,sha256=1qc-CpEvyxHlJpvGG3Y3EOiAwPpciMRJ80TBZw1WvkM,920
 qai_hub_models/models/resnext50_quantized/demo.py,sha256=sl3AOEAMwvqU2v3_7mpy3yUD-8j1JpcL_WCTpkel_8w,578
 qai_hub_models/models/resnext50_quantized/export.py,sha256=PW3ER7OQgO5yQbZQAANFVLWCpM9LS7QJGtwWhBZWkHE,8379
 qai_hub_models/models/resnext50_quantized/info.yaml,sha256=cC9rkqVl4QXSu_EjJRQY97AAqh8FsBuez-Rf3XSWae0,1362
-qai_hub_models/models/resnext50_quantized/model.py,sha256=1ID1l7vViZQJGAzZVSWHEyDmB9oLnxZP61EYrwgllGc,2798
-qai_hub_models/models/resnext50_quantized/perf.yaml,sha256=do9liZYX3GJKp4Lq8uqEUBEzAh_euQ_SqpN9De4Tlcs,2705
+qai_hub_models/models/resnext50_quantized/model.py,sha256=0mq9UHGSzZfPTnAkiEZmPVs1HCZizJ7PPiIoLiN9jN0,3008
+qai_hub_models/models/resnext50_quantized/perf.yaml,sha256=k41HuhIPjpxVryN2K_LcQ-tEE4qhE5oIe3HrYaKm1_w,3642
 qai_hub_models/models/resnext50_quantized/test.py,sha256=zmx2xRiJL2_B6zZwUmhMWzSm7cmcbCGyay7dB9O1XKY,921
 qai_hub_models/models/sam/__init__.py,sha256=z2l9N1qWNXdFDly6YvRC6MBOTANKL28klDYmF2qF7Qs,404
 qai_hub_models/models/sam/app.py,sha256=jCDEbspglkuXi5SS86A96Ek0SaqO-xhHWwHPh_3N8LY,5101
-qai_hub_models/models/sam/conftest.py,sha256=-d5Ti-hHK9XwP1qWn2HQ1IbTB2_LqHWM_9cbb5PRgoI,905
+qai_hub_models/models/sam/conftest.py,sha256=N3pExY_BC9_0ScpQHjvoeLczPt37cjKhr0_hHCrKvTE,1015
 qai_hub_models/models/sam/demo.py,sha256=G-Fv5x7usY6c1YeSdRzKBpw4KhC-9akcxINsspJBiHg,3088
 qai_hub_models/models/sam/export.py,sha256=tJ0yT8gyuzIp5Siu5DE5mkXjxTqbLH0vmyzZttuscVg,10152
 qai_hub_models/models/sam/info.yaml,sha256=b0Dez8dcQ4IAQs0xAHWsYkAvolTKi_hbFSRJvr19f4s,1391
 qai_hub_models/models/sam/model.py,sha256=qaW2mQiobMnmQ-SDme_JYPdbzUKHMqjeu4B7CJTEkx4,12000
-qai_hub_models/models/sam/perf.yaml,sha256=qLiUs615tJkoTS0SwjIlWPJi3KxXUmbny9cI6x8iOhU,2708
+qai_hub_models/models/sam/perf.yaml,sha256=kAt2A5IbOlokGFQbmc5oMaUKmbN7etljkcNjzQ-PPuk,3667
 qai_hub_models/models/sam/requirements.txt,sha256=vtppKtEacR8giw86K6Z90D_Xko9hityPiHQx7PxkAgo,37
 qai_hub_models/models/sam/test.py,sha256=cmynvGV9g_6A0etO-ORNxj16gyCF97MVYxZQK0CNzIM,3062
 qai_hub_models/models/sam/utils.py,sha256=5Zc1YnUm0HXsJ_T-R_Ge0CjMARxWxHA-ITG424uOCic,826
 qai_hub_models/models/sesr_m5/__init__.py,sha256=kS2GuYY43QHK5jRUcssK2u92IM8LMLy3SIbV5YCEsio,464
-qai_hub_models/models/sesr_m5/conftest.py,sha256=adTpVRqwS3ZJsP2M1Eg8Jy6e2Fl_EbXzGKu2zPIstf4,872
+qai_hub_models/models/sesr_m5/conftest.py,sha256=JEkN7NNT2lRIY3iUTgwrB0i9d3bt44vaQymqR-XTQEE,982
 qai_hub_models/models/sesr_m5/demo.py,sha256=uQqrkMLYcKnXc6_uDW8Niuj1YQBiMya3sFZwMGVXlOk,923
 qai_hub_models/models/sesr_m5/export.py,sha256=O8dg1F-ODACIO48vA5qHfBUAoWegV_ZzUDEWq_XnkOs,8006
 qai_hub_models/models/sesr_m5/info.yaml,sha256=xDzw26L21cJQ14jXZFrODO_klhrPTV5L5ALknfT4MnU,1104
 qai_hub_models/models/sesr_m5/model.py,sha256=c9-Q3psWvkFyFKgaOfWN5rhJpsvMZOKIUvapZhv6JFs,2984
-qai_hub_models/models/sesr_m5/perf.yaml,sha256=RV2-omedufM299zPWZoi9H00SNNB0e4JKJ20rgya-MY,2745
+qai_hub_models/models/sesr_m5/perf.yaml,sha256=2_TsvCuPoKczV4eukSBpOIdAdd-jQ4T9_QwRSFY0MD0,4418
 qai_hub_models/models/sesr_m5/test.py,sha256=hH27IYEOa4fPbfgHeQYuiUhHdPvMHX50DdW-LY7btng,1471
 qai_hub_models/models/sesr_m5_quantized/__init__.py,sha256=PZUoiiSQjJOpVhj2TNp_ixSeoy6RwK34nb45232QDsM,475
-qai_hub_models/models/sesr_m5_quantized/conftest.py,sha256=9T8-ZXKw9k4DZ5PkE0hQ5heMrjJBKeuovQDlp5Gz1jM,892
+qai_hub_models/models/sesr_m5_quantized/conftest.py,sha256=xMRNy_u80PgkbU3pst6kWGzPZbZ2giFl7TVWN3nZjGY,1002
 qai_hub_models/models/sesr_m5_quantized/demo.py,sha256=OD2D8ExW3h3SYF2_KX_7Qv_GQ8ylmjui2tmpWsqyAqg,990
 qai_hub_models/models/sesr_m5_quantized/export.py,sha256=4RcsQryaa2A4t8kmJ_Zg6DcR3XNsjoRQ68DBJY8aX1U,8167
 qai_hub_models/models/sesr_m5_quantized/info.yaml,sha256=J1XebgMlJ73n3is32JI0bduz8pFhlImgxaxr6khZfvU,1151
 qai_hub_models/models/sesr_m5_quantized/model.py,sha256=6O-GFAI1vPgyqLIRuMt1MWPQ8xAqfGvTBk4ohFy3w0Q,4269
-qai_hub_models/models/sesr_m5_quantized/perf.yaml,sha256=5jkoM-iTFiQWuGQV9q7Cc0qq1cIs82nOkY0bChAt2FY,2704
+qai_hub_models/models/sesr_m5_quantized/perf.yaml,sha256=HXsffl70zulWA-ekgcQ13r1kuBfAh53qxiNjkYepw6o,2477
 qai_hub_models/models/sesr_m5_quantized/test.py,sha256=3EXTzeXWm0qVHMZmGJeiy7OPzAafb2b-ORgUMtQ5KiI,2927
 qai_hub_models/models/shufflenet_v2/__init__.py,sha256=V__9vnDnnEeNjHp4_cliHUq8Ea7djP5ppdXt1VH3MI4,475
-qai_hub_models/models/shufflenet_v2/conftest.py,sha256=QOXdfhu4kvX5Ul38PM78fcnCV-z4VZnQCyp4moGPTKk,798
+qai_hub_models/models/shufflenet_v2/conftest.py,sha256=S-Wr9fqouHAdPNoxjj-iswGeA67W97fiVVBPuHrviO0,908
 qai_hub_models/models/shufflenet_v2/demo.py,sha256=-yorlVXF_fAdjOp_xfBQeZ63w2hU952DdIcWeLJDMJU,543
 qai_hub_models/models/shufflenet_v2/export.py,sha256=_05PPcIRFYUXYhA5T545JHg4u4D1GEH8lRnNa5IsagI,7895
 qai_hub_models/models/shufflenet_v2/info.yaml,sha256=5myQBF6qAlWS_h8a9emJbmux2ZpQIgsf3o7ZERL-nVE,1353
 qai_hub_models/models/shufflenet_v2/model.py,sha256=TLi9PPf3FIDi5l-pgCkmJGRA8TduOSRpsB3CbNhtVX4,713
-qai_hub_models/models/shufflenet_v2/perf.yaml,sha256=O_DVE5eehmgn_HAq9h3vR-ZesbHVfhZ-TneI6FiIPgE,2757
+qai_hub_models/models/shufflenet_v2/perf.yaml,sha256=lu3g2QXIIA0xC1q-rMIe_Y8uhWgKC2e-95r65ZheXZA,4427
 qai_hub_models/models/shufflenet_v2/test.py,sha256=11Yio-WBjhooUiLFMX7XC70gjCjq-MeiJr8zM854Rhw,857
 qai_hub_models/models/shufflenet_v2_quantized/__init__.py,sha256=CjZcBsRqc8WZXtl4c5QvzSJtfCx0TgArcKOymMp9yw8,584
-qai_hub_models/models/shufflenet_v2_quantized/conftest.py,sha256=AiffjINiY6Grj7eRtu2UEk4OdTkwzD-EU09Ldjj6vZI,818
+qai_hub_models/models/shufflenet_v2_quantized/conftest.py,sha256=0rOP4nvtJHwwfEDsihwwJX6K-R55LH1jddejqRLBVzQ,928
 qai_hub_models/models/shufflenet_v2_quantized/demo.py,sha256=DFJLJ83mzCD7bDyJ9KVFnO8c9rHSYygU6BlzoSEE-OA,588
 qai_hub_models/models/shufflenet_v2_quantized/export.py,sha256=6PwD_86NPYN42RmJTVVeQk3WyOdR7b1-GMaZSyM3diM,8375
 qai_hub_models/models/shufflenet_v2_quantized/info.yaml,sha256=fFtlMqu2yN4_tu5ZZtayMfrNCYxxHuDjXQvOy9k6tw4,1383
-qai_hub_models/models/shufflenet_v2_quantized/model.py,sha256=mXKbo-E9428Dy1UBeHM6EZUHxw3Yk4cKef6YOaYuGb0,5779
-qai_hub_models/models/shufflenet_v2_quantized/perf.yaml,sha256=AHUL4c-fGCzr3zAZ_Yc2LpQkAdf-QITITvXKJ0GuMGc,2767
+qai_hub_models/models/shufflenet_v2_quantized/model.py,sha256=q8sHReFVrVZwHRn_iD8fZjNYt5jb4AehzQpcoeLEo2Y,5989
+qai_hub_models/models/shufflenet_v2_quantized/perf.yaml,sha256=OIr3nTS4PYKyDnt3oGPMyzFKqNR7YewFreiYRQS17hw,3269
 qai_hub_models/models/shufflenet_v2_quantized/test.py,sha256=_U1q8NxyW4nqeb-jfVwqNcISHQpMO9mvVSK7QQK5Hro,899
 qai_hub_models/models/sinet/__init__.py,sha256=WIFJwnJg_47VGh96lUb-Ned-MCqHd9KL_OHzc2GU8Qc,396
 qai_hub_models/models/sinet/app.py,sha256=1w0xj_VwsDGJWRitmBq-iBWjDNI2dB-MOKHqCe7_pr8,3793
-qai_hub_models/models/sinet/conftest.py,sha256=r-CzC7uRb5gFTMVriSsbkfbt4v9O3zPDlOIx3EYZEvs,868
+qai_hub_models/models/sinet/conftest.py,sha256=W0lfLUURU_TSqs5jdAP8Nf5igo5mxegZjfzKfTH0L0A,978
 qai_hub_models/models/sinet/demo.py,sha256=1H922wHmgorXtZKVNVWn30PHA9Xz7NPPkM5wR77vVkA,1657
 qai_hub_models/models/sinet/export.py,sha256=yWEsq9ELCfZJJxs6x-kiyyXDDJMpjc3HHp5tBkoKIwo,8141
 qai_hub_models/models/sinet/info.yaml,sha256=L-fe7Oh7vvQkdYXQ_xaMDXBqtusxxXtBjD2or5fa_8w,1260
 qai_hub_models/models/sinet/model.py,sha256=kTdRqRgfCXsIUcxUwSsIoqsePRM0o2UNKRajxDIK9Og,4770
-qai_hub_models/models/sinet/perf.yaml,sha256=0VOPqUR1VzT8quAGjZsIdPkJDaAH9UotT8MLcSaMfdQ,2746
+qai_hub_models/models/sinet/perf.yaml,sha256=9aVjP6tE75u8Eve3EcWm1cOqgL97HsX_zcbj8KLIRhU,4384
 qai_hub_models/models/sinet/test.py,sha256=3WEZ8v6IIXSA2f_wfWWIeIJaeFCc1h_layHLP2LEf9E,1355
 qai_hub_models/models/squeezenet1_1/__init__.py,sha256=wWegyK2XfBcw4YceoPl-TZKn1uoRNNveDHXHOzA_tGQ,473
-qai_hub_models/models/squeezenet1_1/conftest.py,sha256=sohs5Tnr7eaVIXAuaBteRwxsNblTewQ1aBm31p8KS_4,798
+qai_hub_models/models/squeezenet1_1/conftest.py,sha256=b4i337aB6olxjqcXCfDnZ8Pg5eeb_GuFiGyv4fmrb4Q,908
 qai_hub_models/models/squeezenet1_1/demo.py,sha256=v2sws22uWCnGNOPIUPT_NolPTvTDLH-phqz8IYG6bVg,539
 qai_hub_models/models/squeezenet1_1/export.py,sha256=y2_Td7tSSCP7hbgfGhwIIRgom8JGLL3WB5YaJMLyoPA,7896
 qai_hub_models/models/squeezenet1_1/info.yaml,sha256=fhuQnYnNgu3GELnXi1xO655VmJ4EgaHkWn013HHiD1c,1325
 qai_hub_models/models/squeezenet1_1/model.py,sha256=mfmXr4T7EmhLa_86TXHOwv3XvlZMEsYAuiQmn68mt4c,696
-qai_hub_models/models/squeezenet1_1/perf.yaml,sha256=6fIMYIu06br-aCpoxlD8t0EM2tmfoSmZF7SIOfSGXEs,2748
+qai_hub_models/models/squeezenet1_1/perf.yaml,sha256=aB_XbNjF6H99zhyEdOSZKRKP2MFKw_4IId-LmWO1Wrw,4420
 qai_hub_models/models/squeezenet1_1/test.py,sha256=ytrCi-ZAAYWJ2rTV-6k_yZhYZkfrQRWD9FFoo8vUHEM,851
 qai_hub_models/models/squeezenet1_1_quantized/__init__.py,sha256=lQk7lSxtBwX8Y2q5w0xHIfz9bhvub3pkezT88Tore-U,582
-qai_hub_models/models/squeezenet1_1_quantized/conftest.py,sha256=Wmmh7Kbypo-9wZzwrdZhzP7g1fuHhMEL8ETK4hiKouY,818
+qai_hub_models/models/squeezenet1_1_quantized/conftest.py,sha256=8ivtHd9JOpw8ulknqKw8M8L_8T7EjlCToPhWrzvz_-M,928
 qai_hub_models/models/squeezenet1_1_quantized/demo.py,sha256=khZa64iQFJ9MIwUA5pjiAiq8bOQwXiFxAzNsVLObTgw,584
 qai_hub_models/models/squeezenet1_1_quantized/export.py,sha256=SCohi0Bc_3yg-SReP_641UIDkPtWJViewHxagTq2QwM,8328
 qai_hub_models/models/squeezenet1_1_quantized/info.yaml,sha256=ORH-gyADqkVAWBPF08xspyFovFxhdm6LHlMmRztfK5o,1358
-qai_hub_models/models/squeezenet1_1_quantized/model.py,sha256=bqd5L6UBDaQVgGWfvLbEII94BD1fow8oRKtx4YaedTM,2813
-qai_hub_models/models/squeezenet1_1_quantized/perf.yaml,sha256=PKiYi3PEvM1Bl6mcEptTUv5indYU1K-T5tbxaPVU81c,2757
+qai_hub_models/models/squeezenet1_1_quantized/model.py,sha256=FXk13i2nFxCAy5H3NDXn0MCvJ4Tr2UJ7Rstqvbyh3a8,3023
+qai_hub_models/models/squeezenet1_1_quantized/perf.yaml,sha256=gcRoy0g_mFoXLOrMr6DxAur1sH9KftMLGcvuSWqeikk,4420
 qai_hub_models/models/squeezenet1_1_quantized/test.py,sha256=5e9_c2yGKzkl1OaYkwWXBijYxQijS-bKt7Q10Oo7P3M,895
 qai_hub_models/models/stable_diffusion_quantized/__init__.py,sha256=vtVBYmQud6hMNb2GOWcqEiUr6ue5QU-Jftnss61bUoc,540
 qai_hub_models/models/stable_diffusion_quantized/app.py,sha256=o9Ao1qdv1trphz35GuPUjCi3leh29KoyyYGd3A7LdA8,7966
 qai_hub_models/models/stable_diffusion_quantized/demo.py,sha256=barv_jVC8nGiXsdL6SS8oDbMRSk5Bwm1gfw20St2d_Y,5765
 qai_hub_models/models/stable_diffusion_quantized/export.py,sha256=iZR_G93977K1mActHLw4DQv227VT4qJuAIqtLePEe7s,7432
 qai_hub_models/models/stable_diffusion_quantized/info.yaml,sha256=bnzWKCd80EDo1AOmlfnTDXrAAl0VXbO8CI0VjmdATyg,1355
 qai_hub_models/models/stable_diffusion_quantized/model.py,sha256=Wx2-g4gqcUMQ3hjM9Ah2WZiOuQ85qkVpNqd2P1Mj_aE,3604
 qai_hub_models/models/stable_diffusion_quantized/perf.yaml,sha256=EJT82CEPbK653yyloO5L_exjE2HXoIdU0utrOZ0yHNw,6384
 qai_hub_models/models/stable_diffusion_quantized/requirements.txt,sha256=HWz6kAx8f-AYWf5IWvv-q1IOznXS94gXTQrtKGY4L70,46
 qai_hub_models/models/stable_diffusion_quantized/test.py,sha256=IIEtaueWT-pakv6P0_Uy10jPdKE0suxjwUHJPpij2VA,1599
 qai_hub_models/models/stylegan2/__init__.py,sha256=DEYHc9DKA6dqX9iajm9yRNNFLLVZzwzyo4jepbBghDg,404
 qai_hub_models/models/stylegan2/app.py,sha256=lif1hpxwzpEWKHJUWJn_b8U_UdNQuqOecVqAZxqHGDI,4155
-qai_hub_models/models/stylegan2/conftest.py,sha256=hn-YtW2rorF6hs8z19sZ2Bc43Fl1KqDa6yEbSdC6QQc,876
+qai_hub_models/models/stylegan2/conftest.py,sha256=_Fs_nAyb2o6qYDWyfWJ6-5ePdIJ4Wp9iw7QNnBIMTxs,986
 qai_hub_models/models/stylegan2/demo.py,sha256=FzMK1wvc9Qsf46XK2HqFdzCIel_q5zjOGCoBjlA2BuE,2847
 qai_hub_models/models/stylegan2/export.py,sha256=JhYvexMPMhgdmVwzIxKJqbvm_4pz4M9XNhlQy9G8DmQ,7762
-qai_hub_models/models/stylegan2/info.yaml,sha256=4ALs1JPSQJei4oUVImGi1MI1I_5T3FrHBVJAFFn6UFg,1102
+qai_hub_models/models/stylegan2/info.yaml,sha256=V9PJJsIuSz0pAWl_YfsVUO9-INABRs-aFTpxfEK3jGk,1084
 qai_hub_models/models/stylegan2/model.py,sha256=GxCrDsAd8ovfqMNsYKuTz8VBOqbv8WlUYdXM_0xk_VY,8406
-qai_hub_models/models/stylegan2/perf.yaml,sha256=-IZQ9th-SdO6CQce3SRnL12rJcaVJxuBdCAAYRZ_hSw,2722
+qai_hub_models/models/stylegan2/perf.yaml,sha256=p86BTKQPBnfuLk-gBxORC2dsztadR-uit3kZz9_THRg,3607
 qai_hub_models/models/stylegan2/requirements.txt,sha256=qOlq51yRk-GCNSKWjcoQno6BFnDOutA_gOCsMRiEm50,11
 qai_hub_models/models/stylegan2/test.py,sha256=yv5SE96wBsLm-6YNITvLtP0MQUMEUce-66yyvAbtMfY,2497
 qai_hub_models/models/swin_base/__init__.py,sha256=p2IuNVS1xnxD94TMxel73mdH8VFqkLGalELLTDN2rQk,471
-qai_hub_models/models/swin_base/conftest.py,sha256=jx48sMXDvkGC8RXnSYhWVjL6Fzww8GF_gUU3Kut_mNQ,790
+qai_hub_models/models/swin_base/conftest.py,sha256=z-BksOnLptPDz-ycIZ51L4fQ8MpocZdGgxrfavgBa6E,900
 qai_hub_models/models/swin_base/demo.py,sha256=YsZ3rMrIIZI14QSkHgvlkzk4H4Wb9eVxnR7Ne7ohA5M,531
 qai_hub_models/models/swin_base/export.py,sha256=ytWuoTSFsDlnQ_JR3QpXcDtTBUCHeMLWsMrZAzC4iyk,7899
 qai_hub_models/models/swin_base/info.yaml,sha256=3LfGk69zgLbjR5j35drDhHRZ8F0ZkA6wuZlAB_85JEE,1383
 qai_hub_models/models/swin_base/model.py,sha256=l_TKswq9uU6F5XSqWxgffQrdGD7yPuqvoAWFl1hBM-g,1241
-qai_hub_models/models/swin_base/perf.yaml,sha256=3-XK4WIHfHajiWjvEZ22c1uoVJLaxb1LenYxDRcPuUM,2709
-qai_hub_models/models/swin_base/test.py,sha256=pQM0uuTaTJ3cNKFlqYUyvXIPf0gEbCnFKo2h1r7SFHc,1251
+qai_hub_models/models/swin_base/perf.yaml,sha256=FZVlCXy5uwDekFbIywfbNOtkyJm2lnP6m44zxDNT_Ns,3665
+qai_hub_models/models/swin_base/test.py,sha256=u4-I37mNGQRA9fPOUkcP6RsIWC82mEDlaHO-gBy_45k,1358
 qai_hub_models/models/swin_small/__init__.py,sha256=HOXEswRvtQUl3Mx-uVvmr9RMaEZ5pYSkMG-TiNK-EZU,472
-qai_hub_models/models/swin_small/conftest.py,sha256=G6XShdDAY99jJpxTKD0p993eGPrnmfvj97_TBzD1uXc,792
+qai_hub_models/models/swin_small/conftest.py,sha256=cYsqkK7BsAUKBiFxOZjDxTLioNWz_ZyNHB1SmoKATwU,902
 qai_hub_models/models/swin_small/demo.py,sha256=QpJfG2oCPFgZVNW2OZxOSmQCFBXmsCbQSTrAi-xipp0,534
 qai_hub_models/models/swin_small/export.py,sha256=X2j_A7RciaSBX8JYu7VkgpqUkWvQW8vELpvlE-xpNLY,7903
 qai_hub_models/models/swin_small/info.yaml,sha256=F5iz-3X5s-d6JW-HeCHW4AkSRPcd6QSUTS0Rt_E9ObA,1378
 qai_hub_models/models/swin_small/model.py,sha256=1G-ENU7Vf5cbpwH_cqzHLG7qhTgkDPp85ZVcxydBglg,1242
-qai_hub_models/models/swin_small/perf.yaml,sha256=9WIztINyw3ObPmj7kyYDZJf8i_FDm5zoXgmx-qeW8xE,2709
-qai_hub_models/models/swin_small/test.py,sha256=GLNekES6D58uBPFqKvEa5xYGjZZ_fpfm2HlZtr-88hg,1257
+qai_hub_models/models/swin_small/perf.yaml,sha256=6ENxh11jHEPLWbOXqZPUPi-wfLR878Kg7F3VSQFLtho,3663
+qai_hub_models/models/swin_small/test.py,sha256=6AzCPufcvpD7II5eHrzckEA-T_jaKHSNVWpQmgBPjAA,1364
 qai_hub_models/models/swin_tiny/__init__.py,sha256=KMabHS9sJvTh7SR1iY71UsqXV8UXvWCCYc8rL-Ifbi0,471
-qai_hub_models/models/swin_tiny/conftest.py,sha256=EUGqCccYywY3j2e7yyBogLQkI00vV2rlYQvNQiOqF9A,790
+qai_hub_models/models/swin_tiny/conftest.py,sha256=65Suo7s0xbEchjCA2gJwXjpgl323EqwTS-zbTr35Gts,900
 qai_hub_models/models/swin_tiny/demo.py,sha256=sgvM7gVMjsiMPGwZRGg0MBn7MUdD6PoNj-WD1ejr70M,531
 qai_hub_models/models/swin_tiny/export.py,sha256=WWAyYC8tDoXIDYWXOyikvUHhZTLbV4c_dU6S357mhhc,7899
 qai_hub_models/models/swin_tiny/info.yaml,sha256=xFXYmV7ol4weKYVxrdW2RleeH603mzkJSV1fYQ9XPlM,1376
 qai_hub_models/models/swin_tiny/model.py,sha256=_dgBGuAk4ZWHYPKWLqeHyU605TkcgWOgfQQlDJyBw1c,1241
-qai_hub_models/models/swin_tiny/perf.yaml,sha256=AT0ouvHJS714ykFSxx1gV0OJFa2EXoW7wikuZd5rJ2I,2703
-qai_hub_models/models/swin_tiny/test.py,sha256=xrGOTfdwRrrRsTpVZ1qJGZkjX5urIvUoMnaFimvLwFY,1369
+qai_hub_models/models/swin_tiny/perf.yaml,sha256=URY5rdUA0oGbkTZPErmMINseboL-7uUhqRtygZkYqck,3657
+qai_hub_models/models/swin_tiny/test.py,sha256=pyRcuX_EtrOTbrjGtVXD-vqiW2s_SAFiJSN8SSCqrAI,1476
 qai_hub_models/models/trocr/__init__.py,sha256=wXm8GYsyaT3M3HQlZczeJy3t5Qifdcarms23LJcFT4E,396
 qai_hub_models/models/trocr/app.py,sha256=kiE57iafy8ZZ7_uxo8SR2xs9-LFzaBiNEAjaVzrXbHg,10207
-qai_hub_models/models/trocr/conftest.py,sha256=D5ndwUBbZrd8kRzKJzV4dQWO8VfeUosZb0ziKU-i2zw,782
+qai_hub_models/models/trocr/conftest.py,sha256=XNJ0HVijnxOX9IdS20HKaTnvTHHik01zVBkxJjC01Fw,892
 qai_hub_models/models/trocr/demo.py,sha256=aFQgalfyjuUsZvP5VT7TshR70MCW6UUGfQd8A3nJVag,1779
 qai_hub_models/models/trocr/export.py,sha256=sHJI3nIVxtA6rRcEYmXdFsQfRsbPt7sRGBxOuroGL4o,9655
 qai_hub_models/models/trocr/info.yaml,sha256=XYdHrSlr6IJkxEIvt9trKhBdhW-HSvPA_CFjW-viEcs,1370
 qai_hub_models/models/trocr/model.py,sha256=VF0yXAP60MolsUgkBz1nV-D0X4to_qrNLApcx-TYLnM,10482
-qai_hub_models/models/trocr/perf.yaml,sha256=gSpnY4h9Dv5k157q_oDwzfYVCfN1QzHP9LS-496dBx0,4735
+qai_hub_models/models/trocr/perf.yaml,sha256=BbV1WfRWHwZnSIZc_FAt4RUDfEclqh1wZJiZPFGCE_k,6534
 qai_hub_models/models/trocr/requirements.txt,sha256=cnbvoRqx9v7r3NmR_f70Cgvd_PGeI7GWEBGEY_vOTyw,42
 qai_hub_models/models/trocr/test.py,sha256=OPMndfm1qj4PKF6YmEyHkbjKi_hpXh6zx6D57XDwNvM,2357
 qai_hub_models/models/unet_segmentation/__init__.py,sha256=eCv56Tgc7rcutJMfHTjnd3W1aUffmcuJtgjSURzbOGc,348
 qai_hub_models/models/unet_segmentation/app.py,sha256=DdrUoO1W-Jk99IuBc-JNHgGNlBXQj-p1f0h_xyxiQ1w,1305
-qai_hub_models/models/unet_segmentation/conftest.py,sha256=oEXmoajVdFTzvWIc7Yy_GBsPBTilq3FoBNwC37apueg,806
+qai_hub_models/models/unet_segmentation/conftest.py,sha256=HowREPtuUkvswrlS6mbbFWG90INafrk26pQ_iYauKhA,916
 qai_hub_models/models/unet_segmentation/demo.py,sha256=6WhmNetb5POKcNluaRClyIsyPWHDGRSn1-p6v82yQUE,2509
 qai_hub_models/models/unet_segmentation/export.py,sha256=xyoj8lMrCLi2z-B-B51Znxs4Uo8Npqn5X8zhKBpKIRw,8189
 qai_hub_models/models/unet_segmentation/info.yaml,sha256=XeH1Ge0eqcX-iNM7iZOczv3o_TYjmdXqYlD2qzzt690,1310
 qai_hub_models/models/unet_segmentation/model.py,sha256=RpV7TfLdmaQNQuyX0FNy7KvJOlBXNyZMuQN70LLaR-g,2666
-qai_hub_models/models/unet_segmentation/perf.yaml,sha256=Lf7j24_Bm-yrRIL6uoEe-rNlDjWXT5BTX-qxk0-M5Cw,2774
+qai_hub_models/models/unet_segmentation/perf.yaml,sha256=G_mW_zYejWaAF24qI0HVdH1voVYAcN863D9LVF2uQBk,4464
 qai_hub_models/models/unet_segmentation/test.py,sha256=tMInbwc85HhxL0n8tKutOUcc2xXe0GlcEYhGhkynjPg,1215
 qai_hub_models/models/vit/__init__.py,sha256=sb8lq6b6jX0ld11rHa7wllm3un53paM2DsdWQkwsfCQ,466
-qai_hub_models/models/vit/conftest.py,sha256=UlqNQiqczQPAvdGeiP4bpfd3KVF418PJ2u0C1jqC1Gw,778
+qai_hub_models/models/vit/conftest.py,sha256=PHteQUGOejp1CN_9W3Q22b9nLRfIKPgPz82DxpMAF-w,888
 qai_hub_models/models/vit/demo.py,sha256=WJKe7oH0jOK6__GnIWESX-a2v7LhjX0C6A6vUZvrmZM,515
 qai_hub_models/models/vit/export.py,sha256=uEPCWq3Bkc4OGGg0urRB8UHyLFGnPi0UJG9Fq27piJY,7908
 qai_hub_models/models/vit/info.yaml,sha256=FDb8b6QwZlnXV4D53BxZecQ_AUunJMqgfOMRi-ArmHE,1342
 qai_hub_models/models/vit/model.py,sha256=kIDZHjG_XZs2afBUm5MbB-tv1H3q9Mc7hLzwJ43ITgY,685
-qai_hub_models/models/vit/perf.yaml,sha256=jhssBXAWysS4zqjuudakCu4n0jJpqm4N2zhQdBCXyp4,2701
+qai_hub_models/models/vit/perf.yaml,sha256=aRvkbJ8dbozQc6N4OkhAHiq8IqrDjSWJ2KwC9JOv1ds,3652
 qai_hub_models/models/vit/test.py,sha256=2rVAdhoCo3hpKuMinwO_pU_N27Sj7KD_iG2kWeOFpcU,807
 qai_hub_models/models/whisper_base_en/__init__.py,sha256=gPx7T0jgsv-7IFKaRf-Mm-D99qIGGDdvEZngoTC9hL8,444
-qai_hub_models/models/whisper_base_en/conftest.py,sha256=bXmJ1iMOjqeepCNHRzow2ZinpCBoHyvwMBvj50UTwqA,802
+qai_hub_models/models/whisper_base_en/conftest.py,sha256=q6Y1lNVS205ze1xXYUV9Bp-Cz8lEPd-Qvs9ma2sKhbY,912
 qai_hub_models/models/whisper_base_en/demo.py,sha256=2Ud55e8xLWbFjwnZBHAdV2xWmRCXUnFl9CylXMLADWE,483
 qai_hub_models/models/whisper_base_en/export.py,sha256=c3vnRuPS1ZAQcZE_Dsz_4Fy2BRwJq3qqh0tg8EU-gfM,9707
 qai_hub_models/models/whisper_base_en/info.yaml,sha256=h0b_rJzb3Me1kvHEPgRFCvxVHjdaWNUpd_t9be6KpdY,1849
 qai_hub_models/models/whisper_base_en/model.py,sha256=HPsCIIHuJvVb62t0wYBofNUr6ehqIXrdMYSSrKH65YA,558
-qai_hub_models/models/whisper_base_en/perf.yaml,sha256=iHRhnC8BuVshj6seKs7W_CkfBgl8RZsPXY4oy78fTT0,4743
+qai_hub_models/models/whisper_base_en/perf.yaml,sha256=CjFsMiiu2H9m-iNbew-8Rr6U8QKYuvqEqDePt0jQraM,6521
 qai_hub_models/models/whisper_base_en/requirements.txt,sha256=6mPzVdJaLJE0PzWpF06bHbvLYjjD6uqQgJK9df11eQk,31
 qai_hub_models/models/whisper_base_en/test.py,sha256=YbVbfTk_wimEZ6dNVV5vPC1u6BpWlbCBzZlaSVnlDpM,696
 qai_hub_models/models/whisper_small_en/__init__.py,sha256=AdhsuSgpnju4sajPAn1AD0Ej3eQ67mW802ehQeWftu0,445
-qai_hub_models/models/whisper_small_en/conftest.py,sha256=YAUdxsaf96mqbokgr3nVG3D_jEvDUc9zWpInD-WFEeg,804
+qai_hub_models/models/whisper_small_en/conftest.py,sha256=8f6D1l9G-ADheY0grBH4sALosG5qlvQD-zdkJMjnDwg,914
 qai_hub_models/models/whisper_small_en/demo.py,sha256=Qcz9_UlcZMjkRkob6yEHpH-vreKiEPf2Mz0-IGEsGNA,486
 qai_hub_models/models/whisper_small_en/export.py,sha256=ORS-Pkjg7S9Ga5-Y5GUQJO9swJHXMIycYdvCcsl-Rbo,9711
 qai_hub_models/models/whisper_small_en/info.yaml,sha256=d2gUKgMzU0fHZ8v1Uo0PVchcMFny9O9XV2B7_gS3p0c,1848
 qai_hub_models/models/whisper_small_en/model.py,sha256=pzVmdcKIbKzQDdJfmSpSqrr2nqUXmEctuVNYaxIpB_Q,560
-qai_hub_models/models/whisper_small_en/perf.yaml,sha256=UWGDln6FOcYhQHkPYiN1nESUrf9KX7cxFQEHDSxUVq8,4753
+qai_hub_models/models/whisper_small_en/perf.yaml,sha256=JIkaLtaWR63F7ylP1d8RHVO1o0pdw4cBJ_1IcrzCpyI,6509
 qai_hub_models/models/whisper_small_en/requirements.txt,sha256=5VmKKgsGZpToTOQ9qGw40spPnoGgu1RiCV1LlwT8PZE,38
 qai_hub_models/models/whisper_small_en/test.py,sha256=YbVbfTk_wimEZ6dNVV5vPC1u6BpWlbCBzZlaSVnlDpM,696
 qai_hub_models/models/whisper_tiny_en/__init__.py,sha256=TmMgJVcrcymvkH9ZV4B1C4ap5GOxKq77dR7BWJsQtd4,444
-qai_hub_models/models/whisper_tiny_en/conftest.py,sha256=sVGgLU9g61q453GuMsWgluwUPVcpjTdePi3vvR05tdo,802
+qai_hub_models/models/whisper_tiny_en/conftest.py,sha256=vyPQf2Y2EV4ivkHQ9DyI9fM73pSE_9fRPsmPVycpWEM,912
 qai_hub_models/models/whisper_tiny_en/demo.py,sha256=gvvmZMuOmNLc3eybBOyMcghS4tmMTXec9Q7C0f2Idv0,483
 qai_hub_models/models/whisper_tiny_en/export.py,sha256=czs9SEg-QllerrKX3IgOvh_oYzl0Gcg4FgOK0SYp4vo,9707
 qai_hub_models/models/whisper_tiny_en/info.yaml,sha256=r2AoylFZ7T77Mgi8-YSzF8zhHQFGI72-g127nS1Lw8w,1849
 qai_hub_models/models/whisper_tiny_en/model.py,sha256=osptTKHSqPTiEdh4aypQ2WNjEaHnv6yNFY5JXgGjnqg,558
-qai_hub_models/models/whisper_tiny_en/perf.yaml,sha256=0mas4vpb0cAJDYWDQf3i0PdrT4GtTHC3h2A_kQP_zyc,4733
+qai_hub_models/models/whisper_tiny_en/perf.yaml,sha256=nXXkIhxOIHHWRuuR1F3XXejN9BAHniAgPvkDlfCJRaM,6514
 qai_hub_models/models/whisper_tiny_en/requirements.txt,sha256=6mPzVdJaLJE0PzWpF06bHbvLYjjD6uqQgJK9df11eQk,31
 qai_hub_models/models/whisper_tiny_en/test.py,sha256=YbVbfTk_wimEZ6dNVV5vPC1u6BpWlbCBzZlaSVnlDpM,696
 qai_hub_models/models/wideresnet50/__init__.py,sha256=2gofgGLnNTfjSpI_9iWz-W1gmfqP32BJ8e7hR2OmyhE,475
-qai_hub_models/models/wideresnet50/conftest.py,sha256=-EEzohADvtgMAmpX9_sOC0AjWJmlLVGpq_5S4Kfrxr0,796
+qai_hub_models/models/wideresnet50/conftest.py,sha256=B0lQTCB6j31cczALY5G2gJQ4gk4WF52v13TAs79OKGc,906
 qai_hub_models/models/wideresnet50/demo.py,sha256=kPn94bMa4KF6Q4-yzgeDIr8UfaxAsSGTblk3xG4m9ns,542
 qai_hub_models/models/wideresnet50/export.py,sha256=HQM7vWGFMKXbJxGnyGZDis9d8P-GUJt8zoewYcvH-wc,7891
 qai_hub_models/models/wideresnet50/info.yaml,sha256=MAq6BAeuSZXhglFGyKF_GWmzrYFqLbZFBOxpLaQ1w3A,1298
 qai_hub_models/models/wideresnet50/model.py,sha256=JkEEOEgGikkD_gPlOZDhI9bnZU-pPfxFj8UifbjP4KQ,710
-qai_hub_models/models/wideresnet50/perf.yaml,sha256=7FXtj77MVgHRdR1jF4U65iRg5mfF5ItZ-TiRowMW36g,2760
+qai_hub_models/models/wideresnet50/perf.yaml,sha256=Ifd8dg-GYqDtuQyqsCedYlDdt-oXRrF9ko3NH2Ghqws,4431
 qai_hub_models/models/wideresnet50/test.py,sha256=4pY8YCYKR4_rURwM3byuRUanThobgwlhlVMG44bnwHA,855
 qai_hub_models/models/wideresnet50_quantized/__init__.py,sha256=OVOoOn80LrgiO61p2JZTOPk4wd6MBIpV78Qoa5ei6Jw,582
-qai_hub_models/models/wideresnet50_quantized/conftest.py,sha256=V4j-qjp7iOK4UDI6ryevhnQjWoivzcdKHoRvWIEpmAg,816
+qai_hub_models/models/wideresnet50_quantized/conftest.py,sha256=-kQ3XSeDBJDT_BD_F7Wcv0vtTjOuj-yAqdG3AGHqYdk,926
 qai_hub_models/models/wideresnet50_quantized/demo.py,sha256=WTRZHUaAnWHPKjZvyvDF8XZU1dGrqfjoyjxYSGhLaos,587
 qai_hub_models/models/wideresnet50_quantized/export.py,sha256=A5Om4QPVJIFMeZtOfMOmvKH6qxpyaK94qtOzwFKbThU,8324
 qai_hub_models/models/wideresnet50_quantized/info.yaml,sha256=gP6lIjMqJDuVtTo8IqaoPNc2upCrOyBKfXBucpG-Mw0,1333
-qai_hub_models/models/wideresnet50_quantized/model.py,sha256=KjSPhueanU1RhsyIMhyBlhrxHC9U4t0JBSrvUk9RHOI,3004
-qai_hub_models/models/wideresnet50_quantized/perf.yaml,sha256=-11n-svAzdm4bGoTCBRLM6bZZqDdGv95UxZIv34_hqM,2760
+qai_hub_models/models/wideresnet50_quantized/model.py,sha256=8_KCwK6ydEW0fpAvBGfZlyqygntXmPP-5TavgJIE7WQ,3214
+qai_hub_models/models/wideresnet50_quantized/perf.yaml,sha256=VuC6HxovfmGnXd6oOyck-o43yAZR6ci1_Q4VCo9jdVA,4425
 qai_hub_models/models/wideresnet50_quantized/test.py,sha256=YJwhgaYpuN_9QXUb-o-vzZJnzKXR_x2iT0Xnqg82-xk,932
 qai_hub_models/models/xlsr/__init__.py,sha256=Xj4k054juNe3bPUFmKqSI-I5zJ7qJLcNhSoUEW8Qwgs,461
-qai_hub_models/models/xlsr/conftest.py,sha256=zYbQ3vq8qeCDF2hJche_4iehATwBKaqPqV792qIovS4,866
+qai_hub_models/models/xlsr/conftest.py,sha256=l87rPtEBFtemMnNBdUE0BahCIx6b6IM3PrOkFlorElY,976
 qai_hub_models/models/xlsr/demo.py,sha256=xBY0HiM5h0F6F5LSCMbRG6hiKsINFANd_ifc4NIrFyQ,742
 qai_hub_models/models/xlsr/export.py,sha256=EtqBZx-M-YqFMwVv4ImrltEA2MeNTjQdGss5mvaOL9Y,7994
 qai_hub_models/models/xlsr/info.yaml,sha256=2rij6izH-44dhEtjANktxfoMRctZpcEyvq2583qHVV0,1156
 qai_hub_models/models/xlsr/model.py,sha256=OaTY4JT5HHVVLXJaePfqgtC604FhAZzddfQTMx82y1w,3403
-qai_hub_models/models/xlsr/perf.yaml,sha256=sH-nIk_BXQ5DK54973ea4Q7Bdq79EBXYS827IAc68fk,2743
+qai_hub_models/models/xlsr/perf.yaml,sha256=cU7adOaB7m-AvrcR5eR3Qq5TAxEZ5gjpDGyvifFEL20,4411
 qai_hub_models/models/xlsr/test.py,sha256=Qyu0UUHhC2zr6cN-3u44Ag66nyD7Dod5o17Le3XRnfI,1402
 qai_hub_models/models/xlsr_quantized/__init__.py,sha256=T-8JP8m6jhMk9yhGMGibcnc_uDL-LMR_IHSc5zCqD_E,472
-qai_hub_models/models/xlsr_quantized/conftest.py,sha256=0K9EXoFGvMJ1Pruqx_CPHgyn7VhoiPD8LrGeGsV4YQM,886
+qai_hub_models/models/xlsr_quantized/conftest.py,sha256=TKSaSw43SGIfjzAdvROUYLHyQDKnOs7xnpjtAtRjssQ,996
 qai_hub_models/models/xlsr_quantized/demo.py,sha256=mWpJz3Ignt_53oi5Gn757OxdgTQoVWuz1KXESXaOXyk,956
 qai_hub_models/models/xlsr_quantized/export.py,sha256=p42FnLp0aR7DK6JeDMUZdXUndXa7l6cisUKAfF3UA2c,8447
 qai_hub_models/models/xlsr_quantized/info.yaml,sha256=6qK2zWzJLt9NrUj4EIX0gGSc_RfbExbFDVbmmDoB-Ts,1191
 qai_hub_models/models/xlsr_quantized/model.py,sha256=1gGN57aBaLu0sxnE5GFDYZ2TsvBIzydv1mEhgVB-zmo,3915
-qai_hub_models/models/xlsr_quantized/perf.yaml,sha256=QeXwvSROBR0hEIuSSb0NrOimH5GSAuPCnNFAB6uvzFQ,2701
+qai_hub_models/models/xlsr_quantized/perf.yaml,sha256=io21-9U8F_SJXuP8wqCXCsSzLVwwVR1xVXJQkH7D5a0,2474
 qai_hub_models/models/xlsr_quantized/test.py,sha256=b5hK1dbE8zYxn0fePctYKEbEQfIJBTETUjBZblBG5TY,1607
 qai_hub_models/models/yolov6/__init__.py,sha256=Nj-zEnhLQO70kQCq81cFp9dgULeIydtL993JsUebRVs,436
 qai_hub_models/models/yolov6/app.py,sha256=vZ9FeEPzCDxyetqe9PRRung35W7VlB2agaRnXPJ3a1I,1071
-qai_hub_models/models/yolov6/conftest.py,sha256=vwofRtJUU0c_j82jnb9PL-eRIfPTl8lLu7oWjY23eCM,870
+qai_hub_models/models/yolov6/conftest.py,sha256=W5Pcs3mpUtY08eLXsS9v5o0fyC8afky6QtrAhfUrcTU,980
 qai_hub_models/models/yolov6/demo.py,sha256=53T1nvu3uhTeAjz1OQC8UuOgdHqSYW0lLigjTGj6UD0,1027
 qai_hub_models/models/yolov6/export.py,sha256=gIV7YEiohUf3DaD4_3iKS4nR8tUdfO40nhE8nOWgXQ8,7897
 qai_hub_models/models/yolov6/info.yaml,sha256=lhJNwEPUVxBxRgiHqrAz4lV4Sr48haa7dASp65oXZYE,1168
 qai_hub_models/models/yolov6/model.py,sha256=M5LrnuwB1SE4sOQ-mXTeEtnEBbKCcyCNqiazGavHS5I,4686
-qai_hub_models/models/yolov6/perf.yaml,sha256=44mdomB2H9N7cp0qW-ZmCNHXiu2CFbCUpQLArvNvRq0,2760
+qai_hub_models/models/yolov6/perf.yaml,sha256=5mvAbuYgGjXvIDzMZF-Sz9Aped8FqZXz_vtjDR1zKZg,4431
 qai_hub_models/models/yolov6/test.py,sha256=LaGoMWkMYM-w4WgX8gomuU_3nWa4f-H8mDxNmjk22A0,1845
 qai_hub_models/models/yolov7/__init__.py,sha256=Eou1LnQavGFVBbp1fNjErCYGt5uD82Jy-ID8GRjZb50,436
-qai_hub_models/models/yolov7/app.py,sha256=zJTFNTkaBsIp9OA4T637ZtVWdqUTcbcHrO_7tMnu4I4,1071
-qai_hub_models/models/yolov7/conftest.py,sha256=gMg4_qiyzbNAAB3SD6b3uMD1C8_yc9svSYznfo-_AoQ,870
+qai_hub_models/models/yolov7/app.py,sha256=C_u1KX19yUvyWPCijwIawFhWPWWwIDY84PoIofAYQT4,2033
+qai_hub_models/models/yolov7/conftest.py,sha256=khUND0iZbc1v_tWA_f5fXSdBb6xegL8RB1gyhNJ6-1U,980
 qai_hub_models/models/yolov7/demo.py,sha256=d9tyOftqvwQdh_xP8Bo4xDAeoWx4mynA41caE18xKLY,909
 qai_hub_models/models/yolov7/export.py,sha256=3UcQoGig-Qb4LlUtSzX91iy9_goiPZ18lCGDHg89Ql8,7917
 qai_hub_models/models/yolov7/info.yaml,sha256=IafIJ3NrcVkjlgn9mn1OT44HhnS-Cle3Tq_8vAjX-fA,1131
-qai_hub_models/models/yolov7/model.py,sha256=bT1nwFN0cd3ChB7GJI6ugj_awHrOPZ1p3HV1f93kIFA,9640
-qai_hub_models/models/yolov7/perf.yaml,sha256=AZx5XWvKT5KFnvl2KisW2jyHHw1cG7nlB8qZrE5DiDY,2707
-qai_hub_models/models/yolov7/requirements.txt,sha256=pDV0cvQpiWR-FFERaC1gt9VuCEVTC7uCZIGcNg3Jzbk,47
-qai_hub_models/models/yolov7/test.py,sha256=8e_yblRMHSGrQhvfm3HpmAd8lGPYu8qccz4ejEcbq6M,2323
+qai_hub_models/models/yolov7/model.py,sha256=6JOXwTJKHIF_S1ckCpV1m9Uy06nwJoFj-hy2b2bdN1c,11831
+qai_hub_models/models/yolov7/perf.yaml,sha256=5WCUeT5clxoTLQfGfq6KcGkaQLARnP-UmemotvRs8Bg,3664
+qai_hub_models/models/yolov7/requirements.txt,sha256=PW4Lx0JxDAgGAISG4XX8_qTk1AAh9xaF5VUU9on5LG4,83
+qai_hub_models/models/yolov7/test.py,sha256=AtgMa81Mg20TrZaKK1aVSkZuj7jf0sjMXZ-kda5sfE4,2322
+qai_hub_models/models/yolov7_quantized/__init__.py,sha256=NceTvKTE95x6nsrxuUev_YhyWyBdFWfF_BfGT3H9ajU,447
+qai_hub_models/models/yolov7_quantized/conftest.py,sha256=OcFsNtcxY6tyuJbTDxYk-QcrEHouv33riqLTsWChZhU,1000
+qai_hub_models/models/yolov7_quantized/demo.py,sha256=ksBNS182rXuOGjOKclcsnKfN8wqmL9P1IWHO7YCXHHg,853
+qai_hub_models/models/yolov7_quantized/export.py,sha256=4rwoYoBHEb7sPhc5MmivsmWQ0scz6y5y6-UV5IvPhmM,8330
+qai_hub_models/models/yolov7_quantized/info.yaml,sha256=DxF2q2V6Hy3wV1IUvmUhowiciPxKfeEyqypOCoBqIIk,1318
+qai_hub_models/models/yolov7_quantized/model.py,sha256=0Pkn-GXEQ0Q0OyHu3V6ucZpowFuHUh7ZXxP24XvhR7A,4728
+qai_hub_models/models/yolov7_quantized/perf.yaml,sha256=ZDaPqg66bpQa2DnpFRZIOArG-mDFfS8h6Sq78hlGEJc,3270
+qai_hub_models/models/yolov7_quantized/requirements.txt,sha256=PW4Lx0JxDAgGAISG4XX8_qTk1AAh9xaF5VUU9on5LG4,83
+qai_hub_models/models/yolov7_quantized/test.py,sha256=siyZWwe4gssoTj12kyVRMr6OWOrpz_X3Ae828ZpAHEw,1558
 qai_hub_models/models/yolov8_det/__init__.py,sha256=Nb2Zbj0lG9sZBbpuQNXewrVWXEWCWVeP4lceLzYEhnw,415
 qai_hub_models/models/yolov8_det/app.py,sha256=av7rEkUBYQeL6bO24j_8C_RjLGzR-iO9QG4a_tQ89yo,892
-qai_hub_models/models/yolov8_det/conftest.py,sha256=vucyR2V6CA8YQqFbRcRQ_-6cEMuUDZrUVmlT9TTcVSo,792
+qai_hub_models/models/yolov8_det/conftest.py,sha256=iYtPWbHBhsOP75MK1q_7MXLETanrZM8HuRe9Go2sBG8,988
 qai_hub_models/models/yolov8_det/demo.py,sha256=wQWSWP6jzBUI9jUo5yA8P2Of-JE9IXI1DguJ2mg8du0,926
 qai_hub_models/models/yolov8_det/export.py,sha256=S4fhP3pbFH5HXgxNxb0urRBnbQLDhZYjtCgULhAaJd8,7951
-qai_hub_models/models/yolov8_det/info.yaml,sha256=lCDVEt4SBdypppnQ4X6yjvHe4TIoG-lYDiA2o6Ca730,1163
-qai_hub_models/models/yolov8_det/model.py,sha256=WVTOjHFvTFW_VX-VbmDG95hzMyzq2t0Qt6CYHC-asII,4637
+qai_hub_models/models/yolov8_det/info.yaml,sha256=nkmJtXLXqc8u7zPVbu0F0ztsfGtrQ7dPtVPqJaGWkO8,1171
+qai_hub_models/models/yolov8_det/model.py,sha256=AzwFCVZkftf5VCD0znp_h1HKPh62_GSA7HTsCI--Rq4,7721
 qai_hub_models/models/yolov8_det/perf.yaml,sha256=OFGlCVDTzvn_qreH2Uhdwz3v4DxLM_5tmwfOVBUHpeI,2768
-qai_hub_models/models/yolov8_det/requirements.txt,sha256=bzLR7n9PMXzABwKJJUEb6gOX23t_wZuYJkbyRPJjjQI,64
-qai_hub_models/models/yolov8_det/test.py,sha256=DYt7dJIxkqcR_HsTcpBl_xu_uHyfraQ3S9c9k_qPPbc,2080
+qai_hub_models/models/yolov8_det/requirements.txt,sha256=KeSSTmOmqqXkmr85OvV2DHCUUVVwe3wB7bLEQFKdwfg,100
+qai_hub_models/models/yolov8_det/test.py,sha256=3FiaunOU6sy0X_MKDxlV2-sOGaJ0qZUV26WCDZmcQrE,2270
+qai_hub_models/models/yolov8_det_quantized/__init__.py,sha256=bQ-K9zPqN3IIaEPpmzX0zB0JGpk1ggt_C2IpOa4sQlw,459
+qai_hub_models/models/yolov8_det_quantized/conftest.py,sha256=h1stkj98LYCn2O9GnD-qS683tdhGyDfLjPWVEks0ORQ,1008
+qai_hub_models/models/yolov8_det_quantized/demo.py,sha256=ekFtmhgdxaaaqJSNC11Rz-6HgIO9yvVlPfdjQZnBuMs,804
+qai_hub_models/models/yolov8_det_quantized/export.py,sha256=JIKrDKUEV0GsaBJO14sq-fmLCXUaA4kmZmvZfJ7-42Y,8351
+qai_hub_models/models/yolov8_det_quantized/info.yaml,sha256=9b68CjV_PSrw7K5Z65IXvvPkyH3FhERnkblNJEU-Tm8,1354
+qai_hub_models/models/yolov8_det_quantized/model.py,sha256=BeEaUPdbgZEZjWlQrBnxtKzUKXatByqjDFV-_RmhVvs,3540
+qai_hub_models/models/yolov8_det_quantized/perf.yaml,sha256=XEpQPHaRzp5WR_ADQQrAiXm0QHDCadFrG-v_AG9SE6Y,3279
+qai_hub_models/models/yolov8_det_quantized/requirements.txt,sha256=KeSSTmOmqqXkmr85OvV2DHCUUVVwe3wB7bLEQFKdwfg,100
+qai_hub_models/models/yolov8_det_quantized/test.py,sha256=IFXvXCBWHsuleQUM3C8LaeTtpTg3mq7aTd6AD0quNCk,1542
 qai_hub_models/models/yolov8_seg/__init__.py,sha256=lX4Am1C4ATTR-7lkE-t0OObLD1MzUuPH8EgaNNZRKcY,419
 qai_hub_models/models/yolov8_seg/app.py,sha256=J0ULAGgwVPwk3qA_YbJ8QI9HSaK2z4ziPFifs4SigZ0,7698
-qai_hub_models/models/yolov8_seg/conftest.py,sha256=GHw8cJdevbI0iHZQL5d0Lb2fdV2nJyu12Zl7e2B7oOw,792
+qai_hub_models/models/yolov8_seg/conftest.py,sha256=rmpvVr-xnXSfAptDun-JRUkbpRNUNYGTAqO6kAWCy5I,902
 qai_hub_models/models/yolov8_seg/demo.py,sha256=vSnKZpPUHS1JoFvo7BHU3Ob3LRUyu4AUVimU5JeikjU,3155
 qai_hub_models/models/yolov8_seg/export.py,sha256=70_xLG5FO6PL0AKRl_UFbAE8ymujl0F-hWkWkWsQcG8,7974
-qai_hub_models/models/yolov8_seg/info.yaml,sha256=LBUF30kgP7bUxSYhsgcWDAsiQMo1LdJGqh8rebwVT44,1273
+qai_hub_models/models/yolov8_seg/info.yaml,sha256=pNHALG4CJQq4sYjwljtyRttWOqx8bUWBYkSrV3R335Y,1287
 qai_hub_models/models/yolov8_seg/model.py,sha256=Ge6Jt8U-Ibc55bgJqWi5B15h6VNf3fP6jLOrZBeDx-4,4663
-qai_hub_models/models/yolov8_seg/perf.yaml,sha256=EJFYQGruRl5PEycM_YG1BEr-9p115bCFyVK_pNlXUF4,2710
+qai_hub_models/models/yolov8_seg/perf.yaml,sha256=1FpCyF9bexHtrfHK1vuvLNDRiz31nckhG1ffB3Tfuw4,3665
 qai_hub_models/models/yolov8_seg/requirements.txt,sha256=bzLR7n9PMXzABwKJJUEb6gOX23t_wZuYJkbyRPJjjQI,64
 qai_hub_models/models/yolov8_seg/test.py,sha256=pagCgV1nOZpFXyx8Z34mi6b4okh7hMIPxbGzhNzT6iY,2536
 qai_hub_models/test/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/test/test_async_compile_jobs.py,sha256=YpUEjSSeDKtLUYeglO0OxIH1ph5z88Lmz1W0VIAl9xw,1043
 qai_hub_models/test/e2e/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/test/e2e/test_aimet_compile.py,sha256=q4dXkf3-pvNK_mR5OmgQv0ZzAFPfPRyOB1rC9ZXqTT4,1661
 qai_hub_models/test/test_utils/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/test/test_utils/perf.yaml,sha256=XjLXpqrOwleDdnxWXkgyZZtkRHTq6UoLkaKIAVdTl-U,1493
 qai_hub_models/test/test_utils/test_info_specs.py,sha256=zSIdFoI8SOrcy8MmwC2j7vMAzZFZCBJ-rWvXpMZteLE,3229
-qai_hub_models/test/test_utils/test_perf_summary.py,sha256=QxNL6zRLVPNtMYtm_JNDLpvPa8IWwVEYhNXU1zBgHVo,6515
+qai_hub_models/test/test_utils/test_perf_summary.py,sha256=BRlkxFyjaq5wqTA14rHE5xbbsDwt6qJ2yp1s82f5bek,6525
 qai_hub_models/test/test_utils/test_qai_hub_helpers.py,sha256=0pwOk90MDeUJjubQaMDC8NSTtcX_PABa6mdLZJdpGWU,3295
 qai_hub_models/utils/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/utils/args.py,sha256=H3jQYkCF7ZngVE_d-JJGfKVf91KjLmsaweCSpgO5KXg,16452
-qai_hub_models/utils/asset_loaders.py,sha256=eCGHfl9eN_ka5dVV8sNZi00xK45rDZJwoAhInKQTXdU,33565
+qai_hub_models/utils/asset_loaders.py,sha256=ZFkgBC9vCBumh4t8-RGaayQW9MFODdDibaCjHJM641Y,34094
 qai_hub_models/utils/base_model.py,sha256=6nrJ9qY8L5NHuMEpcDfOholAOPiaLqxttA2z48HCvaY,6052
-qai_hub_models/utils/bounding_box_processing.py,sha256=N_UrLd_mR6qYxmlkjL-etjDSH4QFq4i_mNSC7EGlLpg,8707
+qai_hub_models/utils/bounding_box_processing.py,sha256=Y7-situFnXBfbr2_hbKX1VTyr7u9mZDfuymEF0Ki82k,9261
 qai_hub_models/utils/camera_capture.py,sha256=9W3v2XIEUB2lRuO6DYtLLZs-aaRMwh29Vu7eeQN3M_Q,1771
 qai_hub_models/utils/compare.py,sha256=C-Oj8YSdi5OiLpet-Quxhiaica4KrGnCgimfo4rzeBk,5222
 qai_hub_models/utils/config_loaders.py,sha256=vTnqqrNtu1kn1zASMErFHD60hrtFDwFe4nhy6gNbXKE,32743
 qai_hub_models/utils/display.py,sha256=YlvgoKyKVckfSJfbIbWC110LyQ2ziqK1ZKZUXeggU7c,3066
 qai_hub_models/utils/draw.py,sha256=o5N3H1-QKXKA7gIKaQ7tclI2gjRPiPyvIo-CJqbL7Cs,6403
 qai_hub_models/utils/huggingface.py,sha256=OSLKW14892oyrAYn3ovL1d-TUVHDja-BVylnlnDQnSI,1549
-qai_hub_models/utils/image_processing.py,sha256=1emzPHrWo7lg3RXMt4ENUzDX1gx9Vx-l5GCEawfH06Q,12490
+qai_hub_models/utils/image_processing.py,sha256=hYp8LJ0xoCRAzVs0QXafG7fr3aWmPEaBHTDLzJ8wc7w,13246
 qai_hub_models/utils/inference.py,sha256=hRR0jwhIoam_ydKri15bkbkyE2QwfT-adWSIucKTTjQ,12482
 qai_hub_models/utils/input_spec.py,sha256=3PW9fB0UufkPWiSoH_QPzzFix0Bv_SOYp75IOlAeGRc,1308
 qai_hub_models/utils/measurement.py,sha256=DUsed_0I6RcwD789evI0iCVHZma9z3GK0LF-BMfH2EA,4559
 qai_hub_models/utils/model_adapters.py,sha256=nJ47EPkXSdp8DwRbplCvekFo8sVgiWIgNfmE-l_WLsw,1577
-qai_hub_models/utils/model_card.py,sha256=4p8CALUXSaWIMgRJLir_QGyRgyfE04d1lWQQfxG45f8,12621
 qai_hub_models/utils/path_helpers.py,sha256=WM38eDNpJ3nkI7VyQDknnaEJ7p9BW3kjzjXFuhdHgK0,1406
-qai_hub_models/utils/perf_summary.py,sha256=eiCOrJ0ItEMJZNop7HjVjdyhXzJWwnnIThoUbqk-cys,11378
-qai_hub_models/utils/printing.py,sha256=qOIc-3RsM-TYe76hLQAneckqPXOfF-vl0FWJYvoHssk,4858
+qai_hub_models/utils/printing.py,sha256=3Gz9w9sqjPaQO0MMBQ2V5SMVSZ3w11lw3VEoIjD3pbY,5007
 qai_hub_models/utils/qai_hub_helpers.py,sha256=8v5uwdgSDi6jbXrhbmP_xXWdjC4lE7rFjdgxv2wgqbA,5365
 qai_hub_models/utils/qnn_helpers.py,sha256=TegEPjCtmcRtX2jj3JQlOpuuNHyW1x_X3kaDE2OpqsM,1463
 qai_hub_models/utils/quantization.py,sha256=ah5-teAxv075l2U2THUWUXUy4XF9zSfFE9gg2Uu0OKE,2170
-qai_hub_models/utils/quantization_aimet.py,sha256=oUOCSGHbpef8M2zXp7J6vxgsYf3c4RBwD0h2aiCIUzQ,11791
+qai_hub_models/utils/quantization_aimet.py,sha256=SNcwH-Pim52QqsdO8hUllVYmoF5_D-Xerbaz_WJInSU,17774
 qai_hub_models/utils/test_compare.py,sha256=m9jsmf6l30obMQAnlk88refyfP9HU3W_qcV1-tZq_7o,754
 qai_hub_models/utils/testing.py,sha256=sa2y5NXWyEVih5_0dL8qfTReXUt0pFgP7hpjlViuECM,3173
 qai_hub_models/utils/aimet/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
 qai_hub_models/utils/aimet/config_loader.py,sha256=KxZzYmw4550LnQnlJQclgulV2MHNJhxKkHYQDXu3bKU,876
-qai_hub_models/utils/aimet/default_config.json,sha256=E4HAeMyjdBuG5wQOoaxHvoL0Jbrw3yRLMJ6wCSxzoCI,993
+qai_hub_models/utils/aimet/default_config.json,sha256=uq3OIQ03ON9IHyRbNvLybGMPA4mpCXsE8yE_n57PqkI,1233
 qai_hub_models/utils/aimet/default_config_legacy_v1.json,sha256=2YxxGBslxx_u-bG8n9UGFzc12_13zS6DEQ3cJD5KxH8,946
 qai_hub_models/utils/aimet/default_config_legacy_v2.json,sha256=Beb1iFG4Uu_iCF5aoWNEZ_E4-rqfGbD_qtE5NEDnOKc,955
 qai_hub_models/utils/aimet/default_config_per_channel_qnn.json,sha256=G08RroTHx9H9VrlAcCya4gJ2B9tl1c23NN_SH8N8_Yk,919
 qai_hub_models/utils/aimet/repo.py,sha256=d33BJ9T8pUXA_lOE9uwJrdUn-tH_a2wetk82CewnsAI,1187
-qai_hub_models-0.4.1.dist-info/LICENSE,sha256=i2rmENXGu1jwHqNMu7arhPkIcgMnWTcOyMyXktqe5PA,1481
-qai_hub_models-0.4.1.dist-info/METADATA,sha256=8fNPgG4aaDoxrIS0OropZAaqy_8BfOz4rtJfxa8Yq3I,40686
-qai_hub_models-0.4.1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-qai_hub_models-0.4.1.dist-info/top_level.txt,sha256=p1WCkillFWC1qnvse7gwhc-dqH0dNRTpd4Xe-wqn4IY,15
-qai_hub_models-0.4.1.dist-info/RECORD,,
+qai_hub_models/utils/scorecard/__init__.py,sha256=M8gSdRkFNJhhoTjURjFFwAos_vFZBfrK9VNXYB7yEzo,259
+qai_hub_models/utils/scorecard/common.py,sha256=w2l4xccVavD3lLJ7-1fLBTCcUDk7JDW01tMi3dFxsBs,1468
+qai_hub_models/utils/scorecard/job_summary.py,sha256=r8dZXCfo5VMKNa5KgC6loxq1uyaY0chLfFGpFFhaiq0,12269
+qai_hub_models/utils/scorecard/model_card.py,sha256=Src_R8XdlkoQDcXKlpX7LLIMy3sWpTiwgzcX5EWNyUI,13385
+qai_hub_models/utils/scorecard/perf_summary.py,sha256=nrAKooK5FxonON_qbe45nDw933r0s0rFTHdvNmccxGA,11415
+qai_hub_models-0.5.0.dist-info/LICENSE,sha256=i2rmENXGu1jwHqNMu7arhPkIcgMnWTcOyMyXktqe5PA,1481
+qai_hub_models-0.5.0.dist-info/METADATA,sha256=kyKcL3WSvXkr9LBnSOHQ9dfacY64azQsqrpYLIONRsE,42594
+qai_hub_models-0.5.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+qai_hub_models-0.5.0.dist-info/top_level.txt,sha256=p1WCkillFWC1qnvse7gwhc-dqH0dNRTpd4Xe-wqn4IY,15
+qai_hub_models-0.5.0.dist-info/RECORD,,
```


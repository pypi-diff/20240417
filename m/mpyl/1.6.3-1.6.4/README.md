# Comparing `tmp/mpyl-1.6.3-py3-none-any.whl.zip` & `tmp/mpyl-1.6.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,113 +1,114 @@
-Zip file size: 257038 bytes, number of entries: 111
--rw-r--r--  2.0 unx     1278 b- defN 24-Apr-04 14:02 mpyl/__init__.py
--rw-r--r--  2.0 unx      215 b- defN 24-Apr-04 14:02 mpyl/__main__.py
--rw-r--r--  2.0 unx     7547 b- defN 24-Apr-04 14:02 mpyl/build.py
--rw-r--r--  2.0 unx      260 b- defN 24-Apr-04 14:02 mpyl/constants.py
--rw-r--r--  2.0 unx    20754 b- defN 24-Apr-04 14:02 mpyl/project.py
--rw-r--r--  2.0 unx      574 b- defN 24-Apr-04 14:02 mpyl/project_execution.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-04 14:02 mpyl/py.typed
--rw-r--r--  2.0 unx     2370 b- defN 24-Apr-04 14:02 mpyl/validation.py
--rw-r--r--  2.0 unx       60 b- defN 24-Apr-04 14:02 mpyl/artifacts/__init__.py
--rw-r--r--  2.0 unx     9221 b- defN 24-Apr-04 14:02 mpyl/artifacts/build_artifacts.py
--rw-r--r--  2.0 unx     3512 b- defN 24-Apr-04 14:02 mpyl/cli/__init__.py
--rw-r--r--  2.0 unx    18002 b- defN 24-Apr-04 14:02 mpyl/cli/build.py
--rw-r--r--  2.0 unx      614 b- defN 24-Apr-04 14:02 mpyl/cli/health.py
--rw-r--r--  2.0 unx     2417 b- defN 24-Apr-04 14:02 mpyl/cli/meta_info.py
--rw-r--r--  2.0 unx     8536 b- defN 24-Apr-04 14:02 mpyl/cli/projects.py
--rw-r--r--  2.0 unx     7860 b- defN 24-Apr-04 14:02 mpyl/cli/repository.py
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-04 14:02 mpyl/cli/commands/__init__.py
--rw-r--r--  2.0 unx      425 b- defN 24-Apr-04 14:02 mpyl/cli/commands/build/__init__.py
--rw-r--r--  2.0 unx     1261 b- defN 24-Apr-04 14:02 mpyl/cli/commands/build/artifacts.py
--rw-r--r--  2.0 unx     4524 b- defN 24-Apr-04 14:02 mpyl/cli/commands/build/jenkins.py
--rw-r--r--  2.0 unx       38 b- defN 24-Apr-04 14:02 mpyl/cli/commands/health/__init__.py
--rw-r--r--  2.0 unx     8248 b- defN 24-Apr-04 14:02 mpyl/cli/commands/health/checks.py
--rw-r--r--  2.0 unx       52 b- defN 24-Apr-04 14:02 mpyl/cli/commands/projects/__init__.py
--rw-r--r--  2.0 unx     1771 b- defN 24-Apr-04 14:02 mpyl/cli/commands/projects/formatting.py
--rw-r--r--  2.0 unx     6356 b- defN 24-Apr-04 14:02 mpyl/cli/commands/projects/lint.py
--rw-r--r--  2.0 unx      659 b- defN 24-Apr-04 14:02 mpyl/cli/commands/projects/upgrade.py
--rw-r--r--  2.0 unx      620 b- defN 24-Apr-04 14:02 mpyl/projects/__init__.py
--rw-r--r--  2.0 unx     2006 b- defN 24-Apr-04 14:02 mpyl/projects/find.py
--rw-r--r--  2.0 unx    12121 b- defN 24-Apr-04 14:02 mpyl/projects/versioning.py
--rw-r--r--  2.0 unx      327 b- defN 24-Apr-04 14:02 mpyl/projects/releases/releases.txt
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-04 14:02 mpyl/reporting/__init__.py
--rw-r--r--  2.0 unx       76 b- defN 24-Apr-04 14:02 mpyl/reporting/formatting/__init__.py
--rw-r--r--  2.0 unx     5742 b- defN 24-Apr-04 14:02 mpyl/reporting/formatting/markdown.py
--rw-r--r--  2.0 unx     1340 b- defN 24-Apr-04 14:02 mpyl/reporting/formatting/text.py
--rw-r--r--  2.0 unx     1139 b- defN 24-Apr-04 14:02 mpyl/reporting/targets/__init__.py
--rw-r--r--  2.0 unx     8932 b- defN 24-Apr-04 14:02 mpyl/reporting/targets/github.py
--rw-r--r--  2.0 unx     9568 b- defN 24-Apr-04 14:02 mpyl/reporting/targets/jira.py
--rw-r--r--  2.0 unx     8064 b- defN 24-Apr-04 14:02 mpyl/reporting/targets/slack.py
--rw-r--r--  2.0 unx    11326 b- defN 24-Apr-04 14:02 mpyl/schema/k8s_api_core.schema.yml
--rw-r--r--  2.0 unx    12912 b- defN 24-Apr-04 14:02 mpyl/schema/mpyl_config.schema.yml
--rw-r--r--  2.0 unx    24550 b- defN 24-Apr-04 14:02 mpyl/schema/project.schema.yml
--rw-r--r--  2.0 unx     3296 b- defN 24-Apr-04 14:02 mpyl/schema/run_properties.schema.yml
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-04 14:02 mpyl/stages/__init__.py
--rw-r--r--  2.0 unx     8913 b- defN 24-Apr-04 14:02 mpyl/stages/discovery.py
--rw-r--r--  2.0 unx     6456 b- defN 24-Apr-04 14:02 mpyl/steps/__init__.py
--rw-r--r--  2.0 unx     2686 b- defN 24-Apr-04 14:02 mpyl/steps/collection.py
--rw-r--r--  2.0 unx     8509 b- defN 24-Apr-04 14:02 mpyl/steps/models.py
--rw-r--r--  2.0 unx     4242 b- defN 24-Apr-04 14:02 mpyl/steps/run.py
--rw-r--r--  2.0 unx     3407 b- defN 24-Apr-04 14:02 mpyl/steps/run_properties.py
--rw-r--r--  2.0 unx     9692 b- defN 24-Apr-04 14:02 mpyl/steps/steps.py
--rw-r--r--  2.0 unx       80 b- defN 24-Apr-04 14:02 mpyl/steps/build/__init__.py
--rw-r--r--  2.0 unx     5037 b- defN 24-Apr-04 14:02 mpyl/steps/build/docker_build.py
--rw-r--r--  2.0 unx     1195 b- defN 24-Apr-04 14:02 mpyl/steps/build/echo.py
--rw-r--r--  2.0 unx     2187 b- defN 24-Apr-04 14:02 mpyl/steps/build/post_docker_build.py
--rw-r--r--  2.0 unx     2714 b- defN 24-Apr-04 14:02 mpyl/steps/build/sbt.py
--rw-r--r--  2.0 unx      884 b- defN 24-Apr-04 14:02 mpyl/steps/build/skip.py
--rw-r--r--  2.0 unx       82 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/__init__.py
--rw-r--r--  2.0 unx     7596 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/dagster.py
--rw-r--r--  2.0 unx     1078 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/echo.py
--rw-r--r--  2.0 unx     1533 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/ephemeral_docker_deploy.py
--rw-r--r--  2.0 unx     3221 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/kubernetes.py
--rw-r--r--  2.0 unx     1115 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/kubernetes_job.py
--rw-r--r--  2.0 unx     1188 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/kubernetes_spark_job.py
--rw-r--r--  2.0 unx    10995 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/__init__.py
--rw-r--r--  2.0 unx    28949 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/chart.py
--rw-r--r--  2.0 unx     1276 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/deploy_config.py
--rw-r--r--  2.0 unx     5080 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/helm.py
--rw-r--r--  2.0 unx     1594 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/rancher.py
--rw-r--r--  2.0 unx     4868 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/__init__.py
--rw-r--r--  2.0 unx     3368 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/dagster.py
--rw-r--r--  2.0 unx     2260 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/prometheus.py
--rw-r--r--  2.0 unx      616 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/sealed_secret.py
--rw-r--r--  2.0 unx     5895 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/spark.py
--rw-r--r--  2.0 unx     2818 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/traefik.py
--rw-r--r--  2.0 unx   582312 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
--rw-r--r--  2.0 unx    39299 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
--rw-r--r--  2.0 unx   168371 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
--rw-r--r--  2.0 unx   151469 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
--rw-r--r--  2.0 unx    11703 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
--rw-r--r--  2.0 unx    42950 b- defN 24-Apr-04 14:02 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
--rw-r--r--  2.0 unx       90 b- defN 24-Apr-04 14:02 mpyl/steps/postdeploy/__init__.py
--rw-r--r--  2.0 unx     8518 b- defN 24-Apr-04 14:02 mpyl/steps/postdeploy/cypress_test.py
--rw-r--r--  2.0 unx       78 b- defN 24-Apr-04 14:02 mpyl/steps/test/__init__.py
--rw-r--r--  2.0 unx     1574 b- defN 24-Apr-04 14:02 mpyl/steps/test/after_test.py
--rw-r--r--  2.0 unx     4153 b- defN 24-Apr-04 14:02 mpyl/steps/test/before_test.py
--rw-r--r--  2.0 unx     4606 b- defN 24-Apr-04 14:02 mpyl/steps/test/dockertest.py
--rw-r--r--  2.0 unx     1937 b- defN 24-Apr-04 14:02 mpyl/steps/test/echo.py
--rw-r--r--  2.0 unx     4580 b- defN 24-Apr-04 14:02 mpyl/steps/test/sbt.py
--rw-r--r--  2.0 unx      878 b- defN 24-Apr-04 14:02 mpyl/steps/test/skip.py
--rw-r--r--  2.0 unx      346 b- defN 24-Apr-04 14:02 mpyl/utilities/__init__.py
--rw-r--r--  2.0 unx      953 b- defN 24-Apr-04 14:02 mpyl/utilities/cypress/__init__.py
--rw-r--r--  2.0 unx     1068 b- defN 24-Apr-04 14:02 mpyl/utilities/dagster/__init__.py
--rw-r--r--  2.0 unx    13237 b- defN 24-Apr-04 14:02 mpyl/utilities/docker/__init__.py
--rw-r--r--  2.0 unx     1938 b- defN 24-Apr-04 14:02 mpyl/utilities/github/__init__.py
--rw-r--r--  2.0 unx     1034 b- defN 24-Apr-04 14:02 mpyl/utilities/helm/__init__.py
--rw-r--r--  2.0 unx     1566 b- defN 24-Apr-04 14:02 mpyl/utilities/jenkins/__init__.py
--rw-r--r--  2.0 unx     7910 b- defN 24-Apr-04 14:02 mpyl/utilities/jenkins/runner.py
--rw-r--r--  2.0 unx     1488 b- defN 24-Apr-04 14:02 mpyl/utilities/junit/__init__.py
--rw-r--r--  2.0 unx      318 b- defN 24-Apr-04 14:02 mpyl/utilities/logging/__init__.py
--rw-r--r--  2.0 unx     1003 b- defN 24-Apr-04 14:02 mpyl/utilities/parallel/__init__.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-04 14:02 mpyl/utilities/pyaml_env/__init__.py
--rw-r--r--  2.0 unx    13604 b- defN 24-Apr-04 14:02 mpyl/utilities/repo/__init__.py
--rw-r--r--  2.0 unx     1589 b- defN 24-Apr-04 14:02 mpyl/utilities/sbt/__init__.py
--rw-r--r--  2.0 unx     2573 b- defN 24-Apr-04 14:02 mpyl/utilities/subprocess/__init__.py
--rw-r--r--  2.0 unx      868 b- defN 24-Apr-04 14:02 mpyl/utilities/yaml/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/LICENSE
--rw-r--r--  2.0 unx     6195 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/WHEEL
--rw-r--r--  2.0 unx       35 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        5 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     9857 b- defN 24-Apr-04 14:03 mpyl-1.6.3.dist-info/RECORD
-111 files, 1448657 bytes uncompressed, 241354 bytes compressed:  83.3%
+Zip file size: 257958 bytes, number of entries: 112
+-rw-r--r--  2.0 unx     1278 b- defN 24-Apr-17 10:57 mpyl/__init__.py
+-rw-r--r--  2.0 unx      215 b- defN 24-Apr-17 10:57 mpyl/__main__.py
+-rw-r--r--  2.0 unx     7535 b- defN 24-Apr-17 10:57 mpyl/build.py
+-rw-r--r--  2.0 unx      304 b- defN 24-Apr-17 10:57 mpyl/constants.py
+-rw-r--r--  2.0 unx    20750 b- defN 24-Apr-17 10:57 mpyl/project.py
+-rw-r--r--  2.0 unx      574 b- defN 24-Apr-17 10:57 mpyl/project_execution.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-17 10:57 mpyl/py.typed
+-rw-r--r--  2.0 unx      681 b- defN 24-Apr-17 10:57 mpyl/run_plan.py
+-rw-r--r--  2.0 unx     2370 b- defN 24-Apr-17 10:57 mpyl/validation.py
+-rw-r--r--  2.0 unx       60 b- defN 24-Apr-17 10:57 mpyl/artifacts/__init__.py
+-rw-r--r--  2.0 unx     9222 b- defN 24-Apr-17 10:57 mpyl/artifacts/build_artifacts.py
+-rw-r--r--  2.0 unx     3512 b- defN 24-Apr-17 10:57 mpyl/cli/__init__.py
+-rw-r--r--  2.0 unx    18085 b- defN 24-Apr-17 10:57 mpyl/cli/build.py
+-rw-r--r--  2.0 unx      614 b- defN 24-Apr-17 10:57 mpyl/cli/health.py
+-rw-r--r--  2.0 unx     2417 b- defN 24-Apr-17 10:57 mpyl/cli/meta_info.py
+-rw-r--r--  2.0 unx     8536 b- defN 24-Apr-17 10:57 mpyl/cli/projects.py
+-rw-r--r--  2.0 unx     7944 b- defN 24-Apr-17 10:57 mpyl/cli/repository.py
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-17 10:57 mpyl/cli/commands/__init__.py
+-rw-r--r--  2.0 unx      425 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/__init__.py
+-rw-r--r--  2.0 unx     1261 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/artifacts.py
+-rw-r--r--  2.0 unx     4524 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/jenkins.py
+-rw-r--r--  2.0 unx       38 b- defN 24-Apr-17 10:57 mpyl/cli/commands/health/__init__.py
+-rw-r--r--  2.0 unx     8248 b- defN 24-Apr-17 10:57 mpyl/cli/commands/health/checks.py
+-rw-r--r--  2.0 unx       52 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/__init__.py
+-rw-r--r--  2.0 unx     1771 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/formatting.py
+-rw-r--r--  2.0 unx     6356 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/lint.py
+-rw-r--r--  2.0 unx      659 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/upgrade.py
+-rw-r--r--  2.0 unx      620 b- defN 24-Apr-17 10:57 mpyl/projects/__init__.py
+-rw-r--r--  2.0 unx     2006 b- defN 24-Apr-17 10:57 mpyl/projects/find.py
+-rw-r--r--  2.0 unx    12121 b- defN 24-Apr-17 10:57 mpyl/projects/versioning.py
+-rw-r--r--  2.0 unx      333 b- defN 24-Apr-17 10:57 mpyl/projects/releases/releases.txt
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 10:57 mpyl/reporting/__init__.py
+-rw-r--r--  2.0 unx       76 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/__init__.py
+-rw-r--r--  2.0 unx     5797 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/markdown.py
+-rw-r--r--  2.0 unx     1340 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/text.py
+-rw-r--r--  2.0 unx     1139 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/__init__.py
+-rw-r--r--  2.0 unx     8932 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/github.py
+-rw-r--r--  2.0 unx     9568 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/jira.py
+-rw-r--r--  2.0 unx     8064 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/slack.py
+-rw-r--r--  2.0 unx    11326 b- defN 24-Apr-17 10:57 mpyl/schema/k8s_api_core.schema.yml
+-rw-r--r--  2.0 unx    12912 b- defN 24-Apr-17 10:57 mpyl/schema/mpyl_config.schema.yml
+-rw-r--r--  2.0 unx    24550 b- defN 24-Apr-17 10:57 mpyl/schema/project.schema.yml
+-rw-r--r--  2.0 unx     3296 b- defN 24-Apr-17 10:57 mpyl/schema/run_properties.schema.yml
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-17 10:57 mpyl/stages/__init__.py
+-rw-r--r--  2.0 unx    10713 b- defN 24-Apr-17 10:57 mpyl/stages/discovery.py
+-rw-r--r--  2.0 unx     6456 b- defN 24-Apr-17 10:57 mpyl/steps/__init__.py
+-rw-r--r--  2.0 unx     2686 b- defN 24-Apr-17 10:57 mpyl/steps/collection.py
+-rw-r--r--  2.0 unx     8460 b- defN 24-Apr-17 10:57 mpyl/steps/models.py
+-rw-r--r--  2.0 unx     4320 b- defN 24-Apr-17 10:57 mpyl/steps/run.py
+-rw-r--r--  2.0 unx     3376 b- defN 24-Apr-17 10:57 mpyl/steps/run_properties.py
+-rw-r--r--  2.0 unx     9692 b- defN 24-Apr-17 10:57 mpyl/steps/steps.py
+-rw-r--r--  2.0 unx       80 b- defN 24-Apr-17 10:57 mpyl/steps/build/__init__.py
+-rw-r--r--  2.0 unx     5034 b- defN 24-Apr-17 10:57 mpyl/steps/build/docker_build.py
+-rw-r--r--  2.0 unx     1195 b- defN 24-Apr-17 10:57 mpyl/steps/build/echo.py
+-rw-r--r--  2.0 unx     2187 b- defN 24-Apr-17 10:57 mpyl/steps/build/post_docker_build.py
+-rw-r--r--  2.0 unx     2714 b- defN 24-Apr-17 10:57 mpyl/steps/build/sbt.py
+-rw-r--r--  2.0 unx      884 b- defN 24-Apr-17 10:57 mpyl/steps/build/skip.py
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/__init__.py
+-rw-r--r--  2.0 unx     7596 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/dagster.py
+-rw-r--r--  2.0 unx     1078 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/echo.py
+-rw-r--r--  2.0 unx     1533 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/ephemeral_docker_deploy.py
+-rw-r--r--  2.0 unx     3221 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes.py
+-rw-r--r--  2.0 unx     1115 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes_job.py
+-rw-r--r--  2.0 unx     1188 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes_spark_job.py
+-rw-r--r--  2.0 unx    11433 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/__init__.py
+-rw-r--r--  2.0 unx    28949 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/chart.py
+-rw-r--r--  2.0 unx     1276 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/deploy_config.py
+-rw-r--r--  2.0 unx     5080 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/helm.py
+-rw-r--r--  2.0 unx     1594 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/rancher.py
+-rw-r--r--  2.0 unx     4868 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/__init__.py
+-rw-r--r--  2.0 unx     3368 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/dagster.py
+-rw-r--r--  2.0 unx     2260 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/prometheus.py
+-rw-r--r--  2.0 unx      616 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/sealed_secret.py
+-rw-r--r--  2.0 unx     5895 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/spark.py
+-rw-r--r--  2.0 unx     2818 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/traefik.py
+-rw-r--r--  2.0 unx   582312 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
+-rw-r--r--  2.0 unx    39299 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
+-rw-r--r--  2.0 unx   168371 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
+-rw-r--r--  2.0 unx   151469 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
+-rw-r--r--  2.0 unx    11703 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
+-rw-r--r--  2.0 unx    42950 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
+-rw-r--r--  2.0 unx       90 b- defN 24-Apr-17 10:57 mpyl/steps/postdeploy/__init__.py
+-rw-r--r--  2.0 unx     8518 b- defN 24-Apr-17 10:57 mpyl/steps/postdeploy/cypress_test.py
+-rw-r--r--  2.0 unx       78 b- defN 24-Apr-17 10:57 mpyl/steps/test/__init__.py
+-rw-r--r--  2.0 unx     1574 b- defN 24-Apr-17 10:57 mpyl/steps/test/after_test.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-Apr-17 10:57 mpyl/steps/test/before_test.py
+-rw-r--r--  2.0 unx     4652 b- defN 24-Apr-17 10:57 mpyl/steps/test/dockertest.py
+-rw-r--r--  2.0 unx     1937 b- defN 24-Apr-17 10:57 mpyl/steps/test/echo.py
+-rw-r--r--  2.0 unx     4622 b- defN 24-Apr-17 10:57 mpyl/steps/test/sbt.py
+-rw-r--r--  2.0 unx      878 b- defN 24-Apr-17 10:57 mpyl/steps/test/skip.py
+-rw-r--r--  2.0 unx      346 b- defN 24-Apr-17 10:57 mpyl/utilities/__init__.py
+-rw-r--r--  2.0 unx      953 b- defN 24-Apr-17 10:57 mpyl/utilities/cypress/__init__.py
+-rw-r--r--  2.0 unx     1068 b- defN 24-Apr-17 10:57 mpyl/utilities/dagster/__init__.py
+-rw-r--r--  2.0 unx    13237 b- defN 24-Apr-17 10:57 mpyl/utilities/docker/__init__.py
+-rw-r--r--  2.0 unx     1938 b- defN 24-Apr-17 10:57 mpyl/utilities/github/__init__.py
+-rw-r--r--  2.0 unx     1034 b- defN 24-Apr-17 10:57 mpyl/utilities/helm/__init__.py
+-rw-r--r--  2.0 unx     1566 b- defN 24-Apr-17 10:57 mpyl/utilities/jenkins/__init__.py
+-rw-r--r--  2.0 unx     7910 b- defN 24-Apr-17 10:57 mpyl/utilities/jenkins/runner.py
+-rw-r--r--  2.0 unx     1598 b- defN 24-Apr-17 10:57 mpyl/utilities/junit/__init__.py
+-rw-r--r--  2.0 unx      318 b- defN 24-Apr-17 10:57 mpyl/utilities/logging/__init__.py
+-rw-r--r--  2.0 unx     1003 b- defN 24-Apr-17 10:57 mpyl/utilities/parallel/__init__.py
+-rw-r--r--  2.0 unx      870 b- defN 24-Apr-17 10:57 mpyl/utilities/pyaml_env/__init__.py
+-rw-r--r--  2.0 unx    13604 b- defN 24-Apr-17 10:57 mpyl/utilities/repo/__init__.py
+-rw-r--r--  2.0 unx     1589 b- defN 24-Apr-17 10:57 mpyl/utilities/sbt/__init__.py
+-rw-r--r--  2.0 unx     2573 b- defN 24-Apr-17 10:57 mpyl/utilities/subprocess/__init__.py
+-rw-r--r--  2.0 unx      868 b- defN 24-Apr-17 10:57 mpyl/utilities/yaml/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6195 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       35 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        5 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     9930 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/RECORD
+112 files, 1452099 bytes uncompressed, 242166 bytes compressed:  83.3%
```

## zipnote {}

```diff
@@ -15,14 +15,17 @@
 
 Filename: mpyl/project_execution.py
 Comment: 
 
 Filename: mpyl/py.typed
 Comment: 
 
+Filename: mpyl/run_plan.py
+Comment: 
+
 Filename: mpyl/validation.py
 Comment: 
 
 Filename: mpyl/artifacts/__init__.py
 Comment: 
 
 Filename: mpyl/artifacts/build_artifacts.py
@@ -309,26 +312,26 @@
 
 Filename: mpyl/utilities/subprocess/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/yaml/__init__.py
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/LICENSE
+Filename: mpyl-1.6.4.dist-info/LICENSE
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/METADATA
+Filename: mpyl-1.6.4.dist-info/METADATA
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/WHEEL
+Filename: mpyl-1.6.4.dist-info/WHEEL
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/entry_points.txt
+Filename: mpyl-1.6.4.dist-info/entry_points.txt
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/top_level.txt
+Filename: mpyl-1.6.4.dist-info/top_level.txt
 Comment: 
 
-Filename: mpyl-1.6.3.dist-info/RECORD
+Filename: mpyl-1.6.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mpyl/build.py

```diff
@@ -1,21 +1,22 @@
 """Simple MPyL build runner"""
+
 import json
 import logging
 import os
 from pathlib import Path
 from typing import Optional, Union
 
 from jsonschema import ValidationError
 from rich.console import Console
 from rich.logging import RichHandler
 from rich.markdown import Markdown
 
 from .cli import CliContext, MpylCliParameters
-from .constants import DEFAULT_RUN_PROPERTIES_FILE_NAME, BUILD_ARTIFACTS_FOLDER
+from .constants import DEFAULT_RUN_PROPERTIES_FILE_NAME, RUN_ARTIFACTS_FOLDER
 from .reporting.formatting.markdown import (
     execution_plan_as_markdown,
     run_result_to_markdown,
 )
 from .reporting.targets import Reporter
 from .steps import deploy
 from .steps.collection import StepsCollection
@@ -32,37 +33,37 @@
         config=obj.config,
         properties=obj.run_properties,
         cli_parameters=cli_params,
         explain_run_plan=explain_run_plan,
     )
     console = obj.console
 
-    def write_build_plan_as_json():
-        """Write the build plan as a simple json file to be used by gha"""
-        simple_build_plan: dict[str, list[dict[str, Union[str, bool]]]] = dict(
+    def write_run_plan_as_json():
+        """Write the run plan as a simple JSON file to be used by Github Actions"""
+        simple_run_plan: dict[str, list[dict[str, Union[str, bool]]]] = dict(
             {
                 stage.name: [
                     {
                         "service": project_execution.project.name,
                         "path": project_execution.project.path,
                         "base": project_execution.project.root_path,
                         "cached": project_execution.cached,
                     }
                     for project_execution in project_executions
                 ]
                 for stage, project_executions in run_properties.run_plan.items()
             }
         )
-        build_set_file = Path(BUILD_ARTIFACTS_FOLDER) / "build_plan.json"
-        os.makedirs(os.path.dirname(build_set_file), exist_ok=True)
-        with open(build_set_file, "w", encoding="utf-8") as file:
-            console.print(f"Writing simple json build plan to: {build_set_file}")
-            json.dump(simple_build_plan, file)
+        run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.json"
+        os.makedirs(os.path.dirname(run_plan_file), exist_ok=True)
+        with open(run_plan_file, "w", encoding="utf-8") as file:
+            console.print(f"Writing simple JSON run plan to: {run_plan_file}")
+            json.dump(simple_run_plan, file)
 
-    write_build_plan_as_json()
+    write_run_plan_as_json()
 
     console.print(f"MPyL log level is set to {run_properties.console.log_level}")
     branch = obj.repo.get_branch
     main_branch = obj.repo.main_branch
     tag = run_properties.versioning.tag
 
     if tag is None:
@@ -135,15 +136,15 @@
     try:
         run_result = RunResult(run_properties=run_properties)
 
         if not run_result.has_run_plan_projects:
             logger.info("Nothing to do. Exiting..")
             return run_result
 
-        logger.info("Build plan:")
+        logger.info("Run plan:")
         console.print(Markdown(f"\n\n{run_result_to_markdown(run_result)}"))
 
         if reporter:
             reporter.send_report(run_result)
         try:
             steps = Steps(
                 logger=logger,
```

## mpyl/constants.py

```diff
@@ -1,8 +1,10 @@
 """"Constants for mpyl."""
 
-BUILD_ARTIFACTS_FOLDER = ".mpyl"
+RUN_ARTIFACTS_FOLDER = ".mpyl"
 DEFAULT_CONFIG_FILE_NAME = "mpyl_config.yml"
 DEFAULT_RUN_PROPERTIES_FILE_NAME = "run_properties.yml"
 DEFAULT_STAGES_SCHEMA_FILE_NAME = "mpyl_stages.schema.yml"
 
 PR_NUMBER_PLACEHOLDER = "{PR-NUMBER}"
+
+RUN_RESULT_FILE_GLOB = "run_result-*.pickle"
```

## mpyl/project.py

```diff
@@ -22,15 +22,15 @@
 from pathlib import Path
 from typing import Optional, TypeVar, Any, List
 
 import jsonschema
 from mypy.checker import Generic
 from ruamel.yaml import YAML
 
-from .constants import BUILD_ARTIFACTS_FOLDER
+from .constants import RUN_ARTIFACTS_FOLDER
 from .validation import validate
 
 T = TypeVar("T")
 
 
 def without_keys(dictionary: dict, keys: set[str]):
     return {k: dictionary[k] for k in dictionary.keys() - keys}
@@ -532,15 +532,15 @@
 
     @property
     def deployment_path(self) -> str:
         return str(Path(self.root_path, "deployment"))
 
     @property
     def target_path(self) -> str:
-        return str(Path(self.deployment_path, BUILD_ARTIFACTS_FOLDER))
+        return str(Path(self.deployment_path, RUN_ARTIFACTS_FOLDER))
 
     @property
     def test_containers_path(self) -> str:
         return str(Path(self.deployment_path, "docker-compose-test.yml"))
 
     @property
     def test_report_path(self) -> str:
```

## mpyl/artifacts/build_artifacts.py

```diff
@@ -1,24 +1,25 @@
 """Class that handles remote caching of build artifacts"""
+
 import abc
 import os
 import shutil
 import time
 from abc import ABC
 from enum import Enum
 from logging import Logger
 from pathlib import Path
 from tempfile import TemporaryDirectory
 from typing import Optional
 
-from git import GitCommandError
+from git.exc import GitCommandError
 from github import Github
 
 from ..cli.commands.build.jenkins import get_token
-from ..constants import BUILD_ARTIFACTS_FOLDER
+from ..constants import RUN_ARTIFACTS_FOLDER
 from ..project import Project, Target, load_project
 from ..steps.deploy.k8s.deploy_config import DeployConfig, get_namespace
 from ..steps.models import RunProperties
 from ..utilities.github import GithubConfig
 from ..utilities.repo import Repository, RepoConfig
 
 
@@ -53,15 +54,15 @@
 class BuildCacheTransformer(PathTransformer):
     def artifact_type(self) -> ArtifactType:
         return ArtifactType.CACHE
 
     def transform_for_read(self, project_path: str) -> Path:
         return Path(
             project_path.replace(
-                Project.project_yaml_path(), f"deployment/{BUILD_ARTIFACTS_FOLDER}"
+                Project.project_yaml_path(), f"deployment/{RUN_ARTIFACTS_FOLDER}"
             )
         )
 
     def transform_for_write(self, artifact_path: str, project: Project) -> Path:
         return Path(artifact_path)
```

## mpyl/cli/build.py

```diff
@@ -1,12 +1,14 @@
 """Commands related to build"""
+
 import asyncio
 import pickle
 import shutil
 import sys
+import uuid
 from pathlib import Path
 from typing import Optional, cast, Sequence
 
 import click
 import questionary
 from click import ParamType
 from click.shell_completion import CompletionItem
@@ -32,20 +34,21 @@
     BuildCacheTransformer,
     ArtifactType,
 )
 from ..build import print_status, run_mpyl
 from ..constants import (
     DEFAULT_CONFIG_FILE_NAME,
     DEFAULT_RUN_PROPERTIES_FILE_NAME,
-    BUILD_ARTIFACTS_FOLDER,
+    RUN_ARTIFACTS_FOLDER,
+    RUN_RESULT_FILE_GLOB,
 )
 from ..project import load_project, Target
+from ..run_plan import RunPlan
 from ..steps.deploy.k8s.deploy_config import DeployConfig
 from ..steps.models import RunProperties
-from ..steps.run import RunResult
 from ..steps.run_properties import construct_run_properties
 from ..utilities.github import GithubConfig
 from ..utilities.pyaml_env import parse_config
 from ..utilities.repo import Repository, RepoConfig
 
 
 async def warn_if_update(console: Console):
@@ -92,15 +95,15 @@
 def build(ctx, config, properties, verbose):
     """Pipeline build commands"""
     parsed_properties = parse_config(properties)
     parsed_config = parse_config(config)
     console_config = construct_run_properties(
         properties=parsed_properties,
         config=parsed_config,
-        run_plan={},
+        run_plan=RunPlan.empty(),
         all_projects=set(),
     ).console
     console = create_console_logger(
         show_path=console_config.show_paths,
         verbose=verbose,
         max_width=console_config.width,
     )
@@ -143,15 +146,15 @@
     help="Stage to run",
 )
 @click.option(
     "--sequential",
     is_flag=True,
     default=False,
     required=False,
-    help="Combine results with previous run(s) and load cached build set",
+    help="Combine results with previous run(s) and load existing run plan",
 )
 @click.option(
     "--projects",
     "-p",
     type=str,
     required=False,
     help="Comma separated list of the projects to build",
@@ -170,17 +173,18 @@
     all_,
     tag,
     stage,
     sequential,
     projects,
     dryrun_,
 ):  # pylint: disable=invalid-name
-    run_result_file = Path(BUILD_ARTIFACTS_FOLDER) / "run_result"
-    if not sequential and run_result_file.is_file():
-        run_result_file.unlink()
+    run_result_files = list(Path(RUN_ARTIFACTS_FOLDER).glob(RUN_RESULT_FILE_GLOB))
+    if not sequential:
+        for run_result_file in run_result_files:
+            run_result_file.unlink()
 
     asyncio.run(warn_if_update(obj.console))
 
     parameters = MpylCliParameters(
         local=not ci,
         pull_main=all_,
         all=all_,
@@ -207,22 +211,16 @@
         cli_parameters=parameters,
         sequential=sequential,
     )
     run_result = run_mpyl(
         run_properties=run_properties, cli_parameters=parameters, reporter=None
     )
 
-    Path(BUILD_ARTIFACTS_FOLDER).mkdir(parents=True, exist_ok=True)
-
-    if sequential and run_result_file.is_file():
-        with open(run_result_file, "rb") as file:
-            previous_result: RunResult = pickle.load(file)
-            run_result.update_run_plan(previous_result.run_plan)
-            run_result.extend(previous_result.results)
-
+    Path(RUN_ARTIFACTS_FOLDER).mkdir(parents=True, exist_ok=True)
+    run_result_file = Path(RUN_ARTIFACTS_FOLDER) / f"run_result-{uuid.uuid4()}.pickle"
     with open(run_result_file, "wb") as file:
         pickle.dump(run_result, file, pickle.HIGHEST_PROTOCOL)
 
     sys.exit(0 if run_result.is_success else 1)
 
 
 @build.command(help="The status of the current local branch from MPyL's perspective")
@@ -454,25 +452,30 @@
                 tag_target=getattr(Target, target) if tag else None,
             )
             run_jenkins(run_argument)
     except asyncio.exceptions.TimeoutError:
         pass
 
 
-@build.command(help=f"Clean MPyL metadata in `{BUILD_ARTIFACTS_FOLDER}` folders")
+@build.command(help=f"Clean all MPyL metadata in `{RUN_ARTIFACTS_FOLDER}` folders")
 @click.option(
     "--filter",
     "-f",
     "filter_",
     required=False,
     type=click.STRING,
     help="Filter based on filepath ",
 )
 @click.pass_obj
 def clean(obj: CliContext, filter_):
+    root_path = Path(RUN_ARTIFACTS_FOLDER)
+    if root_path.is_dir():
+        shutil.rmtree(root_path)
+        obj.console.print(f"ðŸ§¹ Cleaned up {root_path}")
+
     found_projects: list[Path] = [
         Path(
             load_project(
                 obj.repo.root_dir, Path(project_path), strict=False
             ).target_path
         )
         for project_path in obj.repo.find_projects(filter_ if filter_ else "")
@@ -507,15 +510,15 @@
     required=False,
 )
 @click.pass_obj
 def pull(obj: CliContext, tag: str, pr: int, path: Path):
     run_properties = construct_run_properties(
         config=obj.config,
         properties=obj.run_properties,
-        run_plan={},
+        run_plan=RunPlan.empty(),
         all_projects=set(),
     )
     target_branch = __get_target_branch(run_properties, tag, pr)
 
     build_artifacts = prepare_artifacts_repo(
         obj=obj, repo_path=path, artifact_type=ArtifactType.CACHE
     )
@@ -555,15 +558,15 @@
     pr: Optional[int],
     path: Path,
     artifact_type: ArtifactType,
 ):
     run_properties = construct_run_properties(
         config=obj.config,
         properties=obj.run_properties,
-        run_plan={},
+        run_plan=RunPlan.empty(),
         all_projects=set(),
     )
     target_branch = __get_target_branch(run_properties, tag, pr)
     if path is None:
         path = Path("tmp") if artifact_type == ArtifactType.CACHE else Path(".")
 
     build_artifacts = prepare_artifacts_repo(
```

## mpyl/cli/repository.py

```diff
@@ -1,20 +1,22 @@
 """Commands related to the VCS (git) repository"""
+
 from dataclasses import dataclass
 from pathlib import Path
 
 import click
 from rich.console import Console
 from rich.markdown import Markdown
 
 from . import (
     CONFIG_PATH_HELP,
     create_console_logger,
 )
 from ..constants import DEFAULT_CONFIG_FILE_NAME, DEFAULT_RUN_PROPERTIES_FILE_NAME
+from ..run_plan import RunPlan
 from ..steps.run_properties import construct_run_properties
 from ..utilities.pyaml_env import parse_config
 from ..utilities.repo import Repository, RepoConfig
 
 
 @dataclass(frozen=True)
 class RepoContext:
@@ -58,15 +60,15 @@
 @click.pass_obj
 def status(obj: RepoContext):
     """Print the status of the current repository"""
     config = parse_config(obj.config)
     run_properties = construct_run_properties(
         config=config,
         properties=parse_config(obj.run_properties),
-        run_plan={},
+        run_plan=RunPlan.empty(),
         all_projects=set(),
     )
     versioning = run_properties.versioning
     ci_branch = versioning.branch
     console = obj.console
     with Repository(config=RepoConfig.from_config(config)) as repo:
         console.print(
@@ -156,33 +158,35 @@
 )
 @click.pass_obj
 def init(obj: RepoContext, url: str, pull: int, branch: str, pristine: bool):
     console = obj.console
 
     console.log("Preparing repository for a new run...")
 
-    with Repository.from_shallow_diff_clone(
-        branch.replace("refs/heads/", ""), url, "main", obj.config, Path(".")
-    ) if pristine else Repository(
-        config=RepoConfig.from_config(parse_config(obj.config))
+    with (
+        Repository.from_shallow_diff_clone(
+            branch.replace("refs/heads/", ""), url, "main", obj.config, Path(".")
+        )
+        if pristine
+        else Repository(config=RepoConfig.from_config(parse_config(obj.config)))
     ) as repo:
         config = parse_config(obj.config)
         if not repo.remote_url:
             with console.status("ðŸ‘· Initializing remote origin") as progress:
                 repo_config = RepoConfig.from_config(config).repo_credentials
                 url = url or (repo_config and repo_config.to_url_with_credentials)
                 remote = repo.init_remote(url)
                 progress.console.log(f"ðŸ‘· Remote initialized at {remote.url}")
 
         console.log(f"âœ… Repository tracking {repo.remote_url}")
 
         properties = construct_run_properties(
             config=config,
             properties=parse_config(obj.run_properties),
-            run_plan={},
+            run_plan=RunPlan.empty(),
             all_projects=set(),
         )
         pr_number = pull or properties.versioning.pr_number
 
         if pr_number:
             target_branch = branch or properties.versioning.branch
             _check_out_pr(target_branch, console, pr_number, repo)
```

## mpyl/projects/releases/releases.txt

```diff
@@ -43,8 +43,9 @@
 1.4.19
 1.4.20
 1.5.0
 1.5.1
 1.6.0
 1.6.1
 1.6.2
-1.6.3
+1.6.3
+1.6.4
```

## mpyl/reporting/formatting/markdown.py

```diff
@@ -1,28 +1,20 @@
 """
 Markdown run result formatters
 """
-import itertools
 import operator
 from typing import cast, Optional
 
-from junitparser import TestSuite
-
 from ...project import Stage
 from ...project_execution import ProjectExecution
 from ...steps import Output, ArtifactType
 from ...steps.deploy.k8s import DeployedHelmAppSpec
 from ...steps.run import RunResult
 from ...steps.steps import StepResult
-from ...utilities.junit import (
-    TestRunSummary,
-    sum_suites,
-    to_test_suites,
-    JunitTestSpec,
-)
+from ...utilities.junit import TestRunSummary, JunitTestSpec
 
 
 def summary_to_markdown(summary: TestRunSummary):
     return (
         f"ðŸ§ª {summary.tests} âŒ {summary.failures} "
         f"ðŸ’” {summary.errors} ðŸ™ˆ {summary.skipped}"
     )
@@ -68,21 +60,25 @@
     step_results: list[StepResult] = run_result.results_for_stage(stage)
     plan = run_result.plan_for_stage(stage)
     if not step_results and not plan:
         return ""
 
     result = f"{stage.icon} {stage.name.capitalize()}:  \n{__to_oneliner(step_results, plan)}  \n"
     test_artifacts: dict[str, JunitTestSpec] = _collect_test_specs(step_results)
-    test_results: dict[str, list[TestSuite]] = _collect_test_results(test_artifacts)
+    test_results: dict[str, TestRunSummary] = _collect_test_results(test_artifacts)
 
     if test_results:
-        test_suites = list(
-            itertools.chain.from_iterable([value for _, value in test_results.items()])
+        test_summaries = [value for _, value in test_results.items()]
+        combined_summary = TestRunSummary(
+            tests=sum(s.tests for s in test_summaries),
+            failures=sum(s.failures for s in test_summaries),
+            errors=sum(s.errors for s in test_summaries),
+            skipped=sum(s.skipped for s in test_summaries),
         )
-        result += to_markdown_test_report(test_suites)
+        result += f"{summary_to_markdown(combined_summary)}"
         unique_artifacts = _collect_unique_test_artifacts_with_url(test_artifacts)
 
         for unique_artifact in unique_artifacts:
             result += (
                 f" [{unique_artifact.test_results_url_name}]"
                 f"({unique_artifact.test_results_url})"
             )
@@ -116,19 +112,14 @@
     for stage in run_result.run_properties.stages:
         result += markdown_for_stage(run_result, stage)
     if result == "":
         return "ðŸ¤· Nothing to do"
     return result
 
 
-def to_markdown_test_report(suites: list[TestSuite]):
-    total_tests = sum_suites(suites)
-    return f"{summary_to_markdown(total_tests)}"
-
-
 def _collect_test_specs(step_results: list[StepResult]) -> dict[str, JunitTestSpec]:
     return {
         res.output.produced_artifact.producing_step: cast(
             JunitTestSpec, res.output.produced_artifact.spec
         )
         for res in step_results
         if (
@@ -136,16 +127,20 @@
             and res.output.produced_artifact.artifact_type == ArtifactType.JUNIT_TESTS
         )
     }
 
 
 def _collect_test_results(
     test_artifacts: dict[str, JunitTestSpec]
-) -> dict[str, list[TestSuite]]:
-    return {k: to_test_suites(v) for k, v in test_artifacts.items()}
+) -> dict[str, TestRunSummary]:
+    return {
+        k: v.test_results_summary
+        for k, v in test_artifacts.items()
+        if v.test_results_summary
+    }
 
 
 def _collect_unique_test_artifacts_with_url(
     test_artifacts: dict[str, JunitTestSpec],
 ) -> list[JunitTestSpec]:
     unique_artifacts: list[JunitTestSpec] = []
     for step_name, test_artifact in test_artifacts.items():
```

## mpyl/stages/discovery.py

```diff
@@ -6,18 +6,19 @@
 import logging
 import os
 import pickle
 from dataclasses import dataclass
 from pathlib import Path
 from typing import Optional
 
-from ..constants import BUILD_ARTIFACTS_FOLDER
+from ..constants import RUN_ARTIFACTS_FOLDER
 from ..project import Project
 from ..project import Stage
 from ..project_execution import ProjectExecution
+from ..run_plan import RunPlan
 from ..steps import deploy
 from ..steps.collection import StepsCollection
 from ..steps.models import Output, ArtifactType
 from ..utilities.repo import Changeset, Repository
 
 
 @dataclass(frozen=True)
@@ -33,15 +34,15 @@
     if startswith:
         logger.debug(
             f"Project {project.name}: {path} touched project root {project.root_path}"
         )
     return startswith
 
 
-def is_dependency_touched(
+def is_dependency_modified(
     logger: logging.Logger,
     project: Project,
     stage: str,
     path: str,
     steps: Optional[StepsCollection],
 ) -> bool:
     deps = project.dependencies
@@ -83,23 +84,59 @@
                 f"is touched"
             )
             return True
 
     return False
 
 
-def is_output_cached(output: Optional[Output], cache_key: str) -> bool:
-    if (
-        output is None
-        or not output.success
-        or output.produced_artifact is None
-        or not output.produced_artifact.hash
-    ):
-        return False
-    return output.produced_artifact.hash == cache_key
+def is_project_cached_for_stage(
+    logger: logging.Logger,
+    project: str,
+    stage: str,
+    output: Optional[Output],
+    cache_key: str,
+) -> bool:
+    cached = False
+
+    if stage == deploy.STAGE_NAME:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because this stage is never cached"
+        )
+    elif output is None:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because there is no previous run"
+        )
+    elif not output.success:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because the previous run was not successful"
+        )
+    elif output.produced_artifact is None:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because there was no artifact in the previous run"
+        )
+    elif not output.produced_artifact.hash:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because there is no cache key in the previous run"
+        )
+    elif output.produced_artifact.hash != cache_key:
+        logger.debug(
+            f"Project {project} will execute stage {stage} again because its content changed since the previous run"
+        )
+        logger.debug(
+            f"Hash of contents for previous run: {output.produced_artifact.hash}"
+        )
+        logger.debug(f"Hash of contents for current run:  {cache_key}")
+    else:
+        logger.debug(
+            f"Project {project} will skip stage {stage} because its content did not change since the previous run"
+        )
+        logger.debug(f"Hash of contents for current run: {cache_key}")
+        cached = True
+
+    return cached
 
 
 def hashed_changes(files: set[str]) -> str:
     sha256 = hashlib.sha256()
 
     for changed_file in sorted(files):
         with open(changed_file, "rb") as file:
@@ -112,120 +149,128 @@
     return sha256.hexdigest()
 
 
 def _to_project_execution(
     logger: logging.Logger,
     project: Project,
     stage: str,
-    changes: Changeset,
+    changeset: Changeset,
     steps: Optional[StepsCollection],
 ) -> Optional[ProjectExecution]:
     if project.stages.for_stage(stage) is None:
         return None
 
-    is_any_dependency_touched = any(
-        is_dependency_touched(logger, project, stage, changed_file, steps)
-        for changed_file in changes.files_touched()
+    is_any_dependency_modified = any(
+        is_dependency_modified(logger, project, stage, changed_file, steps)
+        for changed_file in changeset.files_touched()
     )
     is_project_modified = any(
         file_belongs_to_project(logger, project, changed_file)
-        for changed_file in changes.files_touched()
+        for changed_file in changeset.files_touched()
     )
 
     if is_project_modified:
         files_to_hash = set(
             filter(
                 lambda changed_file: file_belongs_to_project(
                     logger, project, changed_file
                 ),
-                changes.files_touched(status={"A", "M", "R"}),
+                changeset.files_touched(status={"A", "M", "R"}),
             )
         )
 
         if len(files_to_hash) == 0:
-            cache_key = changes.sha
+            cache_key = changeset.sha
+            logger.debug(
+                f"Project {project.name}: using git revision as cache key: {cache_key}"
+            )
         else:
             cache_key = hashed_changes(files=files_to_hash)
-    elif is_any_dependency_touched:
-        cache_key = changes.sha
-    else:
-        return None
+            logger.debug(
+                f"Project {project.name}: using hash of modified files as cache key: {cache_key}"
+            )
 
-    if stage == deploy.STAGE_NAME:
-        cached = False
-    else:
-        cached = is_output_cached(
-            output=Output.try_read(project.target_path, stage),
-            cache_key=cache_key,
+    elif is_any_dependency_modified:
+        cache_key = changeset.sha
+        logger.debug(
+            f"Project {project.name}: using git revision as cache key: {cache_key}"
         )
+    else:
+        return None
 
     return ProjectExecution(
         project=project,
         cache_key=cache_key,
-        cached=cached,
+        cached=is_project_cached_for_stage(
+            logger=logger,
+            project=project.name,
+            stage=stage,
+            output=Output.try_read(project.target_path, stage),
+            cache_key=cache_key,
+        ),
     )
 
 
-def build_project_executions(
+def find_projects_to_execute(
     logger: logging.Logger,
     all_projects: set[Project],
     stage: str,
-    changes: Changeset,
+    changeset: Changeset,
     steps: Optional[StepsCollection],
 ) -> set[ProjectExecution]:
     maybe_execution_projects = set(
         map(
             lambda project: _to_project_execution(
-                logger, project, stage, changes, steps
+                logger, project, stage, changeset, steps
             ),
             all_projects,
         )
     )
     return {
         project_execution
         for project_execution in maybe_execution_projects
         if project_execution is not None
     }
 
 
-def find_build_set(  # pylint: disable=too-many-arguments, too-many-locals
+def create_run_plan(  # pylint: disable=too-many-arguments, too-many-locals
     logger: logging.Logger,
     repository: Repository,
     all_projects: set[Project],
-    stages: list[Stage],
+    all_stages: list[Stage],
     build_all: bool,
     local: bool,
     tag: Optional[str] = None,
     selected_stage: Optional[str] = None,
     selected_projects: Optional[str] = None,
     sequential: Optional[bool] = False,
-) -> dict[Stage, set[ProjectExecution]]:
+) -> RunPlan:
     if selected_projects:
         projects_list = selected_projects.split(",")
 
-    build_set: dict[Stage, set[ProjectExecution]] = {}
+    run_plan: RunPlan = RunPlan.empty()
 
-    build_set_file = Path(BUILD_ARTIFACTS_FOLDER) / "build_plan"
+    run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.pickle"
     if sequential and not build_all and not selected_projects:
-        if not build_set_file.is_file():
+        if not run_plan_file.is_file():
             logger.warning(
-                f"Sequential flag is passed, but no previous build set found: {build_set_file}"
+                f"Sequential flag is passed, but no previous run plan found: {run_plan_file}"
             )
         else:
-            logger.info(f"Loading cached build set: {build_set_file}")
-            return _get_cached_build_set(
-                build_set_file=build_set_file, selected_stage=selected_stage
+            logger.info(f"Loading existing run plan: {run_plan_file}")
+            return _load_existing_run_plan(
+                run_plan_file=run_plan_file, selected_stage=selected_stage
             )
 
-    elif build_set_file.is_file():
-        logger.info(f"Deleting previous build set: {build_set_file}")
-        build_set_file.unlink()
+    elif run_plan_file.is_file():
+        logger.info(f"Deleting previous run plan file: {run_plan_file}")
+        run_plan_file.unlink()
 
-    logger.info("Discovering build set...")
-    for stage in stages:
+    logger.info("Discovering run plan...")
+    for stage in all_stages:
         if selected_stage and selected_stage != stage.name:
             continue
 
         if build_all or selected_projects:
             if selected_projects:
                 all_projects = set(
                     filter(lambda p: p.name in projects_list, all_projects)
@@ -236,30 +281,30 @@
             steps = StepsCollection(logger=logging.getLogger())
             changes_in_branch = (
                 _get_changes(repository, local, tag)
                 if not selected_projects or build_all
                 else []
             )
 
-            project_executions = build_project_executions(
+            project_executions = find_projects_to_execute(
                 logger, all_projects, stage.name, changes_in_branch, steps
             )
             logger.debug(
                 f"Invalidated projects for stage {stage.name}: {[p.name for p in project_executions]}"
             )
 
-        build_set.update({stage: project_executions})
+        run_plan.add_stage(stage, project_executions)
 
     if not selected_stage and not build_all and not selected_projects:
-        os.makedirs(os.path.dirname(build_set_file), exist_ok=True)
-        with open(build_set_file, "wb") as file:
-            logger.info(f"Storing build set in: {build_set_file}")
-            pickle.dump(build_set, file, pickle.HIGHEST_PROTOCOL)
+        os.makedirs(os.path.dirname(run_plan_file), exist_ok=True)
+        with open(run_plan_file, "wb") as file:
+            logger.info(f"Storing run plan in: {run_plan_file}")
+            pickle.dump(run_plan, file, pickle.HIGHEST_PROTOCOL)
 
-    return build_set
+    return run_plan
 
 
 def for_stage(projects: set[Project], stage: Stage) -> set[Project]:
     return set(filter(lambda p: p.stages.for_stage(stage.name), projects))
 
 
 def _get_changes(repo: Repository, local: bool, tag: Optional[str] = None):
@@ -267,19 +312,21 @@
         return repo.changes_in_branch_including_local()
     if tag:
         return repo.changes_in_tagged_commit(tag)
 
     return repo.changes_in_branch()
 
 
-def _get_cached_build_set(
-    build_set_file: Path, selected_stage: Optional[str]
-) -> dict[Stage, set[ProjectExecution]]:
-    with open(build_set_file, "rb") as file:
-        full_build_set: dict[Stage, set[ProjectExecution]] = pickle.load(file)
+def _load_existing_run_plan(
+    run_plan_file: Path, selected_stage: Optional[str]
+) -> RunPlan:
+    with open(run_plan_file, "rb") as file:
+        full_run_plan: RunPlan = pickle.load(file)
         if selected_stage:
-            return {
-                stage: project_executions
-                for stage, project_executions in full_build_set.items()
-                if stage.name == selected_stage
-            }
-        return full_build_set
+            return RunPlan(
+                {
+                    stage: project_executions
+                    for stage, project_executions in full_run_plan.items()
+                    if stage.name == selected_stage
+                }
+            )
+        return full_run_plan
```

## mpyl/steps/models.py

```diff
@@ -1,19 +1,21 @@
 """ Model representation of run-specific configuration. """
+
 import pkgutil
 from dataclasses import dataclass
 from enum import Enum
 from pathlib import Path
 from typing import Optional, cast, Type
 
 from ruamel.yaml import YAML, yaml_object  # type: ignore
 
 from . import deploy
 from ..project import Project, Stage, Target
 from ..project_execution import ProjectExecution
+from ..run_plan import RunPlan
 from ..validation import validate
 
 yaml = YAML()
 
 
 @dataclass(frozen=True)
 class VersioningProperties:
@@ -92,21 +94,21 @@
      """
     console: ConsoleProperties
     """Settings for the console output"""
     stages: list[Stage]
     """All stage definitions"""
     projects: set[Project]
     """All projects"""
-    run_plan: dict[Stage, set[ProjectExecution]]
+    run_plan: RunPlan
     """Stages and projects for this run"""
 
     @staticmethod
     def for_local_run(
         config: dict,
-        run_plan: dict[Stage, set[ProjectExecution]],
+        run_plan: RunPlan,
         revision: str,
         branch: Optional[str],
         stages: list[Stage],
         all_projects: set[Project],
         tag: Optional[str],
     ):
         return RunProperties(
@@ -120,15 +122,15 @@
             projects=all_projects,
         )
 
     @staticmethod
     def from_configuration(
         run_properties: dict,
         config: dict,
-        run_plan: dict[Stage, set[ProjectExecution]],
+        run_plan: RunPlan,
         all_projects: set[Project],
         cli_tag: Optional[str] = None,
         root_dir: Path = Path("."),
     ):
         build_dict = pkgutil.get_data(__name__, "../schema/run_properties.schema.yml")
 
         if build_dict:
```

## mpyl/steps/run.py

```diff
@@ -5,18 +5,19 @@
 import operator
 from typing import Optional
 
 from .models import RunProperties
 from .steps import StepResult, ExecutionException
 from ..project import Stage
 from ..project_execution import ProjectExecution
+from ..run_plan import RunPlan
 
 
 class RunResult:
-    _run_plan: dict[Stage, set[ProjectExecution]]
+    _run_plan: RunPlan
     _results: list[StepResult]
     _run_properties: RunProperties
     _exception: Optional[ExecutionException]
 
     def __init__(self, run_properties: RunProperties):
         self._run_properties = run_properties
         self._run_plan = run_properties.run_plan
@@ -42,20 +43,23 @@
 
         return failed_results if len(failed_results) > 0 else None
 
     @property
     def progress_fraction(self) -> float:
         unfinished = 0
         finished = 0
-        for stage, projects in self.run_plan.items():
+        for stage, project_executions in self.run_plan.items():
             finished_project_names = set(
                 map(lambda r: r.project.name, self.results_for_stage(stage))
             )
-            for project in projects:
-                if project.name in finished_project_names:
+            for project_execution in project_executions:
+                if (
+                    project_execution.name in finished_project_names
+                    or project_execution.cached
+                ):
                     finished += 1
                 else:
                     unfinished += 1
 
         total = unfinished + finished
         if total == 0:
             return 0.0
@@ -71,15 +75,15 @@
         self._exception = exception
 
     @property
     def run_properties(self) -> RunProperties:
         return self._run_properties
 
     @property
-    def run_plan(self) -> dict[Stage, set[ProjectExecution]]:
+    def run_plan(self) -> RunPlan:
         return self._run_plan
 
     @property
     def has_run_plan_projects(self) -> bool:
         """
         We create a ProjectExecution for every project that is changed in the branch we're building, HOWEVER we also
         know per-project whether it's cached or not. In this function we should read that value to exclude projects
@@ -96,15 +100,15 @@
 
     def append(self, result: StepResult):
         self._results.append(result)
 
     def extend(self, results: list[StepResult]):
         self._results.extend(results)
 
-    def update_run_plan(self, run_plan: dict[Stage, set[ProjectExecution]]):
+    def update_run_plan(self, run_plan: RunPlan):
         self._run_plan.update(run_plan)
 
     @property
     def is_success(self):
         if self._exception:
             return False
         return self._results_success()
```

## mpyl/steps/run_properties.py

```diff
@@ -1,25 +1,26 @@
 """Module to initiate run properties"""
+
 import logging
 from pathlib import Path
 from typing import Optional
 
 from ..cli import MpylCliParameters
 from ..project import load_project, Stage, Project
-from ..project_execution import ProjectExecution
-from ..stages.discovery import find_build_set
+from ..run_plan import RunPlan
+from ..stages.discovery import create_run_plan
 from ..steps.models import RunProperties
 from ..utilities.repo import Repository, RepoConfig
 
 
 def construct_run_properties(
     config: dict,
     properties: dict,
     cli_parameters: MpylCliParameters = MpylCliParameters(),
-    run_plan: Optional[dict[Stage, set[ProjectExecution]]] = None,
+    run_plan: Optional[RunPlan] = None,
     all_projects: Optional[set[Project]] = None,
     root_dir: Path = Path(""),
     explain_run_plan: bool = False,
     sequential: bool = False,
 ) -> RunProperties:
     tag = cli_parameters.tag or properties["build"]["versioning"].get("tag")
     if all_projects is None or run_plan is None:
@@ -40,23 +41,23 @@
                 )
 
             if run_plan is None:
                 stages = [
                     Stage(stage["name"], stage["icon"])
                     for stage in properties["stages"]
                 ]
-                build_set_logger = logging.getLogger("mpyl")
+                run_plan_logger = logging.getLogger("mpyl")
                 if explain_run_plan:
-                    build_set_logger.setLevel("DEBUG")
+                    run_plan_logger.setLevel("DEBUG")
                 run_plan = _create_run_plan(
-                    all_projects=all_projects,
                     cli_parameters=cli_parameters,
+                    all_projects=all_projects,
+                    all_stages=stages,
                     explain_run_plan=explain_run_plan,
                     repo=repo,
-                    stages=stages,
                     tag=tag,
                     sequential=sequential,
                 )
 
     if cli_parameters.local:
         return RunProperties.for_local_run(
             config=config,
@@ -75,31 +76,31 @@
         all_projects=all_projects,
         cli_tag=tag,
         root_dir=root_dir,
     )
 
 
 def _create_run_plan(
-    all_projects: set[Project],
     cli_parameters: MpylCliParameters,
+    all_projects: set[Project],
+    all_stages: list[Stage],
     explain_run_plan: bool,
     repo: Repository,
-    stages: list[Stage],
     tag: Optional[str] = None,
     sequential: Optional[bool] = False,
 ):
-    build_set_logger = logging.getLogger("mpyl")
+    run_plan_logger = logging.getLogger("mpyl")
     if explain_run_plan:
-        build_set_logger.setLevel("DEBUG")
+        run_plan_logger.setLevel("DEBUG")
 
-    return find_build_set(
-        logger=build_set_logger,
+    return create_run_plan(
+        logger=run_plan_logger,
         repository=repo,
         all_projects=all_projects,
-        stages=stages,
+        all_stages=all_stages,
         tag=tag,
         local=cli_parameters.local,
         build_all=cli_parameters.all,
         selected_stage=cli_parameters.stage,
         selected_projects=cli_parameters.projects,
         sequential=sequential,
     )
```

## mpyl/steps/build/docker_build.py

```diff
@@ -13,36 +13,37 @@
 to a folder named `$WORKDIR/target/test-reports/`.
 
 #### Example Dockerfile-mpl
 ```docker
 .. include:: ../../../../tests/projects/service/deployment/Dockerfile-mpl
 ```
 """
+
 import os
 from logging import Logger
 
 from .post_docker_build import AfterBuildDocker
 from .. import Step, Meta
 from ..models import Input, Output, ArtifactType, input_to_artifact
 from . import STAGE_NAME
-from ...constants import BUILD_ARTIFACTS_FOLDER
+from ...constants import RUN_ARTIFACTS_FOLDER
 from ...utilities import replace_pr_number
 from ...utilities.docker import (
     DockerConfig,
     build,
     docker_image_tag,
     docker_file_path,
     login,
     DockerImageSpec,
     registry_for_project,
     get_default_build_args,
     full_image_path_for_project,
 )
 
-DOCKER_IGNORE_DEFAULT = ["**/target/*", f"**/{BUILD_ARTIFACTS_FOLDER}/*"]
+DOCKER_IGNORE_DEFAULT = ["**/target/*", f"**/{RUN_ARTIFACTS_FOLDER}/*"]
 
 
 class BuildDocker(Step):
     def __init__(self, logger: Logger) -> None:
         super().__init__(
             logger=logger,
             meta=Meta(
```

## mpyl/steps/deploy/k8s/__init__.py

```diff
@@ -1,8 +1,9 @@
 """Kubernetes deployment related helper methods"""
+
 import datetime
 import os
 from dataclasses import dataclass
 from logging import Logger
 from pathlib import Path
 from typing import Optional
 
@@ -99,17 +100,27 @@
 
     meta_data = rancher_namespace_metadata(
         namespace=namespace, rancher_config=rancher_config, project_id=project_id
     )
     namespaces = api.list_namespace(field_selector=f"metadata.name={namespace}")
 
     if len(namespaces.items) == 0 and not dry_run:
-        api.create_namespace(
-            client.V1Namespace(api_version="v1", kind="Namespace", metadata=meta_data)
-        )
+        try:
+            api.create_namespace(
+                client.V1Namespace(
+                    api_version="v1", kind="Namespace", metadata=meta_data
+                )
+            )
+        except ApiException as error:
+            # when concurrently deploying multiple services of the same PR, we can sometimes still try to create a
+            # namespace that already exists. if that happens, ignore the error
+            if error.status == 409:
+                logger.info(f"Found namespace {namespace}")
+            else:
+                raise error
     else:
         logger.info(f"Found namespace {namespace}")
 
 
 def render_manifests(chart: dict[str, CustomResourceDefinition]):
     result = f"{GENERATED_WARNING}\n"
     for name, template_content in sorted(chart.items()):
```

## mpyl/steps/test/dockertest.py

```diff
@@ -95,16 +95,17 @@
             artifact = self.extract_test_results(
                 self._logger, project, container, step_input
             )
             docker_registry = registry_for_project(docker_config, project)
             if not step_input.dry_run and docker_registry.cache_from_registry:
                 push_to_registry(self._logger, docker_registry, tag)
 
-            suite = to_test_suites(cast(JunitTestSpec, artifact.spec))
-            summary = sum_suites(suite)
+            spec = cast(JunitTestSpec, artifact.spec)
+            summary = sum_suites(to_test_suites(spec))
+            spec.test_results_summary = summary
 
             output = Output(
                 success=summary.is_success,
                 message=f"Tests results produced for {project.name} ({summary})",
                 produced_artifact=artifact,
             )
             remove_container(self._logger, container)
```

## mpyl/steps/test/sbt.py

```diff
@@ -81,18 +81,18 @@
     def execute(self, step_input: Input) -> Output:
         project = step_input.project_execution
         sbt_config = SbtConfig.from_config(config=step_input.run_properties.config)
         self._logger.debug(f"Config {sbt_config}")
         test_result = self._test(step_input=step_input, sbt_config=sbt_config)
 
         if test_result.produced_artifact:
-            suite = to_test_suites(
-                cast(JunitTestSpec, test_result.produced_artifact.spec)
-            )
+            spec = cast(JunitTestSpec, test_result.produced_artifact.spec)
+            suite = to_test_suites(spec)
             summary = sum_suites(suite)
+            spec.test_results_summary = summary
             return Output(
                 success=summary.is_success,
                 message=f"Tests results produced for {project.name} ({summary})",
                 produced_artifact=test_result.produced_artifact,
             )
 
         return test_result
```

## mpyl/utilities/junit/__init__.py

```diff
@@ -9,35 +9,38 @@
 
 from ...steps.models import ArtifactSpec
 
 yaml = YAML()
 
 
 @yaml_object(yaml)
-@dataclass
-class JunitTestSpec(ArtifactSpec):
-    yaml_tag = "!JunitTestSpec"
-    test_output_path: str
-    test_results_url: Optional[str] = None
-    test_results_url_name: Optional[str] = None
-
-
 @dataclass(frozen=True)
 class TestRunSummary:
     __test__ = False
+    yaml_tag = "!TestRunSummary"
     tests: int
     failures: int
     errors: int
     skipped: int
 
     @property
     def is_success(self):
         return self.errors == 0 and self.failures == 0
 
 
+@yaml_object(yaml)
+@dataclass
+class JunitTestSpec(ArtifactSpec):
+    yaml_tag = "!JunitTestSpec"
+    test_output_path: str
+    test_results_url: Optional[str] = None
+    test_results_url_name: Optional[str] = None
+    test_results_summary: Optional[TestRunSummary] = None
+
+
 def to_test_suites(artifact: JunitTestSpec) -> list[TestSuite]:
     junit_result_path = artifact.test_output_path
 
     xml = JUnitXml()
     for file_name in (
         [fn for fn in os.listdir(junit_result_path) if fn.endswith(".xml")]
         if os.path.isdir(junit_result_path)
```

## Comparing `mpyl-1.6.3.dist-info/LICENSE` & `mpyl-1.6.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mpyl-1.6.3.dist-info/METADATA` & `mpyl-1.6.4.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mpyl
-Version: 1.6.3
+Version: 1.6.4
 Summary: Modular Pipeline Library
 Home-page: https://vandebron.github.io/mpyl
 Author: Vandebron Energie BV
 Project-URL: Documentation, https://vandebron.github.io/mpyl
 Project-URL: Source, https://github.com/Vandebron/mpyl
 Project-URL: Tracker, https://github.com/Vandebron/mpyl/issues
 Classifier: Topic :: Software Development :: Build Tools
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: mpyl Version: 1.6.3 Summary: Modular Pipeline
+Metadata-Version: 2.1 Name: mpyl Version: 1.6.4 Summary: Modular Pipeline
 Library Home-page: https://vandebron.github.io/mpyl Author: Vandebron Energie
 BV Project-URL: Documentation, https://vandebron.github.io/mpyl Project-URL:
 Source, https://github.com/Vandebron/mpyl Project-URL: Tracker, https://
 github.com/Vandebron/mpyl/issues Classifier: Topic :: Software Development ::
 Build Tools Classifier: Topic :: Utilities Classifier: Development Status :: 4
 - Beta Classifier: Environment :: Console Classifier: Intended Audience ::
 Developers Classifier: Operating System :: OS Independent Classifier:
```

## Comparing `mpyl-1.6.3.dist-info/RECORD` & `mpyl-1.6.4.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,71 +1,72 @@
 mpyl/__init__.py,sha256=pJ0OOmWsxvMr3JRqfC24VUpEiI6vwJppOTf-G6-nTHI,1278
 mpyl/__main__.py,sha256=2c9boQJDUA6b8p2umOych7HHlwmBdmsIQDLZcE_pBdo,215
-mpyl/build.py,sha256=6AaAucgJn9NPI_nbdJUFGrO5X6HtdCGtoUcb9-dXsZY,7547
-mpyl/constants.py,sha256=KyMNNpYl6yygvzqbGR1BLkayMmxLXTp01vvhXsSh8t8,260
-mpyl/project.py,sha256=PEEWnU6FDryUNv6dqzDDazY8F1wHB03JRwSACGfPb7Y,20754
+mpyl/build.py,sha256=X2iMzm2LpReVOu4A506nsvz56AQvUHWrzfw4QgodvCc,7535
+mpyl/constants.py,sha256=jIcpytI9cpIB7dFo87ct8G6BaGevsDC2pNpvXE0ugkA,304
+mpyl/project.py,sha256=3Aem-0Us8gYy2AwyxccXm5OlD0yxhyHNKUZtk62Wp9o,20750
 mpyl/project_execution.py,sha256=d6QR3NKJGz_UnIXe5K7psbPfjqHTW66EKuarenGtsEE,574
 mpyl/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+mpyl/run_plan.py,sha256=BfvVk_DhQfIwhx7QZYAJJdLAtA9Y4F-xwxH_fSWeRL4,681
 mpyl/validation.py,sha256=Cps5Y_kPD2asBY13wG4G1xxrrM2Xi_EWr37sFXK9f18,2370
 mpyl/artifacts/__init__.py,sha256=0KjD4BVqH5WVi9Rma5R6FsJN9hAcc5u-gNRRYUn945s,60
-mpyl/artifacts/build_artifacts.py,sha256=jhd7etNeZCo67SEchU-4bZaAn6GgScHxbU7d38_ArGg,9221
+mpyl/artifacts/build_artifacts.py,sha256=qm7E2fvSgApCDXZskMPf0ATk1pGBooegFsoyM957k2A,9222
 mpyl/cli/__init__.py,sha256=W0cVhHL0_HrQqtyg-t-TCoD5eYnpcSCNPU8sR6p8eO4,3512
-mpyl/cli/build.py,sha256=ko6mRZG9zflBUdypP1OO3_5qIVee2asNDzdIcDoaYUc,18002
+mpyl/cli/build.py,sha256=xtOAa6fvYyPagNROeMWXTvWDS_WGbbNf8w_TZL6-oF8,18085
 mpyl/cli/health.py,sha256=z0dMZcVM0tZlKKHzCX5qgdIczaDaPx1_JI4SCh6S91A,614
 mpyl/cli/meta_info.py,sha256=a4-M9D_aaddup4Z2gF34WkmsHBzxQECJb8UNit0q6Po,2417
 mpyl/cli/projects.py,sha256=uIbUSKaa-dWNuiClyy3nVi4r6DUbzP5n8cUZeVD_c7M,8536
-mpyl/cli/repository.py,sha256=9gch3qAoDlHfTR_CDfxPgdn158qhAqhxmVyRmosknKc,7860
+mpyl/cli/repository.py,sha256=YcKDL0IBtCcnClsdRNGJDL_wSQ2SjEib_yE-h2t3bwc,7944
 mpyl/cli/commands/__init__.py,sha256=DaL5q4ibFJT7EMlgcQBSpAaaQNiBqnSJZ2WIKtPzLJk,34
 mpyl/cli/commands/build/__init__.py,sha256=yvYblWUNG8vEvU-CT2NSNX6aLUxcKU1Ndw2ZHWZez50,425
 mpyl/cli/commands/build/artifacts.py,sha256=RfprLCJtEzyoy0QlCvyK7boOu8uPZBzGlmUbnStYzHk,1261
 mpyl/cli/commands/build/jenkins.py,sha256=_NQn_5hr2luKhrmWI5_u-nusxSn4QvDrgLHPKeHGO0Q,4524
 mpyl/cli/commands/health/__init__.py,sha256=Bx6QcWIN-EadbpSe1XAXs1aYCD7Ad8_t3lWRlGDsIr0,38
 mpyl/cli/commands/health/checks.py,sha256=Stx0XCJWFVfmh-BWDWeIGMANTSUCJyFW_0advr1d7tQ,8248
 mpyl/cli/commands/projects/__init__.py,sha256=ZJtZz1CwcJerE3K-wz6DeWzxBUKP5gEHgQTkwpnvXhY,52
 mpyl/cli/commands/projects/formatting.py,sha256=Ph1ZMF1XE880XOXM54G_3MEFjjZN4wabQOtmJLJXR9E,1771
 mpyl/cli/commands/projects/lint.py,sha256=t3HICC4jYjT4UgjjFhI0riJJO58QWFCK1n5cpqInhtY,6356
 mpyl/cli/commands/projects/upgrade.py,sha256=4TUv-IyNzmL-Ehc1R05zAyU6gvOILnaoYs9ASVZjHt4,659
 mpyl/projects/__init__.py,sha256=31HPF5jDZK5UkQT8Zw0V0QSJLqzp8f2zFiWd-QkDjRE,620
 mpyl/projects/find.py,sha256=gQwSu4F0FzWDn6YJWBDuo97OZfL3Fj_iQKAARX0b6oY,2006
 mpyl/projects/versioning.py,sha256=vFet-3hp-toe_tDRYQ-9M321UXzBGvuAS4oLMXVvPTg,12121
-mpyl/projects/releases/releases.txt,sha256=eQuEPEvJvXpouRZga6buhRzsUokFOvvd-5fmJaC_FGw,327
+mpyl/projects/releases/releases.txt,sha256=9C6eZU_B60YR7q4OJ02M0KH8pkxnsHgh1gczw7c6hrQ,333
 mpyl/reporting/__init__.py,sha256=vRvt_67opWXCfe_zYZChT-YhjoPOahAjLagoaVzOcFM,92
 mpyl/reporting/formatting/__init__.py,sha256=GAvYJpHT2SMQxjiLCSqFy57PNWsGI_Ow2bFnA8cX08k,76
-mpyl/reporting/formatting/markdown.py,sha256=QAUgX9PubsGOuxqulBRvD_KmM1U6iaPwubPl1ESBu2M,5742
+mpyl/reporting/formatting/markdown.py,sha256=ZoM3Ep_m-wsqP3afTq8pybk3G7viP4MRFPD-fLtmEjI,5797
 mpyl/reporting/formatting/text.py,sha256=-_GFebP6KffJA1eS3RvGFHsH7k8EOkkvjVcnRlqNFYo,1340
 mpyl/reporting/targets/__init__.py,sha256=31UWFweqJqvlE3WZBb2CMBIAnmJJRZpVBwpW-ma4MzA,1139
 mpyl/reporting/targets/github.py,sha256=IOjnWqV6QO6wAWMuVB8Nbxws7U9sUqBhgVJSJEzFkgE,8932
 mpyl/reporting/targets/jira.py,sha256=PE60WdezLBEvq8rbcpQEg0XgQ8MFmFX8agtB9SolISc,9568
 mpyl/reporting/targets/slack.py,sha256=fcvywqWCkdzVl0YWe1jGGq52jC5ePxQg9Qw8_YByTjk,8064
 mpyl/schema/k8s_api_core.schema.yml,sha256=9bPsgRIHa2AvJjXUDqSjEgIpU-tb2YXAAt64wD4YqBo,11326
 mpyl/schema/mpyl_config.schema.yml,sha256=nn-NPQdOVYEbYq1tmVDKrDNWFt64dMRcDuGNHGxl9WQ,12912
 mpyl/schema/project.schema.yml,sha256=kLAh9BbwCyKzUIw-iDCl20kpVgJtvqLl0xioPuOuoJM,24550
 mpyl/schema/run_properties.schema.yml,sha256=hsBJcz9_n9PBAYbSSWsOvJdPIrhJv_B9JQdx0lVfUf4,3296
 mpyl/stages/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mpyl/stages/discovery.py,sha256=1sIZdna8_ItiZzeXkNrygXJt9IKL2ITOHTSzEQNA4X4,8913
+mpyl/stages/discovery.py,sha256=y_oFPz06oCkVyU9bpiR1TsCvFTcgdf89D_vB-HZB2h4,10713
 mpyl/steps/__init__.py,sha256=CwtgCMMbTJZjIiu4RVZonfEpqwMb2WqU4nHnqA-TCEM,6456
 mpyl/steps/collection.py,sha256=12848xJvrCuNBtf7U33EHw733BuTTZPAZzSOW0PSoX0,2686
-mpyl/steps/models.py,sha256=0YwWyAE77JyIshQgEApmvo-doTC5sN4zzwcURO_kMV4,8509
-mpyl/steps/run.py,sha256=yrpVEioTQ-3cjLcMv2wsuiuyPMd9bZAnJTl3M2SVc9A,4242
-mpyl/steps/run_properties.py,sha256=cESEhDl5iuISRBw0ig4ymJP_M8rihXdHcnL0FT_bAVM,3407
+mpyl/steps/models.py,sha256=oBjp7gti7k4AnuuLLqzI4TwCD4OVbyYmxnxfusxR7BE,8460
+mpyl/steps/run.py,sha256=3xn3rRczDh5l5P4YU9Bu9SO0pE1-jU1F1vE1rKTdfq4,4320
+mpyl/steps/run_properties.py,sha256=-2KDiMuVS8W81we3Yq6vC77s8wohh1bpnDS1c0OPB6Y,3376
 mpyl/steps/steps.py,sha256=-mvIAYw9DdpvXNXjhiM7LqJxAfOHtPQRQndxw8MqOeg,9692
 mpyl/steps/build/__init__.py,sha256=Q5BL1Bv5PrZkYBNbQvVNTL-n4Xq88qwtc3PtYunrc5c,80
-mpyl/steps/build/docker_build.py,sha256=SZ4hnoW8oiR8ZDb0gDZ0_awarHWMg-nkeNLfFH--sAE,5037
+mpyl/steps/build/docker_build.py,sha256=6HZnL9PtdXAFVfblwf9R9E-_GzaE2K4xWICPV3YOY0E,5034
 mpyl/steps/build/echo.py,sha256=T5uJ0L43bVNZenJtVr4j0HgIMDr10v5Oaypu9W1VHG8,1195
 mpyl/steps/build/post_docker_build.py,sha256=7qzghmLCf8OJ_BDOKRwVPOZbVcknWOrZ2p958uJjA94,2187
 mpyl/steps/build/sbt.py,sha256=riIyv5tY3hQdCXVbxsxzGoPMIG_0CsNY5EAsqOsyNvs,2714
 mpyl/steps/build/skip.py,sha256=71QJYYjJ5HL8Q2a9pB8ai9mTzTrL7yWQ_-DD2pLWRao,884
 mpyl/steps/deploy/__init__.py,sha256=PApoomqJGBtOt-08vVKjHVJTs2JHRWWF93Y2wFI0lN0,82
 mpyl/steps/deploy/dagster.py,sha256=wpb5FAait7ZXvjucf0ZlAnrELsQwmr5Y23SLwODQ1ZM,7596
 mpyl/steps/deploy/echo.py,sha256=Z6iL3icoxteiFWQkTppHfQAuP7B18lcu3ZJZqg6ssaM,1078
 mpyl/steps/deploy/ephemeral_docker_deploy.py,sha256=Wvz5C5CNaD0jdMTj8LZgZ325Ih0NeRl8_o8mc1Y8RQI,1533
 mpyl/steps/deploy/kubernetes.py,sha256=HzsLU7Ucowr2D_PIYFTPFADXTHDPdJF-g4N639h6mz4,3221
 mpyl/steps/deploy/kubernetes_job.py,sha256=r2pBuEMJ-WOcfHH3HZzQ5wG3tqwGSBnbB5ByapbwQvw,1115
 mpyl/steps/deploy/kubernetes_spark_job.py,sha256=_PJXQtnQ4TRgQj73vWEw6W6kIxD2DYCCo2Z0jjppfy4,1188
-mpyl/steps/deploy/k8s/__init__.py,sha256=Ydfw3zPNmVm9AmeF83ZT9yymyUZEkspAE_Y43j4kEXg,10995
+mpyl/steps/deploy/k8s/__init__.py,sha256=l5RxShdkdXs2nTTNK7GvWmciTyqwvuPhDV2-dERjLUY,11433
 mpyl/steps/deploy/k8s/chart.py,sha256=K0pPYS6NfNxLtDZMhNZk2Cdz3PeZCrm46VWjKthtx6k,28949
 mpyl/steps/deploy/k8s/deploy_config.py,sha256=haNB4oBieRLUVgFTCB-J1xcYJSaCX3EeqeqSCDvvSJ0,1276
 mpyl/steps/deploy/k8s/helm.py,sha256=VQ474ZRpwPvQS9XtILEWdoZdtHV_Q7GhCmNoSFL7lXQ,5080
 mpyl/steps/deploy/k8s/rancher.py,sha256=lJsPWM0l9EWH7YkH4QO6Hk38ZigQ42V7EHNmOvEDw5k,1594
 mpyl/steps/deploy/k8s/resources/__init__.py,sha256=Kn31han_zOgVMW9ElN47YEqi4RlZG63LJcklISxl4Ew,4868
 mpyl/steps/deploy/k8s/resources/dagster.py,sha256=NuN_EMduakIEIEv-c2i-cI0lfHXjlxDVCszIo3gQvNc,3368
 mpyl/steps/deploy/k8s/resources/prometheus.py,sha256=TKhgHbl8i8wbGgYWjZ5S6OnQ1l0P0oLN1EypJL5Sw00,2260
@@ -79,33 +80,33 @@
 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml,sha256=3Oc1awM23acMS36kqpbfqwx6D8Sft4FnL8abNLgcwBI,11703
 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml,sha256=6QCi1F9LJ3cgmwaPBV8dWFvbXb2B5huKvfp4Pa1hoBw,42950
 mpyl/steps/postdeploy/__init__.py,sha256=PDEwBgNjPl89w-5trIH25y0xY6wF3gG9Lw6HI_QA6MY,90
 mpyl/steps/postdeploy/cypress_test.py,sha256=VK8cPe8zFr386TuUeSixj_vBk-sZEr7PvIRoHRIJCgI,8518
 mpyl/steps/test/__init__.py,sha256=AhufNFmq3Rjn9ztt_qivyNdL6oHbSy5wbww-r9LOa5Q,78
 mpyl/steps/test/after_test.py,sha256=VCVWogXbuyaKOMu8jjOJWpZovBU7r4DgFSZQPY0xUIA,1574
 mpyl/steps/test/before_test.py,sha256=RgoNlwnzWM8O7cOPR6rE7_Z8E6M6cYmXFFuU9Au4wtI,4153
-mpyl/steps/test/dockertest.py,sha256=NunxxD87E5alfTZymG1V100WkDiTp87Bs0_ivd-QJjs,4606
+mpyl/steps/test/dockertest.py,sha256=aXITeWyZR14v4cGiCd-hE-5efyjnnXcfI7Rjn28rpCM,4652
 mpyl/steps/test/echo.py,sha256=0wfvRbmyFIHvrPjSzlVRGCzAvaTOFbFJzWqIQs3obLQ,1937
-mpyl/steps/test/sbt.py,sha256=nCsz94JGBwX9M74BzrpeDtW_yGd1_FCb9IEs-qf42Xo,4580
+mpyl/steps/test/sbt.py,sha256=Q-E_uC1R_lEmAF0VJqDKDDljVDh4kvrVtX1i6TUc4OY,4622
 mpyl/steps/test/skip.py,sha256=WNoF2MXBH8sBgc0gVo5Ityc753vIFtMjKpiPwLOIlOM,878
 mpyl/utilities/__init__.py,sha256=-FhhMEriPoXTlrxyF9D48XpgjRfRy_KeLGkGAUsqre8,346
 mpyl/utilities/cypress/__init__.py,sha256=VQZtP7hiFhRNr0jIAutomuL0yjdEY1mWQLqhzC1ZRVA,953
 mpyl/utilities/dagster/__init__.py,sha256=33zcIJaNyeXAy-o_eDcRjLOLsc8wKquxj4Ffppvgu_c,1068
 mpyl/utilities/docker/__init__.py,sha256=JIw48UE0yfCryvTEYWsbHC87Zl-JVPmztNdgKW1BkmE,13237
 mpyl/utilities/github/__init__.py,sha256=9BGCEw96HOHkQGWpZmBbmPrduCH2Zj0idNKLeZPQK2A,1938
 mpyl/utilities/helm/__init__.py,sha256=PrC06s5DEQ7USeMwxzJqzrNtzGaIroD79fqjMpuqa-c,1034
 mpyl/utilities/jenkins/__init__.py,sha256=8MCGdWLCX0oU2FhIfYHM2GIxPKX9lr6sUgdCpSbz_zE,1566
 mpyl/utilities/jenkins/runner.py,sha256=Vfc92TeYVtG_o5oOtTZSW1x91m1JEmkFC1SyvVyrpTs,7910
-mpyl/utilities/junit/__init__.py,sha256=DRZtooYs9Sat6R5rC1Mr8ZbkMzjnPIVVcFcCCTtZcnM,1488
+mpyl/utilities/junit/__init__.py,sha256=BYNX6l0NG_8RrRPUyKS6cqpEb2myXTzv2Z8nCej_CYg,1598
 mpyl/utilities/logging/__init__.py,sha256=CgcGcy44WdScwOo4ncONIUcm47EA1SUMZrXHe4qjepk,318
 mpyl/utilities/parallel/__init__.py,sha256=3pyODnVMj_ecFvzGgh6wmJn95XlxWi91pau3-6A_Hmo,1003
 mpyl/utilities/pyaml_env/__init__.py,sha256=NqinyF-ULX69X48pgLpcmm46JB0o2nPxERi5bruMs48,870
 mpyl/utilities/repo/__init__.py,sha256=__TP3vn7dAGLWVm-MfTaQKSdD8PxuIZKtQqxilTxmVw,13604
 mpyl/utilities/sbt/__init__.py,sha256=JJf1FU8JSyQhKaR78OEAup1VBXOLqNKf3tROtp54gAM,1589
 mpyl/utilities/subprocess/__init__.py,sha256=UeaVmVF1spnkLKnNWzF_9GMVM2WJ4WwOPeb2T6NdlAc,2573
 mpyl/utilities/yaml/__init__.py,sha256=gjNnyh_TwgOfGGIZa5hN5VzRibuzlo1L1dOHeCD1CW4,868
-mpyl-1.6.3.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-mpyl-1.6.3.dist-info/METADATA,sha256=W0JpAYrIo8ihsCqftQaXuKH-JaeRcI6Z-vY7h-mz5_Y,6195
-mpyl-1.6.3.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-mpyl-1.6.3.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
-mpyl-1.6.3.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
-mpyl-1.6.3.dist-info/RECORD,,
+mpyl-1.6.4.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+mpyl-1.6.4.dist-info/METADATA,sha256=N165AqR7QGGHINyKz-8brqsNs8rMXFpx95fLPFqyR64,6195
+mpyl-1.6.4.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+mpyl-1.6.4.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
+mpyl-1.6.4.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
+mpyl-1.6.4.dist-info/RECORD,,
```

